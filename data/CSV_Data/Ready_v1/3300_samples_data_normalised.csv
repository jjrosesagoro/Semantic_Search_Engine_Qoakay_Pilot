paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,fieldsOfStudy/1,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,fieldsOfStudy/3,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name
d9b03cd97db6255081d1e57983fa673d1f8f2d0e,https://www.semanticscholar.org/paper/d9b03cd97db6255081d1e57983fa673d1f8f2d0e,Exploiting Source-side Monolingual Data in Neural Machine Translation,"Neural Machine Translation (NMT) based on the encoder-decoder architecture has recently become a new paradigm. Researchers have proven that the target-side monolingual data can greatly enhance the decoder model of NMT. However, the source-side monolingual data is not fully explored although it should be useful to strengthen the encoder model of NMT, especially when the parallel corpus is far from sufficient. In this paper, we propose two approaches to make full use of the sourceside monolingual data in NMT. The first approach employs the self-learning algorithm to generate the synthetic large-scale parallel data for NMT training. The second approach applies the multi-task learning framework using two NMTs to predict the translation and the reordered source-side monolingual sentences simultaneously. The extensive experiments demonstrate that the proposed methods obtain significant improvements over the strong attention-based NMT.",2016,38,226,14,False,Computer Science,38358352,Jiajun Zhang,2423168.0,Chengqing Zong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d70b5dd40951dc97cb0296668c7affa482f3c970,https://www.semanticscholar.org/paper/d70b5dd40951dc97cb0296668c7affa482f3c970,Support vector learning for fuzzy rule-based classification systems,"To design a fuzzy rule-based classification system (fuzzy classifier) with good generalization ability in a high dimensional feature space has been an active research topic for a long time. As a powerful machine learning approach for pattern recognition problems, the support vector machine (SVM) is known to have good generalization ability. More importantly, an SVM can work very well on a high- (or even infinite) dimensional feature space. This paper investigates the connection between fuzzy classifiers and kernel machines, establishes a link between fuzzy rules and kernels, and proposes a learning algorithm for fuzzy classifiers. We first show that a fuzzy classifier implicitly defines a translation invariant kernel under the assumption that all membership functions associated with the same input variable are generated from location transformation of a reference function. Fuzzy inference on the IF-part of a fuzzy rule can be viewed as evaluating the kernel function. The kernel function is then proven to be a Mercer kernel if the reference functions meet a certain spectral requirement. The corresponding fuzzy classifier is named positive definite fuzzy classifier (PDFC). A PDFC can be built from the given training samples based on a support vector learning approach with the IF-part fuzzy rules given by the support vectors. Since the learning process minimizes an upper bound on the expected risk (expected prediction error) instead of the empirical risk (training error), the resulting PDFC usually has good generalization. Moreover, because of the sparsity properties of the SVMs, the number of fuzzy rules is irrelevant to the dimension of input space. In this sense, we avoid the ""curse of dimensionality."" Finally, PDFCs with different reference functions are constructed using the support vector learning approach. The performance of the PDFCs is illustrated by extensive experimental results. Comparisons with other methods are also provided.",2003,95,234,28,True,Computer Science,2116664201,Yixin Chen,48094094.0,James Ze Wang,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21ae9d6358ee090162b10d3a9da43e0d85ef4c7e,https://www.semanticscholar.org/paper/21ae9d6358ee090162b10d3a9da43e0d85ef4c7e,Design pattern mining enhanced by machine learning,"Design patterns present good solutions to frequently occurring problems in object-oriented software design. Thus their correct application in a system's design may significantly improve its internal quality attributes such as reusability and maintainability. In software maintenance the existence of up-to-date documentation is crucial, so the discovery of as yet unknown design pattern instances can help improve the documentation. Hence a reliable design pattern recognition system is very desirable. However, simpler methods (based on pattern matching) may give imprecise results due to the vague nature of the patterns' structural description. In previous work we presented a pattern matching-based system using the Columbus framework with which we were able to find pattern instances from the source code by considering the patterns' structural descriptions only, and therefore we could not identify false hits and distinguish similar design patterns such as state and strategy. In the present work we use machine learning to enhance pattern mining by filtering out as many false hits as possible. To do so we distinguish true and false pattern instances with the help of a learning database created by manually tagging a large C++ system.",2005,27,93,7,True,Computer Science,3172077,R. Ferenc,1752419.0,Árpád Beszédes,,3025233.0,Lajos Jeno Fülöp,46603077.0,Janos Lele,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46ff1e407be3f9f83cca960cbc075c664e4e7450,https://www.semanticscholar.org/paper/46ff1e407be3f9f83cca960cbc075c664e4e7450,AlphaD3M: Machine Learning Pipeline Synthesis,"We introduce AlphaD3M, an automatic machine learning (AutoML) system based on meta reinforcement learning using sequence models with self play. AlphaD3M is based on edit operations performed over machine learning pipeline primitives providing explainability. We compare AlphaD3M with state-of-the-art AutoML systems: Autosklearn, Autostacker, and TPOT, on OpenML datasets. AlphaD3M achieves competitive performance while being an order of magnitude faster, reducing computation time from hours to minutes, and is explainable by design.",2021,17,58,7,False,Computer Science,2861627,Iddo Drori,2756087.0,Yamuna Krishnamurthy,,3416217.0,Rémi Rampin,120081176.0,Raoni Lourenço,3471393.0,Jorge Piazentin Ono,1979489.0,Kyunghyun Cho,2109873665.0,Cláudio T. Silva,144162611.0,J. Freire,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d375f8b45d8e5e961875bf74a89f32394759b89,https://www.semanticscholar.org/paper/6d375f8b45d8e5e961875bf74a89f32394759b89,"Exploiting Semantic Role Labeling, WordNet and Wikipedia for Coreference Resolution","In this paper we present an extension of a machine learning based coreference resolution system which uses features induced from different semantic knowledge sources. These features represent knowledge mined from WordNet and Wikipedia, as well as information about semantic role labels. We show that semantic features indeed improve the performance on different referring expression types such as pronouns and common nouns.",2006,47,305,27,True,Computer Science,1801255,Simone Paolo Ponzetto,31380436.0,M. Strube,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
989f8a5d28b597b784391656fbd37af961b821dc,https://www.semanticscholar.org/paper/989f8a5d28b597b784391656fbd37af961b821dc,Unsupervised Supervised Learning I: Estimating Classification and Regression Errors without Labels,Estimating the error rates of classifiers or regression models is a fundamental task in machine learning which has thus far been studied exclusively using supervised learning techniques. We propose a novel unsupervised framework for estimating these error rates using only unlabeled data and mild assumptions. We prove consistency results for the framework and demonstrate its practical applicability on both synthetic and real world data.,2010,20,57,1,False,Computer Science,2046500,Pinar Donmez,1717932.0,G. Lebanon,,1682978.0,K. Balasubramanian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1554134e34366adcd69cd021a0b930a003ae789e,https://www.semanticscholar.org/paper/1554134e34366adcd69cd021a0b930a003ae789e,Squares: Supporting Interactive Performance Analysis for Multiclass Classifiers,"Performance analysis is critical in applied machine learning because it influences the models practitioners produce. Current performance analysis tools suffer from issues including obscuring important characteristics of model behavior and dissociating performance from data. In this work, we present Squares, a performance visualization for multiclass classification problems. Squares supports estimating common performance metrics while displaying instance-level distribution information necessary for helping practitioners prioritize efforts and access data. Our controlled study shows that practitioners can assess performance significantly faster and more accurately with Squares than a confusion matrix, a common performance analysis tool in machine learning.",2017,38,156,11,False,Computer Science,40633287,Donghao Ren,1719124.0,Saleema Amershi,Medicine,49132427.0,Bongshin Lee,38972741.0,Jina Suh,47271859.0,J. Williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a56cac78d3a9c56528ca2682cc9dad85de91476d,https://www.semanticscholar.org/paper/a56cac78d3a9c56528ca2682cc9dad85de91476d,Eye-tracking analysis of user behavior in WWW search,"We investigate how users interact with the results page of a WWW search engine using eye-tracking. The goal is to gain insight into how users browse the presented abstracts and how they select links for further exploration. Such understanding is valuable for improved interface design, as well as for more accurate interpretations of implicit feedback (e.g. clickthrough) for machine learning. The following presents initial results, focusing on the amount of time spent viewing the presented abstracts, the total number of abstract viewed, as well as measures of how thoroughly searchers evaluate their results set.",2004,6,745,35,True,Computer Science,2709281,Laura A. Granka,1680188.0,T. Joachims,,40413539.0,Geri Gay,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8ec9d501af6539bc3f1e5c0d434b64035077fa97,https://www.semanticscholar.org/paper/8ec9d501af6539bc3f1e5c0d434b64035077fa97,Learning to suggest: a machine learning framework for ranking query suggestions,"We consider the task of suggesting related queries to users after they issue their initial query to a web search engine. We propose a machine learning approach to learn the probability that a user may find a follow-up query both useful and relevant, given his initial query. Our approach is based on a machine learning model which enables us to generalize to queries that have never occurred in the logs as well. The model is trained on co-occurrences mined from the search logs, with novel utility and relevance models, and the machine learning step is done without any labeled data by human judges. The learning step allows us to generalize from the past observations and generate query suggestions that are beyond the past co-occurred queries. This brings significant gains in coverage while yielding modest gains in relevance. Both offline (based on human judges) and online (based on millions of user interactions) evaluations demonstrate that our approach significantly outperforms strong baselines.",2012,24,81,3,False,Computer Science,2066649585,Umut Ozertem,1730609.0,O. Chapelle,,2046500.0,Pinar Donmez,1701473.0,Emre Velipasaoglu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ee0614b44b2e914b3100cfa917e4255c95206fd4,https://www.semanticscholar.org/paper/ee0614b44b2e914b3100cfa917e4255c95206fd4,The black box inside the glass box: presenting computing concepts to novices,"Simplicity and visibility are two important characteristics of programming languages for novices. Novices start programming with very little idea of the properties of the notional machine implied by the language they are learning. To help them learn these properties, the notional machine should be simple. That is, it should consist of a small number of parts that interact in ways that can be easily understood, possibly by analogy to other mechanisms with which the novice is more familiar. A notional machine is the idealized model of the computer implied by the constructs of the programming language. Visibility is concerned with methods for viewing selected parts and processes of this notional machine in action. We introduce the term “commentary” which is the system's dynamic characterization of the notional machine, expressed in either text or pictures on the user's terminal. We examine the simplicity and visibility of three systems, each designed to provide programming experience to different populations of novices.",1999,20,243,8,False,Computer Science,1738475,John Benedict du Boulay,30657954.0,T. O'Shea,,144771979.0,John Monk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3621fff4a1c791901ea4a1359c10575193ec712d,https://www.semanticscholar.org/paper/3621fff4a1c791901ea4a1359c10575193ec712d,Out-of-Distribution Generalization via Risk Extrapolation (REx),"Generalizing outside of the training distribution is an open challenge for current machine learning systems. A weak form of out-of-distribution (OoD) generalization is the ability to successfully interpolate between multiple observed distributions. One way to achieve this is through robust optimization, which seeks to minimize the worst-case risk over convex combinations of the training distributions. However, a much stronger form of OoD generalization is the ability of models to extrapolate beyond the distributions observed during training. In pursuit of strong OoD generalization, we introduce the principle of Risk Extrapolation (REx). REx can be viewed as encouraging robustness over affine combinations of training risks, by encouraging strict equality between training risks. We show conceptually how this principle enables extrapolation, and demonstrate the effectiveness and scalability of instantiations of REx on various OoD generalization tasks. Our code can be found at this https URL.",2020,42,310,64,False,Computer Science,145055042,David Krueger,24130593.0,Ethan Caballero,Mathematics,51919565.0,J. Jacobsen,2111672235.0,Amy Zhang,1737610.0,Jonathan Binas,10712297.0,Rémi Le Priol,1760871.0,Aaron C. Courville,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d,https://www.semanticscholar.org/paper/c2ecc66c0e5f976b0e0d95c64ed2d1e283a2625d,Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus,"This paper presents the first empirical results to our knowledge on learning synchronous grammars that generate logical forms. Using statistical machine translation techniques, a semantic parser based on a synchronous context-free grammar augmented with �operators is learned given a set of training sentences and their correct logical forms. The resulting parser is shown to be the bestperforming system so far in a database query domain.",2007,19,363,27,False,Computer Science,8075439,Y. W. Wong,1797655.0,R. Mooney,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
42936c2f2f5c8f4152494b94609fb33ec6264b8b,https://www.semanticscholar.org/paper/42936c2f2f5c8f4152494b94609fb33ec6264b8b,Apolo: making sense of large network data by combining rich user interaction and machine learning,"Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.",2011,82,189,5,False,Computer Science,1793506,Duen Horng Chau,145234497.0,A. Kittur,,2110688724.0,Jason I. Hong,1702392.0,C. Faloutsos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64b20f863dc1baf587fb7b5b2c057cbd463112cf,https://www.semanticscholar.org/paper/64b20f863dc1baf587fb7b5b2c057cbd463112cf,Deep machine learning provides state-of-the-art performance in image-based plant phenotyping,"Deep learning is an emerging field that promises unparalleled results on many data analysis problems. We show the success offered by such techniques when applied to the challenging problem of image-based plant phenotyping, and demonstrate state-of-the-art results for root and shoot feature identification and localisation. We predict a paradigm shift in image-based phenotyping thanks to deep learning approaches.",2016,35,241,4,True,Biology,2003379,Michael P. Pound,9821924.0,J. Atkinson,Computer Science,49987662.0,Alexandra J. Townsend,145730982.0,Michael H. Wilson,48442055.0,M. Griffiths,34596685.0,Aaron S. Jackson,145245424.0,Adrian Bulat,2610880.0,Georgios Tzimiropoulos,Medicine,3174172.0,D. Wells,2497679.0,E. Murchie,1762670.0,T. Pridmore,2891011.0,A. French,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
921196c32213a229245a9705ee4768bc941e7a26,https://www.semanticscholar.org/paper/921196c32213a229245a9705ee4768bc941e7a26,An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling,"For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at this http URL .",2018,83,2207,428,False,Computer Science,35836381,Shaojie Bai,145116464.0,J. Z. Kolter,Mathematics,145231047.0,V. Koltun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6500e3512c8c266561d016902a3904f66d453624,https://www.semanticscholar.org/paper/6500e3512c8c266561d016902a3904f66d453624,Comparing Machine Learning Classifiers for Object-Based Land Cover Classification Using Very High Resolution Imagery,"This study evaluates and compares the performance of four machine learning classifiers—support vector machine (SVM), normal Bayes (NB), classification and regression tree (CART) and K nearest neighbor (KNN)—to classify very high resolution images, using an object-based classification procedure. In particular, we investigated how tuning parameters affect the classification accuracy with different training sample sizes. We found that: (1) SVM and NB were superior to CART and KNN, and both could achieve high classification accuracy (>90%); (2) the setting of tuning parameters greatly affected classification accuracy, particularly for the most commonly-used SVM classifier; the optimal values of tuning parameters might vary slightly with the size of training samples; (3) the size of training sample also greatly affected the classification accuracy, when the size of training sample was less than 125. Increasing the size of training samples generally led to the increase of classification accuracies for all four classifiers. In addition, NB and KNN were more sensitive to the sample sizes. This research provides insights into the selection of classifiers and the size of training samples. It also highlights the importance of the appropriate setting of tuning parameters for different machine learning classifiers and provides useful information for optimizing these parameters.",2014,41,241,14,True,Computer Science,4097747,Yuguo Qian,12997991.0,Weiqi Zhou,,4816235.0,Jingli Yan,144989696.0,Weifeng Li,1800746.0,Lijian Han,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
103fdd86f596e419564309e8ff9d578fd0ccf571,https://www.semanticscholar.org/paper/103fdd86f596e419564309e8ff9d578fd0ccf571,Soft optoelectronic sensory foams with proprioception,"An internally illuminated elastomeric foam detects deformations through machine learning techniques. In a step toward soft robot proprioception, and therefore better control, this paper presents an internally illuminated elastomer foam that has been trained to detect its own deformation through machine learning techniques. Optical fibers transmitted light into the foam and simultaneously received diffuse waves from internal reflection. The diffuse reflected light was interpreted by machine learning techniques to predict whether the foam was twisted clockwise, twisted counterclockwise, bent up, or bent down. Machine learning techniques were also used to predict the magnitude of the deformation type. On new data points, the model predicted the type of deformation with 100% accuracy and the magnitude of the deformation with a mean absolute error of 0.06°. This capability may impart soft robots with more complete proprioception, enabling them to be reliably controlled and responsive to external stimuli.",2018,53,88,1,False,Computer Science,9664055,I. M. Van Meerbeek,150947097.0,C. M. De Sa,Medicine,1781229.0,R. Shepherd,,,,,,,,,,,Materials Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62afcc86692049a5e86b2b51450080e4aa9f6f9a,https://www.semanticscholar.org/paper/62afcc86692049a5e86b2b51450080e4aa9f6f9a,Machine learning resistant strong PUF: Possible or a pipe dream?,"Physically unclonable functions (PUFs) are emerging as hardware primitives for key-generation and light-weight authentication. Strong PUFs represent a variant of PUFs which respond to a user challenge with a response determined by its unique manufacturing process variations. Unfortunately many of the Strong PUFs have been shown to be vulnerable to model building attacks when an attacker has access to challenge and response pairs. In mounting a model building attack, typically machine learning is used to build a software model to forge the PUF. Researchers have long been interested in designing Strong PUFs that are resistant to model building attacks. However, with innovations in application of machine learning, nearly all Strong PUFs presented in the literature have been broken. In this paper, first we present results from a set of experiments designed to show that if certain randomness properties can be met, cascaded structure based Strong PUFs can indeed be made machine learning (ML) attack resistant against known ML attacks. Next we conduct machine learning experiments on an abstract PUF model using Support Vector Machines, Logistic Regression, Bagging, Boosting and Evolutionary techniques to establish criteria for machine learning resistant Strong PUF design. This paper does not suggest how to harvest the process variation, which remains within the purview of a circuit designer; rather it suggests what properties of the building blocks to aim for towards building a machine learning resistant Strong PUF - thus paving the path for a systematic design approach.",2016,21,62,5,False,Engineering,1959971,Arunkumar Vijayakumar,1932795.0,Vinay C. Patil,Computer Science,2070551597.0,Charles B. Prado,144454113.0,S. Kundu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c0944b6759e2e1a4026ef43936ee00c0ddb3d79a,https://www.semanticscholar.org/paper/c0944b6759e2e1a4026ef43936ee00c0ddb3d79a,A framework for merging and ranking of answers in DeepQA,"The final stage in the IBM DeepQA pipeline involves ranking all candidate answers according to their evidence scores and judging the likelihood that each candidate answer is correct. In DeepQA, this is done using a machine learning framework that is phase-based, providing capabilities for manipulating the data and applying machine learning in successive applications. We show how this design can be used to implement solutions to particular challenges that arise in applying machine learning for evidence-based hypothesis evaluation. Our approach facilitates an agile development environment for DeepQA; evidence scoring strategies can be easily introduced, revised, and reconfigured without the need for error-prone manual effort to determine how to combine the various evidence scores. We describe the framework, explain the challenges, and evaluate the gain over a baseline machine learning approach.",2012,43,89,11,False,Computer Science,2771137,David Gondek,144071952.0,Adam Lally,,1973186.0,Aditya Kalyanpur,145412011.0,J. William Murdock,2366890.0,P. Duboué,47059333.0,Lei Zhang,144455843.0,Yue Pan,1838785.0,Zhaoming Qiu,,143778120.0,Chris Welty,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b3f2a11d45757e675be123d55ec0eb192bcca990,https://www.semanticscholar.org/paper/b3f2a11d45757e675be123d55ec0eb192bcca990,Chiron: Privacy-preserving Machine Learning as a Service,"Major cloud operators offer machine learning (ML) as a service, enabling customers who have the data but not ML expertise or infrastructure to train predictive models on this data. Existing ML-as-a-service platforms require users to reveal all training data to the service operator. We design, implement, and evaluate Chiron, a system for privacy-preserving machine learning as a service. First, Chiron conceals the training data from the service operator. Second, in keeping with how many existing ML-as-a-service platforms work, Chiron reveals neither the training algorithm nor the model structure to the user, providing only black-box access to the trained model. Chiron is implemented using SGX enclaves, but SGX alone does not achieve the dual goals of data privacy and model confidentiality. Chiron runs the standard ML training toolchain (including the popular Theano framework and C compiler) in an enclave, but the untrusted model-creation code from the service operator is further confined in a Ryoan sandbox to prevent it from leaking the training data outside the enclave. To support distributed training, Chiron executes multiple concurrent enclaves that exchange model parameters via a parameter server. We evaluate Chiron on popular deep learning models, focusing on benchmark image classification tasks such as CIFAR and ImageNet, and show that its training performance and accuracy of the resulting models are practical for common uses of ML-as-a-service.",2018,54,145,14,False,Computer Science,48062937,T. Hunt,3469125.0,Congzheng Song,,2520493.0,R. Shokri,1723945.0,Vitaly Shmatikov,1683338.0,E. Witchel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c45742e95cf8e09ed3283f01079c122cd96e5967,https://www.semanticscholar.org/paper/c45742e95cf8e09ed3283f01079c122cd96e5967,Cue Phrase Classification Using Machine Learning,"Cue phrases may be used in a discourse sense to explicitly signal discourse structure, but also in a sentential sense to convey semantic rather than structural information. Correctly classifying cue phrases as discourse or sentential is critical in natural language processing systems that exploit discourse structure, e.g., for performing tasks such as anaphora resolution and plan recognition. This paper explores the use of machine learning for classifying cue phrases as discourse or sentential. Two machine learning programs (cgrendel and C4.5) are used to induce classification models from sets of pre-classified cue phrases and their features in text and speech. Machine learning is shown to be an effective technique for not only automating the generation of classification models, but also for improving upon previous results. When compared to manually derived classification models already in the literature, the learned models often perform with higher accuracy and contain new linguistic insights into the data. In addition, the ability to automatically construct classification models makes it easier to comparatively analyze the utility of alternative feature representations of the data. Finally, the ease of retraining makes the learning approach more scalable and flexible than manual methods.",1996,41,83,10,True,Computer Science,1737616,D. Litman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7a8900156b939d4377ff2e42af13618fed8ed443,https://www.semanticscholar.org/paper/7a8900156b939d4377ff2e42af13618fed8ed443,SUPERVISED MACHINE LEARNING APPROACHES: A SURVEY,"One of the core objectives of machine learning is to instruct computers to use data or past experience to solve a given problem. A good number of successful applications of machine learning exist already, including classifier to be trained on email messages to learn in order to distinguish between spam and non-spam messages, systems that analyze past sales data to predict customer buying behavior, fraud detection etc. Machine learning can be applied as association analysis through Supervised learning, Unsupervised learning and Reinforcement Learning but in this study we will focus on strength and weakness of supervised learning classification algorithms. The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. We are optimistic that this study will help new researchers to guiding new research areas and to compare the effectiveness and impuissance of supervised learning algorithms.",2015,36,64,4,False,Computer Science,2053894016,Iqbal Muhammad,2142946173.0,Zhu Yan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4ad915a10be9d443206e8ae707d64638be604f8a,https://www.semanticscholar.org/paper/4ad915a10be9d443206e8ae707d64638be604f8a,Convex Formulation for Learning from Positive and Unlabeled Data,"We discuss binary classification from only positive and unlabeled data (PU classification), which is conceivable in various real-world machine learning problems. Since unlabeled data consists of both positive and negative data, simply separating positive and unlabeled data yields a biased solution. Recently, it was shown that the bias can be canceled by using a particular non-convex loss such as the ramp loss. However, classifier training with a non-convex loss is not straightforward in practice. In this paper, we discuss a convex formulation for PU classification that can still cancel the bias. The key idea is to use different loss functions for positive and unlabeled samples. However, in this setup, the hinge loss is not permissible. As an alternative, we propose the double hinge loss. Theoretically, we prove that the estimators converge to the optimal solutions at the optimal parametric rate. Experimentally, we demonstrate that PU classification with the double hinge loss performs as accurate as the non-convex method, with a much lower computational cost.",2015,27,224,39,False,Mathematics,3277454,M. Plessis,47537639.0,Gang Niu,Computer Science,67154907.0,Masashi Sugiyama,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44254390973b3d3e6a98f53f1da961addb4d352b,https://www.semanticscholar.org/paper/44254390973b3d3e6a98f53f1da961addb4d352b,Learning Translation Templates From Bilingual Text,"This paper proposes a two-phase example-based machine translation methodology which develops translation templates from examples and then translates using template matching. This method improves translation quality and facilitates customization of machine translation systems. This paper focuses on the automatic learning of translation templates. A translation template is a bilingual pair of sentences in which corresponding units (words and pharases) are coupled and replaced with variables. Correspondence between units is determined by suing a bilingual dictionary and by analyzing the syntactic structure of the sentences. Syntactic ambiguity and ambiguity in correspondence between units are simultaneously resolved. All of the translation templates generated from a bilingual corpus are grouped by their source language part, and then further refined to resolved conflicts among templates whose source language parts are the same but whose target language parts are different. By using the proposed method, not only transfer rules but also knowledge for lexical selection is effectively extracted from a bilingual corpus.",1992,8,198,20,True,Computer Science,153574717,H. Kaji,2923399.0,Yuuko Kida,,2054477577.0,Yasutsugu Morimoto,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2b65b99e772727dadc1b5e50a9d83367a892ec28,https://www.semanticscholar.org/paper/2b65b99e772727dadc1b5e50a9d83367a892ec28,Learning One More Thing,"Most research on machine learning has focused on scenarios in which a learner faces a single, isolated learning task. The lifelong learning framework assumes instead that the learner encounters a multitude of related learning tasks over its lifetime, providing the opportunity for the transfer of knowledge. This paper studies lifelong learning in the context of binary classification. It presents the invariance approach, in which knowledge is transferred via a learned model of the invariances of the domain. Results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias subsequent learning.",1994,47,158,3,False,Computer Science,144867807,S. Thrun,40975594.0,Tom Michael Mitchell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56fd28e8db60a696adc5b0f7acb9ef41d9ce1ec4,https://www.semanticscholar.org/paper/56fd28e8db60a696adc5b0f7acb9ef41d9ce1ec4,A survey of kernels for structured data,"Kernel methods in general and support vector machines in particular have been successful in various learning tasks on data represented in a single table. Much 'real-world' data, however, is structured - it has no natural representation in a single table. Usually, to apply kernel methods to 'real-world' data, extensive pre-processing is performed to embed the data into areal vector space and thus in a single table. This survey describes several approaches of defining positive definite kernels on structured instances directly.",2003,49,493,24,False,Computer Science,1693945,Thomas Gärtner,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41653772fd26829aae3e3106a573322b47129b8f,https://www.semanticscholar.org/paper/41653772fd26829aae3e3106a573322b47129b8f,Extreme learning machine: A review,"Feedforward neural networks (FFNN) have been utilised for various research in machine learning and they have gained a significantly wide acceptance. However, it was recently noted that the feedforward neural network has been functioning slower than needed. As a result, it has created critical bottlenecks among its applications. Extreme Learning Machines (ELM) were suggested as alternative learning algorithms instead of FFNN. The former is characterised by single-hidden layer feedforward neural networks (SLFN). It selects hidden nodes randomly and analytically determines their output weight. This review aims to, first, present a short mathematical explanation to explain the basic ELM. Second, because of its notable simplicity, efficiency, and remarkable generalisation performance, ELM has had wide uses in various domains, such as computer vision, biomedical engineering, control and robotics, system identification, etc. Thus, in this review, we will aim to present a complete view of these ELM advances for different applications. Finally, ELM’s strengths and weakness will be presented, along with its future perspectives.",2017,132,68,5,False,Computer Science,13696977,Musatafa Abbas Abbood Albadr,9211469.0,S. Tiun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b31fba37f63b88218b49082bdbe3abf9a139e9d1,https://www.semanticscholar.org/paper/b31fba37f63b88218b49082bdbe3abf9a139e9d1,Social Development,"M ost robots are designed to operate in environments that are either highly constrained (as is the case in an assembly line) or extremely hazardous (such as the surface of Mars). Machine learning has been an effective tool in both of these environments by augmenting the flexibility and reliability of robotic systems, but this is often a very difficult problem because the complexity of learning in the real world introduces very high dimensional state spaces and applies severe penalties for mistakes. Human children are raised in environments that are just as complex (or even more so) than those typically studied in robot learning scenarios. However, the presence of parents and other caregivers radically changes the type of learning that is possible. Consciously and unconsciously, adults tailor their actions and the environment to the child. They draw attention to important aspects of a task, help in identifying the cause of errors, and generally tailor the task to the child’s capabilities. Our research group builds robots that learn in the same type of supportive environment that human children have and develop skills incrementally through their interactions. Our robots interact socially with human adults using the same natural conventions that a human child would use. Our work sits at the intersection of the fields of social robotics [1], [2] and autonomous mental development [3]. Together, these two fields offer the vision of a machine that can learn incrementally, directly from humans, in the same ways that humans learn from each other. In this article, we will introduce some of the challenges, goals, and applications of this research.",2008,36,470,47,False,,1792053,B. Scassellati,1802703.0,C. Crick,,2305335.0,K. Gold,1748636.0,Elizabeth S. Kim,1693018.0,F. Shic,1962067.0,Ganghua Sun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
71ff533c8b5001082a3aaade3097eb229864e69e,https://www.semanticscholar.org/paper/71ff533c8b5001082a3aaade3097eb229864e69e,Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values,"Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers. NOTE: This work is now subsumed by our recent manuscript, Sanity Checks for Saliency Maps (to appear NIPS 2018), where we expand on findings and address concerns raised in Sundararajan et. al. (2018).",2018,28,89,4,False,Computer Science,145949622,Julius Adebayo,2058362.0,J. Gilmer,Mathematics,153440022.0,Ian J. Goodfellow,3351164.0,Been Kim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23234a0f211a44d9706b2570d474427b8f899ec1,https://www.semanticscholar.org/paper/23234a0f211a44d9706b2570d474427b8f899ec1,A SNoW-Based Face Detector,"A novel learning approach for human face detection using a network of linear units is presented. The SNoW learning architecture is a sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning in the presence of a very large number of features. A wide range of face images in different poses, with different expressions and under different lighting conditions are used as a training set to capture the variations of human faces. Experimental results on commonly used benchmark data sets of a wide range of face images show that the SNoW-based approach outperforms methods that use neural networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based method are significantly more efficient than with other methods.",1999,33,359,25,False,Computer Science,1715634,Ming-Hsuan Yang,144590225.0,D. Roth,,145237406.0,N. Ahuja,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77a75206bb566fc2ab0f12729e459cb65784745a,https://www.semanticscholar.org/paper/77a75206bb566fc2ab0f12729e459cb65784745a,Machine Learning in Ultrasound Computer-Aided Diagnostic Systems: A Survey,"The ultrasound imaging is one of the most common schemes to detect diseases in the clinical practice. There are many advantages of ultrasound imaging such as safety, convenience, and low cost. However, reading ultrasound imaging is not easy. To support the diagnosis of clinicians and reduce the load of doctors, many ultrasound computer-aided diagnosis (CAD) systems are proposed. In recent years, the success of deep learning in the image classification and segmentation led to more and more scholars realizing the potential of performance improvement brought by utilizing the deep learning in the ultrasound CAD system. This paper summarized the research which focuses on the ultrasound CAD system utilizing machine learning technology in recent years. This study divided the ultrasound CAD system into two categories. One is the traditional ultrasound CAD system which employed the manmade feature and the other is the deep learning ultrasound CAD system. The major feature and the classifier employed by the traditional ultrasound CAD system are introduced. As for the deep learning ultrasound CAD, newest applications are summarized. This paper will be useful for researchers who focus on the ultrasound CAD system.",2018,73,117,2,True,Computer Science,145298369,Qinghua Huang,2153305015.0,Fan Zhang,Medicine,67180560.0,Xuelong Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
781f4b1732cffc30f315eff94d53965a8fd9324f,https://www.semanticscholar.org/paper/781f4b1732cffc30f315eff94d53965a8fd9324f,Recent Advances in Deep Learning: An Overview,"Deep Learning is one of the newest trends in Machine Learning and Artificial Intelligence research. It is also one of the most popular scientific research trends now-a-days. Deep learning methods have brought revolutionary advances in computer vision and machine learning. Every now and then, new and new deep learning techniques are being born, outperforming state-of-the-art machine learning and even existing deep learning techniques. In recent years, the world has seen many major breakthroughs in this field. Since deep learning is evolving at a huge speed, its kind of hard to keep track of the regular advances especially for new researchers. In this paper, we are going to briefly discuss about recent advances in Deep Learning for past few years.",2018,167,80,3,False,Computer Science,41021656,Matiur Rahman Minar,35288935.0,Jibon Naher,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9f36c22892afa9af64d8a5eed13d2d12bfefc64a,https://www.semanticscholar.org/paper/9f36c22892afa9af64d8a5eed13d2d12bfefc64a,Machine and deep learning methods for radiomics.,"Radiomics is an emerging area in quantitative image analysis that aims to relate large-scale extracted imaging information to clinical and biological endpoints. The development of quantitative imaging methods along with machine learning has enabled the opportunity to move data science research towards translation for more personalized cancer treatments. Accumulating evidence has indeed demonstrated that noninvasive advanced imaging analytics, that is, radiomics, can reveal key components of tumor phenotype for multiple three-dimensional lesions at multiple time points over and beyond the course of treatment. These developments in the use of CT, PET, US, and MR imaging could augment patient stratification and prognostication buttressing emerging targeted therapeutic approaches. In recent years, deep learning architectures have demonstrated their tremendous potential for image segmentation, reconstruction, recognition, and classification. Many powerful open-source and commercial platforms are currently available to embark in new research areas of radiomics. Quantitative imaging research, however, is complex and key statistical principles should be followed to realize its full potential. The field of radiomics, in particular, requires a renewed focus on optimal study design/reporting practices and standardization of image acquisition, feature calculation, and rigorous statistical analysis for the field to move forward. In this article, the role of machine and deep learning as a major computational vehicle for advanced model building of radiomics-based signatures or classifiers, and diverse clinical applications, working principles, research opportunities, and available computational platforms for radiomics will be reviewed with examples drawn primarily from oncology. We also address issues related to common applications in medical physics, such as standardization, feature extraction, model building, and validation.",2020,144,101,5,True,Computer Science,6931354,M. Avanzo,30434668.0,Lise Wei,Medicine,2214956.0,J. Stancanello,5425836.0,M. Vallières,1849484.0,A. Rao,10291282.0,O. Morin,12830231.0,S. Mattonen,65739579.0,I. El Naqa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3d25eb8241345f86101fda145d95d89c27844fd1,https://www.semanticscholar.org/paper/3d25eb8241345f86101fda145d95d89c27844fd1,Distributed Submodular Maximization: Identifying Representative Elements in Massive Data,"Many large-scale machine learning problems (such as clustering, non-parametric learning, kernel machines, etc.) require selecting, out of a massive data set, a manageable yet representative subset. Such problems can often be reduced to maximizing a submodular set function subject to cardinality constraints. Classical approaches require centralized access to the full data set; but for truly large-scale problems, rendering the data centrally is often impractical. In this paper, we consider the problem of submodular function maximization in a distributed fashion. We develop a simple, two-stage protocol GREEDI, that is easily implemented using MapReduce style computations. We theoretically analyze our approach, and show, that under certain natural conditions, performance close to the (impractical) centralized approach can be achieved. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, including sparse Gaussian process inference and exemplar-based clustering, on tens of millions of data points using Hadoop.",2013,35,248,29,False,Computer Science,2389094,Baharan Mirzasoleiman,1697131.0,Amin Karbasi,Mathematics,2810893.0,R. Sarkar,145343838.0,Andreas Krause,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1dda1a4414675729f46594a5e609938ef3a48382,https://www.semanticscholar.org/paper/1dda1a4414675729f46594a5e609938ef3a48382,Bayesian Nonparametric Matrix Factorization for Recorded Music,"Recent research in machine learning has focused on breaking audio spectrograms into separate sources of sound using latent variable decompositions. These methods require that the number of sources be specified in advance, which is not always possible. To address this problem, we develop Gamma Process Nonnegative Matrix Factorization (GaP-NMF), a Bayesian nonparametric approach to decomposing spectrograms. The assumptions behind GaP-NMF are based on research in signal processing regarding the expected distributions of spectrogram data, and GaP-NMF automatically discovers the number of latent sources. We derive a mean-field variational inference algorithm and evaluate GaP-NMF on both synthetic data and recorded music.",2010,18,162,21,False,Mathematics,28552618,M. Hoffman,1796335.0,D. Blei,Computer Science,1716507.0,P. Cook,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
afccf0ab762c2aee7d13f3733d1a4f593583d41a,https://www.semanticscholar.org/paper/afccf0ab762c2aee7d13f3733d1a4f593583d41a,Representation of compounds for machine-learning prediction of physical properties,"The representations of a compound, called ``descriptors'' or ``features'', play an essential role in constructing a machine-learning model of its physical properties. In this study, we adopt a procedure for generating a set of descriptors from simple elemental and structural representations. First, it is applied to a large data set composed of the cohesive energy for about 18 000 compounds computed by density functional theory calculation. As a result, we obtain a kernel ridge prediction model with a prediction error of 0.041 eV/atom, which is close to the ``chemical accuracy'' of 1 kcal/mol (0.043 eV/atom). A prediction model with an error of 0.071 eV/atom of the cohesive energy is obtained for the normalized prototype structures, which can be used for the practical purpose of searching for as-yet-unknown structures. The procedure is also applied to two smaller data sets, i.e., a data set of the lattice thermal conductivity for 110 compounds computed by density functional theory calculation and a data set of the experimental melting temperature for 248 compounds. We examine the effect of the descriptor sets on the efficiency of Bayesian optimization in addition to the accuracy of the kernel ridge regression models. They exhibit good predictive performances.",2016,103,159,0,True,Mathematics,1947843,Atsuto Seko,48865897.0,H. Hayashi,Physics,47583203.0,K. Nakayama,2070122276.0,Akira Takahashi,46487378.0,I. Tanaka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1063ee8ef1ce585b51518a1a4d5b0e072477198b,https://www.semanticscholar.org/paper/1063ee8ef1ce585b51518a1a4d5b0e072477198b,Stock market prediction using machine learning techniques,"The main objective of this research is to predict the market performance of Karachi Stock Exchange (KSE) on day closing using different machine learning techniques. The prediction model uses different attributes as an input and predicts market as Positive & Negative. The attributes used in the model includes Oil rates, Gold & Silver rates, Interest rate, Foreign Exchange (FEX) rate, NEWS and social media feed. The old statistical techniques including Simple Moving Average (SMA) and Autoregressive Integrated Moving Average (ARIMA) are also used as input. The machine learning techniques including Single Layer Perceptron (SLP), Multi-Layer Perceptron (MLP), Radial Basis Function (RBF) and Support Vector Machine (SVM) are compared. All these attributes are studied separately also. The algorithm MLP performed best as compared to other techniques. The oil rate attribute was found to be most relevant to market performance. The results suggest that performance of KSE-100 index can be predicted with machine learning techniques.",2016,14,75,3,False,Computer Science,47886742,Mehak Usmani,145229362.0,S. H. Adil,,2095737.0,K. Raza,1955345.0,S. Ali,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7e02c5b0e83cd6bba4c94c458bdb7079e97c36cd,https://www.semanticscholar.org/paper/7e02c5b0e83cd6bba4c94c458bdb7079e97c36cd,"Entity Resolution: Theory, Practice & Open Challenges","This tutorial brings together perspectives on ER from a variety of fields, including databases, machine learning, natural language processing and information retrieval, to provide, in one setting, a survey of a large body of work. We discuss both the practical aspects and theoretical underpinnings of ER. We describe existing solutions, current challenges, and open research problems.",2012,32,293,10,False,Computer Science,1746034,L. Getoor,2357165.0,Ashwin Machanavajjhala,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b79870d22d85dde31c72df6ae147f64d462d177b,https://www.semanticscholar.org/paper/b79870d22d85dde31c72df6ae147f64d462d177b,Machine learning in GI endoscopy: practical guidance in how to interpret a novel field,"There has been a vast increase in GI literature focused on the use of machine learning in endoscopy. The relative novelty of this field poses a challenge for reviewers and readers of GI journals. To appreciate scientific quality and novelty of machine learning studies, understanding of the technical basis and commonly used techniques is required. Clinicians often lack this technical background, while machine learning experts may be unfamiliar with clinical relevance and implications for daily practice. Therefore, there is an increasing need for a multidisciplinary, international evaluation on how to perform high-quality machine learning research in endoscopy. This review aims to provide guidance for readers and reviewers of peer-reviewed GI journals to allow critical appraisal of the most relevant quality requirements of machine learning studies. The paper provides an overview of common trends and their potential pitfalls and proposes comprehensive quality requirements in six overarching themes: terminology, data, algorithm description, experimental setup, interpretation of results and machine learning in clinical practice.",2020,41,53,0,True,Computer Science,15065097,F. van der Sommen,1423745025.0,Jeroen de Groof,Medicine,120631502.0,Maarten P. Struyvenberg,118341291.0,J. van der Putten,1482569768.0,T. Boers,1430744224.0,K. Fockens,2151647.0,E. Schoon,3553816.0,W. Curvers,,122835730.0,P. D. De with,2558826.0,Y. Mori,2167748.0,M. Byrne,1398465128.0,J. Bergman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b661520bf0061b7d96ccf12016e351dd3a6ee780,https://www.semanticscholar.org/paper/b661520bf0061b7d96ccf12016e351dd3a6ee780,What is the Effect of Importance Weighting in Deep Learning?,"Importance-weighted risk minimization is a key ingredient in many machine learning algorithms for causal inference, domain adaptation, class imbalance, and off-policy reinforcement learning. While the effect of importance weighting is well-characterized for low-capacity misspecified models, little is known about how it impacts over-parameterized, deep neural networks. This work is inspired by recent theoretical results showing that on (linearly) separable data, deep linear networks optimized by SGD learn weight-agnostic solutions, prompting us to ask, for realistic deep networks, for which many practical datasets are separable, what is the effect of importance weighting? We present the surprising finding that while importance weighting impacts models early in training, its effect diminishes over successive epochs. Moreover, while L2 regularization and batch normalization (but not dropout), restore some of the impact of importance weighting, they express the effect via (seemingly) the wrong abstraction: why should practitioners tweak the L2 regularization, and by how much, to produce the correct weighting effect? Our experiments confirm these findings across a range of architectures and datasets.",2018,36,210,7,False,Computer Science,40205705,Jonathon Byrd,32219137.0,Zachary Chase Lipton,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
de4d56f96acf57459f3efc60504d0865bb5bec79,https://www.semanticscholar.org/paper/de4d56f96acf57459f3efc60504d0865bb5bec79,Anomaly detection in IP networks,"Network anomaly detection is a vibrant research area. Researchers have approached this problem using various techniques such as artificial intelligence, machine learning, and state machine modeling. In this paper, we first review these anomaly detection methods and then describe in detail a statistical signal processing technique based on abrupt change detection. We show that this signal processing technique is effective at detecting several network anomalies. Case studies from real network data that demonstrate the power of the signal processing approach to network anomaly detection are presented. The application of signal processing techniques to this area is still in its infancy, and we believe that it has great potential to enhance the field, and thereby improve the reliability of IP networks.",2003,49,552,37,False,Computer Science,144349981,M. Thottan,1708645.0,C. Ji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cbe11eda02c4150b0d2a30e4d0755de2324ccdf4,https://www.semanticscholar.org/paper/cbe11eda02c4150b0d2a30e4d0755de2324ccdf4,"Comparison of machine learning methods for stationary wavelet entropy-based multiple sclerosis detection: decision tree, k-nearest neighbors, and support vector machine","In order to detect multiple sclerosis (MS) subjects from healthy controls (HCs) in magnetic resonance imaging, we developed a new system based on machine learning. The MS imaging data was downloaded from the eHealth laboratory at the University of Cyprus, and the HC imaging data was scanned in our local hospital with volunteers enrolled from community advertisement. Inter-scan normalization was employed to remove the gray-level difference. We adjust the misclassification costs to alleviate the effect of unbalanced class distribution to the classification performance. We utilized two-level stationary wavelet entropy (SWE) to extract features from brain images. Then, we compared three machine learning based classifiers: the decision tree, k-nearest neighbors (kNN), and support vector machine. The experimental results showed the kNN performed the best among all three classifiers. In addition, the proposed SWE+kNN approach is superior to four state-of-the-art approaches. Our proposed MS detection approach is effective.",2016,63,135,4,False,Computer Science,121310035,Yudong Zhang,3008614.0,Siyuan Lu,,2238345.0,Xingxing Zhou,50367281.0,Ming Yang,2858143.0,Lenan Wu,,Bin Liu,29671011.0,Preetha Phillips,7488474.0,Shuihua Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
209bdd3d7021c4feb4445b5c667660ab41773a3a,https://www.semanticscholar.org/paper/209bdd3d7021c4feb4445b5c667660ab41773a3a,Imbalance Learning Machine-Based Power System Short-Term Voltage Stability Assessment,"In terms of machine learning-based power system dynamic stability assessment, it is feasible to collect learning data from massive synchrophasor measurements in practice. However, the fact that instability events rarely occur would lead to a challenging class imbalance problem. Besides, short-term feature extraction from scarce instability seems extremely difficult for conventional learning machines. Faced with such a dilemma, this paper develops a systematic imbalance learning machine for online short-term voltage stability assessment. A powerful time series shapelet (discriminative subsequence) classification method is embedded into the machine for sequential transient feature mining. A forecasting-based nonlinear synthetic minority oversampling technique is proposed to mitigate the distortion of class distribution. Cost-sensitive learning is employed to intensify bias toward those scarce yet valuable unstable cases. Furthermore, an incremental learning strategy is put forward for online monitoring, contributing to adaptability and reliability enhancement along with time. Simulation results on the Nordic test system illustrate the high performance of the proposed learning machine and of the assessment scheme.",2017,35,81,3,False,Computer Science,2109090499,Lipeng Zhu,2110141479.0,Chao Lu,Engineering,144402926.0,Z. Dong,3387191.0,Chao Hong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4b2f55f91e63268a58457cccaa95255336c3e0df,https://www.semanticscholar.org/paper/4b2f55f91e63268a58457cccaa95255336c3e0df,Content-based audio classification and retrieval by support vector machines,"Support vector machines (SVMs) have been recently proposed as a new learning algorithm for pattern recognition. In this paper, the SVMs with a binary tree recognition strategy are used to tackle the audio classification problem. We illustrate the potential of SVMs on a common audio database, which consists of 409 sounds of 16 classes. We compare the SVMs based classification with other popular approaches. For audio retrieval, we propose a new metric, called distance-from-boundary (DFB). When a query audio is given, the system first finds a boundary inside which the query pattern is located. Then, all the audio patterns in the database are sorted by their distances to this boundary. All boundaries are learned by the SVMs and stored together with the audio database. Experimental comparisons for audio retrieval are presented to show the superiority of this novel metric to other similarity measures.",2003,25,457,30,False,Computer Science,1822413,G. Guo,34679741.0,S. Li,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81fd20c2b903d979075e0c6a59258b0a84213095,https://www.semanticscholar.org/paper/81fd20c2b903d979075e0c6a59258b0a84213095,Strategic Classification,"Machine learning relies on the assumption that unseen test instances of a classification problem follow the same distribution as observed training data. However, this principle can break down when machine learning is used to make important decisions about the welfare (employment, education, health) of strategic individuals. Knowing information about the classifier, such individuals may manipulate their attributes in order to obtain a better classification outcome. As a result of this behavior -- often referred to as gaming -- the performance of the classifier may deteriorate sharply. Indeed, gaming is a well-known obstacle for using machine learning methods in practice; in financial policy-making, the problem is widely known as Goodhart's law. In this paper, we formalize the problem, and pursue algorithms for learning classifiers that are robust to gaming. We model classification as a sequential game between a player named ""Jury"" and a player named ""Contestant."" Jury designs a classifier, and Contestant receives an input to the classifier drawn from a distribution. Before being classified, Contestant may change his input based on Jury's classifier. However, Contestant incurs a cost for these changes according to a cost function. Jury's goal is to achieve high classification accuracy with respect to Contestant's original input and some underlying target classification function, assuming Contestant plays best response. Contestant's goal is to achieve a favorable classification outcome while taking into account the cost of achieving it. For a natural class of ""separable"" cost functions, and certain generalizations, we obtain computationally efficient learning algorithms which are near optimal, achieving a classification error that is arbitrarily close to the theoretical minimum. Surprisingly, our algorithms are efficient even on concept classes that are computationally hard to learn. For general cost functions, designing an approximately optimal strategy-proof classifier, for inverse-polynomial approximation, is NP-hard.",2015,15,215,25,True,Computer Science,1775622,Moritz Hardt,1706816.0,N. Megiddo,,144102674.0,C. Papadimitriou,1759738.0,Mary Wootters,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
417fd5b826344010caf8f9c3504c7f7a1959602e,https://www.semanticscholar.org/paper/417fd5b826344010caf8f9c3504c7f7a1959602e,Quantum Chemistry in the Age of Machine Learning.,"As quantum chemistry (QC) community embraces machine learning (ML), the surging number of new methods and applications based on combination of QC and ML is emerging. In this Perspective a view on the current state of affairs in this new exciting research field is offered, challenges of using ML in QC applications are described, and potential future developments are outlined. Specifically, examples of how ML is used to improve the accuracy and accelerate QC research are shown. Generalization and classification of existing techniques is provided to ease the navigation in the sea of literature and to guide the researchers entering the field. The emphasis of this Perspective is on the supervised ML.",2020,187,146,0,False,Computer Science,5378288,Pavlo O. Dral,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4a0f2af92eabc0c3eec09244e678cc786d47e598,https://www.semanticscholar.org/paper/4a0f2af92eabc0c3eec09244e678cc786d47e598,"A Data-Driven Predictive Prognostic Model for Lithium-Ion Batteries based on a 
Deep Learning Algorithm","Prognostic and health management (PHM) can ensure that a lithium-ion battery is working safely and reliably. The main approach of PHM evaluation of the battery is to determine the State of Health (SoH) and the Remaining Useful Life (RUL) of the battery. The advancements of computational tools and big data algorithms have led to a new era of data-driven predictive analysis approaches, using machine learning algorithms. This paper presents the preliminary development of the data-driven prognostic, using a Deep Neural Networks (DNN) approach to predict the SoH and the RUL of the lithium-ion battery. The effectiveness of the proposed approach was implemented in a case study with a battery dataset obtained from the National Aeronautics and Space Administration (NASA) Ames Prognostics Center of Excellence (PCoE) database. The proposed DNN algorithm was compared against other machine learning algorithms, namely, Support Vector Machine (SVM), k-Nearest Neighbors (k-NN), Artificial Neural Networks (ANN), and Linear Regression (LR). The experimental results reveal that the performance of the DNN algorithm could either match or outweigh other machine learning algorithms. Further, the presented results could serve as a benchmark of SoH and RUL prediction using machine learning approaches specifically for lithium-ion batteries application.",2019,57,114,1,True,Computer Science,102116785,Phattara Khumprom,24287459.0,Nita Yodo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8ea55bca9b375a7094ae0d8d8af6958e488aee14,https://www.semanticscholar.org/paper/8ea55bca9b375a7094ae0d8d8af6958e488aee14,A review of machine learning in obesity,"Rich sources of obesity‐related data arising from sensors, smartphone apps, electronic medical health records and insurance data can bring new insights for understanding, preventing and treating obesity. For such large datasets, machine learning provides sophisticated and elegant tools to describe, classify and predict obesity‐related risks and outcomes.",2018,87,86,1,False,Computer Science,11022772,K. W. DeGregory,144419720.0,P. Kuiper,Medicine,35687788.0,T. DeSilvio,36422133.0,J. Pleuss,145762644.0,R. Miller,48850872.0,J. Roginski,2168602657.0,C. B. Fisher,89912794.0,D. Harness,,20472796.0,S. Viswanath,1703514.0,S. Heymsfield,35431016.0,I. Dungan,144591421.0,D. Thomas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d143fa58a437dc3cf68972e87f8621583058039d,https://www.semanticscholar.org/paper/d143fa58a437dc3cf68972e87f8621583058039d,Derivation and Validation of Machine Learning Approaches to Predict Acute Kidney Injury after Cardiac Surgery,"Machine learning approaches were introduced for better or comparable predictive ability than statistical analysis to predict postoperative outcomes. We sought to compare the performance of machine learning approaches with that of logistic regression analysis to predict acute kidney injury after cardiac surgery. We retrospectively reviewed 2010 patients who underwent open heart surgery and thoracic aortic surgery. Baseline medical condition, intraoperative anesthesia, and surgery-related data were obtained. The primary outcome was postoperative acute kidney injury (AKI) defined according to the Kidney Disease Improving Global Outcomes criteria. The following machine learning techniques were used: decision tree, random forest, extreme gradient boosting, support vector machine, neural network classifier, and deep learning. The performance of these techniques was compared with that of logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUC). During the first postoperative week, AKI occurred in 770 patients (38.3%). The best performance regarding AUC was achieved by the gradient boosting machine to predict the AKI of all stages (0.78, 95% confidence interval (CI) 0.75–0.80) or stage 2 or 3 AKI. The AUC of logistic regression analysis was 0.69 (95% CI 0.66–0.72). Decision tree, random forest, and support vector machine showed similar performance to logistic regression. In our comprehensive comparison of machine learning approaches with logistic regression analysis, gradient boosting technique showed the best performance with the highest AUC and lower error rate. We developed an Internet–based risk estimator which could be used for real-time processing of patient data to estimate the risk of AKI at the end of surgery.",2018,50,85,4,True,Medicine,2110208828,Hyung‐Chul Lee,152696865.0,H. Yoon,,6255329.0,K. Nam,6412480.0,Y. Cho,3875084.0,T. K. Kim,47902458.0,W. Kim,145569375.0,J. Bahk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a2fe9dbd8858e4e0dcb8ece01563d87ceebe5cbc,https://www.semanticscholar.org/paper/a2fe9dbd8858e4e0dcb8ece01563d87ceebe5cbc,Algorithms and Representations for Reinforcement Learning,"Machine Learning is a field of research aimed at constructing intelligent machines that gain and improve their skills by learning and adaptation. As such, Machine Learning research addresses several classes of learning problems, including for instance, supervised and unsupervised learning. Arguably, the most ubiquitous and realistic class of learning problems, faced by both living creatures and artificial agents, is known as Reinforcement Learning. Reinforcement Learning problems are characterized by a long-term interaction between the learning agent and a dynamic, unfamiliar, uncertain, possibly even hostile environment. Mathematically, this interaction is modeled as a Markov Decision Process (MDP). Probably the most significant contribution of this thesis is in the introduction of a new class of Reinforcement Learning algorithms, which leverage the power of a statistical set of tools known as Gaussian Processes. This new approach to Reinforcement Learning offers viable solutions to some of the major limitations of current Reinforcement Learning methods, such as the lack of confidence intervals for performance predictions, and the difficulty of appropriately reconciling exploration with exploitation. Analysis of these algorithms and their relationship with existing methods also provides us with new insights into the assumptions underlying some of the most popular Reinforcement Learning algorithms to date.",2005,103,101,17,False,Computer Science,2057050,Y. Engel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39604eee28a2401d3e244182504b7b06a71d05c4,https://www.semanticscholar.org/paper/39604eee28a2401d3e244182504b7b06a71d05c4,"Unsupervised machine learning in atomistic simulations, between predictions and understanding.","Automated analyses of the outcome of a simulation have been an important part of atomistic modeling since the early days, addressing the need of linking the behavior of individual atoms and the collective properties that are usually the final quantity of interest. Methods such as clustering and dimensionality reduction have been used to provide a simplified, coarse-grained representation of the structure and dynamics of complex systems from proteins to nanoparticles. In recent years, the rise of machine learning has led to an even more widespread use of these algorithms in atomistic modeling and to consider different classification and inference techniques as part of a coherent toolbox of data-driven approaches. This perspective briefly reviews some of the unsupervised machine-learning methods-that are geared toward classification and coarse-graining of molecular simulations-seen in relation to the fundamental mathematical concepts that underlie all machine-learning techniques. It discusses the importance of using concise yet complete representations of atomic structures as the starting point of the analyses and highlights the risk of introducing preconceived biases when using machine learning to rationalize and understand structure-property relations. Supervised machine-learning techniques that explicitly attempt to predict the properties of a material given its structure are less susceptible to such biases. Current developments in the field suggest that using these two classes of approaches side-by-side and in a fully integrated mode, while keeping in mind the relations between the data analysis framework and the fundamental physical principles, will be key to realizing the full potential of machine learning to help understand the behavior of complex molecules and materials.",2019,111,83,1,True,Computer Science,1917770,M. Ceriotti,,,Medicine,,,,,,,,,,,,,Chemistry,,,,,,,,,Physics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1383a648fe5604f0072a90a1ea8b5d1d0d92a867,https://www.semanticscholar.org/paper/1383a648fe5604f0072a90a1ea8b5d1d0d92a867,Rough-Fuzzy Hybridization: A New Trend in Decision Making,"From the Publisher: 
This volume provides a collection of twenty articles containing new material and describing the basic concepts and characterizing features of rough set theory and its integration with fuzzy set theory, for developing an efficient soft computing strategy of machine learning. Written by leading experts from all over the world, the contributions demonstrate how rough-fuzzy hybridization can be made in various ways to provide flexible information processing capabilities for handling different real-life, ambiguous decision-making problems. This volume provides a balanced mix of theory and application.",1999,0,729,29,False,Computer Science,1736103,S. Pal,1725797.0,A. Skowron,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2e8e099dbb99b840c33d9c435f8d18084a2ca77a,https://www.semanticscholar.org/paper/2e8e099dbb99b840c33d9c435f8d18084a2ca77a,Positive-unlabeled learning for disease gene identification,"Background: Identifying disease genes from human genome is an important but challenging task in biomedical research. Machine learning methods can be applied to discover new disease genes based on the known ones. Existing machine learning methods typically use the known disease genes as the positive training set P and the unknown genes as the negative training set N (non-disease gene set does not exist) to build classifiers to identify new disease genes from the unknown genes. However, such kind of classifiers is actually built from a noisy negative set N as there can be unknown disease genes in N itself. As a result, the classifiers do not perform as well as they could be. Result: Instead of treating the unknown genes as negative examples in N, we treat them as an unlabeled set U. We design a novel positive-unlabeled (PU) learning algorithm PUDI (PU learning for disease gene identification) to build a classifier using P and U. We first partition U into four sets, namely, reliable negative set RN, likely positive set LP, likely negative set LN and weak negative set WN. The weighted support vector machines are then used to build a multi-level classifier based on the four training sets and positive training set P to identify disease genes. Our experimental results demonstrate that our proposed PUDI algorithm outperformed the existing methods significantly. Conclusion: The proposed PUDI algorithm is able to identify disease genes more accurately by treating the unknown data more appropriately as unlabeled set U instead of negative set N. Given that many machine learning problems in biomedical research do involve positive and unlabeled data instead of negative data, it is possible that the machine learning methods for these problems can be further improved by adopting PU learning methods, as we have done here for disease gene identification. Availability and implementation: The executable program and data are available at http://www1.i2r.a-star.edu.sg/∼xlli/PUDI/PUDI.html. Contact: xlli@i2r.a-star.edu.sg or yang0293@e.ntu.edu.sg Supplementary information: Supplementary Data are available at Bioinformatics online.",2012,70,157,9,True,Medicine,2119185448,Peng Yang,39952499.0,Xiaoli Li,Computer Science,51052318.0,Jianxiang Mei,1773946.0,C. Kwoh,1794527.0,See-Kiong Ng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8b9e1793d63744d2fc198da3cc185aef75f5d9ff,https://www.semanticscholar.org/paper/8b9e1793d63744d2fc198da3cc185aef75f5d9ff,COVID-19 Epidemic Analysis using Machine Learning and Deep Learning Algorithms,"The catastrophic outbreak of Severe Acute Respiratory Syndrome - Coronavirus (SARS-CoV-2) also known as COVID-2019 has brought the worldwide threat to the living society. The whole world is putting incredible efforts to fight against the spread of this deadly disease in terms of infrastructure, finance, data sources, protective gears, life-risk treatments and several other resources. The artificial intelligence researchers are focusing their expertise knowledge to develop mathematical models for analyzing this epidemic situation using nationwide shared data. To contribute towards the well-being of living society, this article proposes to utilize the machine learning and deep learning models with the aim for understanding its everyday exponential behaviour along with the prediction of future reachability of the COVID-2019 across the nations by utilizing the real-time information from the Johns Hopkins dashboard.",2020,20,155,4,True,Medicine,52186859,N. Punn,52133313.0,S. K. Sonbhadra,Computer Science,145092061.0,Sonali Agarwal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f42549dc2efdab086af81e06522783409b0e79ec,https://www.semanticscholar.org/paper/f42549dc2efdab086af81e06522783409b0e79ec,Optimal kernel selection in Kernel Fisher discriminant analysis,"In Kernel Fisher discriminant analysis (KFDA), we carry out Fisher linear discriminant analysis in a high dimensional feature space defined implicitly by a kernel. The performance of KFDA depends on the choice of the kernel; in this paper, we consider the problem of finding the optimal kernel, over a given convex set of kernels. We show that this optimal kernel selection problem can be reformulated as a tractable convex optimization problem which interior-point methods can solve globally and efficiently. The kernel selection method is demonstrated with some UCI machine learning benchmark examples.",2006,28,161,22,True,Mathematics,2695019,Seung-Jean Kim,2052320550.0,A. Magnani,Computer Science,1843103.0,Stephen P. Boyd,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b7d471970467a99bec4bce34c7dba5ef6745ad06,https://www.semanticscholar.org/paper/b7d471970467a99bec4bce34c7dba5ef6745ad06,The Curse of Highly Variable Functions for Local Kernel Machines,"We present a series of theoretical arguments supporting the claim that a large class of modern learning algorithms that rely solely on the smoothness prior - with similarity between examples expressed with a local kernel - are sensitive to the curse of dimensionality, or more precisely to the variability of the target. Our discussion covers supervised, semi-supervised and unsupervised learning algorithms. These algorithms are found to be local in the sense that crucial properties of the learned function at x depend mostly on the neighbors of x in the training set. This makes them sensitive to the curse of dimensionality, well studied for classical non-parametric statistical learning. We show in the case of the Gaussian kernel that when the function to be learned has many variations, these algorithms require a number of training examples proportional to the number of variations, which could be large even though there may exist short descriptions of the target function, i.e. their Kolmogorov complexity may be low. This suggests that there exist non-local learning algorithms that at least have the potential to learn about such structured but apparently complex functions (because locally they have many variations), while not using very specific prior domain knowledge.",2005,23,203,7,False,Computer Science,1751762,Yoshua Bengio,2460212.0,Olivier Delalleau,Mathematics,7245737.0,Nicolas Le Roux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f115ac87b891d3873099508456c120f85b87698,https://www.semanticscholar.org/paper/5f115ac87b891d3873099508456c120f85b87698,MLPerf Training Benchmark,"Machine learning (ML) needs industry-standard performance benchmarks to support design and competitive evaluation of the many emerging software and hardware solutions for ML. But ML training presents three unique benchmarking challenges absent from other domains: optimizations that improve training throughput can increase the time to solution, training is stochastic and time to solution exhibits high variance, and software and hardware systems are so diverse that fair benchmarking with the same binary, code, and even hyperparameters is difficult. We therefore present MLPerf, an ML benchmark that overcomes these challenges. Our analysis quantitatively evaluates MLPerf's efficacy at driving performance and scalability improvements across two rounds of results from multiple vendors.",2019,81,171,26,False,Computer Science,2065823421,Peter Mattson,2109795452.0,Christine Cheng,Mathematics,2866919.0,Cody A. Coleman,2040049.0,G. Diamos,1802359.0,P. Micikevicius,2084633463.0,David A. Patterson,39278465.0,Hanlin Tang,2255803.0,Gu-Yeon Wei,,2740804.0,Peter D. Bailis,2932580.0,Victor Bittorf,1896817.0,D. Brooks,7167328.0,Dehao Chen,,46905001.0,Debo Dutta,2633839.0,Udit Gupta,1775500.0,Kim M. Hazelwood,145076564.0,A. Hock,2048519015.0,Xinyuan Huang,33920592.0,Bill Jia,35342489.0,Daniel Kang,2033833485.0,David Kanter,2116960562.0,Naveen Kumar,2075442427.0,Jeffery Liao,1388813853.0,Guokai Ma,22252150.0,D. Narayanan,2814407.0,Tayo Oguntebi,3257164.0,Gennady Pekhimenko,3329554.0,Lillian Pentecost,1805668.0,V. Reddi,46887039.0,Taylor Robie,22033768.0,T. S. John,2797270.0,Carole-Jean Wu,47775733.0,Lingjie Xu,39660914.0,C. Young,143834867.0,M. Zaharia
379f9711c44739d6bb96efe4d530c6d4a20c4924,https://www.semanticscholar.org/paper/379f9711c44739d6bb96efe4d530c6d4a20c4924,Machine Learning Approaches to Predict 6-Month Mortality Among Patients With Cancer,"Key Points Question Can machine learning algorithms identify oncology patients at risk of short-term mortality to inform timely conversations between patients and physicians regrading serious illness? Findings In this cohort study of 26 525 patients seen in oncology practices within a large academic health system, machine learning algorithms accurately identified patients at high risk of 6-month mortality with good discrimination and positive predictive value. When the gradient boosting algorithm was applied in real time, most patients who were classified as having high risk were deemed appropriate by oncology clinicians for a conversation regarding serious illness. Meaning In this study, machine learning algorithms accurately identified patients with cancer who were at risk of 6-month mortality, suggesting that these models could facilitate more timely conversations between patients and physicians regarding goals and values.",2019,38,98,2,True,Medicine,49531201,R. Parikh,37163364.0,Christopher R. Manz,,5070095.0,C. Chivers,2361809.0,S. H. Regli,1387392475.0,J. Braun,10763846.0,M. Draugelis,5812813.0,L. Schuchter,2654757.0,L. Shulman,,2627572.0,A. Navathe,1405911435.0,Mitesh S. Patel,1387836902.0,Nina R. O’Connor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bb82053d4229357925b28ffe647377f56d93b06e,https://www.semanticscholar.org/paper/bb82053d4229357925b28ffe647377f56d93b06e,Intelligent nanophotonics: merging photonics and artificial intelligence at the nanoscale,"Abstract Nanophotonics has been an active research field over the past two decades, triggered by the rising interests in exploring new physics and technologies with light at the nanoscale. As the demands of performance and integration level keep increasing, the design and optimization of nanophotonic devices become computationally expensive and time-inefficient. Advanced computational methods and artificial intelligence, especially its subfield of machine learning, have led to revolutionary development in many applications, such as web searches, computer vision, and speech/image recognition. The complex models and algorithms help to exploit the enormous parameter space in a highly efficient way. In this review, we summarize the recent advances on the emerging field where nanophotonics and machine learning blend. We provide an overview of different computational methods, with the focus on deep learning, for the nanophotonic inverse design. The implementation of deep neural networks with photonic platforms is also discussed. This review aims at sketching an illustration of the nanophotonic design with machine learning and giving a perspective on the future tasks.",2018,237,170,2,True,Physics,2305129,Kan Yao,1944881178.0,R. Unni,Medicine,4011641.0,Yuebing Zheng,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
368a8fbf6304a192a67f614d032510e5a4100552,https://www.semanticscholar.org/paper/368a8fbf6304a192a67f614d032510e5a4100552,Generalizing from a Few Examples,"Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-shot Learning (FSL) is proposed to tackle this problem. Using prior knowledge, FSL can rapidly generalize to new tasks containing only a few samples with supervised information. In this article, we conduct a thorough survey to fully understand FSL. Starting from a formal definition of FSL, we distinguish FSL from several relevant machine learning problems. We then point out that the core issue in FSL is that the empirical risk minimizer is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize FSL methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the FSL problem setups, techniques, applications, and theories, are also proposed to provide insights for future research.1",2020,187,352,2,False,Computer Science,49416601,Yaqing Wang,3259992.0,Quanming Yao,,145193332.0,J. Kwok,1726587.0,L. Ni,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e69c8b5df8a4178b1c8c7f154a761147a6f030be,https://www.semanticscholar.org/paper/e69c8b5df8a4178b1c8c7f154a761147a6f030be,Project Adam: Building an Efficient and Scalable Deep Learning Training System,"Large deep neural network models have recently demonstrated state-of-the-art accuracy on hard visual recognition tasks. Unfortunately such models are extremely time consuming to train and require large amount of compute cycles. We describe the design and implementation of a distributed system called Adam comprised of commodity server machines to train such models that exhibits world-class performance, scaling and task accuracy on visual recognition tasks. Adam achieves high efficiency and scalability through whole system co-design that optimizes and balances workload computation and communication. We exploit asynchrony throughout the system to improve performance and show that it additionally improves the accuracy of trained models. Adam is significantly more efficient and scalable than was previously thought possible and used 30x fewer machines to train a large 2 billion connection model to 2x higher accuracy in comparable time on the ImageNet 22,000 category image classification task than the system that previously held the record for this benchmark. We also show that task accuracy improves with larger models. Our results provide compelling evidence that a distributed systems-driven approach to deep learning using current training algorithms is worth pursuing.",2014,30,710,80,False,Computer Science,3191220,Trishul M. Chilimbi,3312079.0,Yutaka Suzue,,2300600.0,Johnson Apacible,40444389.0,Karthik Kalyanaraman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2d55ff4542eaae18dcd10c2cd74199396e260402,https://www.semanticscholar.org/paper/2d55ff4542eaae18dcd10c2cd74199396e260402,Rawlsian Fairness for Machine Learning,"Motivated by concerns that automated decision-making procedures can unintentionally lead to discriminatory behavior, we study a technical definition of fairness modeled after John Rawls' notion of ""fair equality of opportunity"". In the context of a simple model of online decision making, we give an algorithm that satisfies this fairness constraint, while still being able to learn at a rate that is comparable to (but necessarily worse than) that of the best algorithms absent a fairness constraint. We prove a regret bound for fair algorithms in the linear contextual bandit framework that is a significant improvement over our technical companion paper [16], which gives black-box reductions in a more general setting. We analyze our algorithms both theoretically and experimentally. Finally, we introduce the notion of a ""discrimination index"", and show that standard algorithms for our problem exhibit structured discriminatory behavior, whereas the ""fair"" algorithms we develop do not.",2016,36,74,2,False,Mathematics,144525693,Matthew Joseph,81338045.0,M. Kearns,Computer Science,144848816.0,Jamie H. Morgenstern,5880154.0,Seth Neel,1682008.0,Aaron Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9f905c4050131f82bcfb503a580cfcfdedc25fc9,https://www.semanticscholar.org/paper/9f905c4050131f82bcfb503a580cfcfdedc25fc9,Classifying Software Changes: Clean or Buggy?,"This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features.",2008,65,556,42,True,Computer Science,1787729,Sunghun Kim,145007710.0,E. J. Whitehead,,34577272.0,Yi Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a544d3c8222cf732f570fc6db66489bab66e08d7,https://www.semanticscholar.org/paper/a544d3c8222cf732f570fc6db66489bab66e08d7,Variance-Reduced and Projection-Free Stochastic Optimization,"The Frank-Wolfe optimization algorithm has recently regained popularity for machine learning applications due to its projection-free property and its ability to handle structured constraints. However, in the stochastic learning setting, it is still relatively understudied compared to the gradient descent counterpart. In this work, leveraging a recent variance reduction technique, we propose two stochastic Frank-Wolfe variants which substantially improve previous results in terms of the number of stochastic gradient evaluations needed to achieve 1 - e accuracy. For example, we improve from O(1/e) to O(ln 1/e) if the objective function is smooth and strongly convex, and from O(1/e2) to O(1/e1.5) if the objective function is smooth and Lipschitz. The theoretical improvement is also observed in experiments on real-world datasets for a multiclass classification application.",2016,16,144,31,False,Computer Science,34840427,Elad Hazan,2131127.0,Haipeng Luo,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1c4b2bf81643cc3584efd2812510b33015a0d661,https://www.semanticscholar.org/paper/1c4b2bf81643cc3584efd2812510b33015a0d661,Expert-augmented machine learning,"Significance Machine learning is increasingly used across fields to derive insights from data, which further our understanding of the world and help us anticipate the future. The performance of predictive modeling is dependent on the amount and quality of available data. In practice, we rely on human experts to perform certain tasks and on machine learning for others. However, the optimal learning strategy may involve combining the complementary strengths of humans and machines. We present expert-augmented machine learning, an automated way to automatically extract problem-specific human expert knowledge and integrate it with machine learning to build robust, dependable, and data-efficient predictive models. Machine learning is proving invaluable across disciplines. However, its success is often limited by the quality and quantity of available data, while its adoption is limited by the level of trust afforded by given models. Human vs. machine performance is commonly compared empirically to decide whether a certain task should be performed by a computer or an expert. In reality, the optimal learning strategy may involve combining the complementary strengths of humans and machines. Here, we present expert-augmented machine learning (EAML), an automated method that guides the extraction of expert knowledge and its integration into machine-learned models. We used a large dataset of intensive-care patient data to derive 126 decision rules that predict hospital mortality. Using an online platform, we asked 15 clinicians to assess the relative risk of the subpopulation defined by each rule compared to the total sample. We compared the clinician-assessed risk to the empirical risk and found that, while clinicians agreed with the data in most cases, there were notable exceptions where they overestimated or underestimated the true risk. Studying the rules with greatest disagreement, we identified problems with the training data, including one miscoded variable and one hidden confounder. Filtering the rules based on the extent of disagreement between clinician-assessed risk and empirical risk, we improved performance on out-of-sample data and were able to train with less data. EAML provides a platform for automated creation of problem-specific priors, which help build robust and dependable machine-learning models in critical applications.",2019,38,46,0,True,Computer Science,3088421,Efstathios D. Gennatas,3056361.0,J. Friedman,Medicine,1412391493.0,L. Ungar,4372658.0,R. Pirracchio,144020269.0,Eric Eaton,150192444.0,L. Reichman,3304169.0,Y. Interian,1697525.0,C. Simone,Mathematics,2059212508.0,A. Auerbach,2055966654.0,E. Delgado,145099512.0,M. J. Laan,2286161.0,T. Solberg,,145295389.0,G. Valdes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1d88162907ff9a0b4ca9e39db3b8d593fb83bc64,https://www.semanticscholar.org/paper/1d88162907ff9a0b4ca9e39db3b8d593fb83bc64,Demystifying Membership Inference Attacks in Machine Learning as a Service,"Membership inference attacks seek to infer membership of individual training instances of a model to which an adversary has black-box access through a machine learning-as-a-service API. In providing an in-depth characterization of membership privacy risks against machine learning models, this paper presents a comprehensive study towards demystifying membership inference attacks from two complimentary perspectives. First, we provide a generalized formulation of the development of a black-box membership inference attack model. Second, we characterize the importance of model choice on model vulnerability through a systematic evaluation of a variety of machine learning models and model combinations using multiple datasets. Through formal analysis and empirical evidence from extensive experimentation, we characterize under what conditions a model may be vulnerable to such black-box membership inference attacks. We show that membership inference vulnerability is data-driven and corresponding attack models are largely transferable. Though different model types display different vulnerabilities to membership inference, so do different datasets. Our empirical results additionally show that (1) using the type of target model under attack within the attack model may not increase attack effectiveness and (2) collaborative learning exposes vulnerabilities to membership inference risks when the adversary is a participant. We also discuss countermeasure and mitigation strategies.",2019,0,117,10,False,Computer Science,25121568,Stacey Truex,46458150.0,Ling Liu,,2327300.0,M. E. Gursoy,2112531949.0,Lei Yu,47747953.0,Wenqi Wei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6704cac662a0968215644c13fa4324b05b1e420b,https://www.semanticscholar.org/paper/6704cac662a0968215644c13fa4324b05b1e420b,Machine learning of Calabi-Yau volumes,We employ machine learning techniques to investigate the volume minimum of Sasaki-Einstein base manifolds of noncompact toric Calabi-Yau three-folds. We find that the minimum volume can be approxim ...,2017,22,81,1,True,Physics,32496630,D. Krefl,87283663.0,Rak-Kyeong Seong,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
841fb8bd0af800d198b377a60b78ba39477b1e3b,https://www.semanticscholar.org/paper/841fb8bd0af800d198b377a60b78ba39477b1e3b,State of the Art: Machine Learning Applications in Glioma Imaging.,"OBJECTIVE
Machine learning has recently gained considerable attention because of promising results for a wide range of radiology applications. Here we review recent work using machine learning in brain tumor imaging, specifically segmentation and MRI radiomics of gliomas.


CONCLUSION
We discuss available resources, state-of-the-art segmentation methods, and machine learning radiomics for glioma. We highlight the challenges of these techniques as well as the future potential in clinical diagnostics, prognostics, and decision making.",2019,45,60,3,False,Medicine,4332710,E. Lotan,144004586.0,R. Jain,,2678645.0,N. Razavian,6627525.0,G. Fatterpekar,2376478.0,Y. Lui,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e48285256ed8ff285b69b22634cd59c65c2e1cd2,https://www.semanticscholar.org/paper/e48285256ed8ff285b69b22634cd59c65c2e1cd2,Transparency and Socially Guided Machine Learning,"In this paper we advocate a paradigm of socially guided machine learning, designing agents that take better advantage of the situated aspects of learning. We augmented a standard Reinforcement Learning agent with the social mechanisms of attention direction and gaze. Experiments with an interactive computer game, deployed over the World Wide Web to over 75 players, show the positive impact of these social aspects. Allowing the human to direct the agent’s attention creates a more efficient exploration strategy. Additionally, gaze behavior lets the learning agent improve its own learning environment, using transparency to steer the human’s instruction.",2006,26,65,3,False,,1682788,A. Thomaz,1711777.0,C. Breazeal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97b9cfbc775bf45a485920a0dd1b3ef05b1c70c7,https://www.semanticscholar.org/paper/97b9cfbc775bf45a485920a0dd1b3ef05b1c70c7,Machine learning in suicide science: Applications and ethics.,"For decades, our ability to predict suicide has remained at near-chance levels. Machine learning has recently emerged as a promising tool for advancing suicide science, particularly in the domain of suicide prediction. The present review provides an introduction to machine learning and its potential application to open questions in suicide research. Although only a few studies have implemented machine learning for suicide prediction, results to date indicate considerable improvement in accuracy and positive predictive value. Potential barriers to algorithm integration into clinical practice are discussed, as well as attendant ethical issues. Overall, machine learning approaches hold promise for accurate, scalable, and effective suicide risk detection; however, many critical questions and issues remain unexplored.",2019,29,68,2,False,Medicine,14864293,Kathryn P Linthicum,67345170.0,K. Schafer,Computer Science,144945435.0,J. Ribeiro,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
055bf065328a1b30a386b9fd162978a0b271b987,https://www.semanticscholar.org/paper/055bf065328a1b30a386b9fd162978a0b271b987,Machine learning meets volcano plots: computational discovery of cross-coupling catalysts,The application of modern machine learning to challenges in atomistic simulation is gaining attraction.,2018,133,99,0,True,Materials Science,144156172,Benjamin Meyer,14071021.0,Boodsarin Sawatlon,Medicine,49458045.0,S. Heinen,7847508.0,O. A. von Lilienfeld,145154812.0,C. Corminboeuf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
