paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,fieldsOfStudy/1,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,fieldsOfStudy/2,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name,authors/34/authorId,authors/34/name,authors/35/authorId,authors/35/name
5176a2f31dace77db9135dde7020d2c37f78cca0,https://www.semanticscholar.org/paper/5176a2f31dace77db9135dde7020d2c37f78cca0,"The Elements of Statistical Learning: Data Mining, Inference, and Prediction","In the words of the authors, the goal of this book was to “bring together many of the important new ideas in learning, and explain them in a statistical framework.” The authors have been quite successful in achieving this objective, and their work is a welcome addition to the statistics and learning literatures. Statistics has always been interdisciplinary, borrowing ideas from diverse  elds and repaying the debt with contributions, both theoretical and practical, to the other intellectual disciplines. For statistical learning, this cross-fertilization is especially noticeable. This book is a valuable resource, both for the statistician needing an introduction to machine learning and related  elds and for the computer scientist wishing to learn more about statistics. Statisticians will especially appreciate that it is written in their own language. The level of the book is roughly that of a second-year doctoral student in statistics, and it will be useful as a textbook for such students. In a stimulating article, Breiman (2001) argued that statistics has been focused too much on a “data modeling culture,” where the model is paramount. Breiman argued instead for an “algorithmic modeling culture,” with emphasis on black-box types of prediction. Breiman’s article is controversial, and in his discussion, Efron objects that “prediction is certainly an interesting subject, but Leo’s paper overstates both its role and our profession’s lack of interest in it.” Although I mostly agree with Efron, I worry that the courses offered by most statistics departments include little, if any, treatment of statistical learning and prediction. (Stanford, where Efron and the authors of this book teach, is an exception.) Graduate students in statistics certainly need to know more than they do now about prediction, machine learning, statistical learning, and data mining (not disjoint subjects). I hope that graduate courses covering the topics of this book will become more common in statistics curricula. Most of the book is focused on supervised learning, where one has inputs and outputs from some system and wishes to predict unknown outputs corresponding to known inputs. The methods discussed for supervised learning include linear and logistic regression; basis expansion, such as splines and wavelets; kernel techniques, such as local regression, local likelihood, and radial basis functions; neural networks; additive models; decision trees based on recursive partitioning, such as CART; and support vector machines. There is a  nal chapter on unsupervised learning, including association rules, cluster analysis, self-organizing maps, principal components and curves, and independent component analysis. Many statisticians will be unfamiliar with at least some of these algorithms. Association rules are popular for mining commercial data in what is called “market basket analysis.” The aim is to discover types of products often purchased together. Such knowledge can be used to develop marketing strategies, such as store or catalog layouts. Self-organizing maps (SOMs) involve essentially constrained k-means clustering, where prototypes are mapped to a two-dimensional curved coordinate system. Independent components analysis is similar to principal components analysis and factor analysis, but it uses higher-order moments to achieve independence, not merely zero correlation between components. A strength of the book is the attempt to organize a plethora of methods into a coherent whole. The relationships among the methods are emphasized. I know of no other book that covers so much ground. Of course, with such broad coverage, it is not possible to cover any single topic in great depth, so this book will encourage further reading. Fortunately, each chapter includes bibliographic notes surveying the recent literature. These notes and the extensive references provide a good introduction to the learning literature, including much outside of statistics. The book might be more suitable as a textbook if less material were covered in greater depth; however, such a change would compromise the book’s usefulness as a reference, and so I am happier with the book as it was written.",2004,2,15322,1843,False,Mathematics,144108246,D. Ruppert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
01f702f8b1f9d1314587015f1f038af4d5735e77,https://www.semanticscholar.org/paper/01f702f8b1f9d1314587015f1f038af4d5735e77,Opposition-Based Learning: A New Scheme for Machine Intelligence,"Opposition-based learning as a new scheme for machine intelligence is introduced. Estimates and counter-estimates, weights and opposite weights, and actions versus counter-actions are the foundation of this new approach. Examples are provided. Possibilities for extensions of existing learning algorithms are discussed. Preliminary results are provided",2005,9,1272,142,False,Computer Science,9315255,H. Tizhoosh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d05d86db86a4ac0d95e6dcd951b42a9651939793,https://www.semanticscholar.org/paper/d05d86db86a4ac0d95e6dcd951b42a9651939793,Deep Learning Approach for Intelligent Intrusion Detection System,"Machine learning techniques are being widely used to develop an intrusion detection system (IDS) for detecting and classifying cyberattacks at the network-level and the host-level in a timely and automatic manner. However, many challenges arise since malicious attacks are continually changing and are occurring in very large volumes requiring a scalable solution. There are different malware datasets available publicly for further research by cyber security community. However, no existing study has shown the detailed analysis of the performance of various machine learning algorithms on various publicly available datasets. Due to the dynamic nature of malware with continuously changing attacking methods, the malware datasets available publicly are to be updated systematically and benchmarked. In this paper, a deep neural network (DNN), a type of deep learning model, is explored to develop a flexible and effective IDS to detect and classify unforeseen and unpredictable cyberattacks. The continuous change in network behavior and rapid evolution of attacks makes it necessary to evaluate various datasets which are generated over the years through static and dynamic approaches. This type of study facilitates to identify the best algorithm which can effectively work in detecting future cyberattacks. A comprehensive evaluation of experiments of DNNs and other classical machine learning classifiers are shown on various publicly available benchmark malware datasets. The optimal network parameters and network topologies for DNNs are chosen through the following hyperparameter selection methods with KDDCup 99 dataset. All the experiments of DNNs are run till 1,000 epochs with the learning rate varying in the range [0.01–0.5]. The DNN model which performed well on KDDCup 99 is applied on other datasets, such as NSL-KDD, UNSW-NB15, Kyoto, WSN-DS, and CICIDS 2017, to conduct the benchmark. Our DNN model learns the abstract and high-dimensional feature representation of the IDS data by passing them into many hidden layers. Through a rigorous experimental testing, it is confirmed that DNNs perform well in comparison with the classical machine learning classifiers. Finally, we propose a highly scalable and hybrid DNNs framework called scale-hybrid-IDS-AlertNet which can be used in real-time to effectively monitor the network traffic and host-level events to proactively alert possible cyberattacks.",2019,85,546,24,True,Computer Science,51162051,R. Vinayakumar,2474250.0,M. Alazab,144456263.0,K. Soman,2916235.0,P. Poornachandran,1399133087.0,Ameer Al-Nemrat,145710905.0,S. Venkatraman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cd49acefc8d51e324aa562e5337e1c2aff067053,https://www.semanticscholar.org/paper/cd49acefc8d51e324aa562e5337e1c2aff067053,An Overview of Multi-task Learning,"As a promising area in machine learning, multi-task learning (MTL) aims to improve the performance of multiple related learning tasks by leveraging useful information among them. In this paper, we give an overview of MTL by first giving a definition of MTL. Then several different settings of MTL are introduced, including multi-task supervised learning, multi-task unsupervised learning, multi-task semi-supervised learning, multi-task active learning, multi-task reinforcement learning, multi-task online learning and multi-task multi-view learning. For each setting, representative MTL models are presented. In order to speed up the learning process, parallel and distributed MTL models are introduced. Many areas, including computer vision, bioinformatics, health informatics, speech, natural language processing, web applications and ubiquitous computing, use MTL to improve the performance of the applications involved and some representative works are reviewed. Finally, recent theoretical analyses for MTL are presented.",2018,135,949,29,True,Computer Science,46867608,Yu Zhang,153096457.0,Qiang Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c99179ca3784e3465fd9ed049d7f34b50d39393e,https://www.semanticscholar.org/paper/c99179ca3784e3465fd9ed049d7f34b50d39393e,Ensemble learning: A survey,"Ensemble methods are considered the state‐of‐the art solution for many machine learning challenges. Such methods improve the predictive performance of a single model by training multiple models and combining their predictions. This paper introduce the concept of ensemble learning, reviews traditional, novel and state‐of‐the‐art ensemble methods and discusses current challenges and trends in the field.",2018,167,866,30,False,Computer Science,2066733832,Omer Sagi,1732091.0,L. Rokach,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5,https://www.semanticscholar.org/paper/0bfc6add0390f1b4cfbd0e90ac71475cca88b2d5,A Review on Multi-Label Learning Algorithms,"Multi-label learning studies the problem where each example is represented by a single instance while associated with a set of labels simultaneously. During the past decade, significant amount of progresses have been made toward this emerging machine learning paradigm. This paper aims to provide a timely review on this area with emphasis on state-of-the-art multi-label learning algorithms. Firstly, fundamentals on multi-label learning including formal definition and evaluation metrics are given. Secondly and primarily, eight representative multi-label learning algorithms are scrutinized under common notations with relevant analyses and discussions. Thirdly, several related learning settings are briefly summarized. As a conclusion, online resources and open research problems on multi-label learning are outlined for reference purposes.",2014,201,2102,182,False,Computer Science,3039887,Min-Ling Zhang,145624000.0,Zhi-Hua Zhou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e6cb9e80d1894bbb01882523137145d81dfb0a3c,https://www.semanticscholar.org/paper/e6cb9e80d1894bbb01882523137145d81dfb0a3c,The SHOGUN Machine Learning Toolbox,"We have developed a machine learning toolbox, called SHOGUN, which is designed for unified large-scale learning for a broad range of feature types and learning settings. It offers a considerable number of machine learning models such as support vector machines, hidden Markov models, multiple kernel learning, linear discriminant analysis, and more. Most of the specific algorithms are able to deal with several different data classes. We have used this toolbox in several applications from computational biology, some of them coming with no less than 50 million training examples and others with 7 billion test examples. With more than a thousand installations worldwide, SHOGUN is already widely adopted in the machine learning community and beyond. 
 
SHOGUN is implemented in C++ and interfaces to MATLABTM, R, Octave, Python, and has a stand-alone command line interface. The source code is freely available under the GNU General Public License, Version 3 at http://www.shogun-toolbox.org.",2010,11,292,17,False,Computer Science,3029782,S. Sonnenburg,2414086.0,G. Rätsch,2574834.0,S. Henschel,3263887.0,Christian Widmer,2094634.0,Jonas Behr,2281542.0,A. Zien,,1933978557.0,F. D. Bona,49345823.0,Alexander Binder,2140119.0,C. Gehl,1778663.0,Vojtech Franc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
395dd01c0d24777c660cf195c4cfadcdf51fb7e8,https://www.semanticscholar.org/paper/395dd01c0d24777c660cf195c4cfadcdf51fb7e8,Learning to learn by gradient descent by gradient descent,"The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.",2016,42,1484,166,False,Computer Science,2206490,Marcin Andrychowicz,1715051.0,Misha Denil,2016840.0,Sergio Gomez Colmenarejo,3243579.0,Matthew W. Hoffman,144846367.0,D. Pfau,1725157.0,T. Schaul,,1737568.0,N. D. Freitas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7ab0f0da686cd4094fd96f5a30e0b6072525fd09,https://www.semanticscholar.org/paper/7ab0f0da686cd4094fd96f5a30e0b6072525fd09,Deep Learning in Medical Image Analysis.,"This review covers computer-assisted analysis of images in the field of medical imaging. Recent advances in machine learning, especially with regard to deep learning, are helping to identify, classify, and quantify patterns in medical images. At the core of these advances is the ability to exploit hierarchical feature representations learned solely from data, instead of features designed by hand according to domain-specific knowledge. Deep learning is rapidly becoming the state of the art, leading to enhanced performance in various medical applications. We introduce the fundamentals of deep learning methods and review their successes in image registration, detection of anatomical and cellular structures, tissue segmentation, computer-aided disease diagnosis and prognosis, and so on. We conclude by discussing research issues and suggesting future directions for further improvement.",2017,127,1470,16,True,Medicine,144986260,D. Shen,46531894.0,Guorong Wu,143802908.0,Heung-Il Suk,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4b61c25a86083c20730c9b12737ac6ac4178c364,https://www.semanticscholar.org/paper/4b61c25a86083c20730c9b12737ac6ac4178c364,An Introduction to Deep Reinforcement Learning,"Deep reinforcement learning is the combination of reinforcement learning (RL) and deep learning. This field of research has been able to solve a wide range of complex decision-making tasks that were previously out of reach for a machine. Thus, deep RL opens up many new applications in domains such as healthcare, robotics, smart grids, finance, and many more. This manuscript provides an introduction to deep reinforcement learning models, algorithms and techniques. Particular focus is on the aspects related to generalization and how deep RL can be used for practical applications. We assume the reader is familiar with basic machine learning concepts.",2018,355,606,41,True,Computer Science,1389921282,Vincent François-Lavet,40068904.0,Peter Henderson,18014232.0,Riashat Islam,1792298.0,Marc G. Bellemare,145134886.0,Joelle Pineau,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53,https://www.semanticscholar.org/paper/5c04f8002e24a8c09bfbfedca3c6c346fe1e5d53,An Introduction to Support Vector Machines and Other Kernel-based Learning Methods,"From the publisher: This is the first comprehensive introduction to Support Vector Machines (SVMs), a new generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.",2000,27,13846,1176,True,Mathematics,1685083,N. Cristianini,1404459229.0,J. Shawe-Taylor,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cb8a1b8d87a3fef15635eb4a32173f9c6f966055,https://www.semanticscholar.org/paper/cb8a1b8d87a3fef15635eb4a32173f9c6f966055,A Survey on Deep Learning,"The field of machine learning is witnessing its golden era as deep learning slowly becomes the leader in this domain. Deep learning uses multiple layers to represent the abstractions of data to build computational models. Some key enabler deep learning algorithms such as generative adversarial networks, convolutional neural networks, and model transfers have completely changed our perception of information processing. However, there exists an aperture of understanding behind this tremendously fast-paced domain, because it was never previously represented from a multiscope perspective. The lack of core understanding renders these powerful methods as black-box machines that inhibit development at a fundamental level. Moreover, deep learning has repeatedly been perceived as a silver bullet to all stumbling blocks in machine learning, which is far from the truth. This article presents a comprehensive review of historical and recent state-of-the-art approaches in visual, audio, and text processing; social network analysis; and natural language processing, followed by the in-depth analysis on pivoting and groundbreaking advances in deep learning applications. It was also undertaken to review the issues faced in deep learning such as unsupervised learning, black-box models, and online learning and to illustrate how these challenges can be transformed into prolific future research avenues.",2018,183,410,11,False,Computer Science,1997924,Samira Pouyanfar,8062083.0,Saad Sadiq,39588413.0,Yilin Yan,2229900.0,Haiman Tian,2868174.0,Yudong Tao,39611894.0,Maria E. Presa-Reyes,,144987531.0,M. Shyu,1705664.0,Shu‐Ching Chen,153093860.0,S. S. Iyengar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b57e6468740d9320f3f14c6079168b8e21366416,https://www.semanticscholar.org/paper/b57e6468740d9320f3f14c6079168b8e21366416,The History Began from AlexNet: A Comprehensive Survey on Deep Learning Approaches,"Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].",2018,287,498,56,False,Computer Science,1932404,Md. Zahangir Alom,1799779.0,T. Taha,2498059.0,C. Yakopcic,40893684.0,Stefan Westberg,2325550.0,P. Sidike,100898809.0,M. S. Nasrin,,32977294.0,B. V. Essen,144948131.0,A. Awwal,2401900.0,V. Asari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38aff6df1accc456f6cda7d16d4b9ecf418ef21e,https://www.semanticscholar.org/paper/38aff6df1accc456f6cda7d16d4b9ecf418ef21e,Map-Reduce for Machine Learning on Multicore,"We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and unified way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly applicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Specifically, we show that algorithms that fit the Statistical Query model [15] can be written in a certain ""summation form,"" which allows them to be easily parallelized on multicore computers. We adapt Google's map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regression (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors.",2006,31,1143,55,False,Computer Science,2551676,Cheng-Tao Chu,2109828167.0,Sang Kyun Kim,47904256.0,Yi-An Lin,2117163611.0,YuanYuan Yu,1720184.0,G. Bradski,34699434.0,A. Ng,,1746638.0,K. Olukotun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7e7b9f37ce280787075046727efbaf9b5a390729,https://www.semanticscholar.org/paper/7e7b9f37ce280787075046727efbaf9b5a390729,Applications of Machine Learning in Cancer Prediction and Prognosis,"Machine learning is a branch of artificial intelligence that employs a variety of statistical, probabilistic and optimization techniques that allows computers to “learn” from past examples and to detect hard-to-discern patterns from large, noisy or complex data sets. This capability is particularly well-suited to medical applications, especially those that depend on complex proteomic and genomic measurements. As a result, machine learning is frequently used in cancer diagnosis and detection. More recently machine learning has been applied to cancer prognosis and prediction. This latter approach is particularly interesting as it is part of a growing trend towards personalized, predictive medicine. In assembling this review we conducted a broad survey of the different types of machine learning methods being used, the types of data being integrated and the performance of these methods in cancer prediction and prognosis. A number of trends are noted, including a growing dependence on protein biomarkers and microarray data, a strong bias towards applications in prostate and breast cancer, and a heavy reliance on “older” technologies such artificial neural networks (ANNs) instead of more recently developed or more easily interpretable machine learning methods. A number of published studies also appear to lack an appropriate level of validation or testing. Among the better designed and validated studies it is clear that machine learning methods can be used to substantially (15–25%) improve the accuracy of predicting cancer susceptibility, recurrence and mortality. At a more fundamental level, it is also evident that machine learning is also helping to improve our basic understanding of cancer development and progression.",2006,210,902,28,True,Computer Science,34468738,Joseph A. Cruz,2066145.0,D. Wishart,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dc0c84b7c5e6521216da789f8171544709120cf0,https://www.semanticscholar.org/paper/dc0c84b7c5e6521216da789f8171544709120cf0,Opportunities and obstacles for deep learning in biology and medicine,"Deep learning, which describes a class of machine learning algorithms, has recently showed impressive results across a variety of domains. Biology and medicine are data rich, but the data are complex and often ill-understood. Problems of this nature may be particularly well-suited to deep learning techniques. We examine applications of deep learning to a variety of biomedical problems -- patient classification, fundamental biological processes, and treatment of patients -- to predict whether deep learning will transform these tasks or if the biomedical sphere poses unique challenges. We find that deep learning has yet to revolutionize or definitively resolve any of these problems, but promising advances have been made on the prior state of the art. Even when improvement over a previous baseline has been modest, we have seen signs that deep learning methods may speed or aid human investigation. More work is needed to address concerns related to interpretability and how to best model each problem. Furthermore, the limited amount of labeled data for training presents problems in some domains, as can legal and privacy constraints on work with sensitive health records. Nonetheless, we foresee deep learning powering changes at the bench and bedside with the potential to transform several areas of biology and medicine.",2017,628,1219,18,True,Biology,5926615,T. Ching,1868440.0,Daniel S. Himmelstein,1402651503.0,Brett K. Beaulieu-Jones,32985843.0,Alexandr A Kalinin,48154546.0,Brian T Do,3738725.0,Gregory P. Way,Computer Science,137381074.0,E. Ferrero,2236448.0,P. Agapow,40862218.0,M. Zietz,35290352.0,M. M. Hoffman,Medicine,1993128574.0,W. Xie,6997856.0,G. Rosen,6580840.0,Benjamin J. Lengerich,39246361.0,Johnny Israeli,3369052.0,Jack Lanchantin,8230326.0,S. Woloszynek,1721012.0,Anne E Carpenter,3407268.0,Avanti Shrikumar,1807918.0,Jinbo Xu,30469485.0,Evan M. Cofer,39291675.0,C. A. Lavender,3178417.0,Srinivas C. Turaga,35786407.0,Amr M. Alexandari,144202084.0,Zhiyong Lu,145192391.0,David J Harris,1973239.0,D. DeCaprio,121817403.0,Yanjun Qi,2844479.0,A. Kundaje,2699239.0,Yifan Peng,3116087.0,L. K. Wiley,3451383.0,Marwin H. S. Segler,2831521.0,S. Boca,7946353.0,S. Joshua Joshua Swamidass,119855034.0,Austin Huang,2041407.0,A. Gitter,2104940.0,C. Greene
4d931ea98be69882f547ec6c1b42b78c3e13c36d,https://www.semanticscholar.org/paper/4d931ea98be69882f547ec6c1b42b78c3e13c36d,Quantum circuit learning,"We propose a classical-quantum hybrid algorithm for machine learning on near-term quantum processors, which we call quantum circuit learning. A quantum circuit driven by our framework learns a given task by tuning parameters implemented on it. The iterative optimization of the parameters allows us to circumvent the high-depth circuit. Theoretical investigation shows that a quantum circuit can approximate nonlinear functions, which is further confirmed by numerical simulations. Hybridizing a low-depth quantum circuit and a classical computer for machine learning, the proposed framework paves the way toward applications of near-term quantum devices for quantum machine learning.",2018,43,563,39,True,Computer Science,89418147,K. Mitarai,31729454.0,M. Negoro,2460970.0,M. Kitagawa,144950743.0,K. Fujii,,,,,Physics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
293987e14d64dc768a432115c93171ab8653e3bb,https://www.semanticscholar.org/paper/293987e14d64dc768a432115c93171ab8653e3bb,Machine Learning in Medical Imaging,"This article will discuss very different ways of using machine learning that may be less familiar, and we will demonstrate through examples the role of these concepts in medical imaging. Although the term machine learning is relatively recent, the ideas of machine learning have been applied to medical imaging for decades, perhaps most notably in the areas of computer-aided diagnosis (CAD) and functional brain mapping. We will not attempt in this brief article to survey the rich literature of this field. Instead our goals will be 1) to acquaint the reader with some modern techniques that are now staples of the machine-learning field and 2) to illustrate how these techniques can be employed in various ways in medical imaging.",2010,51,213,3,True,Computer Science,3067670,M. Wernick,46286398.0,Yongyi Yang,2489609.0,J. Brankov,3182604.0,G. Yourganov,2790050.0,S. Strother,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60f43e763b370af0028317d7f6d94885cdfe390a,https://www.semanticscholar.org/paper/60f43e763b370af0028317d7f6d94885cdfe390a,Federated Learning,"How is it possible to allow multiple data owners to collaboratively train and use a shared prediction model while keeping all the local training data private? Traditional machine learning approaches need to combine all data at one location, typically a data center, which may very well violate the laws on user privacy and data confidentiality. Today, many parts of the world demand that technology companies treat user data carefully according to user-privacy laws. The European Union’s General Data Protection Regulation (GDPR) is a prime example. In this book, we describe how federated machine learning addresses this problem with novel solutions combining distributed machine learning, cryptography and security, and incentive mechanism design based on economic principles and game theory. We explain different types of privacypreserving machine learning solutions and their technological backgrounds, and highlight some representative practical use cases.We show how federated learning can become the foundation of next-generation machine learning that caters to technological and societal needs for responsible AI development and application.",2019,172,270,13,False,Computer Science,153096457,Qiang Yang,1614034792.0,Yang Liu,2157394918.0,Yong Cheng,1505828520.0,Yan Kang,11573257.0,Tianjian Chen,2110984588.0,Han Yu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
da5c65b0ac8b525c3d3d4889bf44d8a48d254a07,https://www.semanticscholar.org/paper/da5c65b0ac8b525c3d3d4889bf44d8a48d254a07,Deep Bayesian Active Learning with Image Data,"Even though active learning forms an important pillar of machine learning, deep learning tools are not prevalent within it. Deep learning poses several difficulties when used in an active learning setting. First, active learning (AL) methods generally rely on being able to learn and update models from small amounts of data. Recent advances in deep learning, on the other hand, are notorious for their dependence on large amounts of data. Second, many AL acquisition functions rely on model uncertainty, yet deep learning methods rarely represent such model uncertainty. In this paper we combine recent advances in Bayesian deep learning into the active learning framework in a practical way. We develop an active learning framework for high dimensional data, a task which has been extremely challenging so far, with very sparse existing literature. Taking advantage of specialised models such as Bayesian convolutional neural networks, we demonstrate our active learning techniques with image data, obtaining a significant improvement on existing active learning approaches. We demonstrate this on both the MNIST dataset, as well as for skin cancer diagnosis from lesion images (ISIC2016 task).",2017,42,1014,166,False,Computer Science,2681954,Y. Gal,18014232.0,Riashat Islam,1744700.0,Zoubin Ghahramani,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfea40bf4e4131aab2727e3aaedcf02c1dd594ac,https://www.semanticscholar.org/paper/cfea40bf4e4131aab2727e3aaedcf02c1dd594ac,Bidirectional Extreme Learning Machine for Regression Problem and Its Learning Effectiveness,"It is clear that the learning effectiveness and learning speed of neural networks are in general far slower than required, which has been a major bottleneck for many applications. Recently, a simple and efficient learning method, referred to as extreme learning machine (ELM), was proposed by Huang , which has shown that, compared to some conventional methods, the training time of neural networks can be reduced by a thousand times. However, one of the open problems in ELM research is whether the number of hidden nodes can be further reduced without affecting learning effectiveness. This brief proposes a new learning algorithm, called bidirectional extreme learning machine (B-ELM), in which some hidden nodes are not randomly selected. In theory, this algorithm tends to reduce network output error to 0 at an extremely early learning stage. Furthermore, we find a relationship between the network output error and the network output weights in the proposed B-ELM. Simulation results demonstrate that the proposed method can be tens to hundreds of times faster than other incremental ELM algorithms.",2012,14,162,6,False,Computer Science,2108776795,Yimin Yang,2119048509.0,Yaonan Wang,2474758.0,Xiaofang Yuan,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c4ae802491724aee021f31f02327b9671cead3dc,https://www.semanticscholar.org/paper/c4ae802491724aee021f31f02327b9671cead3dc,Types of Machine Learning Algorithms,"• Supervised learning --where the algorithm generates a function that maps inputs to desired outputs. One standard formulation of the supervised learning task is the classification problem: the learner is required to learn (to approximate the behavior of) a function which maps a vector into one of several classes by looking at several input-output examples of the function. • Unsupervised learning --which models a set of inputs: labeled examples are not available. • Semi-supervised learning --which combines both labeled and unlabeled examples to generate an appropriate function or classifier. • Reinforcement learning --where the algorithm learns a policy of how to act given an observation of the world. Every action has some impact in the environment, and the environment provides feedback that guides the learning algorithm. • Transduction --similar to supervised learning, but does not explicitly construct a function: instead, tries to predict new outputs based on training inputs, training outputs, and new inputs. • Learning to learn --where the algorithm learns its own inductive bias based on previous experience.",2010,57,280,14,False,Computer Science,145298622,T. Ayodele,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
276194e96ebd620b5cff35a9168bdda39a0be57b,https://www.semanticscholar.org/paper/276194e96ebd620b5cff35a9168bdda39a0be57b,Federated Multi-Task Learning,"Federated learning poses new statistical and systems challenges in training machine learning models over distributed networks of devices. In this work, we show that multi-task learning is naturally suited to handle the statistical challenges of this setting, and propose a novel systems-aware optimization method, MOCHA, that is robust to practical systems issues. Our method and theory for the first time consider issues of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. The resulting method achieves significant speedups compared to alternatives in the federated setting, as we demonstrate through simulations on real-world federated datasets.",2017,57,900,74,False,Computer Science,145260024,Virginia Smith,2054892.0,Chao-Kai Chiang,2095979.0,Maziar Sanjabi,145532827.0,Ameet S. Talwalkar,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a20bfec3c95aad003dcb45a21a220c19cca8bb66,https://www.semanticscholar.org/paper/a20bfec3c95aad003dcb45a21a220c19cca8bb66,A Machine Learning Approach to Coreference Resolution of Noun Phrases,"In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text. The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases. It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of organization, person, or other types. We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, indicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches. Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.",2001,24,1091,150,True,Computer Science,2248565,W. M. Soon,34789794.0,H. Ng,3216372.0,Chung Yong Lim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
066dd3d09eb5815e8be1da560abd1abe08f87cb9,https://www.semanticscholar.org/paper/066dd3d09eb5815e8be1da560abd1abe08f87cb9,OP-ELM: Optimally Pruned Extreme Learning Machine,"In this brief, the optimally pruned extreme learning machine (OP-ELM) methodology is presented. It is based on the original extreme learning machine (ELM) algorithm with additional steps to make it more robust and generic. The whole methodology is presented in detail and then applied to several regression and classification problems. Results for both computational time and accuracy (mean square error) are compared to the original ELM and to three other widely used methodologies: multilayer perceptron (MLP), support vector machine (SVM), and Gaussian process (GP). As the experiments for both regression and classification illustrate, the proposed OP-ELM methodology performs several orders of magnitude faster than the other algorithms used in this brief, except the original ELM. Despite the simplicity and fast performance, the OP-ELM is still able to maintain an accuracy that is comparable to the performance of the SVM. A toolbox for the OP-ELM is publicly available online.",2010,17,716,47,False,Computer Science,3194493,Y. Miché,2500799.0,A. Sorjamaa,144224330.0,P. Bas,1738231.0,O. Simula,1696508.0,C. Jutten,1731049.0,A. Lendasse,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0ef9ae1ce8c91ce671a211bdda792bf3752d1522,https://www.semanticscholar.org/paper/0ef9ae1ce8c91ce671a211bdda792bf3752d1522,A Deep Learning Approach for Intrusion Detection Using Recurrent Neural Networks,"Intrusion detection plays an important role in ensuring information security, and the key technology is to accurately identify various attacks in the network. In this paper, we explore how to model an intrusion detection system based on deep learning, and we propose a deep learning approach for intrusion detection using recurrent neural networks (RNN-IDS). Moreover, we study the performance of the model in binary classification and multiclass classification, and the number of neurons and different learning rate impacts on the performance of the proposed model. We compare it with those of J48, artificial neural network, random forest, support vector machine, and other machine learning methods proposed by previous researchers on the benchmark data set. The experimental results show that RNN-IDS is very suitable for modeling a classification model with high accuracy and that its performance is superior to that of traditional machine learning classification methods in both binary and multiclass classification. The RNN-IDS model improves the accuracy of the intrusion detection and provides a new research method for intrusion detection.",2017,26,898,65,False,Computer Science,30796665,Chuanlong Yin,1733625.0,Yuefei Zhu,2191560.0,Jin-long Fei,50046030.0,Xin-Zheng He,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8de174ab5419b9d3127695405efd079808e956e8,https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8,Curriculum learning,"Humans and animals learn much better when the examples are not randomly presented but organized in a meaningful order which illustrates gradually more concepts, and gradually more complex ones. Here, we formalize such training strategies in the context of machine learning, and call them ""curriculum learning"". In the context of recent research studying the difficulty of training in the presence of non-convex training criteria (for deep deterministic and stochastic neural networks), we explore curriculum learning in various set-ups. The experiments show that significant improvements in generalization can be achieved. We hypothesize that curriculum learning has both an effect on the speed of convergence of the training process to a minimum and, in the case of non-convex criteria, on the quality of the local minima obtained: curriculum learning can be seen as a particular form of continuation method (a general strategy for global optimization of non-convex functions).",2009,33,3609,317,False,Computer Science,1751762,Yoshua Bengio,2373952.0,J. Louradour,2939803.0,Ronan Collobert,145183709.0,J. Weston,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9d3e0fce253a4ae4a4456b2f24c03329a2b74621,https://www.semanticscholar.org/paper/9d3e0fce253a4ae4a4456b2f24c03329a2b74621,Deep Learning for Health Informatics,"With a massive influx of multimodality data, the role of data analytics in health informatics has grown rapidly in the last decade. This has also prompted increasing interests in the generation of analytical, data driven models based on machine learning in health informatics. Deep learning, a technique with its foundation in artificial neural networks, is emerging in recent years as a powerful tool for machine learning, promising to reshape the future of artificial intelligence. Rapid improvements in computational power, fast data storage, and parallelization have also contributed to the rapid uptake of the technology in addition to its predictive power and ability to generate automatically optimized high-level features and semantic interpretation from the input data. This article presents a comprehensive up-to-date review of research employing deep learning in health informatics, providing a critical analysis of the relative merit, and potential pitfalls of the technique as well as its future outlook. The paper mainly focuses on key applications of deep learning in the fields of translational bioinformatics, medical imaging, pervasive sensing, medical informatics, and public health.",2017,164,1106,34,False,Computer Science,1859140,D. Ravì,1905807.0,Charence Wong,2775904.0,F. Deligianni,3163767.0,M. Berthelot,1443783456.0,Javier Andreu-Perez,1745644.0,Benny P. L. Lo,Medicine,144574968.0,Guang-Zhong Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9f1e9e56d80146766bc2316efbc54d8b770a23df,https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df,Deep Reinforcement Learning: An Overview,"We give an overview of recent exciting achievements of deep reinforcement learning (RL). We discuss six core elements, six important mechanisms, and twelve applications. We start with background of machine learning, deep learning and reinforcement learning. Next we discuss core RL elements, including value function, in particular, Deep Q-Network (DQN), policy, reward, model, planning, and exploration. After that, we discuss important mechanisms for RL, including attention and memory, unsupervised learning, transfer learning, multi-agent RL, hierarchical RL, and learning to learn. Then we discuss various applications of RL, including games, in particular, AlphaGo, robotics, natural language processing, including dialogue systems, machine translation, and text generation, computer vision, neural architecture design, business management, finance, healthcare, Industry 4.0, smart grid, intelligent transportation systems, and computer systems. We mention topics not reviewed yet, and list a collection of RL resources. After presenting a brief summary, we close with discussions. 
Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant update.",2017,584,844,77,False,Computer Science,2276894,Yuxi Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64be9999b68e12d260ba7423f6b55ffd41552ad3,https://www.semanticscholar.org/paper/64be9999b68e12d260ba7423f6b55ffd41552ad3,Deep Learning Applications in Medical Image Analysis,"The tremendous success of machine learning algorithms at image recognition tasks in recent years intersects with a time of dramatically increased use of electronic medical records and diagnostic imaging. This review introduces the machine learning algorithms as applied to medical image analysis, focusing on convolutional neural networks, and emphasizing clinical aspects of the field. The advantage of machine learning in an era of medical big data is that significant hierarchal relationships within the data can be discovered algorithmically without laborious hand-crafting of features. We cover key research areas and applications of medical image classification, localization, detection, segmentation, and registration. We conclude by discussing research obstacles, emerging trends, and possible future directions.",2018,140,697,10,False,Computer Science,34812292,Justin Ker,46659335.0,Lipo Wang,39917910.0,J. Rao,48508646.0,Tchoyoson C. C. Lim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7574bfa9fa539f1ccbaeabc7c82c295d6143b84c,https://www.semanticscholar.org/paper/7574bfa9fa539f1ccbaeabc7c82c295d6143b84c,Reinforcement Learning,"Reinforcement learning is an approach to artificial intelligence that emphasizes learning by the individual from its interaction with its environment. This contrasts with classical approaches to artificial intelligence and machine learning, which have downplayed learning from interaction, focusing instead on learning from a knowledgeable teacher, or on reasoning from a complete model of the environment. Modern reinforcement learning research is highly interdisciplinary; it includes researchers specializing in operations research, genetic algorithms, neural networks, psychology, and control engineering. Reinforcement learning is learning what to do—how to map situations to actions—so as to maximize a scalar reward signal. The learner is not told which action to take, as in most forms of machine learning, but instead must discover which actions yield the most reward by trying them. In the most interesting and challenging cases, actions may affect not only the immediate reward, but also the next situation, and through that all subsequent rewards. These two characteristics—trial-and-error search and delayed reward—are the two most important distinguishing features of reinforcement learning. One of the challenges that arises in reinforcement learning and not in other kinds of learning is the tradeoff between exploration and exploitation. To obtain a lot of reward, a reinforcement learning agent must prefer actions that it has tried in the past and found to be effective in producing reward. But to discover which actions these are it has to select actions that it has not tried before. The agent has to exploit what it already knows in order to obtain reward, but it also has to explore in order to make better action selections in the future. The dilemma is that neither exploitation nor exploration can be pursued exclusively without failing at the task. Modern reinforcement learning research uses the formal framework of",1992,33,511,12,False,Computer Science,1699645,R. Sutton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
db64f424710d57025c5fb42a564551f093a4d111,https://www.semanticscholar.org/paper/db64f424710d57025c5fb42a564551f093a4d111,The Extreme Value Machine,"It is often desirable to be able to recognize when inputs to a recognition function learned in a supervised manner correspond to classes unseen at training time. With this ability, new class labels could be assigned to these inputs by a human operator, allowing them to be incorporated into the recognition function—ideally under an efficient incremental update mechanism. While good algorithms that assume inputs from a fixed set of classes exist, e.g. , artificial neural networks and kernel machines, it is not immediately obvious how to extend them to perform incremental learning in the presence of unknown query classes. Existing algorithms take little to no distributional information into account when learning recognition functions and lack a strong theoretical foundation. We address this gap by formulating a novel, theoretically sound classifier—the Extreme Value Machine (EVM). The EVM has a well-grounded interpretation derived from statistical Extreme Value Theory (EVT), and is the first classifier to be able to perform nonlinear kernel-free variable bandwidth incremental learning. Compared to other classifiers in the same deep network derived feature space, the EVM is accurate and efficient on an established benchmark partition of the ImageNet dataset.",2015,67,164,25,False,Computer Science,39886114,Ethan M. Rudd,34939951.0,Lalit P. Jain,2613438.0,W. Scheirer,32163276.0,T. Boult,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cc7827a17a7759a04aa389290d1a874db56e85e5,https://www.semanticscholar.org/paper/cc7827a17a7759a04aa389290d1a874db56e85e5,Meta-Learning: A Survey,"Meta-learning, or learning to learn, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or meta-data, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving field.",2018,207,369,22,False,Computer Science,1717534,J. Vanschoren,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12d1d070a53d4084d88a77b8b143bad51c40c38f,https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f,Reinforcement Learning: A Survey,"This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word ""reinforcement."" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning.",1996,128,7677,435,True,Computer Science,1709512,L. Kaelbling,144885169.0,M. Littman,1760402.0,A. Moore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4ea55038daf0907d27296de047008fb58def41c5,https://www.semanticscholar.org/paper/4ea55038daf0907d27296de047008fb58def41c5,Applications of Deep Learning and Reinforcement Learning to Biological Data,"Rapid advances in hardware-based technologies during the past decades have opened up new possibilities for life scientists to gather multimodal data in various application domains, such as omics, bioimaging, medical imaging, and (brain/body)–machine interfaces. These have generated novel opportunities for development of dedicated data-intensive machine learning techniques. In particular, recent research in deep learning (DL), reinforcement learning (RL), and their combination (deep RL) promise to revolutionize the future of artificial intelligence. The growth in computational power accompanied by faster and increased data storage, and declining computing costs have already allowed scientists in various fields to apply these techniques on data sets that were previously intractable owing to their size and complexity. This paper provides a comprehensive survey on the application of DL, RL, and deep RL techniques in mining biological data. In addition, we compare the performances of DL techniques when applied to different data sets across various application domains. Finally, we outline open issues in this challenging research area and discuss future development perspectives.",2017,222,466,3,True,Computer Science,144774721,M. Mahmud,4216715.0,M. S. Kaiser,144664815.0,A. Hussain,47323504.0,S. Vassanelli,,,,,Mathematics,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7e910b031e703caf683d44d7417d702a5aba2e95,https://www.semanticscholar.org/paper/7e910b031e703caf683d44d7417d702a5aba2e95,"Handbook Of Research On Machine Learning Applications and Trends: Algorithms, Methods and Techniques (2 Volumes)","The machine learning approach provides a useful tool when the amount of data is very large and a model is not available to explain the generation and relation of the data set. The Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques provides a set of practical applications for solving problems and applying various techniques in automatic data extraction and setting. A defining collection of field advancements, this Handbook of Research fills the gap between theory and practice, providing a strong reference for academicians, researchers, and practitioners.",2009,83,368,6,True,Computer Science,2060576305,E. S. Olivas,103992067.0,J. D. M. Guerrero,71631370.0,M. M. Sober,35119570.0,J. Benedito,152692443.0,A. López,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a191715b2e3e51cc08114e759b7bf7fdf9f2c206,https://www.semanticscholar.org/paper/a191715b2e3e51cc08114e759b7bf7fdf9f2c206,Deep Learning with Python,"Summary Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher Franois Chollet, this book builds your understanding through intuitive explanations and practical examples. Purchase of the print book includes a free eBook in PDF, Kindle, and ePub formats from Manning Publications. About the Technology Machine learning has made remarkable progress in recent years. We went from near-unusable speech and image recognition, to near-human accuracy. We went from machines that couldn't beat a serious Go player, to defeating a world champion. Behind this progress is deep learninga combination of engineering advances, best practices, and theory that enables a wealth of previously impossible smart applications. About the Book Deep Learning with Python introduces the field of deep learning using the Python language and the powerful Keras library. Written by Keras creator and Google AI researcher Franois Chollet, this book builds your understanding through intuitive explanations and practical examples. You'll explore challenging concepts and practice with applications in computer vision, natural-language processing, and generative models. By the time you finish, you'll have the knowledge and hands-on skills to apply deep learning in your own projects. What's Inside Deep learning from first principles Setting up your own deep-learning environment Image-classification models Deep learning for text and sequences Neural style transfer, text generation, and image generation About the Reader Readers need intermediate Python skills. No previous experience with Keras, TensorFlow, or machine learning is required. About the Author Franois Chollet works on deep learning at Google in Mountain View, CA. He is the creator of the Keras deep-learning library, as well as a contributor to the TensorFlow machine-learning framework. He also does deep-learning research, with a focus on computer vision and the application of machine learning to formal reasoning. His papers have been published at major conferences in the field, including the Conference on Computer Vision and Pattern Recognition (CVPR), the Conference and Workshop on Neural Information Processing Systems (NIPS), the International Conference on Learning Representations (ICLR), and others.",2017,0,442,41,False,Computer Science,1565641737,François Chollet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
efd68f3724942c9de5dc804d3c7cb3f70f42234b,https://www.semanticscholar.org/paper/efd68f3724942c9de5dc804d3c7cb3f70f42234b,Deep learning for computational biology,"Technological advances in genomics and imaging have led to an explosion of molecular and cellular profiling data from large numbers of samples. This rapid increase in biological data dimension and acquisition rate is challenging conventional analysis strategies. Modern machine learning methods, such as deep learning, promise to leverage very large data sets for finding hidden structure within them, and for making accurate predictions. In this review, we discuss applications of this new breed of analysis approaches in regulatory genomics and cellular imaging. We provide background of what deep learning is, and the settings in which it can be successfully applied to derive biological insights. In addition to presenting specific applications and providing tips for practical use, we also highlight possible pitfalls and limitations to guide computational biologists when and how to make the most use of this new technology.",2016,136,937,29,False,Medicine,2414348,Christof Angermueller,3451978.0,Tanel Pärnamaa,2827805.0,L. Parts,152423211.0,O. Stegle,,,,,Biology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
767dcaf77f73f958cfee0f54cfcde0882e8ec50e,https://www.semanticscholar.org/paper/767dcaf77f73f958cfee0f54cfcde0882e8ec50e,Deep Learning: A Practitioner's Approach,"Although interest in machine learning has reached a high point, lofty expectations often scuttle projects before they get very far. How can machine learningespecially deep neural networksmake a real difference in your organization? This hands-on guide not only provides the most practical information available on the subject, but also helps you get started building efficient deep learning networks. Authors Adam Gibson and Josh Patterson provide theory on deep learning before introducing their open-source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, youll learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J. Dive into machine learning concepts in general, as well as deep learning in particular Understand how deep networks evolved from neural network fundamentals Explore the major deep network architectures, including Convolutional and Recurrent Learn how to map specific deep networks to the right problem Walk through the fundamentals of tuning general neural networks and specific deep network architectures Use vectorization techniques for different data types with DataVec, DL4Js workflow toolLearn how to use DL4J natively on Spark and Hadoop",2017,0,362,50,False,Computer Science,2055466552,Joshua Patterson,2052126530.0,Adam Gibson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
298af26244e3ad836c1aa5cf5855d05f5197063d,https://www.semanticscholar.org/paper/298af26244e3ad836c1aa5cf5855d05f5197063d,Machine Learning Methods Without Tears: A Primer for Ecologists,"Machine learning methods, a family of statistical techniques with origins in the field of artificial intelligence, are recognized as holding great promise for the advancement of understanding and prediction about ecological phenomena. These modeling techniques are flexible enough to handle complex problems with multiple interacting elements and typically outcompete traditional approaches (e.g., generalized linear models), making them ideal for modeling ecological systems. Despite their inherent advantages, a review of the literature reveals only a modest use of these approaches in ecology as compared to other disciplines. One potential explanation for this lack of interest is that machine learning techniques do not fall neatly into the class of statistical modeling approaches with which most ecologists are familiar. In this paper, we provide an introduction to three machine learning approaches that can be broadly used by ecologists: classification and regression trees, artificial neural networks, and evolutionary computation. For each approach, we provide a brief background to the methodology, give examples of its application in ecology, describe model development and implementation, discuss strengths and weaknesses, explore the availability of statistical software, and provide an illustrative example. Although the ecological application of machine learning approaches has increased, there remains considerable skepticism with respect to the role of these techniques in ecology. Our review encourages a greater understanding of machine learning approaches and promotes their future application and utilization, while also providing a basis from which ecologists can make informed decisions about whether to select or avoid these approaches in their future modeling endeavors.",2008,110,563,35,True,Computer Science,2008387,J. Olden,34870951.0,J. Lawler,1991309.0,N. Poff,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6241276a3074f73c1ce9b9ce4ac69f748732aecd,https://www.semanticscholar.org/paper/6241276a3074f73c1ce9b9ce4ac69f748732aecd,Data Mining and Machine Learning in Astronomy,"We review the current state of data mining and machine learning in astronomy. 'Data Mining' can have a somewhat mixed connotation from the point of view of a researcher in this field. If used correctly, it can be a powerful approach, holding the potential to fully exploit the exponentially increasing amount of available data, promising great scientific advance. However, if misused, it can be little more than the black-box application of complex computing algorithms that may give little physical insight, and provide questionable results. Here, we give an overview of the entire data mining process, from data collection through to the interpretation of results. We cover common machine learning algorithms, such as artificial neural networks and support vector machines, applications from a broad range of astronomy, emphasizing those where data mining techniques directly resulted in improved science, and important current and future directions, including probability density functions, parallel algorithms, petascale computing, and the time domain. We conclude that, so long as one carefully selects an appropriate algorithm, and is guided by the astronomical problem at hand, data mining can be very much the powerful tool, and not the questionable black box.",2009,314,271,16,True,Physics,2332144,N. Ball,102648043.0,Robert J. Brunner Herzberg Institute of Astrophysics,2073777983.0,Victoria,80559887.0,Bc,69477256.0,Canada.,102339916.0,D. O. Astronomy,,103072545.0,U. I. Urbana-Champaign,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cf8f2ca0c2d618104bc8724a6effc509088f16c4,https://www.semanticscholar.org/paper/cf8f2ca0c2d618104bc8724a6effc509088f16c4,Never-Ending Learning,"Whereas people learn many different types of knowledge from diverse experiences over many years, most current machine learning systems acquire just a single function or data model from just a single data set. We propose a neverending learning paradigm for machine learning, to better reflect the more ambitious and encompassing type of learning performed by humans. As a case study, we describe the Never-Ending Language Learner (NELL), which achieves some of the desired properties of a never-ending learner, and we discuss lessons learned. NELL has been learning to read the web 24 hours/day since January 2010, and so far has acquired a knowledge base with over 80 million confidenceweighted beliefs (e.g., servedWith(tea, biscuits)). NELL has also learned millions of features and parameters that enable it to read these beliefs from the web. Additionally, it has learned to reason over these beliefs to infer new beliefs, and is able to extend its ontology by synthesizing new relational predicates. NELL can be tracked online at http://rtw.ml.cmu.edu, and followed on Twitter at @CMUNELL.",2012,58,823,60,True,Computer Science,40975594,Tom Michael Mitchell,50056360.0,William W. Cohen,1842532.0,Estevam Hruschka,2406435.0,Partha P. Talukdar,2119660368.0,Bo Yang,31779043.0,J. Betteridge,Psychology,143818235.0,Andrew Carlson,40135250.0,Bhavana Dalvi,40642935.0,Matt Gardner,16411658.0,B. Kisiel,,2517825.0,J. Krishnamurthy,1914797.0,N. Lao,2406799.0,Kathryn Mazaitis,35645263.0,Thahir Mohamed,3115592.0,Ndapandula Nakashole,144888672.0,Emmanouil Antonios Platanios,1863425.0,Alan Ritter,32402038.0,M. Samadi,1717452.0,Burr Settles,2108772203.0,Richard C. Wang,2129412.0,D. Wijaya,1726095131.0,A. Gupta,39717886.0,Xinlei Chen,2407368.0,Abulhair Saparov,2062798496.0,Malcolm Greaves,122360608.0,Joel Welling,,,,,,,,,,,,,,,,,,,,
1242d79573397094c5670f55e58c8333cced0beb,https://www.semanticscholar.org/paper/1242d79573397094c5670f55e58c8333cced0beb,Deep Learning: A Primer for Radiologists.,"Deep learning is a class of machine learning methods that are gaining success and attracting interest in many domains, including computer vision, speech recognition, natural language processing, and playing games. Deep learning methods produce a mapping from raw inputs to desired outputs (eg, image classes). Unlike traditional machine learning methods, which require hand-engineered feature extraction from inputs, deep learning methods learn these features directly from data. With the advent of large datasets and increased computing power, these methods can produce models with exceptional performance. These models are multilayer artificial neural networks, loosely inspired by biologic neural systems. Weighted connections between nodes (neurons) in the network are iteratively adjusted based on example pairs of inputs and target outputs by back-propagating a corrective error signal through the network. For computer vision tasks, convolutional neural networks (CNNs) have proven to be effective. Recently, several clinical applications of CNNs have been proposed and studied in radiology for classification, detection, and segmentation tasks. This article reviews the key concepts of deep learning for clinical radiologists, discusses technical requirements, describes emerging applications in clinical radiology, and outlines limitations and future directions in this field. Radiologists should become familiar with the principles and potential applications of deep learning in medical imaging. ©RSNA, 2017.",2017,28,583,14,True,Medicine,38162399,G. Chartrand,34842677.0,P. Cheng,37627814.0,Eugene Vorontsov,3325894.0,M. Drozdzal,3622148.0,S. Turcotte,1972076.0,C. Pal,,1781469.0,S. Kadoury,2080173111.0,A. Tang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bcce96a2a074448953fc61a29a84afbdfc8db55a,https://www.semanticscholar.org/paper/bcce96a2a074448953fc61a29a84afbdfc8db55a,Online Learning and Online Convex Optimization,"Online learning is a well established learning paradigm which has both theoretical and practical appeals. The goal of online learning is to make a sequence of accurate predictions given knowledge of the correct answer to previous prediction tasks and possibly additional available information. Online learning has been studied in several research fields including game theory, information theory, and machine learning. It also became of great interest to practitioners due the recent emergence of large scale applications such as online advertisement placement and online web ranking. In this survey we provide a modern overview of online learning. Our goal is to give the reader a sense of some of the interesting ideas and in particular to underscore the centrality of convexity in deriving efficient online learning algorithms. We do not mean to be comprehensive but rather to give a high-level, rigorous yet easy to follow, survey.",2012,48,1732,216,False,Computer Science,1389955537,S. Shalev-Shwartz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7c7f1bb3d483df4c4a20b78a91b833f32d6bdcc5,https://www.semanticscholar.org/paper/7c7f1bb3d483df4c4a20b78a91b833f32d6bdcc5,Machine learning in virtual screening.,"In this review, we highlight recent applications of machine learning to virtual screening, focusing on the use of supervised techniques to train statistical learning algorithms to prioritize databases of molecules as active against a particular protein target. Both ligand-based similarity searching and structure-based docking have benefited from machine learning algorithms, including naïve Bayesian classifiers, support vector machines, neural networks, and decision trees, as well as more traditional regression techniques. Effective application of these methodologies requires an appreciation of data preparation, validation, optimization, and search methodologies, and we also survey developments in these areas.",2009,161,167,4,False,Computer Science,20751784,James L. Melville,1741789.0,E. Burke,2499418.0,J. Hirst,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e,https://www.semanticscholar.org/paper/ccd1282aea3cc7c3d40300d82472fc5f9f54cb8e,Online Learning for Matrix Factorization and Sparse Coding,"Sparse coding--that is, modelling data vectors as sparse linear combinations of basis elements--is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on the large-scale matrix factorization problem that consists of learning the basis set in order to adapt it to specific data. Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis. In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various matrix factorization formulations, making it suitable for a wide range of learning problems. A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets.",2009,94,2506,299,False,Computer Science,2599292,J. Mairal,144570279.0,F. Bach,144189388.0,J. Ponce,1699339.0,G. Sapiro,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
872352b0a53ab6cbb4420f81df64d215d86c7d9b,https://www.semanticscholar.org/paper/872352b0a53ab6cbb4420f81df64d215d86c7d9b,Emotions from Text: Machine Learning for Text-based Emotion Prediction,"In addition to information, text contains attitudinal, and more specifically, emotional content. This paper explores the text-based emotion prediction problem empirically, using supervised machine learning with the SNoW learning architecture. The goal is to classify the emotional affinity of sentences in the narrative domain of children's fairy tales, for subsequent usage in appropriate expressive rendering of text-to-speech synthesis. Initial experiments on a preliminary data set of 22 fairy tales show encouraging results over a naive baseline and BOW approach for classification of emotional versus non-emotional contents, with some dependency on parameter tuning. We also discuss results for a tripartite model which covers emotional valence, as well as feature set alternations. In addition, we present plans for a more cognitively sound sequential model, taking into consideration a larger set of basic emotions.",2005,35,865,59,True,Computer Science,144648940,Cecilia Ovesdotter Alm,144590225.0,D. Roth,145421878.0,R. Sproat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a206216c3f67605ac6e25b0178c3f156dc0f7ba0,https://www.semanticscholar.org/paper/a206216c3f67605ac6e25b0178c3f156dc0f7ba0,WEKA: a machine learning workbench,"WEKA is a workbench for machine learning that is intended to aid in the application of machine learning techniques to a variety of real-world problems, in particular, those arising from agricultural and horticultural domains. Unlike other machine learning projects, the emphasis is on providing a working environment for the domain specialist rather than the machine learning expert. Lessons learned include the necessity of providing a wealth of interactive tools for data manipulation, result visualization, database linkage, and cross-validation and comparison of rule sets, to complement the basic machine learning tools.<<ETX>>",1994,22,1054,112,True,Computer Science,144189431,G. Holmes,1382098662.0,A. Donkin,9419406.0,I. Witten,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9512facd37bba2ff1ece31900c08901bb011f1ce,https://www.semanticscholar.org/paper/9512facd37bba2ff1ece31900c08901bb011f1ce,Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners,"
 
 We investigate a problem at the intersection of machine learning and security: training-set attacks on machine learners. In such attacks an attacker contaminates the training data so that a specific learning algorithm would produce a model profitable to the attacker. Understanding training-set attacks is important as more intelligent agents (e.g. spam filters and robots) are equipped with learning capability and can potentially be hacked via data they receive from the environment. This paper identifies the optimal training-set attack on a broad family of machine learners. First we show that optimal training-set attack can be formulated as a bilevel optimization problem. Then we show that for machine learners with certain Karush-Kuhn-Tucker conditions we can solve the bilevel problem efficiently using gradient methods on an implicit function. As examples, we demonstrate optimal training-set attacks on Support VectorMachines, logistic regression, and linear regression with extensive experiments. Finally, we discuss potential defenses against such attacks.
 
",2015,32,311,37,True,Computer Science,2121022,Shike Mei,1832364.0,Xiaojin Zhu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9c4da62e9e89e65ac78ee271e424e8b498053e8c,https://www.semanticscholar.org/paper/9c4da62e9e89e65ac78ee271e424e8b498053e8c,Advances in kernel methods: support vector learning,"Introduction to support vector learning roadmap. Part 1 Theory: three remarks on the support vector method of function estimation, Vladimir Vapnik generalization performance of support vector machines and other pattern classifiers, Peter Bartlett and John Shawe-Taylor Bayesian voting schemes and large margin classifiers, Nello Cristianini and John Shawe-Taylor support vector machines, reproducing kernel Hilbert spaces, and randomized GACV, Grace Wahba geometry and invariance in kernel based methods, Christopher J.C. Burges on the annealed VC entropy for margin classifiers - a statistical mechanics study, Manfred Opper entropy numbers, operators and support vector kernels, Robert C. Williamson et al. Part 2 Implementations: solving the quadratic programming problem arising in support vector classification, Linda Kaufman making large-scale support vector machine learning practical, Thorsten Joachims fast training of support vector machines using sequential minimal optimization, John C. Platt. Part 3 Applications: support vector machines for dynamic reconstruction of a chaotic system, Davide Mattera and Simon Haykin using support vector machines for time series prediction, Klaus-Robert Muller et al pairwise classification and support vector machines, Ulrich Kressel. Part 4 Extensions of the algorithm: reducing the run-time complexity in support vector machines, Edgar E. Osuna and Federico Girosi support vector regression with ANOVA decomposition kernels, Mark O. Stitson et al support vector density estimation, Jason Weston et al combining support vector and mathematical programming methods for classification, Bernhard Scholkopf et al.",1999,235,5422,217,False,Mathematics,1707625,B. Schölkopf,2676309.0,C. Burges,46234526.0,Alex Smola,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3c1dfe0b52c0638ff69a187ae183e8cdeebff303,https://www.semanticscholar.org/paper/3c1dfe0b52c0638ff69a187ae183e8cdeebff303,Machine-Learning Research Four Current Directions,"The last five years have seen an explosion in machine-learning research. This explosion has many causes: First, separate research communities in symbolic machine learning, computational learning theory, neural networks, statistics, and pattern recognition have discovered one another and begun to work together. Second, machine-learning techniques are being applied to new kinds of problem, including knowledge discovery in databases, language processing, robot control, and combinatorial optimization, as well as to more traditional problems such as speech recognition, face recognition, handwriting recognition, medical data analysis, and game playing. In this article, I selected four topics within machine learning where there has been a lot of recent activity. The purpose of the article is to describe the results in these areas to a broader AI audience and to sketch some of the open research problems. The topic areas are (1) ensembles of classifiers, (2) methods for scaling up supervised learning algorithms, (3) reinforcement learning, and (4) the learning of complex stochastic models. The reader should be cautioned that this article is not a comprehensive review of each of these topics. Rather, my goal is to provide a representative sample of the research in each of these four areas. In each of the areas, there are many other papers that describe relevant work. I apologize to those authors whose work I was unable to include in the article. Ensembles of Classifiers",1997,128,1003,56,False,Computer Science,144299726,Thomas G. Dietterich,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d517b13f2b152c913b81ce534a149493517dbdad,https://www.semanticscholar.org/paper/d517b13f2b152c913b81ce534a149493517dbdad,Big Data Deep Learning: Challenges and Perspectives,"Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.",2014,110,867,30,False,Computer Science,2145447101,Xue-wen Chen,39376164.0,Xiaotong Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c9d60858f1cbe6b7eb36473b7d37ff4b73c31af8,https://www.semanticscholar.org/paper/c9d60858f1cbe6b7eb36473b7d37ff4b73c31af8,Machine Learning from Imbalanced Data Sets 101,"For research to progress most effectively, we first should establish common ground regarding just what is the problem that imbalanced data sets present to machine learning systems. Why and when should imbalanced data sets be problematic? When is the problem simply an artifact of easily rectified design choices? I will try to pick the low-hanging fruit and share them with the rest of the workshop participants. Specifically, I would like to discuss what the problem is not. I hope this will lead to a profitable discussion of what the problem indeed is, and how it might be addressed most effectively.",2008,8,430,7,False,Computer Science,1752722,F. Provost,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50feafd2cdafdfb1eead14388f6210f6b467eaa0,https://www.semanticscholar.org/paper/50feafd2cdafdfb1eead14388f6210f6b467eaa0,Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies,"Machine learning is inherently a multiobjective task. Traditionally, however, either only one of the objectives is adopted as the cost function or multiple objectives are aggregated to a scalar cost function. This can be mainly attributed to the fact that most conventional learning algorithms can only deal with a scalar cost function. Over the last decade, efforts on solving machine learning problems using the Pareto-based multiobjective optimization methodology have gained increasing impetus, particularly due to the great success of multiobjective optimization using evolutionary algorithms and other population-based stochastic search methods. It has been shown that Pareto-based multiobjective learning approaches are more powerful compared to learning algorithms with a scalar cost function in addressing various topics of machine learning, such as clustering, feature selection, improvement of generalization ability, knowledge extraction, and ensemble generation. One common benefit of the different multiobjective learning approaches is that a deeper insight into the learning problem can be gained by analyzing the Pareto front composed of multiple Pareto-optimal solutions. This paper provides an overview of the existing research on multiobjective machine learning, focusing on supervised learning. In addition, a number of case studies are provided to illustrate the major benefits of the Pareto-based approach to machine learning, e.g., how to identify interpretable models and models that can generalize on unseen data from the obtained Pareto-optimal solutions. Three approaches to Pareto-based multiobjective ensemble generation are compared and discussed in detail. Finally, potentially interesting topics in multiobjective machine learning are suggested.",2008,109,354,19,True,Computer Science,2157835870,Yaochu Jin,1718432.0,B. Sendhoff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5726c7b40fcc454b77d989656c085520bf6c15fa,https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa,Multimodal learning with deep Boltzmann machines,"Data often consists of multiple diverse modalities. For example, images are tagged with textual information and videos are accompanied by audio. Each modality is characterized by having distinct statistical properties. We propose a Deep Boltzmann Machine for learning a generative model of such multimodal data. We show that the model can be used to create fused representations by combining features across modalities. These learned representations are useful for classification and information retrieval. By sampling from the conditional distributions over each data modality, it is possible to create these representations even when some data modalities are missing. We conduct experiments on bimodal image-text and audio-video data. The fused representation achieves good classification results on the MIR-Flickr data set matching or outperforming other deep models as well as SVM based models that use Multiple Kernel Learning. We further demonstrate that this multimodal model helps classification and retrieval even when only unimodal data is available at test time.",2012,46,1555,126,False,Computer Science,2897313,Nitish Srivastava,145124475.0,R. Salakhutdinov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7550a05bf00f7b24aed9c1ac3ef000575388d21c,https://www.semanticscholar.org/paper/7550a05bf00f7b24aed9c1ac3ef000575388d21c,Making large scale SVM learning practical,"Training a support vector machine SVM leads to a quadratic optimization problem with bound constraints and one linear equality constraint. Despite the fact that this type of problem is well understood, there are many issues to be considered in designing an SVM learner. In particular, for large learning tasks with many training examples on the shelf optimization techniques for general quadratic programs quickly become intractable in their memory and time requirements. SVM light is an implementation of an SVM learner which addresses the problem of large tasks. This chapter presents algorithmic and computational results developed for SVM light V 2.0, which make large-scale SVM training more practical. The results give guidelines for the application of SVMs to large domains.",1998,14,5531,507,False,Computer Science,1680188,T. Joachims,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9011405b759b492b1132aea7b6165c9d1b0513e7,https://www.semanticscholar.org/paper/9011405b759b492b1132aea7b6165c9d1b0513e7,Reconciling schemas of disparate data sources: a machine-learning approach,"A data-integration system provides access to a multitude of data sources through a single mediated schema. A key bottleneck in building such systems has been the laborious manual construction of semantic mappings between the source schemas and the mediated schema. We describe LSD, a system that employs and extends current machine-learning techniques to semi-automatically find such mappings. LSD first asks the user to provide the semantic mappings for a small set of data sources, then uses these mappings together with the sources to train a set of learners. Each learner exploits a different type of information either in the source schemas or in their data. Once the learners have been trained, LSD finds semantic mappings for a new data source by applying the learners, then combining their predictions using a meta-learner. To further improve matching accuracy, we extend machine learning techniques so that LSD can incorporate domain constraints as an additional source of knowledge, and develop a novel learner that utilizes the structural information in XML documents. Our approach thus is distinguished in that it incorporates multiple types of knowledge. Importantly, its architecture is extensible to additional learners that may exploit new kinds of information. We describe a set of experiments on several real-world domains, and show that LSD proposes semantic mappings with a high degree of accuracy.",2001,28,901,68,False,Computer Science,3030274,A. Doan,1740213.0,Pedro M. Domingos,1770962.0,A. Halevy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a84f4fe31fcfb4ad92c995dba0fc09ed8fe6a4f4,https://www.semanticscholar.org/paper/a84f4fe31fcfb4ad92c995dba0fc09ed8fe6a4f4,Exploiting Machine Learning to Subvert Your Spam Filter,"Using statistical machine learning for making security decisions introduces new vulnerabilities in large scale systems. This paper shows how an adversary can exploit statistical machine learning, as used in the SpamBayes spam filter, to render it useless--even if the adversary's access is limited to only 1% of the training messages. We further demonstrate a new class of focused attacks that successfully prevent victims from receiving specific email messages. Finally, we introduce two new types of defenses against these attacks.",2008,21,297,17,False,Computer Science,39743720,Blaine Nelson,145140480.0,M. Barreno,1852911.0,F. J. Chi,1687701.0,A. Joseph,1868067.0,Benjamin I. P. Rubinstein,39708572.0,Udam Saini,,37210858.0,Charles Sutton,1787610.0,J. Tygar,2065015702.0,Kai Xia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ae20c630759847cd88655631d0041b0be127fd0c,https://www.semanticscholar.org/paper/ae20c630759847cd88655631d0041b0be127fd0c,Transfer Learning for Visual Categorization: A Survey,"Regular machine learning and data mining techniques study the training data for future inferences under a major assumption that the future data are within the same feature space or have the same distribution as the training data. However, due to the limited availability of human labeled training data, training data that stay in the same feature space or have the same distribution as the future data cannot be guaranteed to be sufficient enough to avoid the over-fitting problem. In real-world applications, apart from data in the target domain, related data in a different domain can also be included to expand the availability of our prior knowledge about the target future data. Transfer learning addresses such cross-domain learning problems by extracting useful information from data in a related domain and transferring them for being used in target tasks. In recent years, with transfer learning being applied to visual categorization, some typical problems, e.g., view divergence in action recognition tasks and concept drifting in image classification tasks, can be efficiently solved. In this paper, we survey state-of-the-art transfer learning algorithms in visual categorization applications, such as object recognition, image classification, and human action recognition.",2015,99,583,16,False,Computer Science,144082425,L. Shao,152506137.0,F. Zhu,67180560.0,Xuelong Li,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b,https://www.semanticscholar.org/paper/391b86cf16c2702dcc4beee55a6dd6d3bd7cf27b,Deep Learning for Content-Based Image Retrieval: A Comprehensive Study,"Learning effective feature representations and similarity measures are crucial to the retrieval performance of a content-based image retrieval (CBIR) system. Despite extensive research efforts for decades, it remains one of the most challenging open problems that considerably hinders the successes of real-world CBIR systems. The key challenge has been attributed to the well-known ``semantic gap'' issue that exists between low-level image pixels captured by machines and high-level semantic concepts perceived by human. Among various techniques, machine learning has been actively investigated as a possible direction to bridge the semantic gap in the long term. Inspired by recent successes of deep learning techniques for computer vision and other applications, in this paper, we attempt to address an open problem: if deep learning is a hope for bridging the semantic gap in CBIR and how much improvements in CBIR tasks can be achieved by exploring the state-of-the-art deep learning techniques for learning feature representations and similarity measures. Specifically, we investigate a framework of deep learning with application to CBIR tasks with an extensive set of empirical studies by examining a state-of-the-art deep learning method (Convolutional Neural Networks) for CBIR tasks under varied settings. From our empirical studies, we find some encouraging results and summarize some important insights for future research.",2014,59,790,39,False,Computer Science,2041852738,Ji Wan,47858913.0,Dayong Wang,1741126.0,S. Hoi,2406415.0,Pengcheng Wu,1704030.0,Jianke Zhu,1699819.0,Yongdong Zhang,,30821609.0,Jintao Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4417f78b31546227784941bbd6f6532a177e60b8,https://www.semanticscholar.org/paper/4417f78b31546227784941bbd6f6532a177e60b8,Deep Learning using Linear Support Vector Machines,"Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these ""deep learning"" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.",2013,25,736,69,False,Computer Science,34312504,Yichuan Tang,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7,https://www.semanticscholar.org/paper/5f198e9f1a6cace1fcee5ec53f5d35d9d83af6b7,Can machine learning be secure?,"Machine learning systems offer unparalled flexibility in dealing with evolving input in a variety of applications, such as intrusion detection systems and spam e-mail filtering. However, machine learning algorithms themselves can be a target of attack by a malicious adversary. This paper provides a framework for answering the question, ""Can machine learning be secure?"" Novel contributions of this paper include a taxonomy of different types of attacks on machine learning techniques and systems, a variety of defenses against those attacks, a discussion of ideas that are important to security for machine learning, an analytical model giving a lower bound on attacker's work function, and a list of open problems.",2006,40,803,56,True,Computer Science,145140480,M. Barreno,39743720.0,Blaine Nelson,145879573.0,R. Sears,1687701.0,A. Joseph,1787610.0,J. Tygar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59882b92d0183163e897a671b8c9298f89df5df3,https://www.semanticscholar.org/paper/59882b92d0183163e897a671b8c9298f89df5df3,Task-Driven Dictionary Learning,"Modeling data with linear combinations of a few elements from a learned dictionary has been the focus of much recent research in machine learning, neuroscience, and signal processing. For signals such as natural images that admit such sparse representations, it is now well established that these models are well suited to restoration tasks. In this context, learning the dictionary amounts to solving a large-scale matrix factorization problem, which can be done efficiently with classical optimization tools. The same approach has also been used for learning features from data for other purposes, e.g., image classification, but tuning the dictionary in a supervised way for these tasks has proven to be more difficult. In this paper, we present a general formulation for supervised dictionary learning adapted to a wide variety of tasks, and present an efficient algorithm for solving the corresponding optimization problem. Experiments on handwritten digit classification, digital art identification, nonlinear inverse image problems, and compressed sensing demonstrate that our approach is effective in large-scale settings, and is well suited to supervised and semi-supervised classification, as well as regression tasks for data that admit sparse representations.",2010,61,877,98,True,Mathematics,2599292,J. Mairal,144570279.0,F. Bach,144189388.0,J. Ponce,,,,,,,Computer Science,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
664b701a39371c5356754dc72cea1349233c8506,https://www.semanticscholar.org/paper/664b701a39371c5356754dc72cea1349233c8506,"Computer Systems That Learn: Classification and Prediction Methods from Statistics, Neural Nets, Machine Learning and Expert Systems","Preface 1 Overview of Learning Systems 1.1 What is a Learning System? 1.2 Motivation for Building Learning Systems 1.3 Types of Practical Empirical Learning Systems 1.3.1 Common Theme: The Classification Model 1.3.2 Let the Data Speak 1.4 What's New in Learning Methods 1.4.1 The Impact of New Technology 1.5 Outline of the Book 1.6 Bibliographical and Historical Remarks 2 How to Estimate the True Performance of a Learning System 2.1 The Importance of Unbiased Error Rate Estimation 2.2. What is an Error? 2.2.1 Costs and Risks 2.3 Apparent Error Rate Estimates 2.4 Too Good to Be True: Overspecialization 2.5 True Error Rate Estimation 2.5.1 The Idealized Model for Unlimited Samples 2.5.2 Train-and Test Error Rate Estimation 2.5.3 Resampling Techniques 2.5.4 Finding the Right Complexity Fit 2.6 Getting the Most Out of the Data 2.7 Classifier Complexity and Feature Dimensionality 2.7.1 Expected Patterns of Classifier Behavior 2.8 What Can Go Wrong? 2.8.1 Poor Features, Data Errors, and Mislabeled Classes 2.8.2 Unrepresentative Samples 2.9 How Close to the Truth? 2.10 Common Mistakes in Performance Analysis 2.11 Bibliographical and Historical Remarks 3 Statistical Pattern Recognition 3.1 Introduction and Overview 3.2 A Few Sample Applications 3.3 Bayesian Classifiers 3.3.1 Direct Application of the Bayes Rule 3.4 Linear Discriminants 3.4.1 The Normality Assumption and Discriminant Functions 3.4.2 Logistic Regression 3.5 Nearest Neighbor Methods 3.6 Feature Selection 3.7 Error Rate Analysis 3.8 Bibliographical and Historical Remarks 4 Neural Nets 4.1 Introduction and Overview 4.2 Perceptrons 4.2.1 Least Mean Square Learning Systems 4.2.2 How Good Is a Linear Separation Network? 4.3 Multilayer Neural Networks 4.3.1 Back-Propagation 4.3.2 The Practical Application of Back-Propagation 4.4 Error Rate and Complexity Fit Estimation 4.5 Improving on Standard Back-Propagation 4.6 Bibliographical and Historical Remarks 5 Machine Learning: Easily Understood Decision Rules 5.1 Introduction and Overview 5.2 Decision Trees 5.2.1 Finding the Perfect Tree 5.2.2 The Incredible Shrinking Tree 5.2.3 Limitations of Tree Induction Methods 5.3 Rule Induction 5.3.1 Predictive Value Maximization 5.4 Bibliographical and Historical Remarks 6 Which Technique is Best? 6.1 What's Important in Choosing a Classifier? 6.1.1 Prediction Accuracy 6.1.2 Speed of Learning and Classification 6.1.3 Explanation and Insight 6.2 So, How Do I Choose a Learning System? 6.3 Variations on the Standard Problem 6.3.1 Missing Data 6.3.2 Incremental Learning 6.4 Future Prospects for Improved Learning Methods 6.5 Bibliographical and Historical Remarks 7 Expert Systems 7.1 Introduction and Overview 7.1.1 Why Build Expert Systems? New vs. Old Knowledge 7.2 Estimating Error Rates for Expert Systems 7.3 Complexity of Knowledge Bases 7.3.1 How Many Rules Are Too Many? 7.4 Knowledge Base Example 7.5 Empirical Analysis of Knowledge Bases 7.6 Future: Combined Learning and Expert Systems 7.7 Bibliographical and Historical Remarks References Author Index Subject Index",1990,0,1065,41,False,Computer Science,145700185,S. Weiss,3285789.0,C. Kulikowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
83cf4b2f39bcc802b09fd59b69e23068447b26b7,https://www.semanticscholar.org/paper/83cf4b2f39bcc802b09fd59b69e23068447b26b7,Multi-Task Learning for Multiple Language Translation,"In this paper, we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages. Our solution is inspired by the recently proposed neural machine translation model which generalizes machine translation as a sequence learning problem. We extend the neural machine translation to a multi-task learning framework which shares source language representation and separates the modeling of different target language translation. Our framework can be applied to situations where either large amounts of parallel data or limited parallel data is available. Experiments show that our multi-task learning model is able to achieve significantly higher translation quality over individually learned model in both situations on the data sets publicly available.",2015,21,509,51,True,Computer Science,9532787,Daxiang Dong,40354707.0,Hua Wu,48692318.0,W. He,3046102.0,Dianhai Yu,144270731.0,Haifeng Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
035256a8a6d8a73af2adb38245f4130daa1f0535,https://www.semanticscholar.org/paper/035256a8a6d8a73af2adb38245f4130daa1f0535,Machine learning in bioinformatics,"This article reviews machine learning methods for bioinformatics. It presents modelling methods, such as supervised classification, clustering and probabilistic graphical models for knowledge discovery, as well as deterministic and stochastic heuristics for optimization. Applications in genomics, proteomics, systems biology, evolution and text mining are also shown.",2006,301,769,19,True,Computer Science,144999310,P. Larrañaga,145892659.0,Borja Calvo,145585784.0,Roberto Santana,1687365.0,C. Bielza,2086344475.0,Josu Galdiano,1788277.0,Iñaki Inza,Medicine,144762651.0,J. A. Lozano,2708156.0,Rubén Armañanzas,1800760.0,G. Santafé,2110404467.0,Aritz Pérez Martínez,,145689219.0,V. Robles,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1f135e98e867ffcde5b359e7b817bbe21f80cfce,https://www.semanticscholar.org/paper/1f135e98e867ffcde5b359e7b817bbe21f80cfce,Deep Learning and Its Application to LHC Physics,"Machine learning has played an important role in the analysis of high-energy physics data for decades. The emergence of deep learning in 2012 allowed for machine learning tools which could adeptly handle higher-dimensional and more complex problems than previously feasible. This review is aimed at the reader who is familiar with high-energy physics but not machine learning. The connections between machine learning and high-energy physics data analysis are explored, followed by an introduction to the core concepts of neural networks, examples of the key results demonstrating the power of deep learning for analysis of LHC data, and discussion of future prospects and concerns.",2018,38,223,6,True,Physics,104284017,D. Guest,11638962.0,K. Cranmer,104317636.0,D. Whiteson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94ac58d1b6132b07ef66c47af8bd506bdb67e0c3,https://www.semanticscholar.org/paper/94ac58d1b6132b07ef66c47af8bd506bdb67e0c3,Investigating statistical machine learning as a tool for software development,"As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.",2008,32,110,7,False,Computer Science,39699737,Kayur Patel,145504534.0,J. Fogarty,9522307.0,J. Landay,40376159.0,B. Harrison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfacdf62b0f3e50993a6a55250127d694a2efdce,https://www.semanticscholar.org/paper/cfacdf62b0f3e50993a6a55250127d694a2efdce,The city as a machine for learning.,"Abstract Despite its centrality to urban politics, economies and life, learning remains a neglected and undertheorised domain in urban geography. In this paper, I address this by exploring a politics of learning through two key sites: first, tactical learning; second, urban learning forums. I offer a conception of learning based on three processes: translation , or the relational distributions through which learning is produced as a sociomaterial epistemology of displacement and change; coordination , or the construction of functional systems that enable learning as a means of linking different forms of knowledge, coping with complexity and facilitating adaptation; and dwelling , or the education of attention through which learning operates as a way of seeing and inhabiting the world. I then consider this conception of learning in relation to tactical learning, i.e. the resources marginal groups use to cope with, negotiate and resist in the city, and urban learning forums, i.e. the possibilities for progressive forms of learning between different constituencies in the city. I conclude with an outline of a critical urbanism of learning.",2011,76,168,18,True,Sociology,51937792,Colin McFarlane,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6f0cde3fcab0044f386b5b8a4244c371507bec15,https://www.semanticscholar.org/paper/6f0cde3fcab0044f386b5b8a4244c371507bec15,A Survey on Metric Learning for Feature Vectors and Structured Data,"The need for appropriate ways to measure the distance or similarity between data is ubiquitous in machine learning, pattern recognition and data mining, but handcrafting such good metrics for specific problems is generally difficult. This has led to the emergence of metric learning, which aims at automatically learning a metric from data and has attracted a lot of interest in machine learning and related fields for the past ten years. This survey paper proposes a systematic review of the metric learning literature, highlighting the pros and cons of each approach. We pay particular attention to Mahalanobis distance metric learning, a well-studied and successful framework, but additionally present a wide range of methods that have recently emerged as powerful alternatives, including nonlinear metric learning, similarity learning and local metric learning. Recent trends and extensions, such as semi-supervised metric learning, metric learning for histogram data and the derivation of generalization guarantees, are also covered. Finally, this survey addresses metric learning for structured data, in particular edit distance learning, and attempts to give an overview of the remaining challenges in metric learning for the years to come.",2013,221,608,38,False,Computer Science,1702915,A. Bellet,1749327.0,Amaury Habrard,1738336.0,M. Sebban,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0628fdf728d0aba31be803a7d834c7f4b569408d,https://www.semanticscholar.org/paper/0628fdf728d0aba31be803a7d834c7f4b569408d,"Imbalanced Learning: Foundations, Algorithms, and Applications","The first book of its kind to review the current status and future direction of the exciting new branch of machine learning/data mining called imbalanced learningImbalanced learning focuses on how an intelligent system can learn when it is provided with imbalanced data. Solving imbalanced learning problems is critical in numerous data-intensive networked systems, including surveillance, security, Internet, finance, biomedical, defense, and more. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. The first comprehensive look at this new branch of machine learning, this book offers a critical review of the problem of imbalanced learning, covering the state of the art in techniques, principles, and real-world applications. Featuring contributions from experts in both academia and industry, Imbalanced Learning: Foundations, Algorithms, and Applications provides chapter coverage on:Foundations of Imbalanced LearningImbalanced Datasets: From Sampling to ClassifiersEnsemble Methods for Class Imbalance LearningClass Imbalance Learning Methods for Support Vector MachinesClass Imbalance and Active LearningNonstationary Stream Data Learning with Imbalanced Class DistributionAssessment Metrics for Imbalanced LearningImbalanced Learning: Foundations, Algorithms, and Applications will help scientists and engineers learn how to tackle the problem of learning from imbalanced datasets, and gain insight into current developments in the field as well as future research directions.",2013,0,595,44,False,Computer Science,2198278,Haibo He,2363386.0,Yunqian Ma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ced4db5d559d4614efb5bbbcef353f7aac7a4f25,https://www.semanticscholar.org/paper/ced4db5d559d4614efb5bbbcef353f7aac7a4f25,Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning),"All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher.",2007,14,583,39,False,Computer Science,1746034,L. Getoor,1685978.0,B. Taskar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76f96dadd80b19bde49e0e1f07bfa9fe8485eeec,https://www.semanticscholar.org/paper/76f96dadd80b19bde49e0e1f07bfa9fe8485eeec,"Learning with Kernels: support vector machines, regularization, optimization, and beyond","From the Publisher: 
In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs-kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. 
Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.",2001,0,3427,135,False,Computer Science,1707625,B. Schölkopf,46234526.0,Alex Smola,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cf80cc34528273d8fbe17783efe802a6509e1562,https://www.semanticscholar.org/paper/cf80cc34528273d8fbe17783efe802a6509e1562,Online dictionary learning for sparse coding,"Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics. This paper focuses on learning the basis set, also called dictionary, to adapt it to specific data, an approach that has recently proven to be very effective for signal reconstruction and classification in the audio and image processing domains. This paper proposes a new online optimization algorithm for dictionary learning, based on stochastic approximations, which scales up gracefully to large datasets with millions of training samples. A proof of convergence is presented, along with experiments with natural images demonstrating that it leads to faster performance and better dictionaries than classical batch algorithms for both small and large datasets.",2009,30,2182,244,True,Computer Science,2599292,J. Mairal,144570279.0,F. Bach,144189388.0,J. Ponce,1699339.0,G. Sapiro,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bad620c25920edbaba8836032459b135669171c3,https://www.semanticscholar.org/paper/bad620c25920edbaba8836032459b135669171c3,Machine Learning and Its Applications to Biology,"The term machine learning refers to a set of topics dealing with the creation and evaluation of algorithms that facilitate pattern recognition, classification, and prediction, based on models derived from existing data. Two facets of mechanization should be acknowledged when considering machine learning in broad terms. Firstly, it is intended that the classification and prediction tasks can be accomplished by a suitably programmed computing machine. That is, the product of machine learning is a classifier that can be feasibly used on available hardware. Secondly, it is intended that the creation of the classifier should itself be highly mechanized, and should not involve too much human input. This second facet is inevitably vague, but the basic objective is that the use of automatic algorithm construction methods can minimize the possibility that human biases could affect the selection and performance of the algorithm. Both the creation of the algorithm and its operation to classify objects or predict events are to be based on concrete, observable data. 
 
The history of relations between biology and the field of machine learning is long and complex. An early technique [1] for machine learning called the perceptron constituted an attempt to model actual neuronal behavior, and the field of artificial neural network (ANN) design emerged from this attempt. Early work on the analysis of translation initiation sequences [2] employed the perceptron to define criteria for start sites in Escherichia coli. Further artificial neural network architectures such as the adaptive resonance theory (ART) [3] and neocognitron [4] were inspired from the organization of the visual nervous system. In the intervening years, the flexibility of machine learning techniques has grown along with mathematical frameworks for measuring their reliability, and it is natural to hope that machine learning methods will improve the efficiency of discovery and understanding in the mounting volume and complexity of biological data. 
 
This tutorial is structured in four main components. Firstly, a brief section reviews definitions and mathematical prerequisites. Secondly, the field of supervised learning is described. Thirdly, methods of unsupervised learning are reviewed. Finally, a section reviews methods and examples as implemented in the open source data analysis and visualization language R (http://www.r-project.org).",2007,50,482,19,True,Computer Science,2490889,A. Tarca,33361123.0,V. Carey,145793137.0,Xue-wen Chen,2142580259.0,R. Romero,1775019.0,S. Drăghici,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1bcbf2a4500d27d036e0f9d36d7af71c72f8ab61,https://www.semanticscholar.org/paper/1bcbf2a4500d27d036e0f9d36d7af71c72f8ab61,Recognizing facial expression: machine learning and application to spontaneous behavior,"We present a systematic comparison of machine learning methods applied to the problem of fully automatic recognition of facial expressions. We report results on a series of experiments comparing recognition engines, including AdaBoost, support vector machines, linear discriminant analysis. We also explored feature selection techniques, including the use of AdaBoost for feature selection prior to classification by SVM or LDA. Best results were obtained by selecting a subset of Gabor filters using AdaBoost followed by classification with support vector machines. The system operates in real-time, and obtained 93% correct generalization to novel subjects for a 7-way forced choice on the Cohn-Kanade expression dataset. The outputs of the classifiers change smoothly as a function of time and thus can be used to measure facial expression dynamics. We applied the system to to fully automated recognition of facial actions (FACS). The present system classifies 17 action units, whether they occur singly or in combination with other actions, with a mean accuracy of 94.8%. We present preliminary results for applying this system to spontaneous facial expressions.",2005,18,701,56,False,Computer Science,2218905,M. Bartlett,46548046.0,G. Littlewort,145595070.0,M. Frank,2767464.0,C. Lainscsek,2039025.0,I. Fasel,1741200.0,J. Movellan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
