paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,fieldsOfStudy/2,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,fieldsOfStudy/3,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name
4aea3547974399a32d7aa7c007b10bd665e93fab,https://www.semanticscholar.org/paper/4aea3547974399a32d7aa7c007b10bd665e93fab,On Variational Bounds of Mutual Information,"Estimating and optimizing Mutual Information (MI) is core to many problems in machine learning; however, bounding MI in high dimensions is challenging. To establish tractable and scalable objectives, recent work has turned to variational bounds parameterized by neural networks, but the relationships and tradeoffs between these bounds remains unclear. In this work, we unify these recent developments in a single framework. We find that the existing variational lower bounds degrade when the MI is large, exhibiting either high bias or high variance. To address this problem, we introduce a continuum of lower bounds that encompasses previous bounds and flexibly trades off bias and variance. On high-dimensional, controlled problems, we empirically characterize the bias and variance of the bounds and their gradients and demonstrate the effectiveness of our new bounds for estimation and representation learning.",2019,53,423,69,False,Computer Science,Mathematics,16443937,Ben Poole,1955694.0,Sherjil Ozair,3422336.0,Aäron van den Oord,122113652.0,Alexander A. Alemi,145499435.0,G. Tucker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
409cbeafc42c841628dcff2dfb373cd1c32a4820,https://www.semanticscholar.org/paper/409cbeafc42c841628dcff2dfb373cd1c32a4820,Multi-centre diagnostic classification of individual structural neuroimaging scans from patients with major depressive disorder.,"Quantitative abnormalities of brain structure in patients with major depressive disorder have been reported at a group level for decades. However, these structural differences appear subtle in comparison with conventional radiologically defined abnormalities, with considerable inter-subject variability. Consequently, it has not been possible to readily identify scans from patients with major depressive disorder at an individual level. Recently, machine learning techniques such as relevance vector machines and support vector machines have been applied to predictive classification of individual scans with variable success. Here we describe a novel hybrid method, which combines machine learning with feature selection and characterization, with the latter aimed at maximizing the accuracy of machine learning prediction. The method was tested using a multi-centre dataset of T(1)-weighted 'structural' scans. A total of 62 patients with major depressive disorder and matched controls were recruited from referred secondary care clinical populations in Aberdeen and Edinburgh, UK. The generalization ability and predictive accuracy of the classifiers was tested using data left out of the training process. High prediction accuracy was achieved (~90%). While feature selection was important for maximizing high predictive accuracy with machine learning, feature characterization contributed only a modest improvement to relevance vector machine-based prediction (~5%). Notably, while the only information provided for training the classifiers was T(1)-weighted scans plus a categorical label (major depressive disorder versus controls), both relevance vector machine and support vector machine 'weighting factors' (used for making predictions) correlated strongly with subjective ratings of illness severity. These results indicate that machine learning techniques have the potential to inform clinical practice and research, as they can make accurate predictions about brain scan data from individual subjects. Furthermore, machine learning weighting factors may reflect an objective biomarker of major depressive disorder illness severity, based on abnormalities of brain structure.",2012,60,171,8,True,Medicine,Psychology,145321317,B. Mwangi,2991780.0,Klaus P. Ebmeier,103363505.0,K. Matthews,143956424.0,J. Steele,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e8b30ebe3351680c3b039555ae0a8d0865ad829b,https://www.semanticscholar.org/paper/e8b30ebe3351680c3b039555ae0a8d0865ad829b,Neural networks and machine learning,"In recent years neural computing has emerged as a practical technology, with successful applications in many fields. The majority of these applications are concerned with problems in pattern recognition, and make use of feedforward network architectures such as the multilayer perceptron and the radial basis function network. Also, it has become widely acknowledged that successful applications of neural computing require a principled, rather than ad hoc, approach. (From the preface to ""Neural Networks for Pattern Recognition"" by C.M. Bishop, Oxford Univ Press 1995.) This NATO volume, based on a 1997 workshop, presents a coordinated series of tutorial articles covering recent developments in the field of neural computing. It is ideally suited to graduate students and researchers.",1998,0,166,6,False,Computer Science,,2113861474,C. Bishop,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4a554da55fd9ff76c99e25d2ce937b225dc1100c,https://www.semanticscholar.org/paper/4a554da55fd9ff76c99e25d2ce937b225dc1100c,A survey of named entity recognition and classification,"This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.",2007,84,2439,184,False,Computer Science,,40421028,David Nadeau,1714612.0,S. Sekine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fbf9812f29156024ec693b4633a21303eead309d,https://www.semanticscholar.org/paper/fbf9812f29156024ec693b4633a21303eead309d,Machine learning algorithm validation with a limited sample size,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.",2019,31,387,7,True,Medicine,Computer Science,8452323,A. Vabalas,2283643.0,E. Gowen,2910758.0,E. Poliakoff,1807736.0,A. Casson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f3e2f770a68128e9cfbabbf591a7c427a0f9e239,https://www.semanticscholar.org/paper/f3e2f770a68128e9cfbabbf591a7c427a0f9e239,Predicting Risk of Suicide Attempts Over Time Through Machine Learning,"Traditional approaches to the prediction of suicide attempts have limited the accuracy and scale of risk detection for these dangerous behaviors. We sought to overcome these limitations by applying machine learning to electronic health records within a large medical database. Participants were 5,167 adult patients with a claim code for self-injury (i.e., ICD-9, E95x); expert review of records determined that 3,250 patients made a suicide attempt (i.e., cases), and 1,917 patients engaged in self-injury that was nonsuicidal, accidental, or nonverifiable (i.e., controls). We developed machine learning algorithms that accurately predicted future suicide attempts (AUC = 0.84, precision = 0.79, recall = 0.95, Brier score = 0.14). Moreover, accuracy improved from 720 days to 7 days before the suicide attempt, and predictor importance shifted across time. These findings represent a step toward accurate and scalable risk detection and provide insight into how suicide attempt risk shifts over time.",2017,45,345,11,False,Psychology,,27032213,Colin G. Walsh,144945435.0,J. Ribeiro,39865485.0,J. Franklin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c2413fa296543159b32d16350d9e29f7db528790,https://www.semanticscholar.org/paper/c2413fa296543159b32d16350d9e29f7db528790,Explaining machine learning classifiers through diverse counterfactual explanations,"Post-hoc explanations of machine learning models are crucial for people to understand and act on algorithmic predictions. An intriguing class of explanations is through counterfactuals, hypothetical examples that show people how to obtain a different prediction. We posit that effective counterfactual explanations should satisfy two properties: feasibility of the counterfactual actions given user context and constraints, and diversity among the counterfactuals presented. To this end, we propose a framework for generating and evaluating a diverse set of counterfactual explanations based on determinantal point processes. To evaluate the actionability of counterfactuals, we provide metrics that enable comparison of counterfactual-based methods to other local explanation methods. We further address necessary tradeoffs and point to causal implications in optimizing for counterfactuals. Our experiments on four real-world datasets show that our framework can generate a set of counterfactuals that are diverse and well approximate local decision boundaries, outperforming prior approaches to generating diverse counterfactuals. We provide an implementation of the framework at https://github.com/microsoft/DiCE.",2019,46,384,77,True,Computer Science,Mathematics,120935900,R. Mothilal,144676398.0,Amit Sharma,40348583.0,Chenhao Tan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1f845410fae2bc7bf2029d7993ea0477fe78f823,https://www.semanticscholar.org/paper/1f845410fae2bc7bf2029d7993ea0477fe78f823,Machine learning for composite materials,"Machine learning (ML) has been perceived as a promising tool for the design and discovery of novel materials for a broad range of applications. In this prospective paper, we summarize recent progress in the applications of ML to composite materials modeling and design. An overview of how different types of ML algorithms can be applied to accelerate composite research is presented. This framework is envisioned to revolutionize approaches to design and optimize composites for the next generation of materials with unprecedented properties.",2019,89,122,0,True,Materials Science,,153246325,Chun‐Teh Chen,11329466.0,Grace X. Gu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
daec341c0819d589b38a781808a5b1aae7c5547e,https://www.semanticscholar.org/paper/daec341c0819d589b38a781808a5b1aae7c5547e,Machine learning: a guide to current research,Judge: A Case-Based Reasoning System.- Changing Language While Learning Recursive Descriptions from Examples.- Learning by Disjunctive Spanning.- Transfer of Knowledge between Teaching and Learning Systems.- Some Approaches to Knowledge Acquisition.- Analogical Learning with Multiple Models.- The World Modelers Project: Objectives and Simulator Architecture.- The Acquisition of Procedural Knowledge through Inductive Learning.- Learning Static Evaluation Functions by Linear Regression.- Plan Invention and Plan Transformation.- A Brief Overview of Explanatory Schema Acquisition.- The EG Project: Recent Progress.- Learning Causal Relations.- Functional Properties and Concept Formation.- Explanation-Based Learning in Logic Circuit Design.- A Proposed Method of Conceptual Clustering for Structured and Decomposable Objects.- Exploiting Functional Vocabularies to Learn Structural Descriptions.- Combining Numeric and Symbolic Learning Techniques.- Learning by Understanding Analogies.- Analogical Reasoning in the Context of Acquiring Problem Solving Expertise.- Planning and Learning in a Design Domain: The Problems Plan Interactions.- Inference of Incorrect Operators.- A Conceptual Framework for Concept Identification.- Neural Modeling as One Approach to Machine Learning.- Steps Toward Building a Dynamic Memory.- Learning by Composition.- Knowledge Acquisition: Investigations and General Principles.- Purpose-Directed Analogy: A Summary of Current Research.- Development of a Framework for Contextual Concept Learning.- On Safely Ignoring Hypotheses.- A Model of Acquiring Problem Solving Expertise.- Another Learning Problem: Symbolic Process Prediction.- Learning at LRI Orsay.- Coper: A Methodology for Learning Invariant Functional Descriptions.- Using Experience as a Guide for Problem Solving.- Heuristics as Invariants and its Application to Learning.- Components of Learning in a Reactive Environment.- The Development of Structures through Interaction.- Complex Learning Environments: Hierarchies and the use of Explanation.- Prediction and Control in an Active Environment.- Better Information Retrieval through Linguistic Sophistication.- Machine Learning Research in the Artificial Intelligence Laboratory at Illinois.- Overview of the Prodigy Learning Apprentice.- A Learning Apprentice System for VLSI Design.- Generalizing Explanations of Narratives into Schemata.- Why Are Design Derivations Hard to Replay?.- An Architecture for Experiential Learning.- Knowledge Extraction through Learning from Examples.- Learning Concepts with a Prototype-Based Model for Concept Representation.- Recent Progress on the Mathematician's Apprentice Project.- Acquiring Domain Knowledge from Fragments of Advice.- Calm: Contestation for Argumentative Learning Machine.- Directed Experimentation for Theory Revision and Conceptual Knowledge Acquisition.- Goal-Free Learning by Analogy.- A Scientific Approach to Practical Induction.- Exploring Shifts of Representation.- Current Research on Learning in Soar.- Learning Concepts in a Complex Robot World.- Learning Evaluation Functions.- Learning from Data with Errors.- Explanation-Based Manipulator Learning.- Learning Classical Physics.- Views and Causality in Discovery: Modelling Human Induction.- Learning Control Information.- An Investigation of the Nature of Mathematical Discovery.- Learning How to Reach a Goal: A Strategy for the Multiple Classes Classification Problem.- Conceptual Clustering Of Structured Objects.- Learning in Intractable Domains.- On Compiling Explainable Models of a Design Domain.- What Can Be Learned?.- Learning Heuristic Rules from Deep Reasoning.- Learning a Domain Theory by Completing Explanations.- Learning Implementation Rules with Operating-Conditions Depending on Internal Structures in VLSI Design.- Overview of the Odysseus Learning Apprentice.- Learning from Exceptions in Databases.- Learning Apprentice Systems Research at Schlumberger.- Language Acquisition: Learning Phrases in Context.- References.,1986,0,118,6,False,Computer Science,,40975594,Tom Michael Mitchell,143712374.0,J. Carbonell,2421006.0,R. Michalski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dccce5d05645a55d9b5b291c02f80e1017892a9e,https://www.semanticscholar.org/paper/dccce5d05645a55d9b5b291c02f80e1017892a9e,More efficiency in multiple kernel learning,"An efficient and general multiple kernel learning (MKL) algorithm has been recently proposed by Sonnenburg et al. (2006). This approach has opened new perspectives since it makes the MKL approach tractable for large-scale problems, by iteratively using existing support vector machine code. However, it turns out that this iterative algorithm needs several iterations before converging towards a reasonable solution. In this paper, we address the MKL problem through an adaptive 2-norm regularization formulation. Weights on each kernel matrix are included in the standard SVM empirical risk minimization problem with a l1 constraint to encourage sparsity. We propose an algorithm for solving this problem and provide an new insight on MKL algorithms based on block 1-norm regularization by showing that the two approaches are equivalent. Experimental results show that the resulting algorithm converges rapidly and its efficiency compares favorably to other MKL algorithms.",2007,16,324,36,True,Mathematics,Computer Science,1792962,A. Rakotomamonjy,144570279.0,F. Bach,1794818.0,S. Canu,1802711.0,Yves Grandvalet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bf79c966b293dbc5551de9785a696c099dff355b,https://www.semanticscholar.org/paper/bf79c966b293dbc5551de9785a696c099dff355b,Inductive Principles for Restricted Boltzmann Machine Learning,"Recent research has seen the proposal of several new inductive principles designed specifically to avoid the problems associated with maximum likelihood learning in models with intractable partition functions. In this paper, we study learning methods for binary restricted Boltzmann machines (RBMs) based on ratio matching and generalized score matching. We compare these new RBM learning methods to a range of existing learning methods including stochastic maximum likelihood, contrastive divergence, and pseudo-likelihood. We perform an extensive empirical evaluation across multiple tasks and data sets.",2010,24,170,34,False,Mathematics,Computer Science,1805742,Benjamin M Marlin,1754860.0,Kevin Swersky,,Bo Chen,1737568.0,N. D. Freitas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b66563fbfa9e02095156b8ec15aa517359b0cbec,https://www.semanticscholar.org/paper/b66563fbfa9e02095156b8ec15aa517359b0cbec,Knowledge Discovery in Databases: An Overview,"After a decade of fundamental interdisciplinary research in machine learning, the spadework in this field has been done; the 1990s should see the widespread exploitation of knowledge discovery as an aid to assembling knowledge bases. The contributors to the AAAI Press book Knowledge Discovery in Databases were excited at the potential benefits of this research. The editors hope that some of this excitement will communicate itself to ""AI Magazine readers of this article.",1992,27,1247,26,False,Computer Science,,101904886,W. Frawley,1398381803.0,G. Piatetsky-Shapiro,1688579.0,C. Matheus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d2a595c5efb4b26245c4353d5d85cbe6c7ecac0f,https://www.semanticscholar.org/paper/d2a595c5efb4b26245c4353d5d85cbe6c7ecac0f,Machine learning for data-driven discovery in solid Earth geoscience,"Automating geoscience analysis Solid Earth geoscience is a field that has very large set of observations, which are ideal for analysis with machine-learning methods. Bergen et al. review how these methods can be applied to solid Earth datasets. Adopting machine-learning techniques is important for extracting information and for understanding the increasing amount of complex data collected in the geosciences. Science, this issue p. eaau0323 BACKGROUND The solid Earth, oceans, and atmosphere together form a complex interacting geosystem. Processes relevant to understanding Earth’s geosystem behavior range in spatial scale from the atomic to the planetary, and in temporal scale from milliseconds to billions of years. Physical, chemical, and biological processes interact and have substantial influence on this complex geosystem, and humans interact with it in ways that are increasingly consequential to the future of both the natural world and civilization as the finiteness of Earth becomes increasingly apparent and limits on available energy, mineral resources, and fresh water increasingly affect the human condition. Earth is subject to a variety of geohazards that are poorly understood, yet increasingly impactful as our exposure grows through increasing urbanization, particularly in hazard-prone areas. We have a fundamental need to develop the best possible predictive understanding of how the geosystem works, and that understanding must be informed by both the present and the deep past. This understanding will come through the analysis of increasingly large geo-datasets and from computationally intensive simulations, often connected through inverse problems. Geoscientists are faced with the challenge of extracting as much useful information as possible and gaining new insights from these data, simulations, and the interplay between the two. Techniques from the rapidly evolving field of machine learning (ML) will play a key role in this effort. ADVANCES The confluence of ultrafast computers with large memory, rapid progress in ML algorithms, and the ready availability of large datasets place geoscience at the threshold of dramatic progress. We anticipate that this progress will come from the application of ML across three categories of research effort: (i) automation to perform a complex prediction task that cannot easily be described by a set of explicit commands; (ii) modeling and inverse problems to create a representation that approximates numerical simulations or captures relationships; and (iii) discovery to reveal new and often unanticipated patterns, structures, or relationships. Examples of automation include geologic mapping using remote-sensing data, characterizing the topology of fracture systems to model subsurface transport, and classifying volcanic ash particles to infer eruptive mechanism. Examples of modeling include approximating the viscoelastic response for complex rheology, determining wave speed models directly from tomographic data, and classifying diverse seismic events. Examples of discovery include predicting laboratory slip events using observations of acoustic emissions, detecting weak earthquake signals using similarity search, and determining the connectivity of subsurface reservoirs using groundwater tracer observations. OUTLOOK The use of ML in solid Earth geosciences is growing rapidly, but is still in its early stages and making uneven progress. Much remains to be done with existing datasets from long-standing data sources, which in many cases are largely unexplored. Newer, unconventional data sources such as light detection and ranging (LiDAR), fiber-optic sensing, and crowd-sourced measurements may demand new approaches through both the volume and the character of information that they present. Practical steps could accelerate and broaden the use of ML in the geosciences. Wider adoption of open-science principles such as open source code, open data, and open access will better position the solid Earth community to take advantage of rapid developments in ML and artificial intelligence. Benchmark datasets and challenge problems have played an important role in driving progress in artificial intelligence research by enabling rigorous performance comparison and could play a similar role in the geosciences. Testing on high-quality datasets produces better models, and benchmark datasets make these data widely available to the research community. They also help recruit expertise from allied disciplines. Close collaboration between geoscientists and ML researchers will aid in making quick progress in ML geoscience applications. Extracting maximum value from geoscientific data will require new approaches for combining data-driven methods, physical modeling, and algorithms capable of learning with limited, weak, or biased labels. Funding opportunities that target the intersection of these disciplines, as well as a greater component of data science and ML education in the geosciences, could help bring this effort to fruition. Digital geology. Digital representation of the geology of the conterminous United States. [Geology of the Conterminous United States at 1:2,500,000 scale; a digital representation of the 1974 P. B. King and H. M. Beikman map by P. G. Schruben, R. E. Arndt, W. J. Bawiec] The list of author affiliations is available in the full article online. Understanding the behavior of Earth through the diverse fields of the solid Earth geosciences is an increasingly important task. It is made challenging by the complex, interacting, and multiscale processes needed to understand Earth’s behavior and by the inaccessibility of nearly all of Earth’s subsurface to direct observation. Substantial increases in data availability and in the increasingly realistic character of computer simulations hold promise for accelerating progress, but developing a deeper understanding based on these capabilities is itself challenging. Machine learning will play a key role in this effort. We review the state of the field and make recommendations for how progress might be broadened and accelerated.",2019,151,385,12,False,Medicine,,46354410,K. Bergen,143862033.0,P. Johnson,39634320.0,M. D. de Hoop,3462562.0,G. Beroza,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ebab687cd1be7d25392c11f89fce6a63bef7219d,https://www.semanticscholar.org/paper/ebab687cd1be7d25392c11f89fce6a63bef7219d,Towards the Science of Security and Privacy in Machine Learning,"Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive—new systems and models are being deployed in every domain imaginable, leading to rapid and widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community’s understanding of the nature and extent of these vulnerabilities remains limited. We systematize recent findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date. We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. We conclude by formally exploring the opposing relationship between model accuracy and resilience to adversarial manipulation. Through these explorations, we show that there are (possibly unavoidable) tensions between model complexity, accuracy, and resilience that must be calibrated for the environments in which they will be used.",2016,112,399,36,False,Computer Science,,1967156,Nicolas Papernot,144061974.0,P. Mcdaniel,2370629.0,Arunesh Sinha,1796536.0,Michael P. Wellman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ad3c82ada3ff848bb36bade1d90820c2e465b2d7,https://www.semanticscholar.org/paper/ad3c82ada3ff848bb36bade1d90820c2e465b2d7,Feature Selection,"Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.",2016,191,1239,46,True,Computer Science,,2040455,Jundong Li,3161399.0,Kewei Cheng,2893721.0,Suhang Wang,2775559.0,Fred Morstatter,39690948.0,Robert P. Trevino,1736632.0,Jiliang Tang,145896397.0,Huan Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,
759d9a6c9206c366a8d94a06f4eb05659c2bb7f2,https://www.semanticscholar.org/paper/759d9a6c9206c366a8d94a06f4eb05659c2bb7f2,Toward Open Set Recognition,"To date, almost all experimental evaluations of machine learning-based recognition algorithms in computer vision have taken the form of “closed set” recognition, whereby all testing classes are known at training time. A more realistic scenario for vision applications is “open set” recognition, where incomplete knowledge of the world is present at training time, and unknown classes can be submitted to an algorithm during testing. This paper explores the nature of open set recognition and formalizes its definition as a constrained minimization problem. The open set recognition problem is not well addressed by existing algorithms because it requires strong generalization. As a step toward a solution, we introduce a novel “1-vs-set machine,” which sculpts a decision space from the marginal distances of a 1-class or binary SVM with a linear kernel. This methodology applies to several different applications in computer vision where open set recognition is a challenging problem, including object recognition and face verification. We consider both in this work, with large scale cross-dataset experiments performed over the Caltech 256 and ImageNet sets, as well as face matching experiments performed over the Labeled Faces in the Wild set. The experiments highlight the effectiveness of machines adapted for open set evaluation compared to existing 1-class and binary SVMs for the same tasks.",2013,57,754,102,False,Medicine,Computer Science,2613438,W. Scheirer,145603848.0,A. Rocha,27469806.0,Archana Sapkota,32163276.0,T. Boult,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bd1f14e7531220c39fad8f86985cce7b283f035d,https://www.semanticscholar.org/paper/bd1f14e7531220c39fad8f86985cce7b283f035d,Kernel Methods for Pattern Analysis,"Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) and look for general types of relations (e.g. rankings, classifications, regressions, clusters). The application areas range from neural networks and pattern recognition to machine learning and data mining. This book, developed from lectures and tutorials, fulfils two major roles: firstly it provides practitioners with a large toolkit of algorithms, kernels and solutions ready to use for standard pattern discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly it provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so.",2003,184,6714,675,False,Computer Science,,1404459229,J. Shawe-Taylor,1685083.0,N. Cristianini,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b6b743de242a2987b3ed0349d90971fdf7ed2faf,https://www.semanticscholar.org/paper/b6b743de242a2987b3ed0349d90971fdf7ed2faf,Algebraic Analysis for Nonidentifiable Learning Machines,"This article clarifies the relation between the learning curve and the algebraic geometrical structure of a nonidentifiable learning machine such as a multilayer neural network whose true parameter set is an analytic set with singular points. By using a concept in algebraic analysis, we rigorously prove that the Bayesian stochastic complexity or the free energy is asymptotically equal to 1 logn (m1 1) loglogn + constant, where n is the number of training samples and 1 and m1 are the rational number and the natural number, which are determined as the birational invariant values of the singularities in the parameter space. Also we show an algorithm to calculate 1 and m1 based on the resolution of singularities in algebraic geometry. In regular statistical models, 21 is equal to the number of parameters and m1 = 1, whereas in nonregular models, such as multilayer networks, 21 is not larger than the number of parameters and m1 1. Since the increase of the stochastic complexity is equal to the learning curve or the generalization error, the nonidentifiable learning machines are better models than the regular ones if Bayesian ensemble learning is applied.",2001,44,223,17,True,Mathematics,Medicine,2041910832,Sumio Watanabe,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,
885af28a751553be48a25b411a5d492767d4cf65,https://www.semanticscholar.org/paper/885af28a751553be48a25b411a5d492767d4cf65,Ensemble Classifiers for Steganalysis of Digital Media,"Today, the most accurate steganalysis methods for digital media are built as supervised classifiers on feature vectors extracted from the media. The tool of choice for the machine learning seems to be the support vector machine (SVM). In this paper, we propose an alternative and well-known machine learning tool-ensemble classifiers implemented as random forests-and argue that they are ideally suited for steganalysis. Ensemble classifiers scale much more favorably w.r.t. the number of training examples and the feature dimensionality with performance comparable to the much more complex SVMs. The significantly lower training complexity opens up the possibility for the steganalyst to work with rich (high-dimensional) cover models and train on larger training sets-two key elements that appear necessary to reliably detect modern steganographic algorithms. Ensemble classification is portrayed here as a powerful developer tool that allows fast construction of steganography detectors with markedly improved detection accuracy across a wide range of embedding methods. The power of the proposed framework is demonstrated on three steganographic methods that hide messages in JPEG images.",2012,57,898,72,True,Computer Science,,1808384,Jan Kodovský,1751812.0,J. Fridrich,37127008.0,V. Holub,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81c0b1135741385de2fc99307065f9741edaec86,https://www.semanticscholar.org/paper/81c0b1135741385de2fc99307065f9741edaec86,Riemannian Manifold Learning,"Recently, manifold learning has been widely exploited in pattern recognition, data analysis, and machine learning. This paper presents a novel framework, called Riemannian manifold learning (RML), based on the assumption that the input high-dimensional data lie on an intrinsically low-dimensional Riemannian manifold. The main idea is to formulate the dimensionality reduction problem as a classical problem in Riemannian geometry, that is, how to construct coordinate charts for a given Riemannian manifold? We implement the Riemannian normal coordinate chart, which has been the most widely used in Riemannian geometry, for a set of unorganized data points. First, two input parameters (the neighborhood size k and the intrinsic dimension d) are estimated based on an efficient simplicial reconstruction of the underlying manifold. Then, the normal coordinates are computed to map the input high-dimensional data into a low- dimensional space. Experiments on synthetic data, as well as real-world images, demonstrate that our algorithm can learn intrinsic geometric structures of the data, preserve radial geodesic distances, and yield regular embeddings.",2008,58,380,17,False,Mathematics,Medicine,2109626482,Tong Lin,1687248.0,H. Zha,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfea40bf4e4131aab2727e3aaedcf02c1dd594ac,https://www.semanticscholar.org/paper/cfea40bf4e4131aab2727e3aaedcf02c1dd594ac,Bidirectional Extreme Learning Machine for Regression Problem and Its Learning Effectiveness,"It is clear that the learning effectiveness and learning speed of neural networks are in general far slower than required, which has been a major bottleneck for many applications. Recently, a simple and efficient learning method, referred to as extreme learning machine (ELM), was proposed by Huang , which has shown that, compared to some conventional methods, the training time of neural networks can be reduced by a thousand times. However, one of the open problems in ELM research is whether the number of hidden nodes can be further reduced without affecting learning effectiveness. This brief proposes a new learning algorithm, called bidirectional extreme learning machine (B-ELM), in which some hidden nodes are not randomly selected. In theory, this algorithm tends to reduce network output error to 0 at an extremely early learning stage. Furthermore, we find a relationship between the network output error and the network output weights in the proposed B-ELM. Simulation results demonstrate that the proposed method can be tens to hundreds of times faster than other incremental ELM algorithms.",2012,14,162,6,False,Computer Science,Medicine,2108776795,Yimin Yang,2119048509.0,Yaonan Wang,2474758.0,Xiaofang Yuan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e9862146f11fb22df97231b3cccf0e95e8fc2749,https://www.semanticscholar.org/paper/e9862146f11fb22df97231b3cccf0e95e8fc2749,Tutelage and socially guided robot learning,"We view the problem of machine learning as a collaboration between the human and the machine. Inspired by human-style tutelage, we situate the learning problem within a dialog in which social interaction structures the learning experience, providing instruction, directing attention, and controlling the complexity of the task. We present a learning mechanism, implemented on a humanoid robot, to demonstrate that a collaborative dialog framework allows a robot to efficiently learn a task from a human, generalize this ability to a new task configuration, and show commitment to the overall goal of the learned task. We also compare this approach to traditional machine learning approaches.",2004,37,168,12,False,Computer Science,,1682788,A. Thomaz,1711777.0,C. Breazeal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5a4a50f6155e8cb7ee95772194f696a4a1aff0b4,https://www.semanticscholar.org/paper/5a4a50f6155e8cb7ee95772194f696a4a1aff0b4,Towards quantum machine learning with tensor networks,"Machine learning is a promising application of quantum computing, but challenges remain for implementation today because near-term devices have a limited number of physical qubits and high error rates. Motivated by the usefulness of tensor networks for machine learning in the classical context, we propose quantum computing approaches to both discriminative and generative learning, with circuits based on tree and matrix product state tensor networks, that could already have benefits with such near-term devices. The result is a unified framework in which classical and quantum computing can benefit from the same theoretical and algorithmic developments, and the same model can be trained classically then transferred to the quantum setting for additional optimization. Tensor network circuits can also provide qubit-efficient schemes in which, depending on the architecture, the number of physical qubits required scales only logarithmically with, or independently of the input or output data sizes. We demonstrate our proposals with numerical experiments, training a discriminative model to perform handwriting recognition using a hybrid quantum-classical optimization procedure that could be carried out on quantum hardware today, and testing the noise resilience of the trained model.",2018,72,189,13,True,Physics,Computer Science,145287043,W. Huggins,2414098.0,P. Patil,144694999.0,B. Mitchell,52089889.0,K. B. Whaley,3407994.0,E. Stoudenmire,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6032773345c73957f87178fd5d0556870299c4e1,https://www.semanticscholar.org/paper/6032773345c73957f87178fd5d0556870299c4e1,Learning Deep Boltzmann Machines using Adaptive MCMC,"When modeling high-dimensional richly structured data, it is often the case that the distribution defined by the Deep Boltzmann Machine (DBM) has a rough energy landscape with many local minima separated by high energy barriers. The commonly used Gibbs sampler tends to get trapped in one local mode, which often results in unstable learning dynamics and leads to poor parameter estimates. In this paper, we concentrate on learning DBM's using adaptive MCMC algorithms. We first show a close connection between Fast PCD and adaptive MCMC. We then develop a Coupled Adaptive Simulated Tempering algorithm that can be used to better explore a highly multimodal energy landscape. Finally, we demonstrate that the proposed algorithm considerably improves parameter estimates, particularly when learning large-scale DBM's.",2010,20,87,7,False,Computer Science,,145124475,R. Salakhutdinov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a8fadb33a38f1096f84f64bd66345717a5bc3241,https://www.semanticscholar.org/paper/a8fadb33a38f1096f84f64bd66345717a5bc3241,Machine Learning Made Easy: A Review of Scikit-learn Package in Python Programming Language,"Machine learning is a popular topic in data analysis and modeling. Many different machine learning algorithms have been developed and implemented in a variety of programming languages over the past 20 years. In this article, we first provide an overview of machine learning and clarify its difference from statistical inference. Then, we review Scikit-learn, a machine learning package in the Python programming language that is widely used in data science. The Scikit-learn package includes implementations of a comprehensive list of machine learning methods under unified data and modeling procedure conventions, making it a convenient toolkit for educational and behavior statisticians.",2019,0,101,6,False,Computer Science,,3433417,J. Hao,1795578.0,T. Ho,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36d442f59c61ea2912d227c24dee76778c546b0a,https://www.semanticscholar.org/paper/36d442f59c61ea2912d227c24dee76778c546b0a,"Graph Signal Processing: Overview, Challenges, and Applications","Research in graph signal processing (GSP) aims to develop tools for processing data defined on irregular graph domains. In this paper, we first provide an overview of core ideas in GSP and their connection to conventional digital signal processing, along with a brief historical perspective to highlight how concepts recently developed in GSP build on top of prior research in other areas. We then summarize recent advances in developing basic GSP tools, including methods for sampling, filtering, or graph learning. Next, we review progress in several application areas using GSP, including processing and analysis of sensor network data, biological data, and applications to image processing and machine learning.",2017,221,908,108,True,Engineering,Computer Science,145029825,Antonio Ortega,1703189.0,P. Frossard,2442915.0,J. Kovacevic,51283515.0,J. Moura,1697397.0,P. Vandergheynst,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c46b08850b9c458704a3ca69172e6a0d40a6cb7f,https://www.semanticscholar.org/paper/c46b08850b9c458704a3ca69172e6a0d40a6cb7f,Online Tracking by Learning Discriminative Saliency Map with Convolutional Neural Network,"We propose an online visual tracking algorithm by learning discriminative saliency map using Convolutional Neural Network (CNN). Given a CNN pre-trained on a large-scale image repository in offline, our algorithm takes outputs from hidden layers of the network as feature descriptors since they show excellent representation performance in various general visual recognition problems. The features are used to learn discriminative target appearance models using an online Support Vector Machine (SVM). In addition, we construct target-specific saliency map by backprojecting CNN features with guidance of the SVM, and obtain the final tracking result in each frame based on the appearance model generatively constructed with the saliency map. Since the saliency map reveals spatial configuration of target effectively, it improves target localization accuracy and enables us to achieve pixel-level target segmentation. We verify the effectiveness of our tracking algorithm through extensive experiment on a challenging benchmark, where our method illustrates outstanding performance compared to the state-of-the-art tracking algorithms.",2015,50,742,83,False,Computer Science,,2241528,Seunghoon Hong,2205770.0,Tackgeun You,2483916.0,Suha Kwak,40030651.0,Bohyung Han,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4778ac8db117bdd831e3776b78de7b7d1b98de3a,https://www.semanticscholar.org/paper/4778ac8db117bdd831e3776b78de7b7d1b98de3a,"Unsupervised Machine Learning for Networking: Techniques, Applications and Research Challenges","While machine learning and artificial intelligence have long been applied in networking research, the bulk of such works has focused on supervised learning. Recently, there has been a rising trend of employing unsupervised machine learning using unstructured raw network data to improve network performance and provide services, such as traffic engineering, anomaly detection, Internet traffic classification, and quality of service optimization. The growing interest in applying unsupervised learning techniques in networking stems from their great success in other fields, such as computer vision, natural language processing, speech recognition, and optimal control (e.g., for developing autonomous self-driving cars). In addition, unsupervised learning can unconstrain us from the need for labeled data and manual handcrafted feature engineering, thereby facilitating flexible, general, and automated methods of machine learning. The focus of this survey paper is to provide an overview of applications of unsupervised learning in the domain of networking. We provide a comprehensive survey highlighting recent advancements in unsupervised learning techniques, and describe their applications in various learning tasks, in the context of networking. We also provide a discussion on future directions and open research issues, while identifying potential pitfalls. While a few survey papers focusing on applications of machine learning in networking have previously been published, a survey of similar scope and breadth is missing in the literature. Through this timely review, we aim to advance the current state of knowledge, by carefully synthesizing insights from previous survey papers, while providing contemporary coverage of the recent advances and innovations.",2017,335,149,5,True,Computer Science,,145474282,M. Usama,1734917.0,Junaid Qadir,10195630.0,Aunn Raza,1413069513.0,Hunain Arif,34896884.0,K. Yau,2067322996.0,Y. Elkhatib,145125161.0,A. Hussain,,1404786833.0,A. Al-Fuqaha,,,,,,,,,,,,,,,,,,,,,,,,,
b2e0b79e6f180af2e0e559f2b1faba66b2bd578a,https://www.semanticscholar.org/paper/b2e0b79e6f180af2e0e559f2b1faba66b2bd578a,Accelerating the Machine Learning Lifecycle with MLflow,"Machine learning development creates multiple new challenges that are not present in a traditional software development lifecycle. These include keeping track of the myriad inputs to an ML application (e.g., data versions, code and tuning parameters), reproducing results, and production deployment. In this paper, we summarize these challenges from our experience with Databricks customers, and describe MLflow, an open source platform we recently launched to streamline the machine learning lifecycle. MLflow covers three key challenges: experimentation, reproducibility, and model deployment, using generic APIs that work with any ML library, algorithm and programming language. The project has a rapidly growing open source community, with over 50 contributors since its launch in June 2018.",2018,12,179,23,False,Computer Science,,143834867,M. Zaharia,2111074632.0,A. Chen,39885771.0,A. Davidson,38565890.0,A. Ghodsi,3352005.0,S. Hong,2371549.0,A. Konwinski,88307932.0,Siddharth Murching,,2766877.0,Tomas Nykodym,1873118.0,Paul Ogilvie,87380811.0,Mani Parkhe,2054585376.0,Fen Xie,52145600.0,Corey Zumar,,,,,,,,,,,,,,,,,
cbac8b0d82ea8e9251d5530695841d816cb196b9,https://www.semanticscholar.org/paper/cbac8b0d82ea8e9251d5530695841d816cb196b9,Pingouin: statistics in Python,"Python is currently the fastest growing programming language in the world, thanks to its ease-of-use, fast learning curve and its numerous high quality packages for data science and machine-learning. Surprisingly however, Python is far behind the R programming language when it comes to general statistics and for this reason many scientists still rely heavily on R to perform their statistical analyses.",2018,5,426,60,True,Computer Science,,2095214091,Raphael Vallat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3adcfd254b271bcc2fb7e2a62d750db17e6c2c08,https://www.semanticscholar.org/paper/3adcfd254b271bcc2fb7e2a62d750db17e6c2c08,A brief introduction to weakly supervised learning,"Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.",2018,104,890,27,False,Computer Science,,145624000,Zhi-Hua Zhou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9ebe893e426d1f4c0e1cc2059ea87cf9bceeb4a1,https://www.semanticscholar.org/paper/9ebe893e426d1f4c0e1cc2059ea87cf9bceeb4a1,Syntactic Methods in Pattern Recognition,"This book is an integrated sequence of papers Professor Michie has published, for a general audience, over the last decade or so. It contains the following: Introduction Trial and Error (Science Survey, 1961) Puzzle-learning versus Game-learning (The Scientist Speculates, 1962) Game-playing Automata (Advances in Programming and Non-Numerical Computation, 1966) Machines that Play and Plan (Science Journal, 1968) Computer servant or master (Theoria to Theory, 1968) Integrated Cognitive Systems (Nature, 1970) Tokyo-Edinburgh Dialogue (The Computer Journal, 1971) Artificial Intelligence (New Society, 1971) On not seeing things (Experimental Programming Report, 1971) Programmer's Gambit (New Scientist, 1972) Machine Intelligence at Edinburgh (Management Informatics, 1973) Theory of Intelligence (Nature, 1973) Memory Mechanisms and Learning (Simple Nervous Systems, 1974) Knowledge Engineering (Kybernetics, 1973) Maching Intelligence as Technology (Proceedings of the Conference on Shop Floor Automation, 1973) 7. The Structure of Belief Systems -Robert P. Abelson",1974,57,504,11,False,Computer Science,,97306284,K. Fu,2545803.0,M. Aizerman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7178bf9576ea3c8094953cbad5cfa950502a3dc0,https://www.semanticscholar.org/paper/7178bf9576ea3c8094953cbad5cfa950502a3dc0,Adversarial Machine Learning,"Abstract The increasing abundance of large high-quality datasets, combined with significant technical advances over the last several decades have made machine learning into a major tool employed ac...",2018,84,41,1,True,Computer Science,,1699600,Yevgeniy Vorobeychik,1741044.0,Murat Kantarcioglu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b6139e7f568f0cbd8bcfc7dfd5885dec474270d6,https://www.semanticscholar.org/paper/b6139e7f568f0cbd8bcfc7dfd5885dec474270d6,Distributed learning in wireless sensor networks,"This paper discusses nonparametric distributed learning. After reviewing the classical learning model and highlighting the success of machine learning in centralized settings, the challenges that wireless sensor networks (WSN) pose for distributed learning are discussed, and research aimed at addressing these challenges is surveyed.",2005,131,293,10,True,Computer Science,Mathematics,2498294,J. Predd,1697413.0,S. Kulkarni,145967056.0,H. Poor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f1024a28c977c9555b77ef2b7c8cada2ae3b36b,https://www.semanticscholar.org/paper/5f1024a28c977c9555b77ef2b7c8cada2ae3b36b,Machine Learning: Hands-On for Developers and Technical Professionals,"Dig deep into the data with a hands-on guide to machine learning Machine Learning: Hands-On for Developers and Technical Professionals provides hands-on instruction and fully-coded working examples for the most common machine learning techniques used by developers and technical professionals. The book contains a breakdown of each ML variant, explaining how it works and how it is used within certain industries, allowing readers to incorporate the presented techniques into their own work as they follow along. A core tenant of machine learning is a strong focus on data preparation, and a full exploration of the various types of learning algorithms illustrates how the proper tools can help any developer extract information and insights from existing data. The book includes a full complement of Instructor's Materials to facilitate use in the classroom, making this resource useful for students and as a professional reference.",2014,0,128,14,False,Computer Science,,51011457,J. Bell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43054544c4ff2e25513de8b1a655593b8ff89338,https://www.semanticscholar.org/paper/43054544c4ff2e25513de8b1a655593b8ff89338,Deep Learning for Classical Japanese Literature,"Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at this https URL",2018,30,411,93,False,Computer Science,Mathematics,52214414,Tarin Clanuwat,1387990552.0,Mikel Bober-Irizar,1730368.0,A. Kitamoto,49071560.0,Alex Lamb,50032855.0,Kazuaki Yamamoto,1389041357.0,David Ha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
168b7d0ab57a331a228ce21ffd1becbb93066f79,https://www.semanticscholar.org/paper/168b7d0ab57a331a228ce21ffd1becbb93066f79,Neural Optimizer Search with Reinforcement Learning,"We present an approach to automate the process of discovering optimization methods, with a focus on deep learning architectures. We train a Recurrent Neural Network controller to generate a string in a domain specific language that describes a mathematical update equation based on a list of primitive functions, such as the gradient, running average of the gradient, etc. The controller is trained with Reinforcement Learning to maximize the performance of a model after a few epochs. On CIFAR-10, our method discovers several update rules that are better than many commonly used optimizers, such as Adam, RMSProp, or SGD with and without Momentum on a ConvNet model. We introduce two new optimizers, named PowerSign and AddSign, which we show transfer well and improve training on a variety of different tasks and architectures, including ImageNet classification and Google's neural machine translation system.",2017,49,300,32,False,Computer Science,Mathematics,4689792,Irwan Bello,2368067.0,Barret Zoph,2053781980.0,Vijay Vasudevan,2827616.0,Quoc V. Le,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5aaa65fbe2abe27afb237b2f40909d686b14b1ee,https://www.semanticscholar.org/paper/5aaa65fbe2abe27afb237b2f40909d686b14b1ee,"Asymptotically Exact, Embarrassingly Parallel MCMC","Communication costs, resulting from synchronization requirements during learning, can greatly slow down many parallel machine learning algorithms. In this paper, we present a parallel Markov chain Monte Carlo (MCMC) algorithm in which subsets of data are processed independently, with very little communication. First, we arbitrarily partition data onto multiple machines. Then, on each machine, any classical MCMC method (e.g., Gibbs sampling) may be used to draw samples from a posterior distribution given the data subset. Finally, the samples from each machine are combined to form samples from the full posterior. This embarrassingly parallel algorithm allows each machine to act independently on a subset of the data (without communication) until the final combination stage. We prove that our algorithm generates asymptotically exact samples and empirically demonstrate its ability to parallelize burn-in and sampling in several models.",2013,27,286,42,False,Computer Science,Mathematics,2934259,W. Neiswanger,2108881999.0,Chong Wang,143977260.0,E. Xing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22a65f6975c98644f9a2601f731e9b2b7e15a216,https://www.semanticscholar.org/paper/22a65f6975c98644f9a2601f731e9b2b7e15a216,A Primer on PAC-Bayesian Learning,"Generalised Bayesian learning algorithms are increasingly popular in machine learning, due to their PAC generalisation properties and flexibility. The present paper aims at providing a self-contained survey on the resulting PAC-Bayes framework and some of its main theoretical and algorithmic developments.",2019,106,131,10,False,Mathematics,Computer Science,3383281,Benjamin Guedj,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31357323cf2e99d33c0441bf3b5d0eeaccb9a59b,https://www.semanticscholar.org/paper/31357323cf2e99d33c0441bf3b5d0eeaccb9a59b,A Hybrid Intelligent System Framework for the Prediction of Heart Disease Using Machine Learning Algorithms,"Heart disease is one of the most critical human diseases in the world and affects human life very badly. In heart disease, the heart is unable to push the required amount of blood to other parts of the body. Accurate and on time diagnosis of heart disease is important for heart failure prevention and treatment. The diagnosis of heart disease through traditional medical history has been considered as not reliable in many aspects. To classify the healthy people and people with heart disease, noninvasive-based methods such as machine learning are reliable and efficient. In the proposed study, we developed a machine-learning-based diagnosis system for heart disease prediction by using heart disease dataset. We used seven popular machine learning algorithms, three feature selection algorithms, the cross-validation method, and seven classifiers performance evaluation metrics such as classification accuracy, specificity, sensitivity, Matthews’ correlation coefficient, and execution time. The proposed system can easily identify and classify people with heart disease from healthy people. Additionally, receiver optimistic curves and area under the curves for each classifier was computed. We have discussed all of the classifiers, feature selection algorithms, preprocessing methods, validation method, and classifiers performance evaluation metrics used in this paper. The performance of the proposed system has been validated on full features and on a reduced set of features. The features reduction has an impact on classifiers performance in terms of accuracy and execution time of classifiers. The proposed machine-learning-based decision support system will assist the doctors to diagnosis heart patients efficiently.",2018,50,243,11,True,Computer Science,,23729239,A. Haq,2109027908.0,Jianping Li,2578437.0,Muhammad Hammad Memon,3195938.0,S. Nazir,123195371.0,Ruinan Sun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fcc9a75d0cd12cfce81fcd22b22867f76b258e0c,https://www.semanticscholar.org/paper/fcc9a75d0cd12cfce81fcd22b22867f76b258e0c,DiSCO: Distributed Optimization for Self-Concordant Empirical Loss,"We propose a new distributed algorithm for empirical risk minimization in machine learning. The algorithm is based on an inexact damped Newton method, where the inexact Newton steps are computed by a distributed preconditioned conjugate gradient method. We analyze its iteration complexity and communication efficiency for minimizing self-concordant empirical loss functions, and discuss the results for distributed ridge regression, logistic regression and binary classification with a smoothed hinge loss. In a standard setting for supervised learning, where the n data points are i.i.d. sampled and when the regularization parameter scales as 1/√n show that the proposed algorithm is communication efficient: the required round of communication does not increase with the sample size n, and only grows slowly with the number of machines.",2015,27,185,34,False,Mathematics,Computer Science,2108471978,Yuchen Zhang,143724437.0,Xiao Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d0c882bcae6531fa13e75bcc5c297b9985f207f7,https://www.semanticscholar.org/paper/d0c882bcae6531fa13e75bcc5c297b9985f207f7,Web mining research: a survey,"With the huge amount of information available online, the World Wide Web is a fertile area for data mining research. The Web mining research is at the cross road of research from several research communities, such as database, information retrieval, and within AI, especially the sub-areas of machine learning and natural language processing. However, there is a lot of confusions when comparing research efforts from different point of views. In this paper, we survey the research in the area of Web mining, point out some confusions regarded the usage of the term Web mining and suggest three Web mining categories. Then we situate some of the research with respect to these three categories. We also explore the connection between the Web mining categories and the related agent paradigm. For the survey, we focus on representation issues, on the process, on the learning algorithm, and on the application of the recent works as the criteria. We conclude the paper with some research issues.",2000,133,1872,88,True,Computer Science,,2937911,R. Kosala,1755851.0,H. Blockeel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8b5c2601b63607d557daa98fdff8899068c2377e,https://www.semanticscholar.org/paper/8b5c2601b63607d557daa98fdff8899068c2377e,Comparison of machine learning and traditional classifiers in glaucoma diagnosis,"Glaucoma is a progressive optic neuropathy with characteristic structural changes in the optic nerve head reflected in the visual field. The visual-field sensitivity test is commonly used in a clinical setting to evaluate glaucoma. Standard automated perimetry (SAP) is a common computerized visual-field test whose output is amenable to machine learning. We compared the performance of a number of machine learning algorithms with STATPAC indexes mean deviation, pattern standard deviation, and corrected pattern standard deviation. The machine learning algorithms studied included multilayer perceptron (MLP), support vector machine (SVM), and linear (LDA) and quadratic discriminant analysis (QDA), Parzen window, mixture of Gaussian (MOG), and mixture of generalized Gaussian (MGG). MLP and SVM are classifiers that work directly on the decision boundary and fall under the discriminative paradigm. Generative classifiers, which first model the data probability density and then perform classification via Bayes' rule, usually give deeper insight into the structure of the data space. We have applied MOG, MGG, LDA, QDA, and Parzen window to the classification of glaucoma from SAP. Performance of the various classifiers was compared by the areas under their receiver operating characteristic curves and by sensitivities (true-positive rates) at chosen specificities (true-negative rates). The machine-learning-type classifiers showed improved performance over the best indexes from STATPAC. Forward-selection and backward-elimination methodology further improved the classification rate and also has the potential to reduce testing time by diminishing the number of visual-field location measurements.",2002,99,188,5,False,Computer Science,Medicine,9261843,K. Chan,103917250.0,Te-Won Lee,2175412.0,P. Sample,32618175.0,M. Goldbaum,2418684.0,R. Weinreb,1714528.0,T. Sejnowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6965c8e2dcd6ecf2a5f3f9320de5fced37391e42,https://www.semanticscholar.org/paper/6965c8e2dcd6ecf2a5f3f9320de5fced37391e42,Classification and modeling with linguistic information granules - advanced approaches to linguistic data mining,Linguistic Information Granules.- Pattern Classification with Linguistic Rules.- Learning of Linguistic Rules.- Input Selection and Rule Selection.- Genetics-Based Machine Learning.- Multi-Objective Design of Linguistic Models.- Comparison of Linguistic Discretization with Interval Discretization.- Modeling with Linguistic Rules.- Design of Compact Linguistic Models.- Linguistic Rules with Consequent Real Numbers.- Handling of Linguistic Rules in Neural Networks.- Learning of Neural Networks from Linguistic Rules.- Linguistic Rule Extraction from Neural Networks.- Modeling of Fuzzy Input-Output Relations.,2004,0,418,19,False,Computer Science,,10022373,H. Ishibuchi,72328943.0,T. Nakashima,3128274.0,M. Nii,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f8c8619ea7d68e604e40b814b40c72888a755e95,https://www.semanticscholar.org/paper/f8c8619ea7d68e604e40b814b40c72888a755e95,Unsupervised Feature Learning and Deep Learning: A Review and New Perspectives,"The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although domain knowledge can be used to help design representations, learning can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, manifold learning, and deep learning. This motivates longer-term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation and manifold learning.",2012,209,501,33,False,Computer Science,,1751762,Yoshua Bengio,1760871.0,Aaron C. Courville,145467703.0,Pascal Vincent,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d517b13f2b152c913b81ce534a149493517dbdad,https://www.semanticscholar.org/paper/d517b13f2b152c913b81ce534a149493517dbdad,Big Data Deep Learning: Challenges and Perspectives,"Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.",2014,110,867,30,False,Computer Science,,2145447101,Xue-wen Chen,39376164.0,Xiaotong Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8012d9c71b9e6c312e3f1ec4cfb089622eceaf9d,https://www.semanticscholar.org/paper/8012d9c71b9e6c312e3f1ec4cfb089622eceaf9d,Transductive Support Vector Machines,"In contrast to learning a general prediction rule, V. Vapnik proposed the transductive learning setting where predictions are made only at a fixed number of known test points. This allows the learning algorithm to exploit the location of the test points, making it a particular type of semi-supervised learning problem. Transductive support vector machines (TSVMs) implement the idea of transductive learning by including test points in the computation of the margin. This chapter will provide some examples for why the margin on the test examples can provide useful prior information for learning, in particular for the problem of text classification. The resulting optimization problems, however, are difficult to solve. The chapter reviews exact and approximate optimization methods and discusses their properties. Finally, the chapter discusses connections to other related semi-supervised learning approaches like co-training and methods based on graph cuts, which can be seen as solving variants of the TSVM optimization problem.",2006,0,59,3,False,Computer Science,,1680188,T. Joachims,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38d8230a7aeae6554497b253848ad5bf677e4fb3,https://www.semanticscholar.org/paper/38d8230a7aeae6554497b253848ad5bf677e4fb3,PennyLane: Automatic differentiation of hybrid quantum-classical computations,"PennyLane is a Python 3 software framework for optimization and machine learning of quantum and hybrid quantum-classical computations. The library provides a unified architecture for near-term quantum computing devices, supporting both qubit and continuous-variable paradigms. PennyLane's core feature is the ability to compute gradients of variational quantum circuits in a way that is compatible with classical techniques such as backpropagation. PennyLane thus extends the automatic differentiation algorithms common in optimization and machine learning to include quantum and hybrid computations. A plugin system makes the framework compatible with any gate-based quantum simulator or hardware. We provide plugins for Strawberry Fields, Rigetti Forest, Qiskit, Cirq, and ProjectQ, allowing PennyLane optimizations to be run on publicly accessible quantum devices provided by Rigetti and IBM Q. On the classical front, PennyLane interfaces with accelerated machine learning libraries such as TensorFlow, PyTorch, and autograd. PennyLane can be used for the optimization of variational quantum eigensolvers, quantum approximate optimization, quantum machine learning models, and many other applications.",2018,55,313,46,False,Physics,Computer Science,3201137,V. Bergholm,2070140.0,J. Izaac,3048564.0,M. Schuld,3348073.0,C. Gogolin,3399181.0,N. Killoran,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,
1b463b36d1bbccc419954cc28bd28b0108c2ca63,https://www.semanticscholar.org/paper/1b463b36d1bbccc419954cc28bd28b0108c2ca63,Predicting solar generation from weather forecasts using machine learning,"A key goal of smart grid initiatives is significantly increasing the fraction of grid energy contributed by renewables. One challenge with integrating renewables into the grid is that their power generation is intermittent and uncontrollable. Thus, predicting future renewable generation is important, since the grid must dispatch generators to satisfy demand as generation varies. While manually developing sophisticated prediction models may be feasible for large-scale solar farms, developing them for distributed generation at millions of homes throughout the grid is a challenging problem. To address the problem, in this paper, we explore automatically creating site-specific prediction models for solar power generation from National Weather Service (NWS) weather forecasts using machine learning techniques. We compare multiple regression techniques for generating prediction models, including linear least squares and support vector machines using multiple kernel functions. We evaluate the accuracy of each model using historical NWS forecasts and solar intensity readings from a weather station deployment for nearly a year. Our results show that SVM-based prediction models built using seven distinct weather forecast metrics are 27% more accurate for our site than existing forecast-based models.",2011,11,369,18,False,Engineering,Computer Science,3233107,Navin Sharma,2112284118.0,Pranshu Sharma,1697572.0,David E. Irwin,2172702597.0,P. Shenoy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a44f2ad10815051142c97fb466c51c8c9eda1d7f,https://www.semanticscholar.org/paper/a44f2ad10815051142c97fb466c51c8c9eda1d7f,Predicting reaction performance in C–N cross-coupling using machine learning,"A guide for catalyst choice in the forest Chemists often discover reactions by applying catalysts to a series of simple compounds. Tweaking those reactions to tolerate more structural complexity in pharmaceutical research is time-consuming. Ahneman et al. report that machine learning can help. Using a high-throughput data set, they trained a random forest algorithm to predict which specific palladium catalysts would best tolerate isoxazoles (cyclic structures with an N–O bond) during C–N bond formation. The predictions also helped to guide analysis of the catalyst inhibition mechanism. Science, this issue p. 186 A random forest algorithm trained on high-throughput data predicts which catalysts best tolerate certain heterocycles. Machine learning methods are becoming integral to scientific inquiry in numerous disciplines. We demonstrated that machine learning can be used to predict the performance of a synthetic reaction in multidimensional chemical space using data obtained via high-throughput experimentation. We created scripts to compute and extract atomic, molecular, and vibrational descriptors for the components of a palladium-catalyzed Buchwald-Hartwig cross-coupling of aryl halides with 4-methylaniline in the presence of various potentially inhibitory additives. Using these descriptors as inputs and reaction yield as output, we showed that a random forest algorithm provides significantly improved predictive performance over linear regression analysis. The random forest model was also successfully applied to sparse training sets and out-of-sample prediction, suggesting its value in facilitating adoption of synthetic methodology.",2018,46,388,11,False,Computer Science,Medicine,8504486,Derek T Ahneman,33072648.0,Jesús G Estrada,2119449773.0,Shishi Lin,6761177.0,S. Dreher,3599914.0,A. Doyle,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23afab3f249477d086819e890ac4aa417998568c,https://www.semanticscholar.org/paper/23afab3f249477d086819e890ac4aa417998568c,Covering Number Bounds of Certain Regularized Linear Function Classes,"Recently, sample complexity bounds have been derived for problems involving linear functions such as neural networks and support vector machines. In many of these theoretical studies, the concept of covering numbers played an important role. It is thus useful to study covering numbers for linear function classes. In this paper, we investigate two closely related methods to derive upper bounds on these covering numbers. The first method, already employed in some earlier studies, relies on the so-called Maurey's lemma; the second method uses techniques from the mistake bound framework in online learning. We compare results from these two methods, as well as their consequences in some learning formulations.",2002,43,260,29,False,Mathematics,Computer Science,2117881943,Tong Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f1b1d5da2b18bb3740a24ff3c75c19c82feae375,https://www.semanticscholar.org/paper/f1b1d5da2b18bb3740a24ff3c75c19c82feae375,Data Mining and Machine Learning Techniques for the Identification of Mutagenicity Inducing Substructures and Structure Activity Relationships of Noncongeneric Compounds,"This paper explores the utility of data mining and machine learning algorithms for the induction of mutagenicity structure-activity relationships (SARs) from noncongeneric data sets. We compare (i) a newly developed algorithm (MOLFEA) for the generation of descriptors (molecular fragments) for noncongeneric compounds with traditional SAR approaches (molecular properties) and (ii) different machine learning algorithms for the induction of SARs from these descriptors. In addition we investigate the optimal parameter settings for these programs and give an exemplary interpretation of the derived models. The predictive accuracies of models using MOLFEA derived descriptors is approximately 10-15%age points higher than those using molecular properties alone. Using both types of descriptors together does not improve the derived models. From the applied machine learning techniques the rule learner PART and support vector machines gave the best results, although the differences between the learning algorithms are only marginal. We were able to achieve predictive accuracies up to 78% for 10-fold cross-validation. The resulting models are relatively easy to interpret and usable for predictive as well as for explanatory purposes.",2004,27,240,10,True,Computer Science,Medicine,3323969,C. Helma,2070118303.0,Tobias Cramer,145471896.0,Stefan Kramer,1740042.0,L. D. Raedt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
abe0bd94e134c7ac0b1c78922ed17cf3bec08d5e,https://www.semanticscholar.org/paper/abe0bd94e134c7ac0b1c78922ed17cf3bec08d5e,A stochastic model of human-machine interaction for learning dialog strategies,"We propose a quantitative model for dialog systems that can be used for learning the dialog strategy. We claim that the problem of dialog design can be formalized as an optimization problem with an objective function reflecting different dialog dimensions relevant for a given application. We also show that any dialog system can be formally described as a sequential decision process in terms of its state space, action set, and strategy. With additional assumptions about the state transition probabilities and cost assignment, a dialog system can be mapped to a stochastic model known as Markov decision process (MDP). A variety of data driven algorithms for finding the optimal strategy (i.e., the one that optimizes the criterion) is available within the MDP framework, based on reinforcement learning. For an effective use of the available training data we propose a combination of supervised and reinforcement learning: the supervised learning is used to estimate a model of the user, i.e., the MDP parameters that quantify the user's behavior. Then a reinforcement learning algorithm is used to estimate the optimal strategy while the system interacts with the simulated user. This approach is tested for learning the strategy in an air travel information system (ATIS) task. The experimental results we present in this paper show that it is indeed possible to find a simple criterion, a state space representation, and a simulated user parameterization in order to automatically learn a relatively complex dialog behavior, similar to one that was heuristically designed by several research groups.",2000,36,588,45,False,Computer Science,,8992604,E. Levin,2115311.0,R. Pieraccini,31717617.0,W. Eckert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9111e0a578ae34664dddcd76794bbe20e168a1ff,https://www.semanticscholar.org/paper/9111e0a578ae34664dddcd76794bbe20e168a1ff,Usilng Machine Learning Technliques to Identify Botnet Traffic,"To date, techniques to counter cyber-attacks have predominantly been reactive; they focus on monitoring network traffic, detecting anomalies and cyber-attack traffic patterns, and, a posteriori, combating the cyber-attacks and mitigating their effects. Contrary to such approaches, we advocate proactively detecting and identifying botnets prior to their being used as part of a cyber-attack (Strayer et al., 2006). In this paper, we present our work on using machine learning-based classification techniques to identify the command and control (C2) traffic of IRC-based botnets - compromised hosts that are collectively commanded using Internet relay chat (IRC). We split this task into two stages: (I) distinguishing between IRC and non-IRC traffic, and (II) distinguishing between botnet and real IRC traffic. For stage I, we compare the performance of J48, naive Bayes, and Bayesian network classifiers, identify the features that achieve good overall classification accuracy, and determine the classification sensitivity to the training set size. While sensitive to the training data and the attributes used to characterize communication flows, machine learning-based classifiers show promise in identifying IRC traffic. Using classification in stage II is trickier, since accurately labeling IRC traffic as botnet and non-botnet is challenging. We are currently exploring labeling flows as suspicious and non-suspicious based on telltales of hosts being compromised",2006,19,348,16,False,Computer Science,,32744942,C. Livadas,145963952.0,R. Walsh,17286974.0,D. Lapsley,1732393.0,W. Strayer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
947498b4518b88909babfb07ea27773ac60b0bdb,https://www.semanticscholar.org/paper/947498b4518b88909babfb07ea27773ac60b0bdb,MACHINE LEARNING METHODS FOR SYSTEMIC RISK ANALYSIS IN FINANCIAL SECTORS,"Financial systemic risk is an important issue in economics and financial systems. Trying to detect and respond to systemic risk with growing amounts of data produced in financial markets and systems, a lot of researchers have increasingly employed machine learning methods. Machine learning methods study the mechanisms of outbreak and contagion of systemic risk in the financial network and improve the current regulation of the financial market and industry. In this paper, we survey existing researches and methodologies on assessment and measurement of financial systemic risk combined with machine learning technologies, including big data analysis, network analysis and sentiment analysis, etc. In addition, we identify future challenges, and suggest further research topics. The main purpose of this paper is to introduce current researches on financial systemic risk with machine learning methods and to propose directions for future work.",2019,180,147,2,True,Business,,46860084,Gang Kou,1978516.0,Xiangrui Chao,144580890.0,Yi Peng,40549277.0,F. Alsaadi,1397996912.0,E. Herrera-Viedma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c8c16a56d2a9520197da9a1546f517db5f19b204,https://www.semanticscholar.org/paper/c8c16a56d2a9520197da9a1546f517db5f19b204,Adversarial Attacks on Neural Network Policies,"Machine learning classifiers are known to be vulnerable to inputs maliciously constructed by adversaries to force misclassification. Such adversarial examples have been extensively studied in the context of computer vision applications. In this work, we show adversarial attacks are also effective when targeting neural network policies in reinforcement learning. Specifically, we show existing adversarial example crafting techniques can be used to significantly degrade test-time performance of trained policies. Our threat model considers adversaries capable of introducing small perturbations to the raw input of the policy. We characterize the degree of vulnerability across tasks and training algorithms, for a subclass of adversarial-example attacks in white-box and black-box settings. Regardless of the learned task or training algorithm, we observe a significant drop in performance, even with small adversarial perturbations that do not interfere with human perception. Videos are available at this http URL.",2017,23,541,57,False,Computer Science,Mathematics,2064588,Sandy H. Huang,1967156.0,Nicolas Papernot,153440022.0,Ian J. Goodfellow,144581158.0,Yan Duan,1689992.0,P. Abbeel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
404f4095b86b12e2dd33a79fbb737171783ba955,https://www.semanticscholar.org/paper/404f4095b86b12e2dd33a79fbb737171783ba955,Deep Learning and Its Applications to Signal and Information Processing,"INTRODUCTION TO DEEP LEARNING Many traditional machine learning and signal processing techniques exploit shallow architectures, which contain a single layer of nonlinear feature transformation. Examples of shallow architectures are conventional hidden Markov models (HMMs), linear or nonlinear dynamical systems, conditional random fields (CRFs), maximum entropy (MaxEnt) models, support vector machines (SVMs), kernel regression, and multilayer perceptron (MLP) with a single hidden layer. A property common to these shallow learning models is the simple architecture that consists of only one layer responsible for transforming the raw input signals or features into a problem-specific feature space, which may be unobservable. Take the example of a support vector machine. It is a shallow linear separation model with one feature transformation layer when kernel trick is used, and with zero feature transformation layer when kernel trick is not used. Human information processing",2011,15,301,7,False,Computer Science,,144580027,Dong Yu,144718788.0,L. Deng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
99fe982dce046869f60e4552c7f91c3627304780,https://www.semanticscholar.org/paper/99fe982dce046869f60e4552c7f91c3627304780,Using “Annotator Rationales” to Improve Machine Learning for Text Categorization,"We propose a new framework for supervised machine learning. Our goal is to learn from smaller amounts of supervised training data, by collecting a richer kind of training data: annotations with “rationales.” When annotating an example, the human teacher will also highlight evidence supporting this annotation—thereby teaching the machine learner why the example belongs to the category. We provide some rationale-annotated data and present a learning method that exploits the rationales during training to boost performance significantly on a sample task, namely sentiment classification of movie reviews. We hypothesize that in some situations, providing rationales is a more fruitful use of an annotator’s time than annotating more examples.",2007,10,273,47,False,Computer Science,,1936277,Omar Zaidan,145043214.0,Jason Eisner,1718753.0,C. Piatko,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
abe8a57dc27598937c2cffde3fc21c1e6d1f11ce,https://www.semanticscholar.org/paper/abe8a57dc27598937c2cffde3fc21c1e6d1f11ce,Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis,"The past decade has seen an explosion in the amount of digital information stored in electronic health records (EHRs). While primarily designed for archiving patient information and performing administrative healthcare tasks like billing, many researchers have found secondary use of these records for various clinical informatics applications. Over the same period, the machine learning community has seen widespread advances in the field of deep learning. In this review, we survey the current research on applying deep learning to clinical tasks based on EHR data, where we find a variety of deep learning techniques and frameworks being applied to several types of clinical applications including information extraction, representation learning, outcome prediction, phenotyping, and deidentification. We identify several limitations of current research involving topics such as model interpretability, data heterogeneity, and lack of universal benchmarks. We conclude by summarizing the state of the field and identifying avenues of future deep EHR research.",2017,71,706,30,True,Computer Science,Mathematics,3383528,Benjamin Shickel,40449634.0,P. Tighe,5484714.0,A. Bihorac,1715006.0,Parisa Rashidi,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,
db4d0e45560ceda35b6212036513bd4ab59ce99d,https://www.semanticscholar.org/paper/db4d0e45560ceda35b6212036513bd4ab59ce99d,SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient,"In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems. Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients. The linear convergence rate of SARAH is proven under strong convexity assumption. We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess. Numerical experiments demonstrate the efficiency of our algorithm.",2017,23,377,80,False,Mathematics,Computer Science,144274166,Lam M. Nguyen,2146651544.0,Jie Liu,2005127.0,K. Scheinberg,144696183.0,Martin Takác,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ab1cfb387e56b6db2f5e8cbc6b253c0231a9af23,https://www.semanticscholar.org/paper/ab1cfb387e56b6db2f5e8cbc6b253c0231a9af23,On ψ-Learning,"The concept of large margins have been recognized as an important principle in analyzing learning methodologies, including boosting, neural networks, and support vector machines (SVMs). However, this concept alone is not adequate for learning in nonseparable cases. We propose a learning methodology, called ψ-learning, that is derived from a direct consideration of generalization errors. We provide a theory for ψ-learning and show that it essentially attains the optimal rates of convergence in two learning examples. Finally, results from simulation studies and from breast cancer classification confirm the ability of ψ-learning to outperform SVM in generalization.",2003,20,426,40,False,Mathematics,,2266946,Xiaotong Shen,1799353.0,G. Tseng,47957199.0,Xuegong Zhang,143725639.0,W. Wong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c0e10356210aefe4ce9afc94f6c3d0c511222c5f,https://www.semanticscholar.org/paper/c0e10356210aefe4ce9afc94f6c3d0c511222c5f,Prediction and Validation of Disease Genes Using HeteSim Scores,"Deciphering the gene disease association is an important goal in biomedical research. In this paper, we use a novel relevance measure, called HeteSim, to prioritize candidate disease genes. Two methods based on heterogeneous networks constructed using protein-protein interaction, gene-phenotype associations, and phenotype-phenotype similarity, are presented. In HeteSim_MultiPath (HSMP), HeteSim scores of different paths are combined with a constant that dampens the contributions of longer paths. In HeteSim_SVM (HSSVM), HeteSim scores are combined with a machine learning method. The 3-fold experiments show that our non-machine learning method HSMP performs better than the existing non-machine learning methods, our machine learning method HSSVM obtains similar accuracy with the best existing machine learning method CATAPULT. From the analysis of the top 10 predicted genes for different diseases, we found that HSSVM avoid the disadvantage of the existing machine learning based methods, which always predict similar genes for different diseases. The data sets and Matlab code for the two methods are freely available for download at  http://lab.malab.cn/data/HeteSim/index.jsp.",2017,29,178,3,False,Computer Science,Medicine,7724819,Xiangxiang Zeng,3098931.0,Yuanlu Liao,2143860654.0,Yuansheng Liu,144268946.0,Q. Zou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7a8665ada37b8a26f2a68c0b9c3f3ceb1e0f655a,https://www.semanticscholar.org/paper/7a8665ada37b8a26f2a68c0b9c3f3ceb1e0f655a,Image Categorization by Learning and Reasoning with Regions,"Designing computer programs to automatically categorize images using low-level features is a challenging research topic in computer vision. In this paper, we present a new learning technique, which extends Multiple-Instance Learning (MIL), and its application to the problem of region-based image categorization. Images are viewed as bags, each of which contains a number of instances corresponding to regions obtained from image segmentation. The standard MIL problem assumes that a bag is labeled positive if at least one of its instances is positive; otherwise, the bag is negative. In the proposed MIL framework, DD-SVM, a bag label is determined by some number of instances satisfying various properties. DD-SVM first learns a collection of instance prototypes according to a Diverse Density (DD) function. Each instance prototype represents a class of instances that is more likely to appear in bags with the specific label than in the other bags. A nonlinear mapping is then defined using the instance prototypes and maps every bag to a point in a new feature space, named the bag feature space. Finally, standard support vector machines are trained in the bag feature space. We provide experimental results on an image categorization problem and a drug activity prediction problem.",2004,47,692,103,False,Computer Science,,2116664201,Yixin Chen,48094094.0,James Ze Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d4414002f23c0f1c497166eb51c5b1d549ff75c8,https://www.semanticscholar.org/paper/d4414002f23c0f1c497166eb51c5b1d549ff75c8,Flux: Elegant machine learning with Julia,"Flux is library for machine learning (ML), written using the numerical computing language Julia (Bezanson et al. 2017). The package allows models to be written using Julia’s simple mathematical syntax, and applies automatic differentiation (AD) to seamlessly calculate derivatives and train the model. Meanwhile, it makes heavy use of Julia’s language and compiler features to carry out code analysis and make optimisations. For example, Julia’s GPU compilation support (Besard, Foket, and De Sutter 2017) can be used to JIT-compile custom GPU kernels for model layers (Innes and others 2017a).",2018,3,185,12,True,Computer Science,,34289387,Mike Innes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
831edc3d67457db83da40d260e93bfd7559347ae,https://www.semanticscholar.org/paper/831edc3d67457db83da40d260e93bfd7559347ae,"Dyna, an integrated architecture for learning, planning, and reacting","Dyna is an AI architecture that integrates learning, planning, and reactive execution. Learning methods are used in Dyna both for compiling planning results and for updating a model of the effects of the agent's actions on the world. Planning is incremental and can use the probabilistic and ofttimes incorrect world models generated by learning processes. Execution is fully reactive in the sense that no planning intervenes between perception and action. Dyna relies on machine learning methods for learning from examples---these are among the basic building blocks making up the architecture---yet is not tied to any particular method. This paper briefly introduces Dyna and discusses its strengths and weaknesses with respect to other architectures.",1990,29,721,64,True,Computer Science,,1699645,R. Sutton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f9de494da473d8a2e90ed331d9ab6c8a39d8737d,https://www.semanticscholar.org/paper/f9de494da473d8a2e90ed331d9ab6c8a39d8737d,Survey of Machine Learning Techniques in Drug Discovery.,"BACKGROUND
Drug discovery, which is the process of discovering new candidate medications, is very important for pharmaceutical industries. At its current stage, discovering new drugs is still a very expensive and time-consuming process, requiring Phases I, II and III for clinical trials. Recently, machine learning techniques in Artificial Intelligence (AI), especially the deep learning techniques which allow a computational model to generate multiple layers, have been widely applied and achieved state-of-the-art performance in different fields, such as speech recognition, image classification, bioinformatics, etc. One very important application of these AI techniques is in the field of drug discovery.


METHODS
We did a large-scale literature search on existing scientific websites (e.g, ScienceDirect, Arxiv) and startup companies to understand current status of machine learning techniques in drug discovery.


RESULTS
Our experiments demonstrated that there are different patterns in machine learning fields and drug discovery fields. For example, keywords like prediction, brain, discovery, and treatment are usually in drug discovery fields. Also, the total number of papers published in drug discovery fields with machine learning techniques is increasing every year.


CONCLUSION
The main focus of this survey is to understand the current status of machine learning techniques in the drug discovery field within both academic and industrial settings, and discuss its potential future applications. Several interesting patterns for machine learning techniques in drug discovery fields are discussed in this survey.",2019,74,126,0,False,Medicine,Computer Science,51183421,Natalie Stephenson,51204603.0,Emily Shane,2056317579.0,Jessica Chase,2066120681.0,Jason Rowland,2064613774.0,David Ries,2065880952.0,Nicola Justice,2159189616.0,Jie Zhang,,145822563.0,Leong Chan,33082702.0,Renzhi Cao,,,,,,,,,,,,,,,,,,,,,,,
35aebe08b34e5cb0d012a16563e5c3f6fd17a906,https://www.semanticscholar.org/paper/35aebe08b34e5cb0d012a16563e5c3f6fd17a906,Federated Learning with Personalization Layers,"The emerging paradigm of federated learning strives to enable collaborative training of machine learning models on the network edge without centrally aggregating raw data and hence, improving data privacy. This sharply deviates from traditional machine learning and necessitates the design of algorithms robust to various sources of heterogeneity. Specifically, statistical heterogeneity of data across user devices can severely degrade the performance of standard federated averaging for traditional machine learning applications like personalization with deep learning. This paper pro-posesFedPer, a base + personalization layer approach for federated training of deep feedforward neural networks, which can combat the ill-effects of statistical heterogeneity. We demonstrate effectiveness ofFedPerfor non-identical data partitions ofCIFARdatasetsand on a personalized image aesthetics dataset from Flickr.",2019,18,208,42,False,Computer Science,Mathematics,1438307381,Manoj Ghuhan Arivazhagan,50429238.0,V. Aggarwal,2109424185.0,Aaditya Singh,37748424.0,Sunav Choudhary,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
899746ba46279cf2b842615ed38d998f9c4654df,https://www.semanticscholar.org/paper/899746ba46279cf2b842615ed38d998f9c4654df,A PAC-Bayesian bound for Lifelong Learning,"Transfer learning has received a lot of attention in the machine learning community over the last years, and several effective algorithms have been developed. However, relatively little is known about their theoretical properties, especially in the setting of lifelong learning, where the goal is to transfer information to tasks for which no data have been observed so far. 
 
In this work we study lifelong learning from a theoretical perspective. Our main result is a PAC-Bayesian generalization bound that offers a unified view on existing paradigms for transfer learning, such as the transfer of parameters or the transfer of low-dimensional representations. We also use the bound to derive two principled lifelong learning algorithms, and we show that these yield results comparable with existing methods.",2013,31,171,19,False,Computer Science,Mathematics,2989149,Anastasia Pentina,1787591.0,Christoph H. Lampert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cd2d8af68590a760fc7a75f45db23657c6c70ce0,https://www.semanticscholar.org/paper/cd2d8af68590a760fc7a75f45db23657c6c70ce0,Stacked Extreme Learning Machines,"Extreme learning machine (ELM) has recently attracted many researchers' interest due to its very fast learning speed, good generalization ability, and ease of implementation. It provides a unified solution that can be used directly to solve regression, binary, and multiclass classification problems. In this paper, we propose a stacked ELMs (S-ELMs) that is specially designed for solving large and complex data problems. The S-ELMs divides a single large ELM network into multiple stacked small ELMs which are serially connected. The S-ELMs can approximate a very large ELM network with small memory requirement. To further improve the testing accuracy on big data problems, the ELM autoencoder can be implemented during each iteration of the S-ELMs algorithm. The simulation results show that the S-ELMs even with random hidden nodes can achieve similar testing accuracy to support vector machine (SVM) while having low memory requirements. With the help of ELM autoencoder, the S-ELMs can achieve much better testing accuracy than SVM and slightly better accuracy than deep belief network (DBN) with much faster training speed.",2015,44,119,14,False,Computer Science,Medicine,2986982,Hongming Zhou,145678691.0,G. Huang,145558868.0,Zhiping Lin,2113289095.0,Han Wang,145850486.0,Y. Soh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
da3bbf1927d42a8b3152500cd1195033f45bb95c,https://www.semanticscholar.org/paper/da3bbf1927d42a8b3152500cd1195033f45bb95c,Machine Learning and Deep Learning,"Now-a-days artificial intelligence has become an asset for engineering and experimental studies, just like statistics and calculus. Data science is a growing field for researchers and artificial intelligence, machine learning and deep learning are roots of it. This paper describes the relation between these roots of data science. There is a need of machine learning if any kind of analysis is to be performed. This study describes machine learning from the scratch. It also focuses on Deep Learning. Deep learning can also be known as new trend of machine learning. This paper gives a light on basic architecture of Deep learning. A comparative study of machine learning and deep learning is also given in the paper and allows researcher to have a broad view on these techniques so that they can understand which one will be preferable solution for a particular problem.",2019,5,71,2,False,,,2429061,J. Cherrie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b57658c6ddee1b813551fb4f378d4520ac5c49bf,https://www.semanticscholar.org/paper/b57658c6ddee1b813551fb4f378d4520ac5c49bf,"Machine Learning: An Algorithmic Perspective, Second Edition","A Proven, Hands-On Approach for Students without a Strong Statistical Foundation Since the best-selling first edition was published, there have been several prominent developments in the field of machine learning, including the increasing work on the statistical interpretations of machine learning algorithms. Unfortunately, computer science students without a strong statistical background often find it hard to get started in this area. Remedying this deficiency, Machine Learning: An Algorithmic Perspective, Second Edition helps students understand the algorithms of machine learning. It puts them on a path toward mastering the relevant mathematics and statistics as well as the necessary programming and experimentation. New to the Second Edition Two new chapters on deep belief networks and Gaussian processes Reorganization of the chapters to make a more natural flow of content Revision of the support vector machine material, including a simple implementation for experiments New material on random forests, the perceptron convergence theorem, accuracy methods, and conjugate gradient optimization for the multi-layer perceptron Additional discussions of the Kalman and particle filters Improved code, including better use of naming conventions in Python Suitable for both an introductory one-semester course and more advanced courses, the text strongly encourages students to practice with the code. Each chapter includes detailed examples along with further reading and problems. All of the code used to create the examples is available on the authors website.",2014,0,170,17,False,Computer Science,,2112255,S. Marsland,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1f93588bb075eed40ffdfae2f7907c946e5974d9,https://www.semanticscholar.org/paper/1f93588bb075eed40ffdfae2f7907c946e5974d9,Deep Learning in Alzheimer's Disease: Diagnostic Classification and Prognostic Prediction Using Neuroimaging Data,"Deep learning, a state-of-the-art machine learning approach, has shown outstanding performance over traditional machine learning in identifying intricate structures in complex high-dimensional data, especially in the domain of computer vision. The application of deep learning to early detection and automated classification of Alzheimer's disease (AD) has recently gained considerable attention, as rapid progress in neuroimaging techniques has generated large-scale multimodal neuroimaging data. A systematic review of publications using deep learning approaches and neuroimaging data for diagnostic classification of AD was performed. A PubMed and Google Scholar search was used to identify deep learning papers on AD published between January 2013 and July 2018. These papers were reviewed, evaluated, and classified by algorithm and neuroimaging type, and the findings were summarized. Of 16 studies meeting full inclusion criteria, 4 used a combination of deep learning and traditional machine learning approaches, and 12 used only deep learning approaches. The combination of traditional machine learning for classification and stacked auto-encoder (SAE) for feature selection produced accuracies of up to 98.8% for AD classification and 83.7% for prediction of conversion from mild cognitive impairment (MCI), a prodromal stage of AD, to AD. Deep learning approaches, such as convolutional neural network (CNN) or recurrent neural network (RNN), that use neuroimaging data without pre-processing for feature selection have yielded accuracies of up to 96.0% for AD classification and 84.2% for MCI conversion prediction. The best classification performance was obtained when multimodal neuroimaging and fluid biomarkers were combined. Deep learning approaches continue to improve in performance and appear to hold promise for diagnostic classification of AD using multimodal neuroimaging data. AD research that uses deep learning is still evolving, improving performance by incorporating additional hybrid data types, such as—omics data, increasing transparency with explainable approaches that add knowledge of specific disease-related features and mechanisms.",2019,106,228,5,True,Engineering,Computer Science,2665454,T. Jo,2177008.0,K. Nho,7992909.0,A. Saykin,,,,,,,,,Mathematics,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,
7e6ce5bd878f24839ba38fe8fb91f30aab3cd863,https://www.semanticscholar.org/paper/7e6ce5bd878f24839ba38fe8fb91f30aab3cd863,Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research,"This survey provides a comprehensive overview of the landscape of crowdsourcing research, targeted at the machine learning community. We begin with an overview of the ways in which crowdsourcing can be used to advance machine learning research, focusing on four application areas: 1) data generation, 2) evaluation and debugging of models, 3) hybrid intelligence systems that leverage the complementary strengths of humans and machines to expand the capabilities of AI, and 4) crowdsourced behavioral experiments that improve our understanding of how humans interact with machine learning systems and technology more broadly. We next review the extensive literature on the behavior of crowdworkers themselves. This research, which explores the prevalence of dishonesty among crowdworkers, how workers respond to both monetary incentives and intrinsic forms of motivation, and how crowdworkers interact with each other, has immediate implications that we distill into best practices that researchers should follow when using crowdsourcing in their own research. We conclude with a discussion of additional tips and best practices that are crucial to the success of any project that uses crowdsourcing, but rarely mentioned in the literature.",2017,232,101,5,False,Computer Science,,4006636,Jennifer Wortman Vaughan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b379c5eb2f8cc501e855d295fa5712294ca2b3ed,https://www.semanticscholar.org/paper/b379c5eb2f8cc501e855d295fa5712294ca2b3ed,Application of Machine Learning Algorithms to KDD Intrusion Detection Dataset within Misuse Detection Context,"A small subset of machine learning algorithms, mostly inductive learning based, applied to the KDD 1999 Cup intrusion detection dataset resulted in dismal performance for user-to-root and remote-to-local attack categories as reported in the recent literature. The uncertainty to explore if other machine learning algorithms can demonstrate better performance compared to the ones already employed constitutes the motivation for the study reported herein. Specifically, exploration of if certain algorithms perform better for certain attack classes and consequently, if a multi-expert classifier design can deliver desired performance measure is of high interest. This paper evaluates performance of a comprehensive set of pattern recognition and machine learning algorithms on four attack categories as found in the KDD 1999 Cup intrusion detection dataset. Results of simulation study implemented to that effect indicated that certain classification algorithms perform better for certain attack categories: a specific algorithm specialized for a given attack category . Consequently, a multi-classifier model, where a specific detection algorithm is associated with an attack category for which it is the most promising, was built. Empirical results obtained through simulation indicate that noticeable performance improvement was achieved for probing, denial of service, and user-to-root",2003,23,310,17,False,Computer Science,,2656269,Maheshkumar Sabhnani,1744384.0,G. Serpen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1c0ed9ed3201ef381cc392fc3ca91cae6ecfc698,https://www.semanticscholar.org/paper/1c0ed9ed3201ef381cc392fc3ca91cae6ecfc698,Learning From Data,"Machine learning allows computational systems to adaptively improve their performance with experience accumulated from the observed data. Its techniques are widely applied in engineering, science, finance, and commerce. This book is designed for a short course on machine learning. It is a short course, not a hurried course. From over a decade of teaching this material, we have distilled what we believe to be the core topics that every student of the subject should know. We chose the title `learning from data' that faithfully describes what the subject is about, and made it a point to cover the topics in a story-like fashion. Our hope is that the reader can learn all the fundamentals of the subject by reading the book cover to cover. ---- Learning from data has distinct theoretical and practical tracks. In this book, we balance the theoretical and the practical, the mathematical and the heuristic. Our criterion for inclusion is relevance. Theory that establishes the conceptual framework for learning is included, and so are heuristics that impact the performance of real learning systems. ---- Learning from data is a very dynamic field. Some of the hot techniques and theories at times become just fads, and others gain traction and become part of the field. What we have emphasized in this book are the necessary fundamentals that give any student of learning from data a solid foundation, and enable him or her to venture out and explore further techniques and theories, or perhaps to contribute their own. ---- The authors are professors at California Institute of Technology (Caltech), Rensselaer Polytechnic Institute (RPI), and National Taiwan University (NTU), where this book is the main text for their popular courses on machine learning. The authors also consult extensively with financial and commercial companies on machine learning applications, and have led winning teams in machine learning competitions.",2012,96,196,15,False,Engineering,,1398965769,Y. Abu-Mostafa,1399249722.0,M. Magdon-Ismail,1798966.0,Hsuan-Tien Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
821fde6dc36d1264c765d249d4247ea66daff55f,https://www.semanticscholar.org/paper/821fde6dc36d1264c765d249d4247ea66daff55f,Edge Machine Learning for AI-Enabled IoT Devices: A Review,"In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors’ data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning “Hello World”.",2020,191,117,5,True,Medicine,Computer Science,34547690,M. Merenda,1675347329.0,Carlo Porcaro,31174303.0,D. Iero,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8c46959d4ce047b857c351b89c88b08f6833208e,https://www.semanticscholar.org/paper/8c46959d4ce047b857c351b89c88b08f6833208e,TensorFlow Quantum: A Software Framework for Quantum Machine Learning,"We introduce TensorFlow Quantum (TFQ), an open source library for the rapid prototyping of hybrid quantum-classical models for classical or quantum data. This framework offers high-level abstractions for the design and training of both discriminative and generative quantum models under TensorFlow and supports high-performance quantum circuit simulators. We provide an overview of the software architecture and building blocks through several examples and review the theory of hybrid quantum-classical neural networks. We illustrate TFQ functionalities via several basic applications including supervised learning for quantum classification, quantum control, and quantum approximate optimization. Moreover, we demonstrate how one can apply TFQ to tackle advanced quantum learning tasks including meta-learning, Hamiltonian learning, and sampling thermal states. We hope this framework provides the necessary tools for the quantum computing and machine learning research communities to explore models of both natural and artificial quantum systems, and ultimately discover new quantum algorithms which could potentially yield a quantum advantage.",2020,59,192,17,False,Computer Science,Physics,96014865,M. Broughton,102620709.0,Guillaume Verdon,1387997379.0,T. Mccourt,2111088987.0,Antonio J. Martinez,2115662711.0,J. Yoo,46826180.0,S. Isakov,2055156577.0,Philip Massey,,10777296.0,M. Niu,2700608.0,R. Halavati,70332752.0,E. Peters,50464368.0,M. Leib,88908378.0,Andrea Skolik,,82911375.0,Michael Streif,10721789.0,David Von Dollen,1933508.0,J. McClean,48703443.0,S. Boixo,36577444.0,D. Bacon,145106485.0,A. Ho,2665814.0,H. Neven,145233982.0,M. Mohseni
30e94e24d67994c5a8e2f20f852a51d28a720de2,https://www.semanticscholar.org/paper/30e94e24d67994c5a8e2f20f852a51d28a720de2,Parameter Server for Distributed Machine Learning,"We propose a parameter server framework to solve distributed machine learning problems. Both data and workload are distributed into client nodes, while server nodes maintain globally shared parameters, which are represented as sparse vectors and matrices. The framework manages asynchronous data communications between clients and servers. Flexible consistency models, elastic scalability and fault tolerance are supported by this framework. We present algorithms and theoretical analysis for challenging nonconvex and nonsmooth problems. To demonstrate the scalability of the proposed framework, we show experimental results on real data with billions of parameters.",2013,27,166,19,False,,,2124778071,Mu Li,48207454.0,Li Zhou,2143505112.0,Zichao Yang,31631336.0,Aaron Q. Li,144956443.0,F. Xia,34752743.0,D. Andersen,46234526.0,Alex Smola,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1d6201d0a64ea89a139a472ddeeec639b853fcd1,https://www.semanticscholar.org/paper/1d6201d0a64ea89a139a472ddeeec639b853fcd1,SemiBoost: Boosting for Semi-Supervised Learning,"Semi-supervised learning has attracted a significant amount of attention in pattern recognition and machine learning. Most previous studies have focused on designing special algorithms to effectively exploit the unlabeled data in conjunction with labeled data. Our goal is to improve the classification accuracy of any given supervised learning algorithm by using the available unlabeled examples. We call this as the Semi-supervised improvement problem, to distinguish the proposed approach from the existing approaches. We design a metasemi-supervised learning algorithm that wraps around the underlying supervised algorithm and improves its performance using unlabeled data. This problem is particularly important when we need to train a supervised learning algorithm with a limited number of labeled examples and a multitude of unlabeled examples. We present a boosting framework for semi-supervised learning, termed as SemiBoost. The key advantages of the proposed semi-supervised learning approach are: 1) performance improvement of any supervised learning algorithm with a multitude of unlabeled data, 2) efficient computation by the iterative boosting algorithm, and 3) exploiting both manifold and cluster assumption in training classification models. An empirical study on 16 different data sets and text categorization demonstrates that the proposed framework improves the performance of several commonly used supervised learning algorithms, given a large number of unlabeled examples. We also show that the performance of the proposed algorithm, SemiBoost, is comparable to the state-of-the-art semi-supervised learning algorithms.",2009,69,326,39,True,Computer Science,Medicine,1943221,Pavan Kumar Mallapragada,144723884.0,Rong Jin,145295484.0,Anil K. Jain,2153629855.0,Yi Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
