paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,fieldsOfStudy/2,fieldsOfStudy/3,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name,authors/34/authorId,authors/34/name,authors/35/authorId,authors/35/name,authors/36/authorId,authors/36/name,authors/37/authorId,authors/37/name,authors/38/authorId,authors/38/name,authors/39/authorId,authors/39/name,authors/40/authorId,authors/40/name,authors/41/authorId,authors/41/name,authors/42/authorId,authors/42/name,authors/43/authorId,authors/43/name,authors/44/authorId,authors/44/name,authors/45/authorId,authors/45/name,authors/46/authorId,authors/46/name,authors/47/authorId,authors/47/name,authors/48/authorId,authors/48/name,authors/49/authorId,authors/49/name,authors/50/authorId,authors/50/name,authors/51/authorId,authors/51/name,authors/52/authorId,authors/52/name,authors/53/authorId,authors/53/name,authors/54/authorId,authors/54/name,authors/55/authorId,authors/55/name,authors/56/authorId,authors/56/name,authors/57/authorId,authors/57/name
3c8a456509e6c0805354bd40a35e3f2dbf8069b1,https://www.semanticscholar.org/paper/3c8a456509e6c0805354bd40a35e3f2dbf8069b1,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.",2019,34,17793,1916,False,Computer Science,Mathematics,3407277,Adam Paszke,39793298.0,S. Gross,1403239967.0,Francisco Massa,1977806.0,Adam Lerer,2065251344.0,James Bradbury,114250963.0,Gregory Chanan,2059271276.0,Trevor Killeen,3370429.0,Zeming Lin,3365851.0,N. Gimelshein,3029482.0,L. Antiga,3050846.0,Alban Desmaison,1473151134.0,Andreas Köpf,2052812305.0,E. Yang,2375710.0,Zach DeVito,10707709.0,Martin Raison,41203992.0,A. Tejani,22236100.0,Sasank Chilamkurthy,32163737.0,Benoit Steiner,152599430.0,Lu Fang,2113829116.0,Junjie Bai,2127604.0,Soumith Chintala,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dd41d656e21c30dd761bee2eba303d1aa014d120,https://www.semanticscholar.org/paper/dd41d656e21c30dd761bee2eba303d1aa014d120,Machine Learning Paradigms for Next-Generation Wireless Networks,"Next-generation wireless networks are expected to support extremely high data rates and radically new applications, which require a new wireless radio technology paradigm. The challenge is that of assisting the radio in intelligent adaptive learning and decision making, so that the diverse requirements of next-generation wireless networks can be satisfied. Machine learning is one of the most promising artificial intelligence tools, conceived to support smart radio terminals. Future smart 5G mobile terminals are expected to autonomously access the most meritorious spectral bands with the aid of sophisticated spectral efficiency learning and inference, in order to control the transmission power, while relying on energy efficiency learning/inference and simultaneously adjusting the transmission protocols with the aid of quality of service learning/inference. Hence we briefly review the rudimentary concepts of machine learning and propose their employment in the compelling applications of 5G networks, including cognitive radios, massive MIMOs, femto/small cells, heterogeneous networks, smart grid, energy harvesting, device-todevice communications, and so on. Our goal is to assist the readers in refining the motivation, problem formulation, and methodology of powerful machine learning algorithms in the context of future networks in order to tap into hitherto unexplored applications and services.",2017,22,774,18,True,Computer Science,,1750017,Chunxiao Jiang,50024622.0,Haijun Zhang,145659296.0,Yong Ren,145169163.0,Zhu Han,66073306.0,Kwang-Cheng Chen,1730180.0,L. Hanzo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5b77625b30ab2fa8abf5c152831a6985a61516ee,https://www.semanticscholar.org/paper/5b77625b30ab2fa8abf5c152831a6985a61516ee,Can machine-learning improve cardiovascular risk prediction using routine clinical data?,"Background Current approaches to predict cardiovascular risk fail to identify many people who would benefit from preventive treatment, while others receive unnecessary intervention. Machine-learning offers opportunity to improve accuracy by exploiting complex interactions between risk factors. We assessed whether machine-learning can improve cardiovascular risk prediction. Methods Prospective cohort study using routine clinical data of 378,256 patients from UK family practices, free from cardiovascular disease at outset. Four machine-learning algorithms (random forest, logistic regression, gradient boosting machines, neural networks) were compared to an established algorithm (American College of Cardiology guidelines) to predict first cardiovascular event over 10-years. Predictive accuracy was assessed by area under the ‘receiver operating curve’ (AUC); and sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV) to predict 7.5% cardiovascular risk (threshold for initiating statins). Findings 24,970 incident cardiovascular events (6.6%) occurred. Compared to the established risk prediction algorithm (AUC 0.728, 95% CI 0.723–0.735), machine-learning algorithms improved prediction: random forest +1.7% (AUC 0.745, 95% CI 0.739–0.750), logistic regression +3.2% (AUC 0.760, 95% CI 0.755–0.766), gradient boosting +3.3% (AUC 0.761, 95% CI 0.755–0.766), neural networks +3.6% (AUC 0.764, 95% CI 0.759–0.769). The highest achieving (neural networks) algorithm predicted 4,998/7,404 cases (sensitivity 67.5%, PPV 18.4%) and 53,458/75,585 non-cases (specificity 70.7%, NPV 95.7%), correctly predicting 355 (+7.6%) more patients who developed cardiovascular disease compared to the established algorithm. Conclusions Machine-learning significantly improves accuracy of cardiovascular risk prediction, increasing the number of patients identified who could benefit from preventive treatment, while avoiding unnecessary treatment of others.",2017,50,648,12,True,Medicine,,8955394,S. Weng,2090454.0,J. Reps,3428487.0,J. Kai,145890843.0,J. Garibaldi,4757323.0,N. Qureshi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1ce15f4a83706b877e86f29549920651a888b144,https://www.semanticscholar.org/paper/1ce15f4a83706b877e86f29549920651a888b144,Data Mining and Analytics in the Process Industry: The Role of Machine Learning,"Data mining and analytics have played an important role in knowledge discovery and decision making/supports in the process industry over the past several decades. As a computational engine to data mining and analytics, machine learning serves as basic tools for information extraction, data pattern recognition and predictions. From the perspective of machine learning, this paper provides a review on existing data mining and analytics applications in the process industry over the past several decades. The state-of-the-art of data mining and analytics are reviewed through eight unsupervised learning and ten supervised learning algorithms, as well as the application status of semi-supervised learning algorithms. Several perspectives are highlighted and discussed for future researches on data mining and analytics in the process industry.",2017,313,545,21,False,Computer Science,,145619185,Zhiqiang Ge,2554622.0,Zhi-huan Song,144558270.0,S. Ding,144466701.0,Biao Huang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a7f8b8e6124901c1e22e940092e87b5b93776ab3,https://www.semanticscholar.org/paper/a7f8b8e6124901c1e22e940092e87b5b93776ab3,Machine Learning With Big Data: Challenges and Approaches,"The Big Data revolution promises to transform how we live, work, and think by enabling process optimization, empowering insight discovery and improving decision making. The realization of this grand potential relies on the ability to extract value from such massive data through data analytics; machine learning is at its core because of its ability to learn from data and provide data driven insights, decisions, and predictions. However, traditional machine learning approaches were developed in a different era, and thus are based upon multiple assumptions, such as the data set fitting entirely into memory, what unfortunately no longer holds true in this new context. These broken assumptions, together with the Big Data characteristics, are creating obstacles for the traditional techniques. Consequently, this paper compiles, summarizes, and organizes machine learning challenges with Big Data. In contrast to other research that discusses challenges, this work highlights the cause–effect relationship by organizing challenges according to Big Data Vs or dimensions that instigated the issue: volume, velocity, variety, or veracity. Moreover, emerging machine learning approaches and techniques are discussed in terms of how they are capable of handling the various challenges with the ultimate objective of helping practitioners select appropriate solutions for their use cases. Finally, a matrix relating the challenges and approaches is presented. Through this process, this paper provides a perspective on the domain, identifies research gaps and opportunities, and provides a strong foundation and encouragement for further research in the field of machine learning with Big Data.",2017,118,446,14,False,Computer Science,,1401702869,Alexandra L’Heureux,2222599.0,Katarina Grolinger,3193379.0,H. F. ElYamany,1711826.0,Miriam A. M. Capretz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
02e2e79a77d8aabc1af1900ac80ceebac20abde4,https://www.semanticscholar.org/paper/02e2e79a77d8aabc1af1900ac80ceebac20abde4,Explanation and Justification in Machine Learning : A Survey Or,"We present a survey of the research concerning explanation and justification in the Machine Learning literature and several adjacent fields. Within Machine Learning, we differentiate between two main branches of current research: interpretable models, and prediction interpretation and justification.",2017,72,387,25,False,Computer Science,,20402453,Or Biran,2244926.0,Courtenay V. Cotton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c0eb2d5d65ecc27cb00501bffdcc55167c61cfe0,https://www.semanticscholar.org/paper/c0eb2d5d65ecc27cb00501bffdcc55167c61cfe0,What can machine learning do? Workforce implications,"Profound change is coming, but roles for humans remain Digital computers have transformed work in almost every sector of the economy over the past several decades (1). We are now at the beginning of an even larger and more rapid transformation due to recent advances in machine learning (ML), which is capable of accelerating the pace of automation itself. However, although it is clear that ML is a “general purpose technology,” like the steam engine and electricity, which spawns a plethora of additional innovations and capabilities (2), there is no widely shared agreement on the tasks where ML systems excel, and thus little agreement on the specific expected impacts on the workforce and on the economy more broadly. We discuss what we see to be key implications for the workforce, drawing on our rubric of what the current generation of ML systems can and cannot do [see the supplementary materials (SM)]. Although parts of many jobs may be “suitable for ML” (SML), other tasks within these same jobs do not fit the criteria for ML well; hence, effects on employment are more complex than the simple replacement and substitution story emphasized by some. Although economic effects of ML are relatively limited today, and we are not facing the imminent “end of work” as is sometimes proclaimed, the implications for the economy and the workforce going forward are profound.",2017,21,374,18,False,Medicine,,2841157,E. Brynjolfsson,144135485.0,Tom. Mitchell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b191fc4294f6f067067e4e152bd4efc8bbb87afd,https://www.semanticscholar.org/paper/b191fc4294f6f067067e4e152bd4efc8bbb87afd,Unintended Consequences of Machine Learning in Medicine,"Over the past decade, machine learning techniques have made substantial advances in many domains. In health care, global interest in the potential of machine learning has increased; for example, a deep learning algorithm has shown high accuracy in detecting diabetic retinopathy.1 There have been suggestions that machine learning will drive changes in health care within a few years, specifically in medical disciplines that require more accurate prognostic models (eg, oncology) and those based on pattern recognition (eg, radiology and pathology). However, comparative studies on the effectiveness of machine learning–based decision support systems (ML-DSS) in medicine are lacking, especially regarding the effects on health outcomes. Moreover, the introduction of new technologies in health care has not always been straightforward or without unintended and adverse effects.2 In this Viewpoint we consider the potential unintended consequences that may result from the application of ML-DSS in clinical practice.",2017,13,503,8,False,Medicine,,3037324,F. Cabitza,15665454.0,Raffaele Rasoini,1981465.0,G. Gensini,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4ab891e6044695abb31c72048f654b3b205c60bb,https://www.semanticscholar.org/paper/4ab891e6044695abb31c72048f654b3b205c60bb,Survey of Machine Learning Algorithms for Disease Diagnostic,"In medical imaging, Computer Aided Diagnosis (CAD) is a rapidly growing dynamic area of research. In recent years, significant attempts are made for the enhancement of computer aided diagnosis applications because errors in medical diagnostic systems can result in seriously misleading medical treatments. Machine learning is important in Computer Aided Diagnosis. After using an easy equation, objects such as organs may not be indicated accurately. So, pattern recognition fundamentally involves learning from examples. In the field of bio-medical, pattern recognition and machine learning promise the improved accuracy of perception and diagnosis of disease. They also promote the objectivity of decision-making process. For the analysis of high-dimensional and multimodal bio-medical data, machine learning offers a worthy approach for making classy and automatic algorithms. This survey paper provides the comparative analysis of different machine learning algorithms for diagnosis of different diseases such as heart disease, diabetes disease, liver disease, dengue disease and hepatitis disease. It brings attention towards the suite of machine learning algorithms and tools that are used for the analysis of diseases and decision-making process accordingly.",2017,25,353,9,True,Computer Science,,30721756,Meherwar Fatima,144225210.0,M. Pasha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31e12b8d558a7515f3a1e3337551f5f30e466cde,https://www.semanticscholar.org/paper/31e12b8d558a7515f3a1e3337551f5f30e466cde,Unified Representation of Molecules and Crystals for Machine Learning,"
 Accurate simulations of atomistic systems from first principles are limited by computational cost. In high-throughput settings, machine learning can reduce these costs significantly by accurately interpolating between reference calculations. For this, kernel learning approaches crucially require a representation that accommodates arbitrary atomistic systems. We introduce a many-body tensor representation that is invariant to translations, rotations, and nuclear permutations of same elements, unique, differentiable, can represent molecules and crystals, and is fast to compute. Empirical evidence for competitive energy and force prediction errors is presented for changes in molecular structure, crystal chemistry, and molecular dynamics using kernel regression and symmetric gradient-domain machine learning as models. Applicability is demonstrated for phase diagrams of Pt-group/transition-metal binary systems.",2017,48,120,7,False,Physics,Chemistry,94267262,Haoyan Huo,48041657.0,M. Rupp,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d15b21bdd117877c2d0e865b17d6a336737aea99,https://www.semanticscholar.org/paper/d15b21bdd117877c2d0e865b17d6a336737aea99,Stealing Machine Learning Models via Prediction APIs,"Machine learning (ML) models may be deemed confidential due to their sensitive training data, commercial value, or use in security applications. Increasingly often, confidential ML models are being deployed with publicly accessible query interfaces. ML-as-a-service (""predictive analytics"") systems are an example: Some allow users to train models on potentially sensitive data and charge others for access on a pay-per-query basis. 
The tension between model confidentiality and public access motivates our investigation of model extraction attacks. In such attacks, an adversary with black-box access, but no prior knowledge of an ML model's parameters or training data, aims to duplicate the functionality of (i.e., ""steal"") the model. Unlike in classical learning theory settings, ML-as-a-service offerings may accept partial feature vectors as inputs and include confidence values with predictions. Given these practices, we show simple, efficient attacks that extract target ML models with near-perfect fidelity for popular model classes including logistic regression, neural networks, and decision trees. We demonstrate these attacks against the online services of BigML and Amazon Machine Learning. We further show that the natural countermeasure of omitting confidence values from model outputs still admits potentially harmful model extraction attacks. Our results highlight the need for careful ML model deployment and new model extraction countermeasures.",2016,57,1112,135,False,Computer Science,Mathematics,2444919,Florian Tramèr,2153304355.0,Fan Zhang,1687161.0,A. Juels,1746214.0,M. Reiter,1707461.0,T. Ristenpart,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1696cbf7da0ee845c50591843993e6605adec177,https://www.semanticscholar.org/paper/1696cbf7da0ee845c50591843993e6605adec177,A few useful things to know about machine learning,"Tapping into the ""folk knowledge"" needed to advance machine learning applications.",2012,30,2330,124,True,Computer Science,,1740213,Pedro M. Domingos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
474d8f5a80ca3dc56ed7b149a1fb09edc71931b2,https://www.semanticscholar.org/paper/474d8f5a80ca3dc56ed7b149a1fb09edc71931b2,Machine Learning for Medical Imaging.,"Machine learning is a technique for recognizing patterns that can be applied to medical images. Although it is a powerful tool that can help in rendering medical diagnoses, it can be misapplied. Machine learning typically begins with the machine learning algorithm system computing the image features that are believed to be of importance in making the prediction or diagnosis of interest. The machine learning algorithm system then identifies the best combination of these image features for classifying the image or computing some metric for the given image region. There are several methods that can be used, each with different strengths and weaknesses. There are open-source versions of most of these machine learning methods that make them easy to try and apply to images. Several metrics for measuring the performance of an algorithm exist; however, one must be aware of the possible associated pitfalls that can result in misleading metrics. More recently, deep learning has started to be used; this method has the benefit that it does not require image feature identification and calculation as a first step; rather, features are identified as part of the learning process. Machine learning has been used in medical imaging and will have a greater influence in the future. Those working in medical imaging must be aware of how machine learning works. ©RSNA, 2017.",2017,60,565,6,False,Medicine,,144917634,B. Erickson,1986491.0,P. Korfiatis,2015410.0,Z. Akkus,4729578.0,T. Kline,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43d1fe40167c5f2ed010c8e06c8e008c774fd22b,https://www.semanticscholar.org/paper/43d1fe40167c5f2ed010c8e06c8e008c774fd22b,Non-convex Optimization for Machine Learning,"A vast majority of machine learning algorithms train their models and perform inference by solving optimization problems. In order to capture the learning and prediction problems accurately, structural constraints such as sparsity or low rank are frequently imposed or else the objective itself is designed to be a non-convex function. This is especially true of algorithms that operate in high-dimensional spaces or that train non-linear models such as tensor models and deep networks.  The freedom to express the learning problem as a non-convex optimization problem gives immense modeling power to the algorithm designer, but often such problems are NP-hard to solve.  A popular workaround to this has been to relax non-convex problems to convex ones and use traditional methods to solve the (convex) relaxed optimization problems. However this approach may be lossy and nevertheless presents significant challenges for large scale optimization.  On the other hand, direct approaches to non-convex optimization have met with resounding success in several domains and remain the methods of choice for the practitioner, as they frequently outperform relaxation-based techniques - popular heuristics include projected gradient descent and alternating minimization. However, these are often poorly understood in terms of their convergence and other properties.  This monograph presents a selection of recent advances that bridge a long-standing gap in our understanding of these heuristics. We hope that an insight into the inner workings of these methods will allow the reader to appreciate the unique marriage of task structure and generative models that allow these heuristic techniques to (provably) succeed. The monograph will lead the reader through several widely used non-convex optimization techniques, as well as applications thereof. The goal of this monograph is to both, introduce the rich literature in this area, as well as equip the reader with the tools and techniques needed to analyze these simple procedures for non-convex problems.",2017,133,316,10,True,Computer Science,Mathematics,48964143,Prateek Jain,39746893.0,Purushottam Kar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f615bd164110160e160c98f59d7bfcc931a3cdc1,https://www.semanticscholar.org/paper/f615bd164110160e160c98f59d7bfcc931a3cdc1,Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution,"Current machine learning systems operate, almost exclusively, in a statistical, or model-blind mode, which entails severe theoretical limits on their power and performance. Such systems cannot reason about interventions and retrospection and, therefore, cannot serve as the basis for strong AI. To achieve human level intelligence, learning machines need the guidance of a model of reality, similar to the ones used in causal inference. To demonstrate the essential role of such models, I will present a summary of seven tasks which are beyond reach of current machine learning systems and which have been accomplished using the tools of causal inference.",2018,24,230,14,True,Computer Science,Mathematics,145430701,J. Pearl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46f74231b9afeb0c290d6d550043c55045284e5f,https://www.semanticscholar.org/paper/46f74231b9afeb0c290d6d550043c55045284e5f,The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web],"In this issue, “Best of the Web” presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.",2012,7,1605,345,False,Computer Science,,2114191181,L. Deng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8da350feb5e18e92bcc91f02899187381382c6e4,https://www.semanticscholar.org/paper/8da350feb5e18e92bcc91f02899187381382c6e4,Machine learning unifies the modeling of materials and molecules,"Statistical learning based on a local representation of atomic structures provides a universal model of chemical stability. Determining the stability of molecules and condensed phases is the cornerstone of atomistic modeling, underpinning our understanding of chemical and materials properties and transformations. We show that a machine-learning model, based on a local description of chemical environments and Bayesian statistical learning, provides a unified framework to predict atomic-scale properties. It captures the quantum mechanical effects governing the complex surface reconstructions of silicon, predicts the stability of different classes of molecules with chemical accuracy, and distinguishes active and inactive protein ligands with more than 99% reliability. The universality and the systematic nature of our framework provide new insight into the potential energy surface of materials and molecules.",2017,83,426,5,False,Physics,Medicine,3938091,A. Bartók,153048885.0,Sandip De,7254603.0,C. Poelking,2105796.0,N. Bernstein,11724553.0,J. Kermode,2559761.0,Gábor Csányi,1917770.0,M. Ceriotti,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d6b01fa6af2a755d3466747cd279b62908e685b4,https://www.semanticscholar.org/paper/d6b01fa6af2a755d3466747cd279b62908e685b4,Machine Learning and Prediction in Medicine - Beyond the Peak of Inflated Expectations.,"Big data, we have all heard, promise to transform health care. But in the “hype cycle” of emerging technologies, machine learning now rides atop the “peak of inflated expectations,” and we need to better appreciate the technology’s capabilities and limitations.",2017,4,545,3,False,Medicine,,1421788668,Jonathan H. Chen,2527115.0,S. Asch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e1f9ef01ab55d53349096a58d76fd0cfa7bb051d,https://www.semanticscholar.org/paper/e1f9ef01ab55d53349096a58d76fd0cfa7bb051d,Quantum machine learning: a classical perspective,"Recently, increased computational power and data availability, as well as algorithmic advances, have led machine learning (ML) techniques to impressive results in regression, classification, data generation and reinforcement learning tasks. Despite these successes, the proximity to the physical limits of chip fabrication alongside the increasing size of datasets is motivating a growing number of researchers to explore the possibility of harnessing the power of quantum computation to speed up classical ML algorithms. Here we review the literature in quantum ML and discuss perspectives for a mixed readership of classical ML and quantum computation experts. Particular emphasis will be placed on clarifying the limitations of quantum algorithms, how they compare with their best classical counterparts and why quantum resources are expected to provide advantages for learning problems. Learning in the presence of noise and certain computationally hard problems in ML are identified as promising directions for the field. Practical questions, such as how to upload classical data into quantum form, will also be addressed.",2017,214,240,4,True,Computer Science,Medicine,7666146,C. Ciliberto,1839746.0,M. Herbster,46403120.0,Alessandro Davide Ialongo,1704699.0,M. Pontil,8478411.0,Andrea Rocchetto,47831052.0,S. Severini,3438240.0,L. Wossnig,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Physics,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ea7887fadc666d6faf92e569d4a10d994ee91297,https://www.semanticscholar.org/paper/ea7887fadc666d6faf92e569d4a10d994ee91297,iml: An R package for Interpretable Machine Learning,"Complex, non-parametric models, which are typically used in machine learning, have proven to be successful in many prediction tasks. But these models usually operate as black boxes: While they are good at predicting, they are often not interpretable. Many inherently interpretable models have been suggested, which come at the cost of losing predictive power. Another option is to apply interpretability methods to a black box model after model training. Given the velocity of research on new machine learning models, it is preferable to have model-agnostic tools which can be applied to a random forest as well as to a neural network. Tools for model-agnostic interpretability methods should improve the adoption of machine learning.",2018,12,236,7,True,Computer Science,,50621691,Christoph Molnar,8662947.0,Giuseppe Casalicchio,1686924.0,B. Bischl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1d7ec1c2c7e60b8097cadaafc5d9380c0de6f287,https://www.semanticscholar.org/paper/1d7ec1c2c7e60b8097cadaafc5d9380c0de6f287,Decoupled Classifiers for Group-Fair and Efficient Machine Learning,"When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the näıve application of machine learning algorithms using sensitive attributes leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, which can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group.",2017,18,193,15,False,Computer Science,,1781565,C. Dwork,1754163.0,Nicole Immorlica,2186481.0,A. Kalai,50756956.0,Mark D. M. Leiserson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1c3752586e7d746b13eb5b2784ac9fe53756b7fd,https://www.semanticscholar.org/paper/1c3752586e7d746b13eb5b2784ac9fe53756b7fd,Attractor reconstruction by machine learning.,"A machine-learning approach called ""reservoir computing"" has been used successfully for short-term prediction and attractor reconstruction of chaotic dynamical systems from time series data. We present a theoretical framework that describes conditions under which reservoir computing can create an empirical model capable of skillful short-term forecasts and accurate long-term ergodic behavior. We illustrate this theory through numerical experiments. We also argue that the theory applies to certain other machine learning methods for time series prediction.",2018,27,214,6,True,Computer Science,Mathematics,34949672,Zhixin Lu,1868698.0,B. Hunt,144596753.0,E. Ott,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Physics,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95615c6bce2123f12e39c3d9eb293ebb759501aa,https://www.semanticscholar.org/paper/95615c6bce2123f12e39c3d9eb293ebb759501aa,"Machine learning, social learning and the governance of self-driving cars","Self-driving cars, a quintessentially ‘smart’ technology, are not born smart. The algorithms that control their movements are learning as the technology emerges. Self-driving cars represent a high-stakes test of the powers of machine learning, as well as a test case for social learning in technology governance. Society is learning about the technology while the technology learns about society. Understanding and governing the politics of this technology means asking ‘Who is learning, what are they learning and how are they learning?’ Focusing on the successes and failures of social learning around the much-publicized crash of a Tesla Model S in 2016, I argue that trajectories and rhetorics of machine learning in transport pose a substantial governance challenge. ‘Self-driving’ or ‘autonomous’ cars are misnamed. As with other technologies, they are shaped by assumptions about social needs, solvable problems, and economic opportunities. Governing these technologies in the public interest means improving social learning by constructively engaging with the contingencies of machine learning.",2017,181,210,6,True,Engineering,Medicine,3416633,J. Stilgoe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd,https://www.semanticscholar.org/paper/22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd,DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning,"Machine-Learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope. Until now, most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy. We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications.",2014,44,1324,154,False,Computer Science,,144049725,Tianshi Chen,1678776.0,Zidong Du,145550877.0,Ninghui Sun,2110368816.0,Jia Wang,7514065.0,Chengyong Wu,7377735.0,Yunji Chen,1731764.0,O. Temam,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d67ddd0855c60ada2fb4151f0f944feffdaf357,https://www.semanticscholar.org/paper/6d67ddd0855c60ada2fb4151f0f944feffdaf357,Machine Learning from Theory to Algorithms: An Overview,"The current SMAC (Social, Mobile, Analytic, Cloud) technology trend paves the way to a future in which intelligent machines, networked processes and big data are brought together. This virtual world has generated vast amount of data which is accelerating the adoption of machine learning solutions & practices. Machine Learning enables computers to imitate and adapt human-like behaviour. Using machine learning, each interaction, each action performed, becomes something the system can learn and use as experience for the next time. This work is an overview of this data analytics method which enables computers to learn and do what comes naturally to humans, i.e. learn from experience. It includes the preliminaries of machine learning, the definition, nomenclature and applications’ describing it’s what, how and why. The technology roadmap of machine learning is discussed to understand and verify its potential as a market & industry practice. The primary intent of this work is to give insight into why machine learning is the future.",2018,49,181,2,False,Physics,Computer Science,3363367,J. Alzubi,3286242.0,A. Nayyar,2116451265.0,Akshi Kumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4f975da00a5b2a2f7236e34edcb7274e5fdab937,https://www.semanticscholar.org/paper/4f975da00a5b2a2f7236e34edcb7274e5fdab937,Combining satellite imagery and machine learning to predict poverty,"Measuring consumption and wealth remotely Nighttime lighting is a rough proxy for economic wealth, and nighttime maps of the world show that many developing countries are sparsely illuminated. Jean et al. combined nighttime maps with high-resolution daytime satellite images (see the Perspective by Blumenstock). With a bit of machine-learning wizardry, the combined images can be converted into accurate estimates of household consumption and assets, both of which are hard to measure in poorer countries. Furthermore, the night- and day-time data are publicly available and nonproprietary. Science, this issue p. 790; see also p. 753 Satellites collect data that can be used to measure income and wealth. Reliable data on economic livelihoods remain scarce in the developing world, hampering efforts to study these outcomes and to design policies that improve them. Here we demonstrate an accurate, inexpensive, and scalable method for estimating consumption expenditure and asset wealth from high-resolution satellite imagery. Using survey and satellite data from five African countries—Nigeria, Tanzania, Uganda, Malawi, and Rwanda—we show how a convolutional neural network can be trained to identify image features that can explain up to 75% of the variation in local-level economic outcomes. Our method, which requires only publicly available data, could transform efforts to track and target poverty in developing countries. It also demonstrates how powerful machine learning techniques can be applied in a setting with limited training data, suggesting broad potential application across many scientific domains.",2016,37,1037,91,False,Medicine,,2752609,Neal Jean,49240687.0,M. Burke,46215055.0,Sang Michael Xie,120334004.0,W. Davis,2465182.0,D. Lobell,2490652.0,S. Ermon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
561269a24f2f2a06409109723a8ab93a01696efc,https://www.semanticscholar.org/paper/561269a24f2f2a06409109723a8ab93a01696efc,Federated Optimization: Distributed Machine Learning for On-Device Intelligence,"We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. 
A motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. 
We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \federated optimization.",2016,109,1069,84,False,Computer Science,,32139366,Jakub Konecný,145057514.0,H. B. McMahan,1878835.0,D. Ramage,2662221.0,Peter Richtárik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
364fb0677a5d7083e56c0e38629a78cb94836f53,https://www.semanticscholar.org/paper/364fb0677a5d7083e56c0e38629a78cb94836f53,API design for machine learning software: experiences from the scikit-learn project,"Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library.",2013,23,1556,125,False,Computer Science,Mathematics,2286302,L. Buitinck,1881041.0,Gilles Louppe,27257992.0,Mathieu Blondel,2570016.0,Fabian Pedregosa,2086994888.0,Andreas Mueller,2958756.0,O. Grisel,2114966.0,Vlad Niculae,2780213.0,P. Prettenhofer,1797840.0,Alexandre Gramfort,40122174.0,Jaques Grobler,1704063.0,R. Layton,2081469.0,J. Vanderplas,2058185.0,Arnaud Joly,2074133423.0,Brian Holt,3025780.0,G. Varoquaux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
91e36e1c6e3d4a5bdc97fa5ab5b89bdf9113413d,https://www.semanticscholar.org/paper/91e36e1c6e3d4a5bdc97fa5ab5b89bdf9113413d,How the machine ‘thinks’: Understanding opacity in machine learning algorithms,"This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.",2016,34,1028,64,False,Computer Science,,48129731,J. Burrell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
971766088dfaf63fb55e6f0190b14f28f2c98ad0,https://www.semanticscholar.org/paper/971766088dfaf63fb55e6f0190b14f28f2c98ad0,A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection,"This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.",2016,116,861,42,False,Computer Science,,2343019,A. Buczak,1922657.0,Erhan Guven,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0de0c3240bda7972bd0a3c8369ebc4b4f2e4f9c2,https://www.semanticscholar.org/paper/0de0c3240bda7972bd0a3c8369ebc4b4f2e4f9c2,Scaling Distributed Machine Learning with the Parameter Server,"Big data may contain big values, but also brings lots of challenges to the computing theory, architecture, framework, knowledge discovery algorithms, and domain specific tools and applications. Beyond the 4-V or 5-V characters of big datasets, the data processing shows the features like inexact, incremental, and inductive manner. This brings new research opportunities to research community across theory, systems, algorithms, and applications. Is there some new ""theory"" for the big data? How to handle the data computing algorithms in an operatable manner? This report shares some view on new challenges identified, and covers some of the application scenarios such as micro-blog data analysis and data processing in building next generation search engines.",2014,53,1505,151,True,Computer Science,,2124778071,Mu Li,34752743.0,D. Andersen,2115992237.0,J. Park,46234526.0,Alex Smola,50731654.0,Amr Ahmed,1679460.0,V. Josifovski,2117316446.0,James Long,2915064.0,E. Shekita,6231754.0,Bor-Yiing Su,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a5c0309b9895066ebd08acfe326b01ce2fdefdd4,https://www.semanticscholar.org/paper/a5c0309b9895066ebd08acfe326b01ce2fdefdd4,Moving beyond regression techniques in cardiovascular risk prediction: applying machine learning to address analytic challenges,"Abstract Risk prediction plays an important role in clinical cardiology research. Traditionally, most risk models have been based on regression models. While useful and robust, these statistical methods are limited to using a small number of predictors which operate in the same way on everyone, and uniformly throughout their range. The purpose of this review is to illustrate the use of machine-learning methods for development of risk prediction models. Typically presented as black box approaches, most machine-learning methods are aimed at solving particular challenges that arise in data analysis that are not well addressed by typical regression approaches. To illustrate these challenges, as well as how different methods can address them, we consider trying to predicting mortality after diagnosis of acute myocardial infarction. We use data derived from our institution's electronic health record and abstract data on 13 regularly measured laboratory markers. We walk through different challenges that arise in modelling these data and then introduce different machine-learning approaches. Finally, we discuss general issues in the application of machine-learning methods including tuning parameters, loss functions, variable importance, and missing data. Overall, this review serves as an introduction for those working on risk modelling to approach the diffuse field of machine learning.",2016,61,272,8,True,Medicine,,35352396,B. Goldstein,86968656.0,A. Navar,145554444.0,R. Carter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f5c7d0998b4cf8de9b5b171e3593427724ec4600,https://www.semanticscholar.org/paper/f5c7d0998b4cf8de9b5b171e3593427724ec4600,"Lifelong Machine Learning, Second Edition","Lifelong Machine Learning, Second Edition is an introduction to an advanced machine learning paradigm that continuously learns by accumulating past knowledge that it then uses in future learning and problem solving. In contrast, the current dominant machine learning paradigm learns in isolation: given a training dataset, it runs a machine learning algorithm on the dataset to produce a model that is then used in its intended application. It makes no attempt to retain the learned knowledge and use it in subsequent learning. Unlike this isolated system, humans learn effectively with only a few examples precisely because our learning is very knowledge-driven: the knowledge learned in the past helps us learn new things with little data or effort. Lifelong learning aims to emulate this capability, because without it, an AI system cannot be considered truly intelligent. Research in lifelong learning has developed significantly in the relatively short time since the first edition of this book was published. The purpose of this second edition is to expand the definition of lifelong learning, update the content of several chapters, and add a new chapter about continual learning in deep neural networks—which has been actively researched over the past two or three years. A few chapters have also been reorganized to make each of them more coherent for the reader. Moreover, the authors want to propose a unified framework for the research area. Currently, there are several research topics in machine learning that are closely related to lifelong learning—most notably, multi-task learning, transfer learning, and meta-learning—because they also employ the idea of knowledge sharing and transfer. This book brings all these topics under one roof and discusses their similarities and differences. Its goal is to introduce this emerging machine learning paradigm and present a comprehensive survey and review of the important research results and latest ideas in the area. This book is thus suitable for students, researchers, and practitioners who are interested in machine learning, data mining, natural language processing, or pattern recognition. Lecturers can readily use the book for courses in any of these related fields.",2018,315,61,2,True,Computer Science,,2111630932,Zhiyuan Chen,145321667.0,B. Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
139b2afafdaccba02c983d2f40f257db64860320,https://www.semanticscholar.org/paper/139b2afafdaccba02c983d2f40f257db64860320,Machine Learning Topological States,"Machine learning, the core of artificial intelligence and data science, is a very active field, with vast applications throughout science and technology. Recently, machine learning techniques have been adopted to tackle intricate quantum many-body problems and phase transitions. In this work, the authors construct exact mappings from exotic quantum states to machine learning network models. This work shows for the first time that the restricted Boltzmann machine can be used to study both symmetry-protected topological phases and intrinsic topological order. The exact results are expected to provide a substantial boost to the field of machine learning of phases of matter.",2016,114,187,8,True,Physics,Computer Science,5204254,D. Deng,2108285127.0,Xiaopeng Li,2888542.0,S. Sarma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2f6000c3be00335633cd490f03d642fcf101cd0d,https://www.semanticscholar.org/paper/2f6000c3be00335633cd490f03d642fcf101cd0d,Machine Learning Predicts Laboratory Earthquakes,"We apply machine learning to data sets from shear laboratory experiments, with the goal of identifying hidden signals that precede earthquakes. Here we show that by listening to the acoustic signal emitted by a laboratory fault, machine learning can predict the time remaining before it fails with great accuracy. These predictions are based solely on the instantaneous physical characteristics of the acoustical signal and do not make use of its history. Surprisingly, machine learning identifies a signal emitted from the fault zone previously thought to be low‐amplitude noise that enables failure forecasting throughout the laboratory quake cycle. We infer that this signal originates from continuous grain motions of the fault gouge as the fault blocks displace. We posit that applying this approach to continuous seismic data may lead to significant advances in identifying currently unknown signals, in providing new insights into fault physics, and in placing bounds on fault failure times.",2017,45,211,8,False,Geology,Physics,1405451125,B. Rouet-Leduc,48443857.0,C. Hulbert,95613409.0,N. Lubbers,2435667.0,K. Barros,3750474.0,C. Humphreys,143862033.0,P. Johnson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31fbba3638f0d930a678d85247045ea5a1a4ec88,https://www.semanticscholar.org/paper/31fbba3638f0d930a678d85247045ea5a1a4ec88,Unsupervised Machine Learning on a Hybrid Quantum Computer,"Machine learning techniques have led to broad adoption of a statistical model of computing. The statistical distributions natively available on quantum processors are a superset of those available classically. Harnessing this attribute has the potential to accelerate or otherwise improve machine learning relative to purely classical performance. A key challenge toward that goal is learning to hybridize classical computing resources and traditional learning techniques with the emerging capabilities of general purpose quantum processors. Here, we demonstrate such hybridization by training a 19-qubit gate model processor to solve a clustering problem, a foundational challenge in unsupervised learning. We use the quantum approximate optimization algorithm in conjunction with a gradient-free Bayesian optimization to train the quantum machine. This quantum/classical hybrid algorithm shows robustness to realistic noise, and we find evidence that classical optimization can be used to train around both coherent and incoherent imperfections.",2017,41,198,9,False,Mathematics,Physics,51100085,J. Otterbach,51103214.0,R. Manenti,4099324.0,N. Alidoust,46970929.0,A. Bestwick,35692165.0,M. Block,35635287.0,B. Bloom,47759624.0,S. Caldwell,50623640.0,N. Didier,144983451.0,E. Fried,2158139650.0,S. Hong,35368333.0,Peter J. Karalekas,39704765.0,C. Osborn,50355079.0,A. Papageorge,2059365466.0,E. C. Peterson,8560581.0,G. Prawiroatmodjo,34743111.0,N. Rubin,8134599.0,C. Ryan,10731825.0,D. Scarabelli,2066443417.0,M. Scheer,4243405.0,E. A. Sete,34588692.0,P. Sivarajah,,,2119026669.0,Robert S. Smith,3974460.0,A. Staley,145950540.0,N. Tezak,40068050.0,W. Zeng,2059325411.0,A. Hudson,48364846.0,Blake R. Johnson,7285332.0,M. Reagor,2107711819.0,M. Silva,3400516.0,C. Rigetti,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fdd025e077a36166b10120b448d0c4e4009824a9,https://www.semanticscholar.org/paper/fdd025e077a36166b10120b448d0c4e4009824a9,Model-Agnostic Interpretability of Machine Learning,"Understanding why machine learning models behave the way they do empowers both system designers and end-users in many ways: in model selection, feature engineering, in order to trust and act upon the predictions, and in more intuitive user interfaces. Thus, interpretability has become a vital concern in machine learning, and work in the area of interpretable models has found renewed interest. In some applications, such models are as accurate as non-interpretable ones, and thus are preferred for their transparency. Even when they are not accurate, they may still be preferred when interpretability is of paramount importance. However, restricting machine learning to interpretable models is often a severe limitation. In this paper we argue for explaining machine learning predictions using model-agnostic approaches. By treating the machine learning models as black-box functions, these approaches provide crucial flexibility in the choice of models, explanations, and representations, improving debugging, comparison, and interfaces for a variety of users and models. We also outline the main challenges for such methods, and review a recently-introduced model-agnostic explanation approach (LIME) that addresses these challenges.",2016,25,511,45,False,Computer Science,Mathematics,78846919,Marco Tulio Ribeiro,34650964.0,Sameer Singh,1730156.0,Carlos Guestrin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
259bd09bc382763f864986498e46ab0178714f58,https://www.semanticscholar.org/paper/259bd09bc382763f864986498e46ab0178714f58,Lifelong Machine Learning,"Lifelong Machine Learning (or Lifelong Learning) is an advanced machine learning paradigm that learns continuously, accumulates the knowledge learned in previous tasks, and uses it to help future learning. In the process, the learner becomes more and more knowledgeable and effective at learning. This learning ability is one of the hallmarks of human intelligence. However, the current dominant machine learning paradigm learns in isolation: given a training dataset, it runs a machine learning algorithm on the dataset to produce a model. It makes no attempt to retain the learned knowledge and use it in future learning. Although this isolated learning paradigm has been very successful, it requires a large number of training examples, and is only suitable for well-defined and narrow tasks. In comparison, we humans can learn effectively with a few examples because we have accumulated so much knowledge in the past which enables us to learn with little data or effort. Lifelong learning aims to achieve this capability. As statistical machine learning matures, it is time to make a major effort to break the isolated learning tradition and to study lifelong learning to bring machine learning to new heights. Applications such as intelligent assistants, chatbots, and physical robots that interact with humans and systems in real-life environments are also calling for such lifelong learning capabilities. Without the ability to accumulate the learned knowledge and use it to learn more knowledge incrementally, a system will probably never be truly intelligent. This book serves as an introductory text and survey to lifelong learning.",2016,380,441,45,True,Computer Science,,2111630932,Zhiyuan Chen,145321667.0,B. Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d0fb3a5ad66c83e9f2ef066d83f0ae23180da41,https://www.semanticscholar.org/paper/6d0fb3a5ad66c83e9f2ef066d83f0ae23180da41,Distributed GraphLab : A Framework for Machine Learning and Data Mining in the Cloud,"While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",2012,40,1289,208,False,,,1680638,Y. Low,2119113835.0,Joseph Gonzalez,1717990.0,Aapo Kyrola,1741745.0,D. Bickson,1730156.0,Carlos Guestrin,1695576.0,J. Hellerstein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bed9dc37c6597136eb5ae761a14b2d7f8e0204a1,https://www.semanticscholar.org/paper/bed9dc37c6597136eb5ae761a14b2d7f8e0204a1,Supervised Machine Learning Algorithms: Classification and Comparison,"--Supervised Machine Learning (SML) is the search for algorithms that reason from externally supplied instances to produce general hypotheses, which then make predictions about future instances. Supervised classification is one of the tasks most frequently carried out by the intelligent systems. This paper describes various Supervised Machine Learning (ML) classification techniques, compares various supervised learning algorithms as well as determines the most efficient classification algorithm based on the data set, the number of instances and variables (features).Seven different machine learning algorithms were considered:Decision Table, Random Forest (RF) , Naïve Bayes (NB) , Support Vector Machine (SVM), Neural Networks (Perceptron), JRip and Decision Tree (J48) using Waikato Environment for Knowledge Analysis (WEKA)machine learning tool.To implement the algorithms, Diabetes data set was used for the classification with 786 instances with eight attributes as independent variable and one as dependent variable for the analysis. The results show that SVMwas found to be the algorithm with most precision and accuracy. Naïve Bayes and Random Forest classification algorithms were found to be the next accurate after SVM accordingly. The research shows that time taken to build a model and precision (accuracy) is a factor on one hand; while kappa statistic and Mean Absolute Error (MAE) is another factor on the other hand. Therefore, ML algorithms requires precision, accuracy and minimum error to have supervised predictive machine learning.",2017,31,228,6,False,Computer Science,,1413845318,Osisanwo F.Y,1414392916.0,T. AkinsolaJ.E.,144682233.0,O. Awodele,1414096593.0,O. HinmikaiyeJ.,13667313.0,O. Olakanmi,120150977.0,J. Akinjobi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4ec306ab408839fa060cfe4f6ce969c43df65ed9,https://www.semanticscholar.org/paper/4ec306ab408839fa060cfe4f6ce969c43df65ed9,Machine Learning Phases of Strongly Correlated Fermions,"Machine learning offers an unprecedented perspective for the problem of classifying phases in condensed matter physics. We employ neural-network machine learning techniques to distinguish finite-temperature phases of the strongly correlated fermions on cubic lattices. We show that a three dimensional convolutional network trained on auxiliary field configurations produced by quantum Monte Carlo simulations of the Hubbard model can correctly predict the magnetic phase diagram of the model at the average density of one (half filling). We then use the network, trained at half filling, to explore the trend in the transition temperature as the system is doped away from half filling. This transfer learning approach predicts that the instability to the magnetic phase extends to at least 5% doping in this region. Our results pave the way for other machine learning applications in correlated quantum many-body systems.",2016,32,258,3,True,Physics,,1411979208,K. Ch'ng,5048394.0,J. Carrasquilla,3422513.0,R. Melko,2203253.0,E. Khatami,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4157ed3db4c656854e69931cb6089b64b08784b9,https://www.semanticscholar.org/paper/4157ed3db4c656854e69931cb6089b64b08784b9,DaDianNao: A Machine-Learning Supercomputer,"Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects.",2014,50,1145,149,False,Computer Science,,7377735,Yunji Chen,2068286576.0,Tao Luo,39419985.0,Shaoli Liu,2145407329.0,Shijin Zhang,37167270.0,Liqiang He,2110368816.0,Jia Wang,3353457.0,Ling Li,144049725.0,Tianshi Chen,1719934.0,Zhiwei Xu,145550877.0,Ninghui Sun,1731764.0,O. Temam,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f488e4a252c018f9391b0dc90036687a0b361844,https://www.semanticscholar.org/paper/f488e4a252c018f9391b0dc90036687a0b361844,Implementing Machine Learning in Radiology Practice and Research.,"OBJECTIVE
The purposes of this article are to describe concepts that radiologists should understand to evaluate machine learning projects, including common algorithms, supervised as opposed to unsupervised techniques, statistical pitfalls, and data considerations for training and evaluation, and to briefly describe ethical dilemmas and legal risk.


CONCLUSION
Machine learning includes a broad class of computer programs that improve with experience. The complexity of creating, training, and monitoring machine learning indicates that the success of the algorithms will require radiologist involvement for years to come, leading to engagement rather than replacement.",2017,18,186,2,False,Medicine,,145744080,M. Kohli,144477836.0,L. Prevedello,3005117.0,Ross W. Filice,144304449.0,J. R. Geis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7aaede70f5efcb1542a80707c1f0f8b01955a7d2,https://www.semanticscholar.org/paper/7aaede70f5efcb1542a80707c1f0f8b01955a7d2,Oblivious Multi-Party Machine Learning on Trusted Processors,"Privacy-preserving multi-party machine learning allows multiple organizations to perform collaborative data analytics while guaranteeing the privacy of their individual datasets. Using trusted SGX-processors for this task yields high performance, but requires a careful selection, adaptation, and implementation of machine-learning algorithms to provably prevent the exploitation of any side channels induced by data-dependent access patterns. 
 
We propose data-oblivious machine learning algorithms for support vector machines, matrix factorization, neural networks, decision trees, and k-means clustering. We show that our efficient implementation based on Intel Skylake processors scales up to large, realistic datasets, with overheads several orders of magnitude lower than with previous approaches based on advanced cryptographic multi-party computation schemes.",2016,87,422,37,False,Computer Science,,144849964,O. Ohrimenko,145124099.0,Felix Schuster,25650985.0,C. Fournet,37655483.0,Aastha Mehta,2388416.0,S. Nowozin,1796965.0,Kapil Vaswani,144638568.0,Manuel Costa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ebab687cd1be7d25392c11f89fce6a63bef7219d,https://www.semanticscholar.org/paper/ebab687cd1be7d25392c11f89fce6a63bef7219d,Towards the Science of Security and Privacy in Machine Learning,"Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive—new systems and models are being deployed in every domain imaginable, leading to rapid and widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community’s understanding of the nature and extent of these vulnerabilities remains limited. We systematize recent findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date. We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. We conclude by formally exploring the opposing relationship between model accuracy and resilience to adversarial manipulation. Through these explorations, we show that there are (possibly unavoidable) tensions between model complexity, accuracy, and resilience that must be calibrated for the environments in which they will be used.",2016,112,399,36,False,Computer Science,,1967156,Nicolas Papernot,144061974.0,P. Mcdaniel,2370629.0,Arunesh Sinha,1796536.0,Michael P. Wellman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9d46dc975aeed3f96bddb144079b50238f746ecd,https://www.semanticscholar.org/paper/9d46dc975aeed3f96bddb144079b50238f746ecd,"Machine learning in manufacturing: advantages, challenges, and applications","The nature of manufacturing systems faces ever more complex, dynamic and at times even chaotic behaviors. In order to being able to satisfy the demand for high-quality products in an efficient manner, it is essential to utilize all means available. One area, which saw fast pace developments in terms of not only promising results but also usability, is machine learning. Promising an answer to many of the old and new challenges of manufacturing, machine learning is widely discussed by researchers and practitioners alike. However, the field is very broad and even confusing which presents a challenge and a barrier hindering wide application. Here, this paper contributes in presenting an overview of available machine learning techniques and structuring this rather complicated area. A special focus is laid on the potential benefit, and examples of successful applications in a manufacturing environment.",2016,139,616,16,True,Engineering,,2511781,T. Wuest,2051446256.0,Daniel Weimer,1852549.0,C. Irgens,144199043.0,K. Thoben,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
441c31274f4535a4a50892c1ad6e19eacfd17f8c,https://www.semanticscholar.org/paper/441c31274f4535a4a50892c1ad6e19eacfd17f8c,Perspective: Machine learning potentials for atomistic simulations.,"Nowadays, computer simulations have become a standard tool in essentially all fields of chemistry, condensed matter physics, and materials science. In order to keep up with state-of-the-art experiments and the ever growing complexity of the investigated problems, there is a constantly increasing need for simulations of more realistic, i.e., larger, model systems with improved accuracy. In many cases, the availability of sufficiently efficient interatomic potentials providing reliable energies and forces has become a serious bottleneck for performing these simulations. To address this problem, currently a paradigm change is taking place in the development of interatomic potentials. Since the early days of computer simulations simplified potentials have been derived using physical approximations whenever the direct application of electronic structure methods has been too demanding. Recent advances in machine learning (ML) now offer an alternative approach for the representation of potential-energy surfaces by fitting large data sets from electronic structure calculations. In this perspective, the central ideas underlying these ML potentials, solved problems and remaining challenges are reviewed along with a discussion of their current applicability and limitations.",2016,60,732,9,True,Medicine,,144136091,J. Behler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b,https://www.semanticscholar.org/paper/07912741c6c96e6ad5b2c2d6c6c3b2de5c8a271b,Advances and Open Problems in Federated Learning,"Federated learning (FL) is a machine learning setting where many clients (e.g. mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (e.g. service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this paper discusses recent advances and presents an extensive collection of open problems and challenges.",2019,517,2240,201,True,Computer Science,Mathematics,3115341,P. Kairouz,145057514.0,H. B. McMahan,15519668.0,Brendan Avent,1702915.0,A. Bellet,1702172.0,M. Bennis,10754103.0,A. Bhagoji,2039588.0,Keith Bonawitz,143676545.0,Zachary B. Charles,1709589.0,Graham Cormode,49326047.0,Rachel Cummings,1410457573.0,Rafael G. L. D'Oliveira,40464010.0,S. Rouayheb,2116660698.0,David Evans,33685819.0,Josh Gardner,40449749.0,Zachary Garrett,145511365.0,Adrià Gascón,2529354.0,Badih Ghazi,1974678.0,Phillip B. Gibbons,1708469.0,M. Gruteser,1753355.0,Z. Harchaoui,31927890.0,Chaoyang He,,,51222147.0,Lie He,3382735.0,Zhouyuan Huo,2054968684.0,Ben Hutchinson,39756252.0,Justin Hsu,2456863.0,Martin Jaggi,47197693.0,T. Javidi,144225970.0,Gauri Joshi,10398264.0,M. Khodak,32139366.0,Jakub Konecný,2823893.0,A. Korolova,3018662.0,F. Koushanfar,143812875.0,O. Koyejo,1792616.0,Tancrède Lepoint,1614034792.0,Yang Liu,143615345.0,Prateek Mittal,81080659.0,M. Mohri,1718786.0,R. Nock,2064241030.0,A. Özgür,1801719.0,R. Pagh,1702744.0,Mariana Raykova,2072589474.0,Hang Qi,1878835.0,D. Ramage,145711633.0,R. Raskar,143711382.0,D. Song,2118727912.0,Weikang Song,2127057.0,Sebastian U. Stich,8908922.0,Ziteng Sun,9486035.0,A. Suresh,2444919.0,Florian Tramèr,2927870.0,Praneeth Vepakomma,30880777.0,Jianyu Wang,2068239439.0,Li Xiong,144897102.0,Zheng Xu,153096457.0,Qiang Yang,1815972.0,Felix X. Yu,2110984588.0,Han Yu,49113001.0,Sen Zhao
c87a4433c57ddabd50f32ca2c2d2197244692106,https://www.semanticscholar.org/paper/c87a4433c57ddabd50f32ca2c2d2197244692106,mlr: Machine Learning in R,"The MLR package provides a generic, object-oriented, and extensible framework for classification, regression, survival analysis and clustering for the R language. It provides a unified interface to more than 160 basic learners and includes meta-algorithms and model selection techniques to improve and extend the functionality of basic learners with, e.g., hyperparameter tuning, feature selection, and ensemble construction. Parallel high-performance computing is natively supported. The package targets practitioners who want to quickly apply machine learning algorithms, as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment.",2016,18,501,22,False,Computer Science,,1686924,B. Bischl,143962282.0,Michel Lang,1722782.0,Lars Kotthoff,1763314.0,J. Schiffner,145444740.0,Jakob Richter,2083245997.0,Erich Studerus,8662947.0,Giuseppe Casalicchio,2076956892.0,Zachary M. Jones,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44479cc5266788c3bafcc0b12ef0758827741fe3,https://www.semanticscholar.org/paper/44479cc5266788c3bafcc0b12ef0758827741fe3,Guidelines for Developing and Reporting Machine Learning Predictive Models in Biomedical Research: A Multidisciplinary View,"Background As more and more researchers are turning to big data for new opportunities of biomedical discoveries, machine learning models, as the backbone of big data analysis, are mentioned more often in biomedical journals. However, owing to the inherent complexity of machine learning methods, they are prone to misuse. Because of the flexibility in specifying machine learning models, the results are often insufficiently reported in research articles, hindering reliable assessment of model validity and consistent interpretation of model outputs. Objective To attain a set of guidelines on the use of machine learning predictive models within clinical settings to make sure the models are correctly applied and sufficiently reported so that true discoveries can be distinguished from random coincidence. Methods A multidisciplinary panel of machine learning experts, clinicians, and traditional statisticians were interviewed, using an iterative process in accordance with the Delphi method. Results The process produced a set of guidelines that consists of (1) a list of reporting items to be included in a research article and (2) a set of practical sequential steps for developing predictive models. Conclusions A set of guidelines was generated to enable correct application of machine learning models and consistent reporting of model specifications and results in biomedical research. We believe that such guidelines will accelerate the adoption of big data analysis, particularly with machine learning methods, in the biomedical research community.",2016,59,417,12,False,Medicine,Computer Science,145951567,Wei Luo,145890410.0,Dinh Phung,6254479.0,T. Tran,119971153.0,Sunil Gupta,2867032.0,S. Rana,145467385.0,C. Karmakar,49512795.0,A. Shilton,1726789.0,J. Yearwood,2160177.0,N. Dimitrova,1719940.0,T. Ho,143761093.0,S. Venkatesh,2274601.0,M. Berk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c396ba3ce3c58591b8ee282e65ab5a6d610e16ed,https://www.semanticscholar.org/paper/c396ba3ce3c58591b8ee282e65ab5a6d610e16ed,Machine Teaching: A New Paradigm for Building Machine Learning Systems,"The current processes for building machine learning systems require practitioners with deep knowledge of machine learning. This significantly limits the number of machine learning systems that can be created and has led to a mismatch between the demand for machine learning systems and the ability for organizations to build them. We believe that in order to meet this growing demand for machine learning systems we must significantly increase the number of individuals that can teach machines. We postulate that we can achieve this goal by making the process of teaching machines easy, fast and above all, universally accessible. 
While machine learning focuses on creating new algorithms and improving the accuracy of ""learners"", the machine teaching discipline focuses on the efficacy of the ""teachers"". Machine teaching as a discipline is a paradigm shift that follows and extends principles of software engineering and programming languages. We put a strong emphasis on the teacher and the teacher's interaction with data, as well as crucial components such as techniques and design principles of interaction and visualization. 
In this paper, we present our position regarding the discipline of machine teaching and articulate fundamental machine teaching principles. We also describe how, by decoupling knowledge about machine learning algorithms from the process of teaching, we can accelerate innovation and empower millions of new uses for machine learning models.",2017,6,125,14,False,Computer Science,Mathematics,2812486,P. Simard,1719124.0,Saleema Amershi,1724065.0,D. M. Chickering,21134435.0,Alicia Edelman Pelton,39715299.0,S. Ghorashi,50004012.0,Christopher Meek,2057749310.0,Gonzalo A. Ramos,38972741.0,Jina Suh,39963433.0,J. Verwey,2109019287.0,Mo Wang,2372116.0,J. Wernsing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77233d2f6fd10465a574ca33b869707822bf0c0b,https://www.semanticscholar.org/paper/77233d2f6fd10465a574ca33b869707822bf0c0b,A brief survey of machine learning methods and their sensor and IoT applications,"This paper provides a brief survey of the basic concepts and algorithms used for Machine Learning and its applications. We begin with a broader definition of machine learning and then introduce various learning modalities including supervised and unsupervised methods and deep learning paradigms. In the rest of the paper, we discuss applications of machine learning algorithms in various fields including pattern recognition, sensor networks, anomaly detection, Internet of Things (IoT) and health monitoring. In the final sections, we present some of the software tools and an extensive bibliography.",2017,222,155,5,False,Computer Science,,40692862,U. Shanthamallu,144924839.0,A. Spanias,1755611.0,C. Tepedelenlioğlu,147607265.0,M. Stanley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
528ecb0f88a9ea6110ba309b98cc2f0678f257c9,https://www.semanticscholar.org/paper/528ecb0f88a9ea6110ba309b98cc2f0678f257c9,Data Mining Practical Machine Learning Tools And Techniques With Java Implementations,"Thank you for reading data mining practical machine learning tools and techniques with java implementations. As you may know, people have look hundreds times for their favorite novels like this data mining practical machine learning tools and techniques with java implementations, but end up in infectious downloads. Rather than reading a good book with a cup of tea in the afternoon, instead they juggled with some malicious bugs inside their laptop.",2016,1,358,48,False,Computer Science,,49882421,Marcel Abendroth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1eb131a34fbb508a9dd8b646950c65901d6f1a5b,https://www.semanticscholar.org/paper/1eb131a34fbb508a9dd8b646950c65901d6f1a5b,Hidden Technical Debt in Machine Learning Systems,"Machine learning offers a fantastically powerful toolkit for building useful complex prediction systems quickly. This paper argues it is dangerous to think of these quick wins as coming for free. Using the software engineering framework of technical debt, we find it is common to incur massive ongoing maintenance costs in real-world ML systems. We explore several ML-specific risk factors to account for in system design. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and a variety of system-level anti-patterns.",2015,16,667,63,False,Computer Science,,1733143,D. Sculley,144510728.0,Gary Holt,145973657.0,D. Golovin,143698521.0,Eugene Davydov,2054375101.0,Todd Phillips,49236095.0,D. Ebner,2055477158.0,Vinay Chaudhary,2114084357.0,Michael Young,40169157.0,J. Crespo,47019745.0,Dan Dennison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9e6060316394393c226b5c86ce51b06c4c75bee1,https://www.semanticscholar.org/paper/9e6060316394393c226b5c86ce51b06c4c75bee1,Machine Learning Classification over Encrypted Data,"Machine learning classification is used for numerous tasks nowadays, such as medical or genomics predictions, spam detection, face recognition, and financial predictions. Due to privacy concerns, in some of these applications, it is important that the data and the classifier remain confidential. In this work, we construct three major classification protocols that satisfy this privacy constraint: hyperplane decision, Naïve Bayes, and decision trees. We also enable these protocols to be combined with AdaBoost. At the basis of these constructions is a new library of building blocks, which enables constructing a wide range of privacy-preserving classifiers; we demonstrate how this library can be used to construct other classifiers than the three mentioned above, such as a multiplexer and a face detection classifier. We implemented and evaluated our library and our classifiers. Our protocols are efficient, taking milliseconds to a few seconds to perform a classification when running on real medical datasets.",2015,73,627,62,True,Computer Science,,39940567,Raphael Bost,144963510.0,R. A. Popa,2058019574.0,Stephen Tu,1706681.0,S. Goldwasser,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56e8863838b4dcc4790108cd1e7e680a104a7c30,https://www.semanticscholar.org/paper/56e8863838b4dcc4790108cd1e7e680a104a7c30,Machine Learning Algorithms : A Review,"In this paper, various machine learning algorithms have been discussed. These algorithms are used for various purposes like data mining, image processing, predictive analytics, etc. to name a few. The main advantage of using machine learning is that, once an algorithm learns what to do with data, it can do its work automatically.",2016,14,370,25,False,Computer Science,,50349508,Ayon Dey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772,https://www.semanticscholar.org/paper/e9e6bb5f2a04ae30d8ecc9287f8b702eedd7b772,Some Studies in Machine Learning Using the Game of Checkers,"Abstract A new signature-table technique is described together with an improved book-learning procedure which is thought to be much superior to the linear polynomial method. Full use is made of the so-called “alpha-beta” pruning and several forms of forward pruning to restrict the spread of the move tree and to permit the program to look ahead to a much greater depth than it otherwise could do. While still unable to outplay checker masters, the program's playing ability has been greatly improved.tplay checker masters, the",1967,9,4060,134,True,Computer Science,,7991309,A. Samuel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6aae0dc122102693e8136856ffc8b72df7f78386,https://www.semanticscholar.org/paper/6aae0dc122102693e8136856ffc8b72df7f78386,A study of the behavior of several methods for balancing machine learning training data,"There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods.",2004,33,2672,240,False,Computer Science,,145666101,Gustavo E. A. P. A. Batista,1793286.0,R. Prati,1737677.0,M. C. Monard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
233e1651094717e3df60d231c65000eb2105e283,https://www.semanticscholar.org/paper/233e1651094717e3df60d231c65000eb2105e283,Python Machine Learning,"Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analyticsAbout This BookLeverage Python's most powerful open-source libraries for deep learning, data wrangling, and data visualizationLearn effective strategies and best practices to improve and optimize machine learning systems and algorithmsAsk and answer tough questions of your data with robust statistical models, built for a range of datasetsWho This Book Is ForIf you want to find out how to use Python to start answering critical questions of your data, pick up Python Machine Learning whether you want to get started from scratch or want to extend your data science knowledge, this is an essential and unmissable resource.What You Will LearnExplore how to use different machine learning models to ask different questions of your dataLearn how to build neural networks using Keras and TheanoFind out how to write clean and elegant Python code that will optimize the strength of your algorithmsDiscover how to embed your machine learning model in a web application for increased accessibilityPredict continuous target outcomes using regression analysisUncover hidden patterns and structures in data with clusteringOrganize data using effective pre-processing techniquesGet to grips with sentiment analysis to delve deeper into textual and social media dataIn DetailMachine learning and predictive analytics are transforming the way businesses and other organizations operate. Being able to understand trends and patterns in complex data is critical to success, becoming one of the key strategies for unlocking growth in a challenging contemporary marketplace. Python can help you deliver key insights into your data its unique capabilities as a language let you build sophisticated algorithms and statistical models that can reveal new perspectives and answer key questions that are vital for success.Python Machine Learning gives you access to the world of predictive analytics and demonstrates why Python is one of the world's leading data science languages. If you want to ask better questions of data, or need to improve and extend the capabilities of your machine learning systems, this practical data science book is invaluable. Covering a wide range of powerful Python libraries, including scikit-learn, Theano, and Keras, and featuring guidance and tips on everything from sentiment analysis to neural networks, you'll soon be able to answer some of the most important questions facing you and your organization.Style and approachPython Machine Learning connects the fundamental theoretical principles behind machine learning to their practical application in a way that focuses you on asking and answering the right questions. It walks you through the key elements of Python and its powerful machine learning libraries, while demonstrating how to get to grips with a range of statistical models.",2015,2,581,41,False,Computer Science,,2562040,S. Raschka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
92f20a1e21a20ab24ce7e335b6f1844b92515864,https://www.semanticscholar.org/paper/92f20a1e21a20ab24ce7e335b6f1844b92515864,Introduction to Machine Learning with Python: A Guide for Data Scientists, ,2016,0,435,40,False,Computer Science,,2113786044,Andreas Müller,2094280216.0,Sarah Guido,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2ea6a93199c9227fa0c1c7de13725f918c9be3a4,https://www.semanticscholar.org/paper/2ea6a93199c9227fa0c1c7de13725f918c9be3a4,Dlib-ml: A Machine Learning Toolkit,"There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classification, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools.",2009,14,2375,177,False,Computer Science,,2065224236,Davis E. King,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28e488cc9c0008fb95f7d36edafcbbc9d62ab0dc,https://www.semanticscholar.org/paper/28e488cc9c0008fb95f7d36edafcbbc9d62ab0dc,Machine Learning,"W ith recent advances in machine learning technology, data-driven research is beginning to permeate natural science and engineering fields. Synchrotron radiation science is also expected to benefit significantly from machine learning. The progress of these studies will make it possible to observe materials that could not be observed in the past or to perform synchrotron radiation measurements and detailed data analysis much more efficiently than before, leading to more effective use of limited beamtime. In addition, machine learning has the potential to bring about advanced and more efficient research through software without the need for major hardware upgrades at synchrotron radiation facilities. The encounter between machine learning and materials science has opened up a new academic field called materials informatics. Especially in the last decades, the progress has been remarkable, and the concept of informatics has been incorporated into all areas of materials science, from material design and material synthesis to measurement and analysis. The rise of materials informatics was due to advances in information science in terms of both hardware and software; namely, the dramatic development of computing power and artificial intelligence technologies such as machine learning, which have made it possible to handle large volumes of complex data that were difficult to handle in the past. In addition, it is now possible to extract useful information and new knowledge from the data, bringing about changes in various fields. Furthermore, machine learning technology has become much easier than in the past, thanks not only to simple programming languages such as Python but also to open source platforms on which an ecosystem for data analysis has been built. Taking synchrotron radiation experiments as an example, the measurement space to be explored in experiments is extremely wide. In order to extract knowledge from complex data analysis, it is necessary to efficiently search a high-dimensional search space consisting of an enormous number of parameters to find the optimal solution. Parameter search in such a highdimensional space, which skilled experts conventionally conduct based on tacit knowledge such as intuition and experience, poses problems such as bottlenecks to automation, human bias, and poor reproducibility, and requires a new research methodology that will fundamentally change conventional research methods. The wide range of new developments in the combination of synchrotron radiation and machine learning discussed in this special issue will extend synchrotron radiation experiments to more advanced measurements, bring about more efficient and automated synchrotron radiation experiments, and increase the amount of information obtained from these experiments. We hope these efforts will contribute significantly to further developing and revitalizing the synchrotron radiation community and opening up new research fields. n Kanta Ono Guest Editor Osaka University, Osaka, Japan ono@ap.eng.osaka-u.ac.jp Synchrotron Radiation News ISSN 0894-0886 is published bi-monthly. Coden Code: SRN EFR",2022,0,0,0,True,,,81008838,Kanta Ono,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3804ca5590a0829c5d56e84d860a2b2a456e3757,https://www.semanticscholar.org/paper/3804ca5590a0829c5d56e84d860a2b2a456e3757,Principles of Explanatory Debugging to Personalize Interactive Machine Learning,"How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.",2015,50,417,48,True,Computer Science,,1847827,T. Kulesza,1737204.0,M. Burnett,37535697.0,Weng-Keen Wong,2121662.0,S. Stumpf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46d71d947231f86e1f9d4581e61212385debbe14,https://www.semanticscholar.org/paper/46d71d947231f86e1f9d4581e61212385debbe14,OpenML: networked science in machine learning,"Many sciences have made significant breakthroughs by adopting online tools that help organize, structure and mine information that is too detailed to be printed in journals. In this paper, we introduce OpenML, a place for machine learning researchers to share and organize data in fine detail, so that they can work more effectively, be more visible, and collaborate with others to tackle harder problems. We discuss how OpenML relates to other examples of networked science and what benefits it brings for machine learning research, individual scientists, as well as students and practitioners.",2014,50,869,110,True,Computer Science,,1717534,J. Vanschoren,1764155.0,J. N. Rijn,1686924.0,B. Bischl,66444903.0,L. Torgo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f743833c22961537791171ef1d3fb42db8f357a3,https://www.semanticscholar.org/paper/f743833c22961537791171ef1d3fb42db8f357a3,Machine Learning Methods for Attack Detection in the Smart Grid,"Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.",2015,82,352,26,True,Computer Science,Medicine,2159942,M. Ozay,2549673.0,I. Esnaola,1398326708.0,F. Yarman-Vural,1697413.0,S. Kulkarni,145967056.0,H. Poor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
92ace17730c2173e642934d64f96d359697b7a93,https://www.semanticscholar.org/paper/92ace17730c2173e642934d64f96d359697b7a93,Bayesian reasoning and machine learning,"Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.",2012,323,1386,143,True,Computer Science,,145617808,D. Barber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f15367ed93c3505b1d62d802f3f4b769ae0f4ba5,https://www.semanticscholar.org/paper/f15367ed93c3505b1d62d802f3f4b769ae0f4ba5,Machine learning for neuroimaging with scikit-learn,"Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g., multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g., resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain.",2014,42,1057,91,True,Computer Science,Mathematics,2958954,A. Abraham,2570016.0,Fabian Pedregosa,1823753.0,Michael Eickenberg,1643887240.0,Philippe Gervais,2086994888.0,Andreas Mueller,3125761.0,Jean Kossaifi,1797840.0,Alexandre Gramfort,8493461.0,B. Thirion,3025780.0,G. Varoquaux,,,,,,,,,,,,,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
