paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,fieldsOfStudy/2,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name
b5be3165d56580b60e29ad1a4a08b124d6cb8264,https://www.semanticscholar.org/paper/b5be3165d56580b60e29ad1a4a08b124d6cb8264,Scaling up machine learning: parallel and distributed approaches,"This tutorial gives a broad view of modern approaches for scaling up machine learning and data mining methods on parallel/distributed platforms. Demand for scaling up machine learning is task-specific: for some tasks it is driven by the enormous dataset sizes, for others by model complexity or by the requirement for real-time prediction. Selecting a task-appropriate parallelization platform and algorithm requires understanding their benefits, trade-offs and constraints. This tutorial focuses on providing an integrated overview of state-of-the-art platforms and algorithm choices. These span a range of hardware options (from FPGAs and GPUs to multi-core systems and commodity clusters), programming frameworks (including CUDA, MPI, MapReduce, and DryadLINQ), and learning settings (e.g., semi-supervised and online learning). The tutorial is example-driven, covering a number of popular algorithms (e.g., boosted trees, spectral clustering, belief propagation) and diverse applications (e.g., recommender systems and object recognition in vision).The tutorial is based on (but not limited to) the material from our upcoming Cambridge U. Press edited book which is currently in production.Visit the tutorial website at http://hunch.net/~large_scale_survey/",2011,6,386,16,False,Computer Science,,1988453,R. Bekkerman,47695762.0,M. Bilenko,144162125.0,J. Langford,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
008abebf4a9404db9050c9d2fbca769f4faf3ca6,https://www.semanticscholar.org/paper/008abebf4a9404db9050c9d2fbca769f4faf3ca6,Learning by Transduction,"We describe a method for predicting a classification of an object given classifications of the objects in the training set, assuming that the pairs object/classification are generated by an i.i.d. process from a continuous probability distribution. Our method is a modification of Vapnik's support-vector machine; its main novelty is that it gives not only the prediction itself but also a practicable measure of the evidence found in support of that prediction. We also describe a procedure for assigning degrees of confidence to predictions made by the support vector machine. Some experimental results are presented, and possible extensions of the algorithms are discussed.",1998,10,421,18,False,Computer Science,Mathematics,1793317,A. Gammerman,145675281.0,V. Vovk,50560492.0,V. Vapnik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4a77a2ed53529431d816c42ec4554364e80ee18b,https://www.semanticscholar.org/paper/4a77a2ed53529431d816c42ec4554364e80ee18b,Machine learning of molecular electronic properties in chemical compound space,"The combination of modern scientific computing with electronic structure theory can lead to an unprecedented amount of data amenable to intelligent data analysis for the identification of meaningful, novel and predictive structure–property relationships. Such relationships enable high-throughput screening for relevant properties in an exponentially growing pool of virtual compounds that are synthetically accessible. Here, we present a machine learning model, trained on a database of ab initio calculation results for thousands of organic molecules, that simultaneously predicts multiple electronic ground- and excited-state properties. The properties include atomization energy, polarizability, frontier orbital eigenvalues, ionization potential, electron affinity and excitation energies. The machine learning model is based on a deep multi-task artificial neural network, exploiting the underlying correlations between various molecular properties. The input is identical to ab initio methods, i.e. nuclear charges and Cartesian coordinates of all atoms. For small organic molecules, the accuracy of such a ‘quantum machine’ is similar, and sometimes superior, to modern quantum-chemical methods—at negligible computational cost.",2013,74,478,13,False,Physics,,144535526,G. Montavon,48041657.0,M. Rupp,49302932.0,Vivekanand V Gobre,1397645825.0,Á. Vázquez-Mayagoitia,39960184.0,K. Hansen,2462983.0,A. Tkatchenko,2113612432.0,Klaus-Robert Müller,12643877.0,O. Anatole von Lilienfeld,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46d0aa6b357c5427f46c7f8ff7053617c4309649,https://www.semanticscholar.org/paper/46d0aa6b357c5427f46c7f8ff7053617c4309649,Linguistic Input Features Improve Neural Machine Translation,"Neural machine translation has recently achieved impressive results, while using little in the way of external linguistic information. In this paper we show that the strong learning capability of neural MT models does not make linguistic features redundant; they can be easily incorporated to provide further improvements in performance. We generalize the embedding layer of the encoder in the attentional encoder--decoder architecture to support the inclusion of arbitrary features, in addition to the baseline word feature. We add morphological features, part-of-speech tags, and syntactic dependency labels as input features to English German, and English->Romanian neural machine translation systems. In experiments on WMT16 training and test sets, we find that linguistic input features improve model quality according to three metrics: perplexity, BLEU and CHRF3. An open-source implementation of our neural MT system is available, as are sample files and configurations.",2016,37,346,46,True,Computer Science,,2082372,Rico Sennrich,2259100.0,B. Haddow,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7d89abfe87ed7d1b40391d37364560656d208117,https://www.semanticscholar.org/paper/7d89abfe87ed7d1b40391d37364560656d208117,Learning Memory Access Patterns,"The explosion in workload complexity and the recent slow-down in Moore's law scaling call for new approaches towards efficient computing. Researchers are now beginning to use recent advances in machine learning in software optimizations, augmenting or replacing traditional heuristics and data structures. However, the space of machine learning for computer hardware architecture is only lightly explored. In this paper, we demonstrate the potential of deep learning to address the von Neumann bottleneck of memory performance. We focus on the critical problem of learning memory access patterns, with the goal of constructing accurate and efficient memory prefetchers. We relate contemporary prefetching strategies to n-gram models in natural language processing, and show how recurrent neural networks can serve as a drop-in replacement. On a suite of challenging benchmark datasets, we find that neural networks consistently demonstrate superior performance in terms of precision and recall. This work represents the first step towards practical neural-network based prefetching, and opens a wide range of exciting directions for machine learning in computer architecture research.",2018,50,122,20,False,Computer Science,Mathematics,33798741,Milad Hashemi,1754860.0,Kevin Swersky,2119124568.0,Jamie A. Smith,46369381.0,Grant Ayers,2655459.0,Heiner Litz,1698747.0,Jichuan Chang,1700331.0,C. Kozyrakis,1770926.0,P. Ranganathan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86e5827087e11dc929d592ee7b3d7581fc48265e,https://www.semanticscholar.org/paper/86e5827087e11dc929d592ee7b3d7581fc48265e,Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN,"Machine learning has been used to detect new malware in recent years, while malware authors have strong motivation to attack such algorithms. Malware authors usually have no access to the detailed structures and parameters of the machine learning models used by malware detection systems, and therefore they can only perform black-box attacks. This paper proposes a generative adversarial network (GAN) based algorithm named MalGAN to generate adversarial malware examples, which are able to bypass black-box machine learning based detection models. MalGAN uses a substitute detector to fit the black-box malware detection system. A generative network is trained to minimize the generated adversarial examples' malicious probabilities predicted by the substitute detector. The superiority of MalGAN over traditional gradient based adversarial example generation algorithms is that MalGAN is able to decrease the detection rate to nearly zero and make the retraining based defensive method against adversarial examples hard to work.",2017,32,383,45,False,Computer Science,,2146241447,Weiwei Hu,143692919.0,Ying Tan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9664778568004b26d3a51db03c2d2a0a865a136b,https://www.semanticscholar.org/paper/9664778568004b26d3a51db03c2d2a0a865a136b,Hierarchical document categorization with support vector machines,"Automatically categorizing documents into pre-defined topic hierarchies or taxonomies is a crucial step in knowledge and content management. Standard machine learning techniques like Support Vector Machines and related large margin methods have been successfully applied for this task, albeit the fact that they ignore the inter-class relationships. In this paper, we propose a novel hierarchical classification method that generalizes Support Vector Machine learning and that is based on discriminant functions that are structured in a way that mirrors the class hierarchy. Our method can work with arbitrary, not necessarily singly connected taxonomies and can deal with task-specific loss functions. All parameters are learned jointly by optimizing a common objective function corresponding to a regularized upper bound on the empirical loss. We present experimental results on the WIPO-alpha patent collection to show the competitiveness of our approach.",2004,26,422,45,True,Computer Science,,3050583,Lijuan Cai,143936663.0,Thomas Hofmann,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31e12b8d558a7515f3a1e3337551f5f30e466cde,https://www.semanticscholar.org/paper/31e12b8d558a7515f3a1e3337551f5f30e466cde,Unified representation of molecules and crystals for machine learning,"Accurate simulations of atomistic systems from first principles are limited by computational cost. In high-throughput settings, machine learning can reduce these costs significantly by accurately interpolating between reference calculations. For this, kernel learning approaches crucially require a representation that accommodates arbitrary atomistic systems. We introduce a many-body tensor representation that is invariant to translations, rotations, and nuclear permutations of same elements, unique, differentiable, can represent molecules and crystals, and is fast to compute. Empirical evidence for competitive energy and force prediction errors is presented for changes in molecular structure, crystal chemistry, and molecular dynamics using kernel regression and symmetric gradient-domain machine learning as models. Applicability is demonstrated for phase diagrams of Pt-group/transition-metal binary systems.",2017,98,121,7,False,Physics,Chemistry,94267262,Haoyan Huo,48041657.0,M. Rupp,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66f44806cd46a27f02ceb74bdfd9ad6e77e044ca,https://www.semanticscholar.org/paper/66f44806cd46a27f02ceb74bdfd9ad6e77e044ca,Toward an Online Anomaly Intrusion Detection System Based on Deep Learning,"In the past twenty years, progress in intrusion detection has been steady but slow. The biggest challenge is to detect new attacks in real time. In this work, a deep learning approach for anomaly detection using a Restricted Boltzmann Machine (RBM) and a deep belief network are implemented. Our method uses a one-hidden layer RBM to perform unsupervised feature reduction. The resultant weights from this RBM are passed to another RBM producing a deep belief network. The pre-trained weights are passed into a fine tuning layer consisting of a Logistic Regression (LR) classifier with multi-class soft-max. We have implemented the deep learning architecture in C++ in Microsoft Visual Studio 2013 and we use the DARPA KDDCUP'99 dataset to evaluate its performance. Our architecture outperforms previous deep learning methods implemented by Li and Salama in both detection speed and accuracy. We achieve a detection rate of 97.9% on the total 10% KDDCUP'99 test dataset. By improving the training process of the simulation, we are also able to produce a low false negative rate of 2.47%. Although the deficiencies in the KDDCUP'99 dataset are well understood, it still presents machine learning approaches for predicting attacks with a reasonable challenge. Our future work will include applying our machine learning strategy to larger and more challenging datasets, which include larger classes of attacks.",2016,22,165,11,False,Computer Science,,8837455,Khaled Alrawashdeh,145554708.0,C. Purdy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
087874409722c38bbb643e3c7328e86a49a1aac6,https://www.semanticscholar.org/paper/087874409722c38bbb643e3c7328e86a49a1aac6,Multi-Agent Machine Learning: A Reinforcement Approach,"multi agent machine learning a reinforcement approach multi-agent machine learning: a reinforcement approach by multi agent machine learning a reinforcement approach multi agent machine learning a reinforcement approach user crowd simulation via multi-agent reinforcement learning multi-agent machine learning: a reinforcement approach by multi-agent reinforcement learning for planning and multi-agent machine download.e-bookshelf multi-agent machine learning buch cooperative multi-agent learning: the state of the art learning to communicate with deep multi-agent a modular approach to multi-agent reinforcement learning multi agent machine learning a reinforcement approach multi-agent machine learning: a reinforcement approach by multi-agent machine learning: a reinforcement approach multi agent machine learning a reinforcement approach interactive machine learning 2015w, se, 2.0 3.0 ects 45 06 online learning for multi-agent local navigation learning to communicate with deep multi-agent a mas reinforcement learning approach for indeterministic safe, multi-agent, reinforcement learning for arxiv multi-agent inverse reinforcement learning combining machine learning and multi-agent approach for robocup soccer simulation: a reinforcement learning approach multi-agent relational reinforcement learning a generic multi-agent reinforcement learning approach for supervised rule learning and reinforcement learning in a multi-agent reinforcement learning simulation for multi iensemble: a framework for committee machine based on simulation and investigation of multi-agent reinforcement hierarchical reinforcement learning in multi-agent environment learning to cooperate in multi-agent systems by combining traf?c light control by multiagent reinforcement learning multi-agent relational reinforcement learning cooperative reinforcement learning in topology-based multi multi-agent case-based reasoning for cooperative cooperative coevolution of multi-agent systems conditional random fields for multi-agent reinforcement",2014,5,91,6,True,Computer Science,,8488870,H. Schwartz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f986968735459e789890f24b6b277b0920a9725d,https://www.semanticscholar.org/paper/f986968735459e789890f24b6b277b0920a9725d,Places: A 10 Million Image Database for Scene Recognition,"The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification performance at tasks such as visual object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories, comprising a large and diverse list of the types of environments encountered in the world. Using the state-of-the-art Convolutional Neural Networks (CNNs), we provide scene classification CNNs (Places-CNNs) as baselines, that significantly outperform the previous approaches. Visualization of the CNNs trained on Places shows that object detectors emerge as an intermediate representation of scene classification. With its high-coverage and high-diversity of exemplars, the Places Database along with the Places-CNNs offer a novel resource to guide future progress on scene recognition problems.",2018,46,2414,491,False,Computer Science,Medicine,145291669,Bolei Zhou,2677488.0,À. Lapedriza,2556428.0,A. Khosla,143868587.0,A. Oliva,143805211.0,A. Torralba,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16ea21723cbc1dcafec799072d47ef202b9fb172,https://www.semanticscholar.org/paper/16ea21723cbc1dcafec799072d47ef202b9fb172,Machine Learning and Law,"This Article explores the application of machine learning techniques within the practice of law. Broadly speaking “machine learning” refers to computer algorithms that have the ability to “learn” or improve in performance over time on some task. In general, machine learning algorithms are designed to detect patterns in data and then apply these patterns going forward to new data in order to automate particular tasks. Outside of law, machine learning techniques have been successfully applied to automate tasks that were once thought to necessitate human intelligence — for example language translation, fraud-detection, driving automobiles, facial recognition, and data-mining. If performing well, machine learning algorithms can produce automated results that approximate those that would have been made by a similarly situated person.This Article begins by explaining some basic principles underlying machine learning methods, in a manner accessible to non-technical audiences. The second part explores a broader puzzle: legal practice is thought to require advanced cognitive abilities, but such higher-order cognition remains outside the capability of current machine-learning technology. This part identifies a core principle: how certain tasks that are normally thought to require human intelligence can sometimes be automated through the use of non-intelligent computational techniques that employ heuristics or proxies (e.g., statistical correlations) capable of producing useful, “intelligent” results. The third part applies this principle to the practice of law, discussing machine-learning automation in the context of certain legal tasks currently performed by attorneys: including predicting the outcomes of legal cases, finding hidden relationships in legal documents and data, electronic discovery, and the automated organization of documents.",2014,2,111,4,False,Computer Science,,2363337,Harry Surden,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
09622b0c84bf812814af5b64b0c83dce796899c4,https://www.semanticscholar.org/paper/09622b0c84bf812814af5b64b0c83dce796899c4,Content-based book recommending using learning for text categorization,"Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes. Most existing recommender systems use collaborative filtering methods that base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization. Initial experimental results demonstrate that this approach can produce accurate recommendations.",1999,73,1553,64,False,Computer Science,,1797655,R. Mooney,143747945.0,Loriene Roy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33e46a618fdb22d46951f548d6ceeb384e7f1687,https://www.semanticscholar.org/paper/33e46a618fdb22d46951f548d6ceeb384e7f1687,Pedestrian Detection via Classification on Riemannian Manifolds,"We present a new algorithm to detect pedestrian in still images utilizing covariance matrices as object descriptors. Since the descriptors do not form a vector space, well known machine learning techniques are not well suited to learn the classifiers. The space of d-dimensional nonsingular covariance matrices can be represented as a connected Riemannian manifold. The main contribution of the paper is a novel approach for classifying points lying on a connected Riemannian manifold using the geometry of the space. The algorithm is tested on INRIA and DaimlerChrysler pedestrian datasets where superior detection rates are observed over the previous approaches.",2008,62,965,86,False,Medicine,Computer Science,2577513,Oncel Tuzel,29905643.0,F. Porikli,145776090.0,P. Meer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
562a596836f42714d81e1f861671959ba12e0246,https://www.semanticscholar.org/paper/562a596836f42714d81e1f861671959ba12e0246,Machine Learning Methods for Predicting Failures in Hard Drives: A Multiple-Instance Application,"We compare machine learning methods applied to a difficult real-world problem: predicting computer hard-drive failure using attributes monitored internally by individual drives. The problem is one of detecting rare events in a time series of noisy and nonparametrically-distributed data. We develop a new algorithm based on the multiple-instance learning framework and the naive Bayesian classifier (mi-NB) which is specifically designed for the low false-alarm case, and is shown to have promising performance. Other methods compared are support vector machines (SVMs), unsupervised clustering, and non-parametric statistical tests (rank-sum and reverse arrangements). The failure-prediction performance of the SVM, rank-sum and mi-NB algorithm is considerably better than the threshold method currently implemented in drives, while maintaining low false alarm rates. Our results suggest that nonparametric statistical tests should be considered for learning problems involving detecting rare events in time series data. An appendix details the calculation of rank-sum significance probabilities in the case of discrete, tied observations, and we give new recommendations about when the exact calculation should be used instead of the commonly-used normal approximation. These normal approximations may be particularly inaccurate for rare event problems like hard drive failures.",2005,51,255,25,False,Computer Science,,31052092,J. Murray,2066539.0,G. Hughes,1395421758.0,K. Kreutz-Delgado,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a39398f68ae7e042f2ef5009e31b4e6a20fd5736,https://www.semanticscholar.org/paper/a39398f68ae7e042f2ef5009e31b4e6a20fd5736,Learning Deep Transformer Models for Machine Translation,"Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT’16 English-German and NIST OpenMT’12 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4-2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big.",2019,36,316,40,True,Computer Science,,2183631046,Qiang Wang,49730090.0,Bei Li,1391183811.0,Tong Xiao,1728004.0,Jingbo Zhu,2348067.0,Changliang Li,1758353.0,Derek F. Wong,1774304.0,Lidia S. Chao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bf5cf36407ece2569f0717f2b5593c4bd2140ebb,https://www.semanticscholar.org/paper/bf5cf36407ece2569f0717f2b5593c4bd2140ebb,Machine Learning for Predictive Maintenance: A Multiple Classifier Approach,"In this paper, a multiple classifier machine learning (ML) methodology for predictive maintenance (PdM) is presented. PdM is a prominent strategy for dealing with maintenance issues given the increasing need to minimize downtime and associated costs. One of the challenges with PdM is generating the so-called “health factors,” or quantitative indicators, of the status of a system associated with a given maintenance issue, and determining their relationship to operating costs and failure risk. The proposed PdM methodology allows dynamical decision rules to be adopted for maintenance management, and can be used with high-dimensional and censored data problems. This is achieved by training multiple classification modules with different prediction horizons to provide different performance tradeoffs in terms of frequency of unexpected breaks and unexploited lifetime, and then employing this information in an operating cost-based maintenance decision system to minimize expected costs. The effectiveness of the methodology is demonstrated using a simulated example and a benchmark semiconductor manufacturing maintenance problem.",2015,31,446,14,True,Engineering,Computer Science,3126083,Gian Antonio Susto,2979820.0,A. Schirru,2383035.0,S. Pampuri,48147378.0,S. McLoone,1744705.0,A. Beghi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2ebdfa3852e4ad68a0cfde9f0f69b95953d69178,https://www.semanticscholar.org/paper/2ebdfa3852e4ad68a0cfde9f0f69b95953d69178,On-Line Sequential Extreme Learning Machine,"The primitive Extreme Learning Machine (ELM) [1, 2, 3] with additive neurons and RBF kernels was implemented in batch mode. In this paper, its sequential modification based on recursive least-squares (RLS) algorithm, which referred as Online Sequential Extreme Learning Machine (OS-ELM), is introduced. Based on OS-ELM, Online Sequential Fuzzy Extreme Learning Machine (Fuzzy-ELM) is also introduced to implement zero order TSK model and first order TSK model. The performance of OS-ELM and Fuzzy-ELM are evaluated and compared with other popular sequential learning algorithms, and experimental results on some real benchmark regression problems show that the proposedOnlineSequentialExtreme Learning Machine (OS-ELM) produces better generalization performance at very fast learning speed.",2005,14,194,17,False,Computer Science,,145678691,G. Huang,2972859.0,Nan-Ying Liang,2774247.0,Hai-Jun Rong,1800678.0,P. Saratchandran,145411276.0,N. Sundararajan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5939ac3b5a9d64d8371ee179751351d7698637df,https://www.semanticscholar.org/paper/5939ac3b5a9d64d8371ee179751351d7698637df,Using Machine Learning to Advance Personality Assessment and Theory,"Machine learning has led to important advances in society. One of the most exciting applications of machine learning in psychological science has been the development of assessment tools that can powerfully predict human behavior and personality traits. Thus far, machine learning approaches to personality assessment have focused on the associations between social media and other digital records with established personality measures. The goal of this article is to expand the potential of machine learning approaches to personality assessment by embedding it in a more comprehensive construct validation framework. We review recent applications of machine learning to personality assessment, place machine learning research in the broader context of fundamental principles of construct validation, and provide recommendations for how to use machine learning to advance our understanding of personality.",2019,68,117,1,True,Medicine,Psychology,5199283,W. Bleidorn,2066036.0,C. Hopwood,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15c10b24ef645d83ff4059affd86945c33e00328,https://www.semanticscholar.org/paper/15c10b24ef645d83ff4059affd86945c33e00328,Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces,"This paper presents the machine learning architecture of the Snips Voice Platform, a software solution to perform Spoken Language Understanding on microprocessors typical of IoT devices. The embedded inference is fast and accurate while enforcing privacy by design, as no personal user data is ever collected. Focusing on Automatic Speech Recognition and Natural Language Understanding, we detail our approach to training high-performance Machine Learning models that are small enough to run in real-time on small devices. Additionally, we describe a data generation procedure that provides sufficient, high-quality training data without compromising user privacy.",2018,59,489,120,False,Computer Science,,3478709,A. Coucke,16927419.0,Alaa Saade,46190149.0,Adrien Ball,3387810.0,Théodore Bluche,8228681.0,A. Caulier,2064189593.0,David Leroy,46231361.0,Clément Doumouro,2977214.0,Thibault Gisselbrecht,2905619.0,F. Caltagirone,46183616.0,Thibaut Lavril,2245637.0,Maël Primet,7432502.0,J. Dureau,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8ccdee6826cbc97256bd4d082ebfa8cdfd2c727f,https://www.semanticscholar.org/paper/8ccdee6826cbc97256bd4d082ebfa8cdfd2c727f,Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations,"Machine-learning fluid flow Quantifying fluid flow is relevant to disciplines ranging from geophysics to medicine. Flow can be experimentally visualized using, for example, smoke or contrast agents, but extracting velocity and pressure fields from this information is tricky. Raissi et al. developed a machine-learning approach to tackle this problem. Their method exploits the knowledge of Navier-Stokes equations, which govern the dynamics of fluid flow in many scientifically relevant situations. The authors illustrate their approach using examples such as blood flow in an aneurysm. Science, this issue p. 1026 A machine learning approach exploiting the knowledge of Navier-Stokes equations can extract detailed fluid flow information. For centuries, flow visualization has been the art of making fluid motion visible in physical and biological systems. Although such flow patterns can be, in principle, described by the Navier-Stokes equations, extracting the velocity and pressure fields directly from the images is challenging. We addressed this problem by developing hidden fluid mechanics (HFM), a physics-informed deep-learning framework capable of encoding the Navier-Stokes equations into the neural networks while being agnostic to the geometry or the initial and boundary conditions. We demonstrate HFM for several physical and biomedical problems by extracting quantitative information for which direct measurements may not be possible. HFM is robust to low resolution and substantial noise in the observation data, which is important for potential applications.",2020,30,567,19,True,Medicine,Computer Science,145401977,M. Raissi,37412357.0,A. Yazdani,1720124.0,G. Karniadakis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62ec643e5415b6ab89f7186d3631f5549fd8a0cc,https://www.semanticscholar.org/paper/62ec643e5415b6ab89f7186d3631f5549fd8a0cc,Support Vector Machines and Kernel Methods: The New Generation of Learning Machines,"Kernel methods, a new generation of learning algorithms, utilize techniques from optimization, statistics, and functional analysis to achieve maximal generality, flexibility, and performance. These algorithms are different from earlier techniques used in machine learning in many respects: For example, they are explicitly based on a theoretical model of learning rather than on loose analogies with natural learning systems or other heuristics. They come with theoretical guarantees about their performance and have a modular design that makes it possible to separately implement and analyze their components. They are not affected by the problem of local minima because their training amounts to convex optimization. In the last decade, a sizable community of theoreticians and practitioners has formed around these methods, and a number of practical applications have been realized. Although the research is not concluded, already now kernel methods are considered the state of the art in several machine learning tasks. Their ease of use, theoretical appeal, and remarkable performance have made them the system of choice for many learning problems. Successful applications range from text categorization to handwriting recognition to classification of gene-expression data.",2002,11,210,23,False,Computer Science,,1685083,N. Cristianini,1707625.0,B. Schölkopf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1574d71de4270c65e2bff693ed126f480daf10e2,https://www.semanticscholar.org/paper/1574d71de4270c65e2bff693ed126f480daf10e2,Job shop scheduling with a genetic algorithm and machine learning,"Dynamic job shop scheduling has been proven to be an intractable problem for analytical procedures. Recent advances in computing technology, especially in artificial intelligence, have alleviated this problem by intelligently restricting the search space considered, thus opening the possibility of obtaining better results. Researchers have used various techniques that were developed under the general rubric of artificial intelligence to solve job shop scheduling problems. The most common of these have been expert systems, genetic algorithms and machine learning. Of these, we identify machine learning and genetic algorithms to be promising for scheduling applications in a job shop. In this paper, we propose to combine complementarily the strengths of genetic algorithms and induced decision trees, a machine learning technique, to develop a job shop scheduling system. Empirical results, using machine learning for releasing jobs into the shop floor and a genetic algorithm to dispatch jobs at each machine, are...",1997,0,166,6,False,Computer Science,,144220988,Chung-Yee Lee,1730130.0,S. Piramuthu,143798211.0,Y. Tsai,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5151d6cb3a4eaec14a56944d58338251fca344ab,https://www.semanticscholar.org/paper/5151d6cb3a4eaec14a56944d58338251fca344ab,Overcoming catastrophic forgetting in neural networks,"Significance Deep neural networks are currently the most successful machine-learning technique for solving a variety of tasks, including language translation, image classification, and image generation. One weakness of such models is that, unlike humans, they are unable to learn multiple tasks sequentially. In this work we propose a practical solution to train such models sequentially by protecting the weights important for previous tasks. This approach, inspired by synaptic consolidation in neuroscience, enables state of the art results on multiple reinforcement learning problems experienced sequentially. The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Until now neural networks have not been capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks that they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on a hand-written digit dataset and by learning several Atari 2600 games sequentially.",2016,47,3277,715,True,Computer Science,Mathematics,2066516991,J. Kirkpatrick,1996134.0,Razvan Pascanu,3422052.0,Neil C. Rabinowitz,144056327.0,J. Veness,2755582.0,Guillaume Desjardins,2228824.0,Andrei A. Rusu,8181864.0,K. Milan,34660073.0,John Quan,34505275.0,Tiago Ramalho,1398898827.0,Agnieszka Grabska-Barwinska,48987704.0,D. Hassabis,2388737.0,C. Clopath,2106164.0,D. Kumaran,2315504.0,R. Hadsell,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
7e910b031e703caf683d44d7417d702a5aba2e95,https://www.semanticscholar.org/paper/7e910b031e703caf683d44d7417d702a5aba2e95,"Handbook Of Research On Machine Learning Applications and Trends: Algorithms, Methods and Techniques (2 Volumes)","The machine learning approach provides a useful tool when the amount of data is very large and a model is not available to explain the generation and relation of the data set. The Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques provides a set of practical applications for solving problems and applying various techniques in automatic data extraction and setting. A defining collection of field advancements, this Handbook of Research fills the gap between theory and practice, providing a strong reference for academicians, researchers, and practitioners.",2009,83,368,6,True,Computer Science,,2060576305,E. S. Olivas,103992067.0,J. D. M. Guerrero,71631370.0,M. M. Sober,35119570.0,J. Benedito,152692443.0,A. López,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93436a26d744e0417e21df10abdfce2cc74b1e58,https://www.semanticscholar.org/paper/93436a26d744e0417e21df10abdfce2cc74b1e58,BOHB: Robust and Efficient Hyperparameter Optimization at Scale,"Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.",2018,58,632,121,False,Computer Science,Mathematics,2154062,S. Falkner,145227684.0,Aaron Klein,144661829.0,F. Hutter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ffaa313b8da3695627cd9915ca46b8bed24a9f4a,https://www.semanticscholar.org/paper/ffaa313b8da3695627cd9915ca46b8bed24a9f4a,Probability Product Kernels,"The advantages of discriminative learning algorithms and kernel machines are combined with generative modeling using a novel kernel between distributions. In the probability product kernel, data points in the input space are mapped to distributions over the sample space and a general inner product is then evaluated as the integral of the product of pairs of distributions. The kernel is straightforward to evaluate for all exponential family models such as multinomials and Gaussians and yields interesting nonlinear kernels. Furthermore, the kernel is computable in closed form for latent distributions such as mixture models, hidden Markov models and linear dynamical systems. For intractable models, such as switching linear dynamical systems, structured mean-field approximations can be brought to bear on the kernel evaluation. For general distributions, even if an analytic expression for the kernel is not feasible, we show a straightforward sampling method to evaluate it. Thus, the kernel permits discriminative learning methods, including support vector machines, to exploit the properties, metrics and invariances of the generative models we infer from each datum. Experiments are shown using multinomial models for text, hidden Markov models for biological data sets and linear dynamical systems for time series data.",2004,36,582,58,False,Mathematics,Computer Science,1768120,T. Jebara,2834541.0,R. Kondor,2068068778.0,Andrew G. Howard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7ef26fb13e7b8d7555b6f58af141609535f7e28e,https://www.semanticscholar.org/paper/7ef26fb13e7b8d7555b6f58af141609535f7e28e,A review of classification algorithms for EEG-based brain–computer interfaces: a 10 year update,"Objective. Most current electroencephalography (EEG)-based brain–computer interfaces (BCIs) are based on machine learning algorithms. There is a large diversity of classifier types that are used in this field, as described in our 2007 review paper. Now, approximately ten years after this review publication, many new algorithms have been developed and tested to classify EEG signals in BCIs. The time is therefore ripe for an updated review of EEG classification algorithms for BCIs. Approach. We surveyed the BCI and machine learning literature from 2007 to 2017 to identify the new classification approaches that have been investigated to design BCIs. We synthesize these studies in order to present such algorithms, to report how they were used for BCIs, what were the outcomes, and to identify their pros and cons. Main results. We found that the recently designed classification algorithms for EEG-based BCIs can be divided into four main categories: adaptive classifiers, matrix and tensor classifiers, transfer learning and deep learning, plus a few other miscellaneous classifiers. Among these, adaptive classifiers were demonstrated to be generally superior to static ones, even with unsupervised adaptation. Transfer learning can also prove useful although the benefits of transfer learning remain unpredictable. Riemannian geometry-based methods have reached state-of-the-art performances on multiple BCI problems and deserve to be explored more thoroughly, along with tensor-based methods. Shrinkage linear discriminant analysis and random forests also appear particularly useful for small training samples settings. On the other hand, deep learning methods have not yet shown convincing improvement over state-of-the-art BCI methods. Significance. This paper provides a comprehensive overview of the modern classification algorithms used in EEG-based BCIs, presents the principles of these methods and guidelines on when and how to use them. It also identifies a number of challenges to further advance EEG classification in BCI.",2018,346,985,71,True,Physics,Medicine,2890785,F. Lotte,1765001.0,L. Bougrain,145683892.0,A. Cichocki,48021716.0,Maureen Clerc,3276441.0,M. Congedo,1792962.0,A. Rakotomamonjy,1783082.0,F. Yger,,,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
9be7e7579fbec5d45e3e6ea1c4465258225a183d,https://www.semanticscholar.org/paper/9be7e7579fbec5d45e3e6ea1c4465258225a183d,Initializing Bayesian Hyperparameter Optimization via Meta-Learning,"Model selection and hyperparameter optimization is crucial in applying machine learning to a novel dataset. Recently, a subcommunity of machine learning has focused on solving this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating substantial successes in many applications. However, for computationally expensive algorithms the overhead of hyperparameter optimization can still be prohibitive. In this paper we mimic a strategy human domain experts use: speed up optimization by starting from promising configurations that performed well on similar datasets. The resulting initialization technique integrates naturally into the generic SMBO framework and can be trivially applied to any SMBO method. To validate our approach, we perform extensive experiments with two established SMBO frameworks (Spearmint and SMAC) with complementary strengths; optimizing two machine learning frameworks on 57 datasets. Our initialization procedure yields mild improvements for low-dimensional hyperparameter optimization and substantially improves the state of the art for the more complex combined algorithm selection and hyperparameter optimization problem.",2015,41,350,39,True,Computer Science,,2868444,Matthias Feurer,2060551.0,J. T. Springenberg,144661829.0,F. Hutter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
be1496e9620089b377ef631692478f5034ee95b8,https://www.semanticscholar.org/paper/be1496e9620089b377ef631692478f5034ee95b8,Machine learning applications in epilepsy,"Machine learning leverages statistical and computer science principles to develop algorithms capable of improving performance through interpretation of data rather than through explicit instructions. Alongside widespread use in image recognition, language processing, and data mining, machine learning techniques have received increasing attention in medical applications, ranging from automated imaging analysis to disease forecasting. This review examines the parallel progress made in epilepsy, highlighting applications in automated seizure detection from electroencephalography (EEG), video, and kinetic data, automated imaging analysis and pre‐surgical planning, prediction of medication response, and prediction of medical and surgical outcomes using a wide variety of data sources. A brief overview of commonly used machine learning approaches, as well as challenges in further application of machine learning techniques in epilepsy, is also presented. With increasing computational capabilities, availability of effective machine learning algorithms, and accumulation of larger datasets, clinicians and researchers will increasingly benefit from familiarity with these techniques and the significant progress already made in their application in epilepsy.",2019,114,139,3,False,Medicine,Computer Science,48487599,B. Abbasi,2423726.0,D. Goldenholz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6cf1d69e447e9687dbd2d92572f44bddbabd8192,https://www.semanticscholar.org/paper/6cf1d69e447e9687dbd2d92572f44bddbabd8192,Deep Anomaly Detection with Outlier Exposure,"It is important to detect anomalous inputs when deploying machine learning systems. The use of larger and more complex inputs in deep learning magnifies the difficulty of distinguishing between anomalous and in-distribution examples. At the same time, diverse image and text data are available in enormous quantities. We propose leveraging these data to improve deep anomaly detection by training anomaly detectors against an auxiliary dataset of outliers, an approach we call Outlier Exposure (OE). This enables anomaly detectors to generalize and detect unseen anomalies. In extensive experiments on natural language processing and small- and large-scale vision tasks, we find that Outlier Exposure significantly improves detection performance. We also observe that cutting-edge generative models trained on CIFAR-10 may assign higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to mitigate this issue. We also analyze the flexibility and robustness of Outlier Exposure, and identify characteristics of the auxiliary dataset that improve performance.",2018,51,751,175,False,Computer Science,Mathematics,3422872,Dan Hendrycks,16787428.0,Mantas Mazeika,144299726.0,Thomas G. Dietterich,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16bd1fbe3694173eda4ad4338a85f8288d19bf02,https://www.semanticscholar.org/paper/16bd1fbe3694173eda4ad4338a85f8288d19bf02,Relational Learning of Pattern-Match Rules for Information Extraction,"Information extraction is a form of shallow text processing that locates a specified set of relevant items in a natural-language document. Systems for this task require significant domain-specific knowledge and are time-consuming and difficult to build by hand, making them a good application for machine learning. We present a system, RAPIER, that uses pairs of sample documents and filled templates to induce pattern-match rules that directly extract fillers for the slots in the template. RAPIER employs a bottom-up learning algorithm which incorporates techniques from several inductive logic programming systems and acquires unbounded patterns that include constraints on the words, part-of-speech tags, and semantic classes present in the filler and the surrounding text. We present encouraging experimental results on two domains.",1999,38,707,38,False,Computer Science,,1967815,Mary Elaine Califf,1797655.0,R. Mooney,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3a84214cb69ea0b34352285029f368b75718c32b,https://www.semanticscholar.org/paper/3a84214cb69ea0b34352285029f368b75718c32b,Understanding of a convolutional neural network,"The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.",2017,14,1314,100,False,Computer Science,,147999774,Saad Albawi,37517325.0,T. Mohammed,1410550919.0,Saad Al-Zawi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d12864a8acbab1830be755bfb9cb177e31ca5e20,https://www.semanticscholar.org/paper/d12864a8acbab1830be755bfb9cb177e31ca5e20,On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey,"Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered.",2000,715,2785,93,False,Computer Science,,144586498,R. Plamondon,1696384.0,S. Srihari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5b918ae410569af12be0f4ce3055d28d5ec3cab0,https://www.semanticscholar.org/paper/5b918ae410569af12be0f4ce3055d28d5ec3cab0,Interactive machine learning: letting users build classifiers,"Abstract According to standard procedure, building a classifier using machine learning is a fully automated process that follows the preparation of training data by a domain expert. In contrast, interactive machine learning engages users in actually generating the classifier themselves. This offers a natural way of integrating background knowledge into the modelling stage—as long as interactive tools can be designed that support efficient and effective communication. This paper shows that appropriate techniques can empower users to create models that compete with classifiers built by state-of-the-art learning algorithms. It demonstrates that users—even users who are not domain experts—can often construct good classifiers, without any help from a learning algorithm, using a simple two-dimensional visual interface. Experiments on real data demonstrate that, not surprisingly, success hinges on the domain: if a few attributes can support good predictions, users generate accurate classifiers, whereas domains with many high-order attribute interactions favour standard machine learning techniques. We also present an artificial example where domain knowledge allows an “expert user” to create a much more accurate model than automatic learning algorithms. These results indicate that our system has the potential to produce highly accurate classifiers in the hands of a domain expert who has a strong interest in the domain and therefore some insights into how to partition the data. Moreover, small expert-defined models offer the additional advantage that they will generally be more intelligible than those generated by automatic techniques.",2002,10,195,13,True,Computer Science,,70564156,Malcolm Ware,143713826.0,Eibe Frank,144282963.0,G. Holmes,118860642.0,M. Hall,9419406.0,I. Witten,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d4de528645fdfc6d954364a8e6eeeed9480ccfa2,https://www.semanticscholar.org/paper/d4de528645fdfc6d954364a8e6eeeed9480ccfa2,"Machine Learning for Networking: Workflow, Advances and Opportunities","Recently, machine learning has been used in every possible field to leverage its amazing power. For a long time, the networking and distributed computing system is the key infrastructure to provide efficient computational resources for machine learning. Networking itself can also benefit from this promising technology. This article focuses on the application of MLN, which can not only help solve the intractable old network questions but also stimulate new network applications. In this article, we summarize the basic workflow to explain how to apply machine learning technology in the networking domain. Then we provide a selective survey of the latest representative advances with explanations of their design principles and benefits. These advances are divided into several network design objectives and the detailed information of how they perform in each step of MLN workflow is presented. Finally, we shed light on the new opportunities in networking design and community building of this new inter-discipline. Our goal is to provide a broad research guideline on networking with machine learning to help motivate researchers to develop innovative algorithms, standards and frameworks.",2017,18,280,12,True,Computer Science,,2109018752,Mowei Wang,143905357.0,Yong Cui,2153687403.0,Xin Wang,1994540.0,Shihan Xiao,1727978.0,Junchen Jiang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a8e3a1871f50ebd5e3c457bbe1a0c72c4655cee9,https://www.semanticscholar.org/paper/a8e3a1871f50ebd5e3c457bbe1a0c72c4655cee9,Layered learning in multiagent systems - a winning approach to robotic soccer,"From the Publisher: This book looks at multiagent systems that consist of teams of autonomous agents acting in real-time, noisy, collaborative, and adversarial environments. The book makes four main contributions to the fields of machine learning and multiagent systems. First, it describes an architecture within which a flexible team structure allows member agents to decompose a task into flexible roles and to switch roles while acting. Second, it presents layered learning, a general-purpose machine-learning method for complex domains in which learning a mapping directly from agents' sensors to their actuators is intractable with existing machine-learning methods. Third, the book introduces a new multiagent reinforcement learning algorithm--team-partitioned, opaque-transition reinforcement learning (TPOT-RL)--designed for domains in which agents cannot necessarily observe the state-changes caused by other agents' actions. The final contribution is a fully functioning multiagent system that incorporates learning in a real-time, noisy domain with teammates and adversaries--a computer-simulated robotic soccer team. Peter Stone's work is the basis for the CMUnited Robotic Soccer Team, which has dominated recent RoboCup competitions. RoboCup not only helps roboticists to prove their theories in a realistic situation, but has drawn considerable public and professional attention to the field of intelligent robotics. The CMUnited team won the 1999 Stockholm simulator competition, outscoring its opponents by the rather impressive cumulative score of 110-0.",2000,0,342,14,True,Engineering,Computer Science,144848112,P. Stone,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77233d2f6fd10465a574ca33b869707822bf0c0b,https://www.semanticscholar.org/paper/77233d2f6fd10465a574ca33b869707822bf0c0b,A brief survey of machine learning methods and their sensor and IoT applications,"This paper provides a brief survey of the basic concepts and algorithms used for Machine Learning and its applications. We begin with a broader definition of machine learning and then introduce various learning modalities including supervised and unsupervised methods and deep learning paradigms. In the rest of the paper, we discuss applications of machine learning algorithms in various fields including pattern recognition, sensor networks, anomaly detection, Internet of Things (IoT) and health monitoring. In the final sections, we present some of the software tools and an extensive bibliography.",2017,222,156,5,False,Computer Science,,40692862,U. Shanthamallu,144924839.0,A. Spanias,1755611.0,C. Tepedelenlioğlu,147607265.0,M. Stanley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
531e3a7b7768f199fdd401b266504db245ca039a,https://www.semanticscholar.org/paper/531e3a7b7768f199fdd401b266504db245ca039a,On Detecting Adversarial Perturbations,"Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small ""detector"" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack.",2017,23,757,52,False,Computer Science,Mathematics,2708564,J. H. Metzen,3081854.0,Tim Genewein,47092548.0,Volker Fischer,3452473.0,B. Bischoff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77826df024f97583eb05700a28e11056a4aab848,https://www.semanticscholar.org/paper/77826df024f97583eb05700a28e11056a4aab848,Latent Intention Dialogue Models,"Developing a dialogue agent that is capable of making autonomous decisions and communicating by natural language is one of the long-term goals of machine learning research. Traditional approaches either rely on hand-crafting a small state-action set for applying reinforcement learning that is not scalable or constructing deterministic models for learning dialogue sentences that fail to capture natural conversational variability. In this paper, we propose a Latent Intention Dialogue Model (LIDM) that employs a discrete latent variable to learn underlying dialogue intentions in the framework of neural variational inference. In a goal-oriented dialogue scenario, these latent intentions can be interpreted as actions guiding the generation of machine responses, which can be further refined autonomously by reinforcement learning. The experimental evaluation of LIDM shows that the model out-performs published benchmarks for both corpus-based and human evaluation, demonstrating the effectiveness of discrete latent variable models for learning goal-oriented dialogues.",2017,47,134,21,False,Computer Science,Mathematics,144256365,Tsung-Hsien Wen,2666898.0,Yishu Miao,1685771.0,P. Blunsom,145259603.0,S. Young,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
219355e8c58b78c409e34677da50b49fb4c1eacd,https://www.semanticscholar.org/paper/219355e8c58b78c409e34677da50b49fb4c1eacd,AutoML-Zero: Evolving Machine Learning Algorithms From Scratch,"Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as AutoML, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that AutoML can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.",2020,119,118,9,False,Computer Science,Mathematics,2892780,Esteban Real,145246869.0,Chen Liang,48165870.0,David R. So,2827616.0,Quoc V. Le,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
512b8ef0002e0bfd0ecb5ab17d533c1762eb9786,https://www.semanticscholar.org/paper/512b8ef0002e0bfd0ecb5ab17d533c1762eb9786,Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks,"Many machine learning tasks such as multiple instance learning, 3D shape recognition, and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces the computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating the state-of-the-art performance compared to recent methods for set-structured data.",2018,39,540,129,False,Computer Science,Mathematics,2108550899,Juho Lee,2110392124.0,Yoonho Lee,2629559.0,Jungtaek Kim,7497792.0,Adam R. Kosiorek,3960497.0,Seungjin Choi,1725303.0,Y. Teh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
427b168f490b56716f22b129ac93aba5425ea08f,https://www.semanticscholar.org/paper/427b168f490b56716f22b129ac93aba5425ea08f,Training linear SVMs in linear time,"Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N, while each example has only s << N non-zero features. This paper presents a Cutting Plane Algorithm for training linear SVMs that provably has training time 0(s,n) for classification problems and o(sn log (n))for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets.",2006,25,2147,338,False,Mathematics,Computer Science,1680188,T. Joachims,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f488e4a252c018f9391b0dc90036687a0b361844,https://www.semanticscholar.org/paper/f488e4a252c018f9391b0dc90036687a0b361844,Implementing Machine Learning in Radiology Practice and Research.,"OBJECTIVE The purposes of this article are to describe concepts that radiologists should understand to evaluate machine learning projects, including common algorithms, supervised as opposed to unsupervised techniques, statistical pitfalls, and data considerations for training and evaluation, and to briefly describe ethical dilemmas and legal risk.CONCLUSIONMachine learning includes a broad class of computer programs that improve with experience. The complexity of creating, training, and monitoring machine learning indicates that the success of the algorithms will require radiologist involvement for years to come, leading to engagement rather than replacement.",2017,18,186,2,False,Medicine,,145744080,M. Kohli,144477836.0,L. Prevedello,3005117.0,Ross W. Filice,144304449.0,J. R. Geis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2bc3644ce4de7fce5812c1455e056649a47c1bbf,https://www.semanticscholar.org/paper/2bc3644ce4de7fce5812c1455e056649a47c1bbf,Effective Heart Disease Prediction Using Hybrid Machine Learning Techniques,"Heart disease is one of the most significant causes of mortality in the world today. Prediction of cardiovascular disease is a critical challenge in the area of clinical data analysis. Machine learning (ML) has been shown to be effective in assisting in making decisions and predictions from the large quantity of data produced by the healthcare industry. We have also seen ML techniques being used in recent developments in different areas of the Internet of Things (IoT). Various studies give only a glimpse into predicting heart disease with ML techniques. In this paper, we propose a novel method that aims at finding significant features by applying machine learning techniques resulting in improving the accuracy in the prediction of cardiovascular disease. The prediction model is introduced with different combinations of features and several known classification techniques. We produce an enhanced performance level with an accuracy level of 88.7% through the prediction model for heart disease with the hybrid random forest with a linear model (HRFLM).",2019,46,438,26,True,Computer Science,,150302778,Senthilkumar Mohan,9727014.0,Chandrasegar Thirumalai,144369609.0,Gautam Srivastava,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31fbba3638f0d930a678d85247045ea5a1a4ec88,https://www.semanticscholar.org/paper/31fbba3638f0d930a678d85247045ea5a1a4ec88,Unsupervised Machine Learning on a Hybrid Quantum Computer,"Machine learning techniques have led to broad adoption of a statistical model of computing. The statistical distributions natively available on quantum processors are a superset of those available classically. Harnessing this attribute has the potential to accelerate or otherwise improve machine learning relative to purely classical performance. A key challenge toward that goal is learning to hybridize classical computing resources and traditional learning techniques with the emerging capabilities of general purpose quantum processors. Here, we demonstrate such hybridization by training a 19-qubit gate model processor to solve a clustering problem, a foundational challenge in unsupervised learning. We use the quantum approximate optimization algorithm in conjunction with a gradient-free Bayesian optimization to train the quantum machine. This quantum/classical hybrid algorithm shows robustness to realistic noise, and we find evidence that classical optimization can be used to train around both coherent and incoherent imperfections.",2017,41,198,9,False,Mathematics,Physics,51100085,J. Otterbach,51103214.0,R. Manenti,4099324.0,N. Alidoust,46970929.0,A. Bestwick,35692165.0,M. Block,35635287.0,B. Bloom,47759624.0,S. Caldwell,50623640.0,N. Didier,144983451.0,E. Fried,2158139650.0,S. Hong,35368333.0,Peter J. Karalekas,39704765.0,C. Osborn,50355079.0,A. Papageorge,2059365466.0,E. C. Peterson,8560581.0,G. Prawiroatmodjo,34743111.0,N. Rubin,8134599.0,C. Ryan,10731825.0,D. Scarabelli,2066443417.0,M. Scheer,4243405.0,E. A. Sete,,34588692.0,P. Sivarajah,2119026669.0,Robert S. Smith,3974460.0,A. Staley,145950540.0,N. Tezak,40068050.0,W. Zeng,2059325411.0,A. Hudson,48364846.0,Blake R. Johnson,7285332.0,M. Reagor,2107711819.0,M. Silva,3400516.0,C. Rigetti
a86171e13f84fe32212dd7fb6a1c31a34a47155f,https://www.semanticscholar.org/paper/a86171e13f84fe32212dd7fb6a1c31a34a47155f,Knowledge-based analysis of microarray gene expression data by using support vector machines.,"We introduce a method of functionally classifying genes by using gene expression data from DNA microarray hybridization experiments. The method is based on the theory of support vector machines (SVMs). SVMs are considered a supervised computer learning method because they exploit prior knowledge of gene function to identify unknown genes of similar function from expression data. SVMs avoid several problems associated with unsupervised clustering methods, such as hierarchical clustering and self-organizing maps. SVMs have many mathematical features that make them attractive for gene expression analysis, including their flexibility in choosing a similarity function, sparseness of solution when dealing with large data sets, the ability to handle large feature spaces, and the ability to identify outliers. We test several SVMs that use different similarity metrics, as well as some other supervised learning methods, and find that the SVMs best identify sets of genes with a common function using expression data. Finally, we use SVMs to predict functional roles for uncharacterized yeast ORFs based on their expression data.",2000,43,2381,83,True,Computer Science,Medicine,144379841,M. P. Brown,2361327.0,W. Grundy,2116443182.0,D. Lin,1685083.0,N. Cristianini,2070640.0,C. Sugnet,1716986.0,T. Furey,145729499.0,M. Ares,1733689.0,D. Haussler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
227e0591634cef50d0bcfc73fe6c5b34a2256e5f,https://www.semanticscholar.org/paper/227e0591634cef50d0bcfc73fe6c5b34a2256e5f,Radio Machine Learning Dataset Generation with GNU Radio,"This paper surveys emerging applications of Machine Learning (ML) to the Radio Signal Processing domain.  Provides some brief background on enabling methods and discusses some of the potential advancements for the field.  It discusses the critical importance of good datasets for model learning, testing, and evaluation and introduces several public open source synthetic datasets for various radio machine learning tasks.  These are intended to provide a robust common baselines for those working in the field and to provide a benchmark measure against which many techniques can be rapidly evaluated and compared.",2016,21,251,32,False,Engineering,,1388350203,Tim O'Shea,145028728.0,Nathan E. West,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3bc4736f9b8512043ed47357a81f26b93a1204b6,https://www.semanticscholar.org/paper/3bc4736f9b8512043ed47357a81f26b93a1204b6,Semi-supervised learning with graphs,"In traditional machine learning approaches to classification, one uses only a labeled set to train the classifier. Labeled instances however are often difficult, expensive, or time consuming to obtain, as they require the efforts of experienced human annotators. Meanwhile unlabeled data may be relatively easy to collect, but there has been few ways to use them. Semi-supervised learning addresses this problem by using large amount of unlabeled data, together with the labeled data, to build better classifiers. Because semi-supervised learning requires less human effort and gives higher accuracy, it is of great interest both in theory and in practice. 
We present a series of novel semi-supervised learning approaches arising from a graph representation, where labeled and unlabeled instances are represented as vertices, and edges encode the similarity between instances. They address the following questions: How to use unlabeled data? (label propagation); What is the probabilistic interpretation? (Gaussian fields and harmonic functions); What if we can choose labeled data? (active learning); How to construct good graphs? (hyperparameter learning); How to work with kernel machines like SVM? (graph kernels); How to handle complex data like sequences? (kernel conditional random fields); How to handle scalability and induction? (harmonic mixtures). An extensive literature review is included at the end.",2005,136,636,63,False,Computer Science,,1832364,Xiaojin Zhu,1739581.0,J. Lafferty,145903504.0,R. Rosenfeld,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cc944c3a1b51ff3112840cb147c32c14433b1279,https://www.semanticscholar.org/paper/cc944c3a1b51ff3112840cb147c32c14433b1279,Systematic Poisoning Attacks on and Defenses for Machine Learning in Healthcare,"Machine learning is being used in a wide range of application domains to discover patterns in large datasets. Increasingly, the results of machine learning drive critical decisions in applications related to healthcare and biomedicine. Such health-related applications are often sensitive, and thus, any security breach would be catastrophic. Naturally, the integrity of the results computed by machine learning is of great importance. Recent research has shown that some machine-learning algorithms can be compromised by augmenting their training datasets with malicious data, leading to a new class of attacks called poisoning attacks. Hindrance of a diagnosis may have life-threatening consequences and could cause distrust. On the other hand, not only may a false diagnosis prompt users to distrust the machine-learning algorithm and even abandon the entire system but also such a false positive classification may cause patient distress. In this paper, we present a systematic, algorithm-independent approach for mounting poisoning attacks across a wide range of machine-learning algorithms and healthcare datasets. The proposed attack procedure generates input data, which, when added to the training set, can either cause the results of machine learning to have targeted errors (e.g., increase the likelihood of classification into a specific class), or simply introduce arbitrary errors (incorrect classification). These attacks may be applied to both fixed and evolving datasets. They can be applied even when only statistics of the training dataset are available or, in some cases, even without access to the training dataset, although at a lower efficacy. We establish the effectiveness of the proposed attacks using a suite of six machine-learning algorithms and five healthcare datasets. Finally, we present countermeasures against the proposed generic attacks that are based on tracking and detecting deviations in various accuracy metrics, and benchmark their effectiveness.",2015,47,164,4,False,Computer Science,Medicine,1703366,Mehran Mozaffari Kermani,1398781979.0,S. Sur-Kolay,145291370.0,A. Raghunathan,144874163.0,N. Jha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14d0faa1e9e3e33c400176a33c657992ab332a88,https://www.semanticscholar.org/paper/14d0faa1e9e3e33c400176a33c657992ab332a88,Statistical topological data analysis using persistence landscapes,"We define a new topological summary for data that we call the persistence landscape. Since this summary lies in a vector space, it is easy to combine with tools from statistics and machine learning, in contrast to the standard topological summaries. Viewed as a random variable with values in a Banach space, this summary obeys a strong law of large numbers and a central limit theorem. We show how a number of standard statistical tests can be used for statistical inference using this summary. We also prove that this summary is stable and that it can be used to provide lower bounds for the bottleneck and Wasserstein distances.",2012,78,610,68,False,Mathematics,Computer Science,3123376,Peter Bubenik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
02adea3455cd7b09e1dac9ddf2637a1e7ae84005,https://www.semanticscholar.org/paper/02adea3455cd7b09e1dac9ddf2637a1e7ae84005,Inductive learning algorithms and representations for text categorization,"1. ABSTRACT Text categorization – the assignment of natural language texts to one or more predefined categories based on their content – is an important component in many information organization and management tasks. We compare the effectiveness of five different automatic learning algorithms for text categorization in terms of learning speed, realtime classification speed, and classification accuracy. We also examine training set size, and alternative document representations. Very accurate text classifiers can be learned automatically from training examples. Linear Support Vector Machines (SVMs) are particularly promising because they are very accurate, quick to train, and quick to evaluate. 1.1",1998,31,1400,66,True,Computer Science,,1728602,S. Dumais,144189092.0,John C. Platt,1934343.0,David Hecherman,1764547.0,M. Sahami,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a9565f70db3a6b5e4ff1df272238b8d7a84a1337,https://www.semanticscholar.org/paper/a9565f70db3a6b5e4ff1df272238b8d7a84a1337,Experience with a learning personal assistant,"Personal software assistants that help users with tasks like finding information, scheduling calendars, or managing work-flow will require significant customization to each individual user. For example, an assistant that helps schedule a particular user’s calendar will have to know that user’s scheduling preferences. This paper explores the potential of machine learning methods to automatically create and maintain such customized knowledge for personal software assistants. We describe the design of one particular learning assistant: a calendar manager, called CAP (Calendar APprentice), that learns user scheduling preferences from experience. Results are summarized from approximately five user-years of experience, during which CAP has learned an evolving set of several thousand rules that characterize the scheduling preferences of its users. Based on this experience, we suggest that machine learning methods may play an important role in future personal software assistants.",1994,25,513,28,True,Computer Science,,40975594,Tom Michael Mitchell,145727186.0,R. Caruana,1758106.0,D. Freitag,14828509.0,J. McDermott,39787642.0,David Zabowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f4387d52b5c48f386a1fa3e11d529c3a89ee0717,https://www.semanticscholar.org/paper/f4387d52b5c48f386a1fa3e11d529c3a89ee0717,Machine learning using intrinsic genomic signatures for rapid classification of novel pathogens: COVID-19 case study,"As of February 20, 2020, the 2019 novel coronavirus (renamed to COVID-19) spread to 30 countries with 2130 deaths and more than 75500 confirmed cases. COVID-19 is being compared to the infamous SARS coronavirus, which resulted, between November 2002 and July 2003, in 8098 confirmed cases worldwide with a 9.6% death rate and 774 deaths. Though COVID-19 has a death rate of 2.8% as of 20 February, the 75752 confirmed cases in a few weeks (December 8, 2019 to February 20, 2020) are alarming, with cases likely being under-reported given the comparatively longer incubation period. Such outbreaks demand elucidation of taxonomic classification and origin of the virus genomic sequence, for strategic planning, containment, and treatment. This paper identifies an intrinsic COVID-19 genomic signature and uses it together with a machine learning-based alignment-free approach for an ultra-fast, scalable, and highly accurate classification of whole COVID-19 genomes. The proposed method combines supervised machine learning with digital signal processing for genome analyses, augmented by a decision tree approach to the machine learning component, and a Spearman’s rank correlation coefficient analysis for result validation. These tools are used to analyze a large dataset of over 5000 unique viral genomic sequences, totalling 61.8 million bp. Our results support a hypothesis of a bat origin and classify COVID-19 as Sarbecovirus, within Betacoronavirus. Our method achieves high levels of classification accuracy and discovers the most relevant relationships among over 5,000 viral genomes within a few minutes, ab initio, using raw DNA sequence data alone, and without any specialized biological knowledge, training, gene or genome annotations. This suggests that, for novel viral and pathogen genome sequences, this alignment-free whole-genome machine-learning approach can provide a reliable real-time option for taxonomic classification.",2020,107,446,8,True,Biology,Medicine,66763448,Gurjit S. Randhawa,66202600.0,M. P. Soltysiak,1571741100.0,Hadi El Roz,50128573.0,Camila P. E. de Souza,31640060.0,K. Hill,144073818.0,L. Kari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94ac58d1b6132b07ef66c47af8bd506bdb67e0c3,https://www.semanticscholar.org/paper/94ac58d1b6132b07ef66c47af8bd506bdb67e0c3,Investigating statistical machine learning as a tool for software development,"As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process, (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.",2008,32,110,7,False,Computer Science,,39699737,Kayur Patel,145504534.0,J. Fogarty,9522307.0,J. Landay,40376159.0,B. Harrison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
adc7bfe0a2c140d9401ea1eae8e8935b1428ccbf,https://www.semanticscholar.org/paper/adc7bfe0a2c140d9401ea1eae8e8935b1428ccbf,Horizon Detection Using Machine Learning Techniques,"Detecting a horizon in an image is an important part of many image related applications such as detecting ships on the horizon, flight control, and port security. Most of the existing solutions for the problem only use image processing methods to identify a horizon line in an image. This results in good accuracy for many cases and is fast in computation. However, for some images with difficult environmental conditions like a foggy or cloudy sky these image processing methods are inherently inaccurate in identifying the correct horizon. This paper investigates how to detect the horizon line in a set of images using a machine learning approach. The performance of the SVM, J48, and naive Bayes classifiers, used for the problem, has been compared. Accuracy of 90-99% in identifying horizon was achieved on image data set of 20 images",2006,8,94,10,False,Computer Science,,2908158,Sergiy Fefilatyev,3237672.0,Volha Smarodzinava,25887296.0,L. Hall,1698267.0,D. Goldgof,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0dc6960a406b6040c8eb9645a89e39bf34226b3e,https://www.semanticscholar.org/paper/0dc6960a406b6040c8eb9645a89e39bf34226b3e,Biometrics from Brain Electrical Activity: A Machine Learning Approach,"The potential of brain electrical activity generated as a response to a visual stimulus is examined in the context of the identification of individuals. Specifically, a framework for the visual evoked potential (VEP)-based biometrics is established, whereby energy features of the gamma band within VEP signals were of particular interest. A rigorous analysis is conducted which unifies and extends results from our previous studies, in particular, with respect to 1) increased bandwidth, 2) spatial averaging, 3) more robust power spectrum features, and 4) improved classification accuracy. Simulation results on a large group of subject support the analysis",2007,31,247,13,False,Computer Science,Medicine,1806913,R. Palaniappan,9368519.0,D. Mandic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b87c0cf95208caacb025bf87d9ba451a87aacaca,https://www.semanticscholar.org/paper/b87c0cf95208caacb025bf87d9ba451a87aacaca,Machine Health Monitoring Using Local Feature-Based Gated Recurrent Unit Networks,"In modern industries, machine health monitoring systems (MHMS) have been applied wildly with the goal of realizing predictive maintenance including failures tracking, downtime reduction, and assets preservation. In the era of big machinery data, data-driven MHMS have achieved remarkable results in the detection of faults after the occurrence of certain failures (diagnosis) and prediction of the future working conditions and the remaining useful life (prognosis). The numerical representation for raw sensory data is the key stone for various successful MHMS. Conventional methods are the labor-extensive as they usually depend on handcrafted features, which require expert knowledge. Inspired by the success of deep learning methods that redefine representation learning from raw data, we propose local feature-based gated recurrent unit (LFGRU) networks. It is a hybrid approach that combines handcrafted feature design with automatic feature learning for machine health monitoring. First, features from windows of input time series are extracted. Then, an enhanced bidirectional GRU network is designed and applied on the generated sequence of local features to learn the representation. A supervised learning layer is finally trained to predict machine condition. Experiments on three machine health monitoring tasks: tool wear prediction, gearbox fault diagnosis, and incipient bearing fault detection verify the effectiveness and generalization of the proposed LFGRU.",2018,41,417,23,False,Computer Science,Engineering,49832912,Rui Zhao,2047932486.0,Dongzhe Wang,35374692.0,Ruqiang Yan,144067957.0,K. Mao,40592209.0,Fei Shen,49605588.0,Jinjiang Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41bebd1951e57588e7829e44fab1bac0cc9251d2,https://www.semanticscholar.org/paper/41bebd1951e57588e7829e44fab1bac0cc9251d2,Torchvision the machine-vision package of torch,"This paper presents Torchvision an open source machine vision package for Torch. Torch is a machine learning library providing a series of the state-of-the-art algorithms such as Neural Networks, Support Vector Machines, Gaussian Mixture Models, Hidden Markov Models and many others. Torchvision provides additional functionalities to manipulate and process images with standard image processing algorithms. Hence, the resulting images can be used directly with the Torch machine learning algorithms as Torchvision is fully integrated with Torch. Both Torch and Torchvision are written in C++ language and are publicly available under the Free-BSD License.",2010,3,240,29,False,Computer Science,,145607451,S. Marcel,145835170.0,Y. Rodriguez,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5389977ca9f0fa3a628a4182d0f09c8cedef2421,https://www.semanticscholar.org/paper/5389977ca9f0fa3a628a4182d0f09c8cedef2421,Learning Machines,"This book is about machines that learn to discover hidden relationships in data. A constant sfream of data bombards our senses and millions of sensory channels carry information into our brains. Brains are also learning machines that condition, combine, parse, and store data. Is it possible to learn something about learning by observing the style of computation used by brains? This is the motivation for research into computational devices that today are called ""neural networks."" Neural networks are nonlinear dynamical systems with many degrees of freedom that can be used to solve computational problems. The mathematical foundations for learning in this class of machines was laid by agroup of researchers in the 1940s and 1950s. The achievement documented in this book is the thorough study of one of the simplest members of this class, feedforward networks with one layer of m w ~ a b l e weights connecting input units to output units. In a sense, these might be called reflex machines. The knee-jerk reflex, for example, is mediated by synaptic connections from the sensory recepton in your knee directly onto rnotoneurons in your spinal cord that in turn activate leg muscles. There are limits to how much computation can be accomplished by such reflexes, and these limits have been carefully delineated in this book. Just as more complex creatures evolved by layering control loops on the primitive reflexes, network models have also evolved in recent years and now have achieved vastly greater capabilities than reflex machines by making use of multilayered architectures with feedback connections. Nonetheless, recent work could not have been accomplished without building on these foundations. vii viil INTRODUCTION INTRODUCTION ix Despite the early promise of research on neural networks, there was a period of about 20 years, from the mid 1960s to the mid 1980s. when interest in neural networks as computational devices and models of human behavior waned in favor of models based on symbol processing. There are many reasons for this, some of them now evident in this book. Still, Learning Machines was an underground classic among the neural network modelers who were active during this ""dark age"" and deserves to be better known to the generation that is ""relearning"" what was once known about statistical learning machines. The intuitive geometric explanations and the mathematical foundations in this monograph are as invaluable today as they were when it was first written. Nilsson is …",2020,87,104,3,False,Computer Science,,2815219,M. Boman,1689109.0,Magnus Sahlgren,1810096.0,Olof Görnerup,2338283.0,D. Gillblad,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1242d79573397094c5670f55e58c8333cced0beb,https://www.semanticscholar.org/paper/1242d79573397094c5670f55e58c8333cced0beb,Deep Learning: A Primer for Radiologists.,"Deep learning is a class of machine learning methods that are gaining success and attracting interest in many domains, including computer vision, speech recognition, natural language processing, and playing games. Deep learning methods produce a mapping from raw inputs to desired outputs (eg, image classes). Unlike traditional machine learning methods, which require hand-engineered feature extraction from inputs, deep learning methods learn these features directly from data. With the advent of large datasets and increased computing power, these methods can produce models with exceptional performance. These models are multilayer artificial neural networks, loosely inspired by biologic neural systems. Weighted connections between nodes (neurons) in the network are iteratively adjusted based on example pairs of inputs and target outputs by back-propagating a corrective error signal through the network. For computer vision tasks, convolutional neural networks (CNNs) have proven to be effective. Recently, several clinical applications of CNNs have been proposed and studied in radiology for classification, detection, and segmentation tasks. This article reviews the key concepts of deep learning for clinical radiologists, discusses technical requirements, describes emerging applications in clinical radiology, and outlines limitations and future directions in this field. Radiologists should become familiar with the principles and potential applications of deep learning in medical imaging. ©RSNA, 2017.",2017,28,583,14,True,Medicine,,38162399,G. Chartrand,34842677.0,P. Cheng,37627814.0,Eugene Vorontsov,3325894.0,M. Drozdzal,3622148.0,S. Turcotte,1972076.0,C. Pal,1781469.0,S. Kadoury,2080173111.0,A. Tang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0f910174d2e19101ca8f008909006e79416821fd,https://www.semanticscholar.org/paper/0f910174d2e19101ca8f008909006e79416821fd,When Edge Meets Learning: Adaptive Control for Resource-Constrained Distributed Machine Learning,"Emerging technologies and applications including Internet of Things (IoT), social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent based approaches. We analyze the convergence rate of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best trade-off between local update and global parameter aggregation to minimize the loss function under a given resource budget. The performance of the proposed algorithm is evaluated via extensive experiments with real datasets, both on a networked prototype system and in a larger-scale simulated environment. The experimentation results show that our proposed approach performs near to the optimum with various machine learning models and different data distributions.",2018,30,305,19,True,Computer Science,,50695457,Shiqiang Wang,40917131.0,Tiffany Tuor,2522394.0,Theodoros Salonidis,145353889.0,K. Leung,1702283.0,C. Makaya,145299837.0,T. He,46998035.0,K. Chan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
