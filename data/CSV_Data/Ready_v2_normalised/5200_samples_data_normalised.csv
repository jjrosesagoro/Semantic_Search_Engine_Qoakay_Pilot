paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,fieldsOfStudy/2,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name
62b6c6c7f3cd1583cec342f7483bee4d725a0cca,https://www.semanticscholar.org/paper/62b6c6c7f3cd1583cec342f7483bee4d725a0cca,LoAdaBoost: Loss-based AdaBoost federated machine learning with reduced computational complexity on IID and non-IID intensive care data,"Intensive care data are valuable for improvement of health care, policy making and many other purposes. Vast amount of such data are stored in different locations, on many different devices and in different data silos. Sharing data among different sources is a big challenge due to regulatory, operational and security reasons. One potential solution is federated machine learning, which is a method that sends machine learning algorithms simultaneously to all data sources, trains models in each source and aggregates the learned models. This strategy allows utilization of valuable data without moving them. One challenge in applying federated machine learning is the possibly different distributions of data from diverse sources. To tackle this problem, we proposed an adaptive boosting method named LoAdaBoost that increases the efficiency of federated machine learning. Using intensive care unit data from hospitals, we investigated the performance of learning in IID and non-IID data distribution scenarios, and showed that the proposed LoAdaBoost method achieved higher predictive accuracy with lower computational complexity than the baseline method.",2018,24,64,2,False,Computer Science,Medicine,2143702320,Li Huang,1640266327.0,Yifeng Yin,2068057580.0,Z. Fu,50202240.0,Shifa Zhang,2072970968.0,Hao Deng,6396156.0,Dianbo Liu,,,,,,,,,,,,,,,
7ac7b6dbcf5107c7ad0ce29161f60c2834a06795,https://www.semanticscholar.org/paper/7ac7b6dbcf5107c7ad0ce29161f60c2834a06795,Alignment for Advanced Machine Learning Systems,"We survey eight research areas organized around one question: As learning systems become increasingly intelligent and autonomous, what design principles can best ensure that their behavior is aligned with the interests of the operators? We focus on two major technical obstacles to AI alignment: the challenge of specifying the right kind of objective functions, and the challenge of designing AI systems that avoid unintended consequences and undesirable behavior even in cases where the objective function does not line up perfectly with the intentions of the designers. Open problems surveyed in this research proposal include: How can we train reinforcement learners to take actions that are more amenable to meaningful assessment by intelligent overseers? What kinds of objective functions incentivize a system to “not have an overly large impact” or “not have many side effects”? We discuss these questions, related work, and potential directions for future research, with the goal of highlighting relevant research topics in machine learning that appear tractable today.",2020,109,58,4,False,Computer Science,,144364160,Jessica Taylor,2542795.0,Eliezer Yudkowsky,2254026.0,Patrick LaVictoire,2651789.0,Andrew Critch,,,,,,,,,,,,,,,,,,,
f4f9c7a52882e46fef6bca5e4732f3ca7ddefc65,https://www.semanticscholar.org/paper/f4f9c7a52882e46fef6bca5e4732f3ca7ddefc65,"BioSeq-Analysis: a platform for DNA, RNA and protein sequence analysis based on machine learning approaches","With the avalanche of biological sequences generated in the post-genomic age, one of the most challenging problems is how to computationally analyze their structures and functions. Machine learning techniques are playing key roles in this field. Typically, predictors based on machine learning techniques contain three main steps: feature extraction, predictor construction and performance evaluation. Although several Web servers and stand-alone tools have been developed to facilitate the biological sequence analysis, they only focus on individual step. In this regard, in this study a powerful Web server called BioSeq-Analysis (http://bioinformatics.hitsz.edu.cn/BioSeq-Analysis/) has been proposed to automatically complete the three main steps for constructing a predictor. The user only needs to upload the benchmark data set. BioSeq-Analysis can generate the optimized predictor based on the benchmark data set, and the performance measures can be reported as well. Furthermore, to maximize user's convenience, its stand-alone program was also released, which can be downloaded from http://bioinformatics.hitsz.edu.cn/BioSeq-Analysis/download/, and can be directly run on Windows, Linux and UNIX. Applied to three sequence analysis tasks, experimental results showed that the predictors generated by BioSeq-Analysis even outperformed some state-of-the-art methods. It is anticipated that BioSeq-Analysis will become a useful tool for biological sequence analysis.",2019,118,226,6,False,Biology,Computer Science,47655556,Bin Liu,,,,,,,,,,,Medicine,,,,,,,,,,,,,,
01cb4071a0a43aeef63e5d568ad5afe1fb8b2411,https://www.semanticscholar.org/paper/01cb4071a0a43aeef63e5d568ad5afe1fb8b2411,Domain Separation Networks,"The cost of large scale data collection and annotation often makes the application of machine learning algorithms to new tasks or datasets prohibitively expensive. One approach circumventing this cost is training models on synthetic data where annotations are provided automatically. Despite their appeal, such models often fail to generalize from synthetic to real images, necessitating domain adaptation algorithms to manipulate these models before they can be successfully applied. Existing approaches focus either on mapping representations from one domain to the other, or on learning to extract features that are invariant to the domain from which they were extracted. However, by focusing only on creating a mapping or shared representation between the two domains, they ignore the individual characteristics of each domain. We hypothesize that explicitly modeling what is unique to each domain can improve a model's ability to extract domain-invariant features. Inspired by work on private-shared component analysis, we explicitly learn to extract image representations that are partitioned into two subspaces: one component which is private to each domain and one which is shared across domains. Our model is trained to not only perform the task we care about in the source domain, but also to use the partitioned representation to reconstruct the images from both domains. Our novel architecture results in a model that outperforms the state-of-the-art on a range of unsupervised domain adaptation scenarios and additionally produces visualizations of the private and shared representations enabling interpretation of the domain adaptation process.",2016,34,1045,122,False,Computer Science,,2732737,Konstantinos Bousmalis,2814229.0,George Trigeorgis,2286640.0,N. Silberman,1707347.0,Dilip Krishnan,1761978.0,D. Erhan,,,,,,,,,,,,,,,,,
4a83b5a3967457b4f6d55396833f43aa3d97ff81,https://www.semanticscholar.org/paper/4a83b5a3967457b4f6d55396833f43aa3d97ff81,Machine fault classification: a neural network approach,"This paper presents a neural network approach for machine fault diagnosis. Specifically, two tasks are explained and discussed: (1) a neural network-based machine fault diagnosis model is developed using the back propagation (BP) learning paradigm; (2) network training efficiency is studied by varying the learning rate and learning momentum of the activation function. The results are presented and discussed.",1992,12,56,1,False,Engineering,,4265272,G. Knapp,2464624.0,Hsu-Pin Wang,,,,,,,,,,,,,,,,,,,,,,,
6ee1181b36af21e226e4c7c6fcb82bda63c1363a,https://www.semanticscholar.org/paper/6ee1181b36af21e226e4c7c6fcb82bda63c1363a,pCAMP: Performance Comparison of Machine Learning Packages on the Edges,"Machine learning has changed the computing paradigm. Products today are built with machine intelligence as a central attribute, and consumers are beginning to expect near-human interaction with the appliances they use. However, much of the deep learning revolution has been limited to the cloud. Recently, several machine learning packages based on edge devices have been announced which aim to offload the computing to the edges. However, little research has been done to evaluate these packages on the edges, making it difficult for end users to select an appropriate pair of software and hardware. In this paper, we make a performance comparison of several state-of-the-art machine learning packages on the edges, including TensorFlow, Caffe2, MXNet, PyTorch, and TensorFlow Lite. We focus on evaluating the latency, memory footprint, and energy of these tools with two popular types of neural networks on different edge devices. This evaluation not only provides a reference to select appropriate combinations of hardware and software packages for end users but also points out possible future directions to optimize packages for developers.",2019,29,67,5,False,Computer Science,,2153648026,Xingzhou Zhang,2118420197.0,Yifan Wang,38737155.0,Weisong Shi,,,,,,,,,,,,,,,,,,,,,
33e1bbb2c76b69f7a2d64d0cf754d1cddc056be1,https://www.semanticscholar.org/paper/33e1bbb2c76b69f7a2d64d0cf754d1cddc056be1,Near-linear time approximation algorithms for optimal transport via Sinkhorn iteration,"Computing optimal transport distances such as the earth mover's distance is a fundamental problem in machine learning, statistics, and computer vision. Despite the recent introduction of several algorithms with good empirical performance, it is unknown whether general optimal transport distances can be approximated in near-linear time. This paper demonstrates that this ambitious goal is in fact achieved by Cuturi's Sinkhorn Distances. This result relies on a new analysis of Sinkhorn iteration, which also directly suggests a new greedy coordinate descent algorithm, Greenkhorn, with the same theoretical guarantees. Numerical simulations illustrate that Greenkhorn significantly outperforms the classical Sinkhorn algorithm in practice.",2017,45,402,52,False,Computer Science,Mathematics,3407979,Jason M. Altschuler,51071691.0,J. Weed,2352281.0,P. Rigollet,,,,,,,,,,,,,,,,,,,,,
bf3fd0a26f7d4c4037aa0fb7fa54e947f498bca6,https://www.semanticscholar.org/paper/bf3fd0a26f7d4c4037aa0fb7fa54e947f498bca6,Lowering the barrier to applying machine learning,"Machine learning algorithms are key components in many cutting edge applications of computation. However, the full potential of machine learning has not been realized because using machine learning is hard, even for otherwise tech-savvy developers. This is because developing with machine learning is different than normal programming. My thesis is that developers applying machine learning need new general-purpose tools that provide structure for common processes and common pipelines while remaining flexible to account for variability in problems. In this paper, I describe my efforts to understanding the difficulties that developers face when applying machine learning. I then describe Gestalt, a general-purpose integrated development environment designed the application of machine learning. Finally, I describe work on developing a pattern language for building machine learning systems and creating new techniques that help developers understand the interaction between their data and learning algorithms.",2010,122,29,3,True,Computer Science,,39699737,Kayur Patel,,,,,,,,,,,,,,,,,,,,,,,,,
61c05d7cab4448a1585596cc7e00ab271c442c2e,https://www.semanticscholar.org/paper/61c05d7cab4448a1585596cc7e00ab271c442c2e,Optimizing distributions over molecular space. An Objective-Reinforced Generative Adversarial Network for Inverse-design Chemistry (ORGANIC),"Molecular discovery seeks to generate chemical species tailored to very speciﬁc needs. In this paper, we present ORGANIC , a framework based on Objective-Reinforced Generative Adversarial Networks (ORGAN), capable of producing a distribution over molecular space that matches with a certain set of desirable metrics. This methodology combines two successful techniques from the machine learning community: a Generative Adversarial Network (GAN), to create non-repetitive sensible molecular species, and Reinforcement Learning (RL), to bias this generative distribution towards certain attributes. We explore several applications, from optimization of random physicochemical properties to candidates for drug discovery and organic photovoltaic material design.",2017,48,193,6,False,Mathematics,,1380248978,Benjamín Sánchez-Lengeling,51112526.0,C. Outeiral,2176123442.0,GL Guimaraes,1380248954.0,Alán Aspuru-Guzik,,,,,,,,,,,,,,,,,,,
063b4fcf59444df073144675ac2c5fe1a63c233a,https://www.semanticscholar.org/paper/063b4fcf59444df073144675ac2c5fe1a63c233a,Extraction Patterns for Information Extraction Tasks : A Survey,"Information Extraction systems rely on a set of extraction patternsthat they use in order to retrieve from each document the relevant information. In this paper we survey the various types of extraction patterns that are generated by machine learning algorithms. We identify three main categories of patterns, which cover a variety of application domains, and we compare and contrast the patterns from each category.",1999,16,178,7,False,,,123035064,K. Minton,,,,,,,,,,,,,,,,,,,,,,,,,
5145a5c8fb950ff52d3ad991d9c1d9886d726451,https://www.semanticscholar.org/paper/5145a5c8fb950ff52d3ad991d9c1d9886d726451,On the Prospects for a (Deep) Learning Health Care System,"In 1976, Maxmen1 predicted that artificial intelligence (AI) in the 21st century would usher in “the postphysician era,” with health care provided by paramedics and computers. Today, the mass extinction of physicians remains unlikely. However, as outlined by Hinton2 in a related Viewpoint, the emergence of a radically different approach to AI, called deep learning, has the potential to effect major changes in clinical medicine and health care delivery. This Viewpoint reviews some of the factors driving wide adoption of deep learning and other forms of machine learning in the health ecosystem.",2018,19,140,4,False,Medicine,,144625283,C. Naylor,,,,,,,,,,,,,,,,,,,,,,,,,
eea2d27488e5ee098c62f85274a294c4c1993543,https://www.semanticscholar.org/paper/eea2d27488e5ee098c62f85274a294c4c1993543,Curious machines: active learning with structured instances,"Supervised machine learning is a branch of artificial intelligence concerned with automatically inducing predictive models from labeled data. Such learning approaches are useful for many interesting real-world applications, but particularly shine for tasks involving the automatic organization, extraction, and retrieval of information from large collections of data (e.g., text, images, and other digital media). In traditional supervised learning, one uses ""labeled"" training data to induce a model. However, labeled instances for real-world applications are often difficult, expensive, or time consuming to obtain. Consider a complex task such as extracting key person and organization names from text documents. While gathering large amounts of unlabeled documents for these tasks is often relatively easy (e.g., from the World Wide Web), labeling these texts usually requires experienced human annotators with specific domain knowledge and training. There are implicit costs associated with obtaining these labels from domain experts, such as limited time and financial resources. This is especially true for applications that involve learning from instances with complex structures, which can require labels at varying levels of granularity. Active learning addresses this inherent bottleneck by allowing the learner to selectively choose which parts of the available data are labeled for training. The goal is to maximize the accuracy of the learner through such ""queries,"" while minimizing the work required of human annotators. In this thesis, I explore several important questions regarding active learning for these and similar tasks involving structured instances. What query strategies are available for these learning algorithms, and how do they compare? How might a learner pose queries at different levels of granularity, as with multiple-instance learning? Are there relationships between certain properties of a query and its difficulty for the annotator? If so, can these relationships be learned and exploited during active learning? The answers to the questions illustrate the utility and promise of active learning algorithms in complex real-world learning systems.",2008,157,52,5,False,Computer Science,,144557047,M. Craven,1717452.0,Burr Settles,,,,,,,,,,,,,,,,,,,,,,,
570948aca9ba058da1a42d7dc7101326092d8be1,https://www.semanticscholar.org/paper/570948aca9ba058da1a42d7dc7101326092d8be1,A learning interface agent for scheduling meetings,"This paper describes a Learning Interface Agent for a meeting scheduling application. The agent employs Machine Learning techniques to customize itself to the user’s personal scheduling rules and preferences by observing the user’s actions and receiving direct userfeedback. Our approach provides the user with sophisticated control over the gradual delegation of scheduling tasks to the agent, as a trust relationship is built. We report upon an experiment in which a collection of such assistants became gradually more helpful to their users through the use of memory-based and reinforcement learning. The experimental data reported upon demonstrate that the learning approach to building intelligent interface agents is a very promising one which has several advantages over more standard approaches.",1993,12,192,8,False,Computer Science,,2683445,Robyn Kozierok,1701876.0,P. Maes,,,,,,,,,,,,,,,,,,,,,,,
e9a8de5f88f3807ffff97355c9f0c5dc7031fc7a,https://www.semanticscholar.org/paper/e9a8de5f88f3807ffff97355c9f0c5dc7031fc7a,Learning Graphs From Data: A Signal Representation Perspective,"The construction of a meaningful graph topology plays a crucial role in the effective representation, processing, analysis, and visualization of structured data. When a natural choice of the graph is not readily available from the data sets, it is thus desirable to infer or learn a graph topology from the data. In this article, we survey solutions to the problem of graph learning, including classical viewpoints from statistics and physics, and more recent approaches that adopt a graph signal processing (GSP) perspective. We further emphasize the conceptual similarities and differences between classical and GSP-based graph-inference methods and highlight the potential advantage of the latter in a number of theoretical and practical scenarios. We conclude with several open issues and challenges that are keys to the design of future signal processing and machine-learning algorithms for learning graphs from data.",2018,108,236,13,True,Mathematics,Computer Science,145392527,Xiaowen Dong,3333045.0,D. Thanou,1747902.0,M. Rabbat,1703189.0,P. Frossard,,,,,,,,,,,,,,,,,,,
6c1309a5cb147856f785253d99424685cf5c12fc,https://www.semanticscholar.org/paper/6c1309a5cb147856f785253d99424685cf5c12fc,Reinforcement learning for true adaptive traffic signal control,"The ability to exert real-time, adaptive control of transportation processes is the core of many intelligent transportation systems decision support tools. Reinforcement learning, an artificial intelligence approach undergoing development in the machine- learning community, offers key advantages in this regard. The ability of a control agent to learn relationships between control actions and their effect on the environment while pursuing a goal is a distinct improvement over prespecified models of the environment. Prespecified models are a prerequisite of conventional control methods and their accuracy limits the performance of control agents. This paper contains an introduction to Q-learning, a simple yet powerful reinforcement learning algorithm, and presents a case study involving application to traffic signal control. Encouraging results of the application to an isolated traffic signal, particularly under variable traffic conditions, are presented. A broader research effort is outlined, including extension to linear and networked signal systems and integration with dynamic route guidance. The research objective involves optimal control of heavily congested traffic across a two-dimensional road network—a challenging task for conventional traffic signal control methodologies.",2003,26,408,19,False,Engineering,,1770243,B. Abdulhai,98155768.0,R. Pringle,69037486.0,G. J. Karakoulas,,,,,,,,,,,,,,,,,,,,,
e46429c5522d6a598b1f3e6c29a87fbeaf118538,https://www.semanticscholar.org/paper/e46429c5522d6a598b1f3e6c29a87fbeaf118538,Machine Learning Based DDoS Attack Detection from Source Side in Cloud,"Denial of service (DOS) attacks are a serious threat to network security. These attacks are often sourced from virtual machines in the cloud, rather than from the attacker's own machine, to achieve anonymity and higher network bandwidth. Past research focused on analyzing traffic on the destination (victim's) side with predefined thresholds. These approaches have significant disadvantages. They are only passive defenses after the attack, they cannot use the outbound statistical features of attacks, and it is hard to trace back to the attacker with these approaches. In this paper, we propose a DOS attack detection system on the source side in the cloud, based on machine learning techniques. This system leverages statistical information from both the cloud server's hypervisor and the virtual machines, to prevent network packages from being sent out to the outside network. We evaluate nine machine learning algorithms and carefully compare their performance. Our experimental results show that more than 99.7% of four kinds of DOS attacks are successfully detected. Our approach does not degrade performance and can be easily extended to broader DOS attacks.",2017,16,95,10,False,Computer Science,,21145493,Zecheng He,2146331573.0,Tianwei Zhang,144220460.0,R. Lee,,,,,,,,,,,,,,,,,,,,,
c1eea18c70325f1ae381b3efa7d6dc50c649c69c,https://www.semanticscholar.org/paper/c1eea18c70325f1ae381b3efa7d6dc50c649c69c,Intelligent Parkinson Disease Prediction Using Machine Learning Algorithms,"Diagnosis of the Parkinson disease through machine learning approache provides better understanding from PD dataset in the present decade. Orange v2.0b and weka v3.4.10 has been used in the present experimentation for the statistical analysis, classification, Evaluation and unsupervised learning methods. Voice dataset for Parkinson disease has been retrieved from UCI Machine learning repository from Center for Machine Learning and Intelligent Systems. The dataset contains name, MDVP:Fo(Hz), MDVP:Fhi(Hz), MDVP:Flo(Hz), MDVP:Jitter(%), MDVP: Jitter(Abs), MDVP:RAP, MDVP:PPQ, Jitter:DDP, MDVP:Shimmer, MDVP:Shimmer(dB), Shimmer:APQ3, Shimmer:APQ5, MDVP:APQ, Shimmer:DDA, NHR, HNR, status, RPDE, DFA, spread1, spread2, D2, PPE attributes. The parallel coordinates shows higher variation in Parkinson disease dataset. SVM has shown good accuracy (88.9%) compared to Majority and k-NN algorithms. Classification algorithm like Random Forest has shown good accuracy (90.26) and Naive Bayes has shown least accuracy (69.23. Higher number of clusters in healthy dataset in Fo and less number in diseased data has been predicted by Hierarchal clustering and SOM.",2013,15,54,2,False,Computer Science,,2151493349,M. Rao,9293181.0,G. V. L. Narayana,144350988.0,D. Kaladhar,145014843.0,T. Vital,,,,,,,,,,,,,,,,,,,
66773ecea49a061fd5dd6561e0e36afa8cae54ba,https://www.semanticscholar.org/paper/66773ecea49a061fd5dd6561e0e36afa8cae54ba,Security analysis of online centroid anomaly detection,"Security issues are crucial in a number of machine learning applications, especially in scenarios dealing with human activity rather than natural phenomena (e.g., information ranking, spam detection, malware detection, etc.). In such cases, learning algorithms may have to cope with manipulated data aimed at hampering decision making. Although some previous work addressed the issue of handling malicious data in the context of supervised learning, very little is known about the behavior of anomaly detection methods in such scenarios. In this contribution, we analyze the performance of a particular method--online centroid anomaly detection--in the presence of adversarial noise. Our analysis addresses the following security-related issues: formalization of learning and attack processes, derivation of an optimal attack, and analysis of attack efficiency and limitations. We derive bounds on the effectiveness of a poisoning attack against centroid anomaly detection under different conditions: attacker's full or limited control over the traffic and bounded false positive rate. Our bounds show that whereas a poisoning attack can be effectively staged in the unconstrained case, it can be made arbitrarily difficult (a strict upper bound on the attacker's gain) if external constraints are properly used. Our experimental evaluation, carried out on real traces of HTTP and exploit traffic, confirms the tightness of our theoretical bounds and the practicality of our protection mechanisms.",2010,69,96,5,False,Mathematics,Computer Science,2749512,M. Kloft,1754215.0,P. Laskov,,,,,,,,,,,,,,,,,,,,,,,
cec81c1acbc36503108337a74d845008d5e68f70,https://www.semanticscholar.org/paper/cec81c1acbc36503108337a74d845008d5e68f70,Machine Learning for Prediction in Electronic Health Data.,"Machine learning for prediction in electronic health data has been deployed for many clinical questions during the last decade. Machine learning methods may excel at finding new features or nonlinear relationships in the data, as well as handling settings with more predictor variables than observations. However, the usefulness of both these data and machine learning has varied. Electronic health data often have quality issues (eg, missingness, misclassification, measurement error), and machine learning may perform similarly to standard techniques for some research questions. Ensembles (running multiple algorithms and either selecting the single best algorithm or creating a weighted average) can help mitigate the latter concern. Using several machine learning tools, Wong et al1 predicted delirium risk for newly hospitalized patients with high-dimensional electronic health record data at a large academic health institution. They compared these approaches with a questionnaire-based scoring system and found improved performance for machine learning with respect to several metrics calculated in a single holdout sample. Their article is a step toward updating delirium risk prediction. It also provides an opportunity to discuss 2 key issues in the current state of machine learning for prediction in electronic health data: evaluation and generalizability. The machine learning researchers who develop novel algorithms for prediction and the clinical teams interested in implementing them are frequently and unfortunately 2 nonintersecting groups. Thus, these algorithms may originally be built and evaluated in the machine learning literature based on metrics that are less clinically useful than other choices. Computer scientists and statisticians may optimize to achieve the best area under the receiver operating characteristic curve (AUC), but what a clinical team might need is high sensitivity or positive predictive value. Worse yet, algorithms can have misleading performance when evaluated only along 1 or 2 dimensions. For example, high AUC, accuracy, and positive predictive values can be accompanied by near-zero levels of sensitivity and specificity. It can also be essential to calculate metrics like the percentage of true cases in the top risk percentile.2 This is especially important when a goal of the tool is to target high-risk patients for interventions. Wong and colleagues1 helpfully compute AUC, positive predictive values, sensitivity, and specificity. However, one accepted standard for evaluation that should be adopted in future clinical machine learning applications is K-fold cross-validation (eg, with K = 10) rather than the single holdout validation sample in their article. K-fold cross-validation involves K successive mutually exclusive validation sets where the algorithm fitting is iteratively performed on the nonvalidation data (ie, training set). At the end, each observation in the full data has a predicted value that was obtained from when it was part of a validation set. Typically, metrics calculated based on these K-fold cross-validated predicted values will more effectively assess overfitting and have lower variance.3 Of course, assessing the generalizability of a prediction algorithm goes well beyond using crossvalidated metrics to evaluate overfitting. Wong et al1 carefully discussed a number of limitations in their work, including the lack of external validation in other health systems. As in similar studies, the step from good performance in the study to a generalizable algorithm is vast and sometimes may not be feasible. Patients receiving treatment in varied care settings or geographic regions simply may require tailored tools. Recognizing the need for unique tools in different populations is not inherently negative, but one of many considerations not magically solved by using machine learning. Even those algorithms that prove to be generalizable may quickly become outdated as treatment patterns or physician incentives to code health conditions change.4 Increased social tolerance for certain + Related article",2018,11,54,1,True,Computer Science,Medicine,48345067,Sherri Rose,,,,,,,,,,,,,,,,,,,,,,,,,
cedea36fa3692281b3ac767335fe49a16d00957d,https://www.semanticscholar.org/paper/cedea36fa3692281b3ac767335fe49a16d00957d,Structural Topic Models for Open‐Ended Survey Responses,"Collection and especially analysis of open-ended survey responses are relatively rare in the discipline and when conducted are almost exclusively done through human coding. We present an alternative, semiautomated approach, the structural topic model (STM) (Roberts, Stewart, and Airoldi 2013; Roberts et al. 2013), that draws on recent developments in machine learning based analysis of textual data. A crucial contribution of the method is that it incorporates information about the document, such as the author's gender, political affiliation, and treatment assignment (if an experimental study). This article focuses on how the STM is helpful for survey researchers and experimentalists. The STM makes analyzing open-ended responses easier, more revealing, and capable of being used to estimate treatment effects. We illustrate these innovations with analysis of text from surveys and experiments.",2014,71,920,111,True,Computer Science,,2464550,Margaret E. Roberts,28924497.0,Brandon M Stewart,3252940.0,D. Tingley,2061550766.0,Christopher Lucas,1403360325.0,Jetson Leder-Luis,13901928.0,S. Gadarian,,50483051.0,B. Albertson,2157480.0,David G. Rand,,,,,,,,,,
0d482366a508c33346bf8af10736d10a31233dfc,https://www.semanticscholar.org/paper/0d482366a508c33346bf8af10736d10a31233dfc,Fault Detection in Wireless Sensor Networks Through SVM Classifier,"Wireless sensor networks (WSNs) are prone to many failures such as hardware failures, software failures, and communication failures. The fault detection in WSNs is a challenging problem due to sensor resources limitation and the variety of deployment field. Furthermore, the detection has to be precise to avoid negative alerts, and rapid to limit loss. The use of machine learning seems to be one of the most convenient solutions for detecting failure in WSNs. In this paper, support vector machines (SVMs) classification method is used for this purpose. Based on statistical learning theory, SVM is used in our context to define a decision function. As a light process in term of required resources, this decision function can be easily executed at cluster heads to detect anomalous sensor. The effectiveness of SVM for fault detection in WSNs is shown through an experimental study, comparing it to latest for the same application.",2018,26,153,16,False,Computer Science,,2522993,S. Zidi,2099267.0,T. Moulahi,2894526.0,B. Alaya,,,,,,,,,,,,,,,,,,,,,
eb3caabde41ce45f895b60e59ef88d66eeaf9711,https://www.semanticscholar.org/paper/eb3caabde41ce45f895b60e59ef88d66eeaf9711,A Contextual Bandit Bake-off,"Contextual bandit algorithms are essential for solving many real-world interactive machine learning problems. Despite multiple recent successes on statistically and computationally efficient methods, the practical behavior of these algorithms is still poorly understood. We leverage the availability of large numbers of supervised learning datasets to compare and empirically optimize contextual bandit algorithms, focusing on practical methods that learn by relying on optimization oracles from supervised learning. We find that a recent method (Foster et al., 2018) using optimism under uncertainty works the best overall. A surprisingly close second is a simple greedy baseline that only explores implicitly through the diversity of contexts, followed by a variant of Online Cover (Agarwal et al., 2014) which tends to be more conservative but robust to problem specification by design. Along the way, we also evaluate and improve several internal components of contextual bandit algorithm design. Overall, this is a thorough study and review of contextual bandit methodology.",2018,39,65,14,False,Computer Science,Mathematics,2269602,A. Bietti,40333747.0,Alekh Agarwal,144162125.0,J. Langford,,,,,,,,,,,,,,,,,,,,,
6c44f8e62d824bcda4f291c679a5518bbd4225f6,https://www.semanticscholar.org/paper/6c44f8e62d824bcda4f291c679a5518bbd4225f6,Adversarial Attacks on Neural Networks for Graph Data,"Deep learning models for graphs have achieved strong performance for the task of node classification. Despite their proliferation, currently there is no study of their robustness to adversarial attacks. Yet, in domains where they are likely to be used, e.g. the web, adversaries are common. Can deep learning models for graphs be easily fooled? In this work, we introduce the first study of adversarial attacks on attributed graphs, specifically focusing on models exploiting ideas of graph convolutions. In addition to attacks at test time, we tackle the more challenging class of poisoning/causative attacks, which focus on the training phase of a machine learning model.We generate adversarial perturbations targeting the node's features and the graph structure, thus, taking the dependencies between instances in account. Moreover, we ensure that the perturbations remain unnoticeable by preserving important data characteristics. To cope with the underlying discrete domain we propose an efficient algorithm Nettack exploiting incremental computations. Our experimental study shows that accuracy of node classification significantly drops even when performing only few perturbations. Even more, our attacks are transferable: the learned attacks generalize to other state-of-the-art node classification models and unsupervised approaches, and likewise are successful even when only limited knowledge about the graph is given.",2018,65,574,131,True,Computer Science,Mathematics,3156540,Daniel Zügner,46256784.0,Amir Akbarnejad,3075189.0,Stephan Günnemann,,,,,,,,,,,,,,,,,,,,,
187110ea2bb38456b73fc50399bd7ce5f622702a,https://www.semanticscholar.org/paper/187110ea2bb38456b73fc50399bd7ce5f622702a,Discriminative Least Squares Regression for Multiclass Classification and Feature Selection,"This paper presents a framework of discriminative least squares regression (LSR) for multiclass classification and feature selection. The core idea is to enlarge the distance between different classes under the conceptual framework of LSR. First, a technique called ε-dragging is introduced to force the regression targets of different classes moving along opposite directions such that the distances between classes can be enlarged. Then, the ε-draggings are integrated into the LSR model for multiclass classification. Our learning framework, referred to as discriminative LSR, has a compact model form, where there is no need to train two-class machines that are independent of each other. With its compact form, this model can be naturally extended for feature selection. This goal is achieved in terms of L2,1 norm of matrix, generating a sparse learning model for feature selection. The model for multiclass classification and its extension for feature selection are finally solved elegantly and efficiently. Experimental evaluation over a range of benchmark datasets indicates the validity of our method.",2012,66,310,47,False,Mathematics,Medicine,1683738,Shiming Xiang,144962210.0,F. Nie,3182192.0,Gaofeng Meng,144809241.0,Chunhong Pan,14966740.0,Changshui Zhang,,,Computer Science,,,,,,,,,,,,,,
deb5b5b7cbc6e542b4334854be9efcd9d360b784,https://www.semanticscholar.org/paper/deb5b5b7cbc6e542b4334854be9efcd9d360b784,The Berlin Brain-Computer Interface: Accurate performance from first-session in BCI-naive subjects,"The Berlin brain-computer interface (BBCI) project develops a noninvasive BCI system whose key features are: 1) the use of well-established motor competences as control paradigms; 2) high-dimensional features from multichannel EEG; and 3) advanced machine-learning techniques. Spatio-spectral changes of sensorimotor rhythms are used to discriminate imagined movements (left hand, right hand, and foot). A previous feedback study [M. Krauledat, K.-R. Muller, and G. Curio. (2007) The non-invasive Berlin brain-computer Interface: Fast acquisition of effective performance in untrained subjects. NeuroImage. [Online]. 37(2), pp. 539--550. Available: http://dx.doi.org/10.1016/j.neuroimage.2007.01.051] with ten subjects provided preliminary evidence that the BBCI system can be operated at high accuracy for subjects with less than five prior BCI exposures. Here, we demonstrate in a group of 14 fully BCI-naive subjects that 8 out of 14 BCI novices can perform at >84% accuracy in their very first BCI session, and a further four subjects at >70%. Thus, 12 out of 14 BCI-novices had significant above-chance level performances without any subject training even in the first session, as based on an optimized EEG analysis by advanced machine-learning algorithms.",2008,72,313,10,False,Computer Science,Medicine,3156886,B. Blankertz,46733761.0,F. Losch,1831901.0,M. Krauledat,2115772.0,G. Dornhege,3073253.0,G. Curio,145034054.0,K. Müller,,,,,,,,,,,,,,,
79a8674b05b045b459cf6eeba3b4687da1878fcd,https://www.semanticscholar.org/paper/79a8674b05b045b459cf6eeba3b4687da1878fcd,Risk-Aware Machine Learning Classifier for Skin Lesion Diagnosis,"Knowing when a machine learning system is not confident about its prediction is crucial in medical domains where safety is critical. Ideally, a machine learning algorithm should make a prediction only when it is highly certain about its competency, and refer the case to physicians otherwise. In this paper, we investigate how Bayesian deep learning can improve the performance of the machine–physician team in the skin lesion classification task. We used the publicly available HAM10000 dataset, which includes samples from seven common skin lesion categories: Melanoma (MEL), Melanocytic Nevi (NV), Basal Cell Carcinoma (BCC), Actinic Keratoses and Intraepithelial Carcinoma (AKIEC), Benign Keratosis (BKL), Dermatofibroma (DF), and Vascular (VASC) lesions. Our experimental results show that Bayesian deep networks can boost the diagnostic performance of the standard DenseNet-169 model from 81.35% to 83.59% without incurring additional parameters or heavy computation. More importantly, a hybrid physician–machine workflow reaches a classification accuracy of 90% while only referring 35% of the cases to physicians. The findings are expected to generalize to other medical diagnosis applications. We believe that the availability of risk-aware machine learning methods will enable a wider adoption of machine learning technology in clinical settings.",2019,77,49,5,True,Medicine,,27588412,Aryan Mobiny,2109435489.0,Aditi Singh,151497174.0,Hien Van Nguyen,,,,,,,,,,,,,,,,,,,,,
e9256e49151f5ff23e2ac25fcd11f2dfe25729c2,https://www.semanticscholar.org/paper/e9256e49151f5ff23e2ac25fcd11f2dfe25729c2,Machine Learning in Proof General: Interfacing Interfaces,"We present ML4PG - a machine learning extension for Proof General. It allows users to gather proof statistics related to shapes of goals, sequences of applied tactics, and proof tree structures from the libraries of interactive higher-order proofs written in Coq and SSReflect. The gathered data is clustered using the state-of-the-art machine learning algorithms available in MATLAB and Weka. ML4PG provides automated interfacing between Proof General and MATLAB/Weka. The results of clustering are used by ML4PG to provide proof hints in the process of interactive proof development.",2012,61,54,2,True,Computer Science,,2875686,E. Komendantskaya,1751150.0,J. Heras,1687679.0,G. Grov,,,,,,,,,,,,,,,,,,,,,
b0742e0cd29d318761bc7918a4f05399b7d67e19,https://www.semanticscholar.org/paper/b0742e0cd29d318761bc7918a4f05399b7d67e19,Machine-learning-based hotspot detection using topological classification and critical feature extraction,"Because of the widening sub-wavelength lithography gap in advanced fabrication technology, lithography hotspot detection has become an essential task in design for manufacturability. Current state-of-the-art works unite pattern matching and machine learning engines. Unlike them, we fully exploit the strengths of machine learning using novel techniques. By combing topological classification and critical feature extraction, our hotspot detection framework achieves very high accuracy. Furthermore, to speed up the evaluation, we verify only possible layout clips instead of full-layout scanning. After detection, we filter hotspots to reduce the false alarm. Experimental results show that the proposed framework is very accurate and demonstrates a rapid training convergence. Moreover, our framework outperforms the 2012 CAD Contest at ICCAD winner on accuracy and false alarm.",2013,27,110,11,False,Computer Science,Engineering,2116068526,Yen-Ting Yu,2809872.0,Geng-He Lin,1717610.0,I. Jiang,144434073.0,C. Chiang,,,,,,,,,,,,,,,,,,,
904af59cff4712c84c57439bb9c481eb4b22cbea,https://www.semanticscholar.org/paper/904af59cff4712c84c57439bb9c481eb4b22cbea,Algorithmic Inference in Machine Learning,"This book can be succinctly characterized as a coherent and comprehensive treatise of the fundamentals, algorithms, and practice of machine learning. Being more specific, the authors have focused on various inference paradigms developed within a framework of the computational learning theory. The content in the book, as stated by authors, encompasses ideas, experience and experiments developed throughout the life of the Laboratory for Neural Networks, University of Milan, Milan, Italy. The volume is structured into five chapters. The first one titled “Knowledge versus randomness” addresses an important and practically relevant question of relationships between these two concepts and demonstrates how probabilistic models help capture and quantify randomness. Most of this chapter serves as a solid prerequisite to the rest of the book by covering the fundamentals of calculus of random variables. The next chapter focuses on mechanisms of algorithmic inferences realized in the statistical setting. The reader finds here ideas of sufficient statistics, confidence intervals, adequacy of sample size, point estimators, and issues of entropy. The first two chapters naturally form the introductory part of the book as dealing with the foundations of the subject. The second part is about the applications of machine learning and consists of three comprehensive chapters: on computational learning theory, regression theory, and subsymbolic learning. This combination very much reflects the main directions of the key developments encountered in machine learning. Chapter 3 is devoted to computational learning and includes its core concepts. Learning Boolean functions along with their well known probably approximately correct (PAC) principle occupies a prominent position in the theory and the same becomes true in this chapter. A lot of attention is paid to computing the hypotheses, confidence intervals for learning errors, high level abstraction and learnability. The chapter on regression theory (Chapter 4) is quite extensive and includes aspects of linear and nonlinear regression, PAC learning of regression functions, point estimators and confidence intervals. When looking at neural networks (the subject covered in a number of sections of the book), it is worth stressing that this material is nicely cast in the framework of the general learning theory. I would say this is a quite inspiring environment that is both useful and appealing to newcomers to the area of neurocomputing as well as those very much versatile in learning algorithms of neural networks. Neural networks dominate a chapter on subsymbolic learning (Chapter 5 of the book). Here the authors cover a generic taxonomy of the networks, elaborate on various learning strategies (cast in the setting of machine learning) and tackle the subject of learning without supervision (self associative memories and self-organizing memories/maps). Some of the topics that deliver another look at neural networks concern networks and data compression (the compression relates to the idea of Kolgomorov complexity), sufficient statistics, and stochastic facets of learning mechanisms. A comprehensive, well-organized and carefully compiled bibliography is an asset of the book; one can find here entries to classic texts in statistics, probability, learning theory, fuzzy sets, granular computing, and neural networks. The book is equipped with sidebars highlighting",2005,0,38,0,False,Computer Science,,1685367,B. Apolloni,2374535.0,D. Malchiodi,2089200.0,S. Gaito,,,,,,,,,,,,,,,,,,,,,
c5209f8559c97800ae06451cd34c14506c20ec23,https://www.semanticscholar.org/paper/c5209f8559c97800ae06451cd34c14506c20ec23,Structured Recurrent Temporal Restricted Boltzmann Machines,"The recurrent temporal restricted Boltzmann machine (RTRBM) is a probabilistic time-series model. The topology of the RTRBM graphical model, however, assumes full connectivity between all the pairs of visible units and hidden units, thereby ignoring the dependency structure within the observations. Learning this structure has the potential for not only improving the prediction performance, but also revealing important dependency patterns in the data. For example, given a meteorological dataset, we could identify regional weather patterns. In this work, we propose a new class of RTRBM, which we refer to as the structured RTRBM (SRTRBM), which explicitly uses a graph to model the dependency structure. Our technique is related to methods such as graphical lasso, which are used to learn the topology of Gaussian graphical models. We also develop a spike-and-slab version of the RTRBM, and combine it with the SRTRBM to learn dependency structures in datasets with real-valued observations. Our experimental results using synthetic and real datasets demonstrate that the SRTRBM can significantly improve the prediction performance of the RTRBM, particularly when the number of visible units is large and the size of the training set is small. It also reveals the dependency structures underlying our benchmark datasets.",2014,27,68,9,False,Computer Science,,1785530,Roni Mittelman,145585296.0,B. Kuipers,1702137.0,S. Savarese,1697141.0,Honglak Lee,,,,,,,,,,,,,,,,,,,
72db4f5be89655b13e943f60566e65ae4d437344,https://www.semanticscholar.org/paper/72db4f5be89655b13e943f60566e65ae4d437344,Learning-based imaging through scattering media.,"We present a machine-learning-based method for single-shot imaging through scattering media. The inverse scattering process was calculated based on a nonlinear regression algorithm by learning a number of training object-speckle pairs. In the experimental demonstration, multilayer phase objects between scattering plates were reconstructed from intensity measurements. Our approach enables model-free sensing, where it is not necessary to know the sensing processes/models.",2016,14,133,2,False,Physics,Medicine,3614205,R. Horisaki,2065889114.0,Ryosuke Takagi,2063601.0,J. Tanida,,,,,,,,,,,,,,,,,,,,,
0e02f64d1b71a9b89f62e23f4672902ec4740f06,https://www.semanticscholar.org/paper/0e02f64d1b71a9b89f62e23f4672902ec4740f06,Cyberbullying Detection with Weakly Supervised Machine Learning,"Detrimental online behavior such as harassment and cyberbullying is becoming a serious, large-scale problem damaging people’s lives. This phenomenon is creating a need for automated, data-driven techniques for analyzing and detecting such behaviors. We propose a machine learning method for simultaneously inferring user roles in harassment-based bullying and new vocabulary indicators of bullying. The learning algorithm considers social structure and infers which users tend to bully and which tend to be victimized. To address the elusive nature of cyberbullying, the learning algorithm only requires weak supervision. Experts provide a small seed vocabulary of bullying indicators, and the algorithm uses a large, unlabeled corpus of social media interactions to extract bullying roles of users and additional vocabulary indicators of bullying. The model estimates whether each social interaction is bullying based on who participates and based on what language is used, and it tries to maximize the agreement between these estimates, i.e., participant-vocabulary consistency (PVC). We evaluate PVC on three social media data sets, demonstrating quantitatively and qualitatively its effectiveness in cyberbullying detection.",2017,49,59,3,False,Computer Science,,3422165,Elaheh Raisi,40486307.0,Bert Huang,,,,,,,,,,,,,,,,,,,,,,,
7cbe4b20e36b97ab51b04224f4261db0ad51291e,https://www.semanticscholar.org/paper/7cbe4b20e36b97ab51b04224f4261db0ad51291e,Machine perception and learning of complex social systems,"The study of complex social systems has traditionally been an arduous process, involving extensive surveys, interviews, ethnographic studies, or analysis of online behavior. Today, however, it is possible to use the unprecedented amount of information generated by pervasive mobile phones to provide insights into the dynamics of both individual and group behavior. Information such as continuous proximity, location, communication and activity data, has been gathered from the phones of 100 human subjects at MIT. Systematic measurements from these 100 people over the course of eight months have generated one of the largest datasets of continuous human behavior ever collected, representing over 300,000 hours of daily activity. In this thesis we describe how this data can be used to uncover regular rules and structure in behavior of both individuals and organizations, infer relationships between subjects, verify selfreport survey data, and study social network dynamics. By combining theoretical models with rich and systematic measurements, we show it is possible to gain insight into the underlying behavior of complex social systems. Thesis Supervisor: Alex P. Pentland Title: Toshiba Professor of Media Arts and Sciences, MIT.",2005,120,137,8,False,Computer Science,,2724608,N. Eagle,,,,,,,,,,,,,,,,,,,,,,,,,
90c4ddaa3cbee82896d58af2351f66e3dddd9fdc,https://www.semanticscholar.org/paper/90c4ddaa3cbee82896d58af2351f66e3dddd9fdc,Fairwashing: the risk of rationalization,"Black-box explanation is the problem of explaining how a machine learning model -- whose internal logic is hidden to the auditor and generally complex -- produces its outcomes. Current approaches for solving this problem include model explanation, outcome explanation as well as model inspection. While these techniques can be beneficial by providing interpretability, they can be used in a negative manner to perform fairwashing, which we define as promoting the false perception that a machine learning model respects some ethical values. In particular, we demonstrate that it is possible to systematically rationalize decisions taken by an unfair black-box model using the model explanation as well as the outcome explanation approaches with a given fairness metric. Our solution, LaundryML, is based on a regularized rule list enumeration algorithm whose objective is to search for fair rule lists approximating an unfair black-box model. We empirically evaluate our rationalization technique on black-box models trained on real-world datasets and show that one can obtain rule lists with high fidelity to the black-box model while being considerably less unfair at the same time.",2019,40,79,1,False,Computer Science,Mathematics,40907220,U. Aïvodji,2987344.0,Hiromi Arai,79379858.0,O. Fortineau,1777382.0,S. Gambs,50006358.0,Satoshi Hara,1909393.0,A. Tapp,,,,,,,,,,,,,,,
20438e2a38a0c4723fbd9de50b44b7335f6f43cb,https://www.semanticscholar.org/paper/20438e2a38a0c4723fbd9de50b44b7335f6f43cb,ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning,"Incorporating second-order curvature information into machine learning optimization algorithms can be subtle, and doing so naïvely can lead to high per-iteration costs associated with forming the Hessian and performing the associated linear system solve. To address this, we introduce ADAHESSIAN, a new stochastic optimization algorithm. ADAHESSIAN directly incorporates approximate curvature information from the loss function, and it includes several novel performance-improving features, including: (i) a fast Hutchinson based method to approximate the curvature matrix with low computational overhead; (ii) a spatial averaging to reduce the variance of the second derivative; and (iii) a root-mean-square exponential moving average to smooth out variations of the second-derivative across different iterations. We perform extensive tests on NLP, CV, and recommendation system tasks, and ADAHESSIAN achieves state-of-the-art results. In particular, we find that ADAHESSIAN: (i) outperforms AdamW for transformers by0.13/0.33 BLEU score on IWSLT14/WMT14, 2.7/1.0 PPLon PTB/Wikitext-103; (ii) outperforms AdamW for Squeeze-Bert by 0.41 points on GLUE; (iii) achieves 1.45%/5.55%higher accuracy on ResNet32/ResNet18 on Cifar10/ImageNetas compared to Adam; and (iv) achieves 0.032% better score than Adagrad for DLRM on the Criteo Ad Kaggle dataset. The cost per iteration of ADAHESSIANis comparable to first-order methods, and ADAHESSIAN exhibits improved robustness towards variations in hyperparameter values. The code for ADAHESSIAN is open-sourced and publicly-available [1].",2020,80,96,24,True,Computer Science,Mathematics,9088433,Z. Yao,10419477.0,A. Gholami,2191455.0,Sheng Shen,1732330.0,K. Keutzer,1717098.0,M. Mahoney,,,,,,,,,,,,,,,,,
bac1f98a14b9bf687de3b9bb9592ed049fa93bfe,https://www.semanticscholar.org/paper/bac1f98a14b9bf687de3b9bb9592ed049fa93bfe,A Shared Vision for Machine Learning in Neuroscience,"With ever-increasing advancements in technology, neuroscientists are able to collect data in greater volumes and with finer resolution. The bottleneck in understanding how the brain works is consequently shifting away from the amount and type of data we can collect and toward what we actually do with the data. There has been a growing interest in leveraging this vast volume of data across levels of analysis, measurement techniques, and experimental paradigms to gain more insight into brain function. Such efforts are visible at an international scale, with the emergence of big data neuroscience initiatives, such as the BRAIN initiative (Bargmann et al., 2014), the Human Brain Project, the Human Connectome Project, and the National Institute of Mental Health's Research Domain Criteria initiative. With these large-scale projects, much thought has been given to data-sharing across groups (Poldrack and Gorgolewski, 2014; Sejnowski et al., 2014); however, even with such data-sharing initiatives, funding mechanisms, and infrastructure, there still exists the challenge of how to cohesively integrate all the data. At multiple stages and levels of neuroscience investigation, machine learning holds great promise as an addition to the arsenal of analysis tools for discovering how the brain works.",2018,51,100,2,True,Computer Science,Medicine,144470981,Mai-Anh T. Vu,144353151.0,T. Adalı,137243233.0,Demba E. Ba,144128278.0,G. Buzsáki,144752689.0,David Edwin Carlson,145993598.0,K. Heller,,145624793.0,C. Liston,48395540.0,C. Rudin,1757668.0,V. Sohal,2179271.0,A. Widge,2245080.0,H. Mayberg,1699339.0,G. Sapiro,2470448.0,K. Dzirasa
77e71aed1d8827ea65367933503ce24d6fbfb4ae,https://www.semanticscholar.org/paper/77e71aed1d8827ea65367933503ce24d6fbfb4ae,Efficient Continuous Pareto Exploration in Multi-Task Learning,"Tasks in multi-task learning often correlate, conflict, or even compete with each other. As a result, a single solution that is optimal for all tasks rarely exists. Recent papers introduced the concept of Pareto optimality to this field and directly cast multi-task learning as multi-objective optimization problems, but solutions returned by existing methods are typically finite, sparse, and discrete. We present a novel, efficient method that generates locally continuous Pareto sets and Pareto fronts, which opens up the possibility of continuous analysis of Pareto optimal solutions in machine learning problems. We scale up theoretical results in multi-objective optimization to modern machine learning problems by proposing a sample-based sparse linear system, for which standard Hessian-free solvers in machine learning can be applied. We compare our method to the state-of-the-art algorithms and demonstrate its usage of analyzing local Pareto sets on various multi-task classification and regression problems. The experimental results confirm that our algorithm reveals the primary directions in local Pareto sets for trade-off balancing, finds more solutions with different trade-offs efficiently, and scales well to tasks with millions of parameters.",2020,15,33,6,False,Computer Science,Mathematics,12558026,Pingchuan Ma,2056897446.0,Tao Du,1752521.0,W. Matusik,,,,,,,,,,,,,,,,,,,,,
1509dde6c6142f1d95bcc4e9f99dec8ae5b51158,https://www.semanticscholar.org/paper/1509dde6c6142f1d95bcc4e9f99dec8ae5b51158,Fake News Detection Using Machine Learning Ensemble Methods,"The advent of the World Wide Web and the rapid adoption of social media platforms (such as Facebook and Twitter) paved the way for information dissemination that has never been witnessed in the human history before. With the current usage of social media platforms, consumers are creating and sharing more information than ever before, some of which are misleading with no relevance to reality. Automated classification of a text article as misinformation or disinformation is a challenging task. Even an expert in a particular domain has to explore multiple aspects before giving a verdict on the truthfulness of an article. In this work, we propose to use machine learning ensemble approach for automated classification of news articles. Our study explores different textual properties that can be used to distinguish fake contents from real. By using those properties, we train a combination of different machine learning algorithms using various ensemble methods and evaluate their performance on 4 real world datasets. Experimental evaluation confirms the superior performance of our proposed ensemble learner approach in comparison to individual learners.",2020,38,92,8,True,Computer Science,,2074278563,Iftikhar Ahmad,2134570398.0,M. Yousaf,16524525.0,S. Yousaf,2110092715.0,Muhammad Ovais Ahmad,,,,,,,,,,,,,,,,,,,
42787ed26cf50555ce7405d1cd1891ab3faeacdc,https://www.semanticscholar.org/paper/42787ed26cf50555ce7405d1cd1891ab3faeacdc,Machine learning or discrete choice models for car ownership demand estimation and prediction?,"Discrete choice models are widely used to explain transportation behaviors, including a household's decision to own a car. They show how some distinct choice of human behavior or preference influences a decision. They are also used to project future demand estimates to support policy exploration. This latter use for prediction is indirectly aligned with and conditional to the model's estimation which aims to fit the observed data. In contrast, machine learning models are derived to maximize prediction accuracy through mechanisms such as out-of-sample validation, non-linear structure, and automated covariate selection, albeit at the expense of interpretability and sound behavioral theory. We investigate how machine learning models can outperform discrete choice models for prediction of car ownership using transportation household survey data from Singapore. We compare our household car ownership model (multinomial logit model) against various machine learning models (e.g. Random Forest, Support Vector Machines) by using 2008 data to derive, i.e. estimate models that we then use to predict 2012 ownership. The machine learning models are inferior to the discrete choice model when using discrete choice features. However, after engineering features more appropriate for machine learning they are superior. These results highlight both the cost of applying machine learning models in econometric contexts and an opportunity for improved prediction and better urban policy making through machine learning models with appropriate features.",2017,13,39,3,False,Engineering,Computer Science,144081101,Miguel Paredes,1807219.0,Erik Hemberg,1398192342.0,Una-May O’Reilly,97735715.0,C. Zegras,,,,,,,,,,,,,,,,,,,
2ac0d8e7b2099933fe4f56a63abf981c0269cbce,https://www.semanticscholar.org/paper/2ac0d8e7b2099933fe4f56a63abf981c0269cbce,Structural Machine Learning with Galois Lattice and Graphs,"This paper defines a formal approach to learning from examples described by labelled graphs. We propose a formal model based upon lattice theory and in particular with the use of Galois lattice. We enlarge the domain of formal concept analysis, by the use of the Galois lattice model with structural description of examples and concepts. Our implementation, called ""Graal"" (for GRAph And Learning) constructs a Galois lattice for any description language provided that the two operations of comparison and generalization are determined for that language. We prove that these operations exist in the case of labelled graphs.",1998,40,105,3,False,Computer Science,,1721628,M. Liquiere,1733472.0,J. Sallantin,,,,,,,,,,,,,,,,,,,,,,,
78e95099ec2ac3cb087eb47ba7c87ddb01a19405,https://www.semanticscholar.org/paper/78e95099ec2ac3cb087eb47ba7c87ddb01a19405,On the Error of Random Fourier Features,"Kernel methods give powerful, flexible, and theoretically grounded approaches to solving many problems in machine learning. The standard approach, however, requires pairwise evaluations of a kernel function, which can lead to scalability issues for very large datasets. Rahimi and Recht (2007) suggested a popular approach to handling this problem, known as random Fourier features. The quality of this approximation, however, is not well understood. We improve the uniform error bound of that paper, as well as giving novel understandings of the embedding's variance, approximation error, and use in some machine learning methods. We also point out that surprisingly, of the two main variants of those features, the more widely used is strictly higher-variance for the Gaussian kernel and has worse bounds.",2015,33,148,15,False,Computer Science,Mathematics,36326783,Danica J. Sutherland,1753432.0,J. Schneider,,,,,,,,,,,,,,,,,,,,,,,
6df11b0bb0244d4d36e8955436067cc5d19734fa,https://www.semanticscholar.org/paper/6df11b0bb0244d4d36e8955436067cc5d19734fa,Evaluating the Visualization of What a Deep Neural Network Has Learned,"Deep neural networks (DNNs) have demonstrated impressive performance in complex machine learning tasks such as image classification or speech recognition. However, due to their multilayer nonlinear structure, they are not transparent, i.e., it is hard to grasp what makes them arrive at a particular classification or recognition decision, given a new unseen data sample. Recently, several approaches have been proposed enabling one to understand and interpret the reasoning embodied in a DNN for a single test image. These methods quantify the “importance” of individual pixels with respect to the classification decision and allow a visualization in terms of a heatmap in pixel/input space. While the usefulness of heatmaps can be judged subjectively by a human, an objective quality measure is missing. In this paper, we present a general methodology based on region perturbation for evaluating ordered collections of pixels such as heatmaps. We compare heatmaps computed by three different methods on the SUN397, ILSVRC2012, and MIT Places data sets. Our main result is that the recently proposed layer-wise relevance propagation algorithm qualitatively and quantitatively provides a better explanation of what made a DNN arrive at a particular classification decision than the sensitivity-based approach or the deconvolution method. We provide theoretical arguments to explain this result and discuss its practical implications. Finally, we investigate the use of heatmaps for unsupervised assessment of the neural network performance.",2015,47,774,72,True,Medicine,Computer Science,1699054,W. Samek,49345823.0,Alexander Binder,144535526.0,G. Montavon,3633358.0,S. Lapuschkin,145034054.0,K. Müller,,,,,,,,,,,,,,,,,
73e1644ad4aab9e11c1e46eea513141c4930602d,https://www.semanticscholar.org/paper/73e1644ad4aab9e11c1e46eea513141c4930602d,A Literature Survey on Domain Adaptation of Statistical Classifiers,"The domain adaptation problem, especially domain adaptation in natural language processing, started gaining much attention very recently [Daumé III and Marcu, 2006, Blitzer et al., 2006, Ben-David et al., 2007, Daumé III, 2007, Satpal and Sarawagi, 2007]. However, some special kinds of domain adaptation problems have been studied before under different names such as class imbalance [Japkowicz and Stephen, 2002], covariate shift [Shimodaira, 2000], and sample selection bias [Heckman, 1979]. There are also some well-studied machine learning problems that are closely related but not equivalent to domain adaptation, including multi-task learning [Caruana, 1997] and semi-supervised learning [Chapelle et al., 2006]. In this literature survey, we review existing work in both the machine learning and the natural language processing communities related to domain adaptation. Because this relatively new topic is constantly attracting attention, our survey is necessarily incomplete. Nevertheless, we try to cover the major lines of work that we are aware of up to the date this survey is written. This survey will also be constantly updated. The goal of this literature survey is twofold. First, existing studies on domain adaptation seem very different from each other, and different terms are used to refer to the problem. There has not been any survey that connects these different studies. This survey thus tries to organize the existing work in a systematic way and draw a big picture of the domain adaptation problem with its possible solutions. Second, a systematic literature survey shows the limitations of current work and points out promising directions that should be explored.",2007,40,257,13,False,Computer Science,,143610475,James J. Jiang,,,,,,,,,,,,,,,,,,,,,,,,,
e54414dca2e8bc0da410db0b7d08fee4651d2357,https://www.semanticscholar.org/paper/e54414dca2e8bc0da410db0b7d08fee4651d2357,SageDB: A Learned Database System,"Modern data processing systems are designed to be general purpose, in that they can handle a wide variety of different schemas, data types, and data distributions, and aim to provide efficient access to that data via the use of optimizers and cost models. This general purpose nature results in systems that do not take advantage of the characteristics of the particular application and data of the user. With SageDB we present a vision towards a new type of a data processing system, one which highly specializes to an application through code synthesis and machine learning. By modeling the data distribution, workload, and hardware, SageDB learns the structure of the data and optimal access methods and query plans. These learned models are deeply embedded, through code synthesis, in essentially every component of the database. As such, SageDB presents radical departure from the way database systems are currently developed, raising a host of new problems in databases, machine learning and programming systems.",2019,38,146,13,False,Computer Science,,1746961,Tim Kraska,79404966.0,M. Alizadeh,2638246.0,Alex Beutel,2226805.0,Ed H. Chi,66851124.0,Ani Kristo,39224358.0,Guillaume Leclerc,,144478906.0,S. Madden,2512621.0,Hongzi Mao,2335477.0,Vikram Nathan,,,,,,,,
de017ec1ab6a2fafb6cf9665c5d2d3efd27f142e,https://www.semanticscholar.org/paper/de017ec1ab6a2fafb6cf9665c5d2d3efd27f142e,The upside of uncertainty: Identification of lithology contact zones from airborne geophysics and satellite data using random forests and support vector machines,"ABSTRACTInductive machine learning algorithms attempt to recognize patterns in, and generalize from empirical data. They provide a practical means of predicting lithology, or other spatially varying physical features, from multidimensional geophysical data sets. It is for this reason machine learning approaches are increasing in popularity for geophysical data inference. A key motivation for their use is the ease with which uncertainty measures can be estimated for nonprobabilistic algorithms. We have compared and evaluated the abilities of two nonprobabilistic machine learning algorithms, random forests (RF) and support vector machines (SVM), to recognize ambiguous supervised classification predictions using uncertainty calculated from estimates of class membership probabilities. We formulated a method to establish optimal uncertainty threshold values to identify and isolate the maximum number of incorrect predictions while preserving most of the correct classifications. This is illustrated using a case ...",2013,80,64,2,False,Computer Science,,1840787,M. Cracknell,36882569.0,A. Reading,,,,,,,,,,,,,,,,,,,,,,,
345796dd6038042697749cef024464ffa4df62a8,https://www.semanticscholar.org/paper/345796dd6038042697749cef024464ffa4df62a8,"Machine Learning for E-mail Spam Filtering: Review, Techniques and Trends","We present a comprehensive review of the most effective content-based e-mail spam filtering techniques. We focus primarily on Machine Learning-based spam filters and their variants, and report on a broad review ranging from surveying the relevant ideas, efforts, effectiveness, and the current progress. The initial exposition of the background examines the basics of e-mail spam filtering, the evolving nature of spam, spammers playing cat-and-mouse with e-mail service providers (ESPs), and the Machine Learning front in fighting spam. We conclude by measuring the impact of Machine Learning-based filters and explore the promising offshoots of latest developments.",2016,145,49,6,False,Computer Science,Mathematics,2785110,Alexy Bhowmick,2350548.0,S. Hazarika,,,,,,,,,,,,,,,,,,,,,,,
290c735c8e3e2ffe896d80ea379e48b8177a7f39,https://www.semanticscholar.org/paper/290c735c8e3e2ffe896d80ea379e48b8177a7f39,Hybrid Parallelization Strategies for Large-Scale Machine Learning in SystemML,"SystemML aims at declarative, large-scale machine learning (ML) on top of MapReduce, where high-level ML scripts with R-like syntax are compiled to programs of MR jobs. The declarative specification of ML algorithms enables---in contrast to existing large-scale machine learning libraries---automatic optimization. SystemML's primary focus is on data parallelism but many ML algorithms inherently exhibit opportunities for task parallelism as well. A major challenge is how to efficiently combine both types of parallelism for arbitrary ML scripts and workloads. In this paper, we present a systematic approach for combining task and data parallelism for large-scale machine learning on top of MapReduce. We employ a generic Parallel FOR construct (ParFOR) as known from high performance computing (HPC). Our core contributions are (1) complementary parallelization strategies for exploiting multi-core and cluster parallelism, as well as (2) a novel cost-based optimization framework for automatically creating optimal parallel execution plans. Experiments on a variety of use cases showed that this achieves both efficiency and scalability due to automatic adaptation to ad-hoc workloads and unknown data characteristics.",2014,37,91,9,True,Computer Science,,40237241,Matthias Boehm,1947100.0,S. Tatikonda,1698945.0,B. Reinwald,40655309.0,P. Sen,1968180.0,Yuanyuan Tian,143894459.0,D. Burdick,,2066721.0,Shivakumar Vaithyanathan,,,,,,,,,,,,
859d506f4ff9301acfd66651437039073727187e,https://www.semanticscholar.org/paper/859d506f4ff9301acfd66651437039073727187e,Automatic programming of binary morphological machines by design of statistically optimal operators in the context of computational learning theory,"Representation of set operators by artificial neural networks and design of such operators by inference of network parameters is a popular technique in binary image analysis. We propose an alternative to this technique: automatic programming of morphological machines (MMachs) by the design of statistically optimal operators. We propose a formulation of the procedure for designing set operators that extends the one stated by Dougherty for binary image restoration, show the relation of this new formulation with the one stated by Haussler for learning Boolean concepts in the context of machine learning theory (which usually is applied to neural networks), present a new learning algorithm for Boolean concepts represented as MMach programs, and give some application examples in binary image analysis.",1997,21,97,1,False,Computer Science,,144487267,J. Barrera,1693776.0,E. Dougherty,2647831.0,N. Hirata,,,,,,,,,,,,,,,,,,,,,
060c4de5ded208663478914ea33ba1809a2fa7e9,https://www.semanticscholar.org/paper/060c4de5ded208663478914ea33ba1809a2fa7e9,Machine learning for architectural design: Practices and infrastructure,"In this article, we propose that new architectural design practices might be based on machine learning approaches to better leverage data-rich environments and workflows. Through reference to recent architectural research, we describe how the application of machine learning can occur throughout the design and fabrication process, to develop varied relations between design, performance and learning. The impact of machine learning on architectural practices with performance-based design and fabrication is assessed in two cases by the authors. We then summarise what we perceive as current limits to a more widespread application and conclude by providing an outlook and direction for future research for machine learning in architectural design practice.",2018,12,36,2,False,Computer Science,,3030356,M. Tamke,95301942.0,P. Nicholas,153138616.0,Mateusz Zwierzycki,,,,,,,,,,,,,,,,,,,,,
cc76f1a128f64f9e7e2d4aa653569e0d1a0d6504,https://www.semanticscholar.org/paper/cc76f1a128f64f9e7e2d4aa653569e0d1a0d6504,Machine Learning for Predicting Outcomes in Trauma,"ABSTRACT To date, there are no reviews on machine learning (ML) for predicting outcomes in trauma. Consequently, it remains unclear as to how ML-based prediction models compare in the triage and assessment of trauma patients. The objective of this review was to survey and identify studies involving ML for predicting outcomes in trauma, with the hypothesis that models predicting similar outcomes may share common features but the performance of ML in these studies will differ greatly. MEDLINE and other databases were searched for studies involving trauma and ML. Sixty-five observational studies involving ML for the prediction of trauma outcomes met inclusion criteria. In total 2,433,180 patients were included in the studies. The studies focused on prediction of the following outcome measures: survival/mortality (n = 34), morbidity/shock/hemorrhage (n = 12), hospital length of stay (n = 7), hospital admission/triage (n = 6), traumatic brain injury (n = 4), life-saving interventions (n = 5), post-traumatic stress disorder (n = 4), and transfusion (n = 1). Six studies were prospective observational studies. Of the 65 studies, 33 used artificial neural networks for prediction. Importantly, most studies demonstrated the benefits of ML models. However, algorithm performance was assessed differently by different authors. Sensitivity-specificity gap values varied greatly from 0.035 to 0.927. Notably, studies shared many features for model development. A common ML feature base may be determined for predicting outcomes in trauma. However, the impact of ML will require further validation in prospective observational studies and randomized clinical trials, establishment of common performance criteria, and high-quality evidence about clinical and economic impacts before ML can be widely accepted in practice.",2017,79,62,0,False,Medicine,,2359238,Nehemiah T. Liu,145848239.0,J. Salinas,,,,,,,,,,,,,,,,,,,,,,,
bd4cf5a6987ef0f39b7e4e88d59b3a3365abcc70,https://www.semanticscholar.org/paper/bd4cf5a6987ef0f39b7e4e88d59b3a3365abcc70,The relationship between trust in AI and trustworthy machine learning technologies,"To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.",2019,100,102,3,True,Computer Science,,2405396,Ehsan Toreini,47301404.0,M. Aitken,3133152.0,Kovila P. L. Coopamootoo,48519378.0,Karen Elliott,146452648.0,Carlos Vladimiro Gonzalez Zelaya,9072212.0,A. Moorsel,,,,,,,,,,,,,,,
7da7d5fac66b1b699cee2a681c83db3d564e54dc,https://www.semanticscholar.org/paper/7da7d5fac66b1b699cee2a681c83db3d564e54dc,Genomic Prediction of Breeding Values Using a Subset of SNPs Identified by Three Machine Learning Methods,"The analysis of large genomic data is hampered by issues such as a small number of observations and a large number of predictive variables (commonly known as “large P small N”), high dimensionality or highly correlated data structures. Machine learning methods are renowned for dealing with these problems. To date machine learning methods have been applied in Genome-Wide Association Studies for identification of candidate genes, epistasis detection, gene network pathway analyses and genomic prediction of phenotypic values. However, the utility of two machine learning methods, Gradient Boosting Machine (GBM) and Extreme Gradient Boosting Method (XgBoost), in identifying a subset of SNP makers for genomic prediction of breeding values has never been explored before. In this study, using 38,082 SNP markers and body weight phenotypes from 2,093 Brahman cattle (1,097 bulls as a discovery population and 996 cows as a validation population), we examined the efficiency of three machine learning methods, namely Random Forests (RF), GBM and XgBoost, in (a) the identification of top 400, 1,000, and 3,000 ranked SNPs; (b) using the subsets of SNPs to construct genomic relationship matrices (GRMs) for the estimation of genomic breeding values (GEBVs). For comparison purposes, we also calculated the GEBVs from (1) 400, 1,000, and 3,000 SNPs that were randomly selected and evenly spaced across the genome, and (2) from all the SNPs. We found that RF and especially GBM are efficient methods in identifying a subset of SNPs with direct links to candidate genes affecting the growth trait. In comparison to the estimate of prediction accuracy of GEBVs from using all SNPs (0.43), the 3,000 top SNPs identified by RF (0.42) and GBM (0.46) had similar values to those of the whole SNP panel. The performance of the subsets of SNPs from RF and GBM was substantially better than that of evenly spaced subsets across the genome (0.18–0.29). Of the three methods, RF and GBM consistently outperformed the XgBoost in genomic prediction accuracy.",2018,96,79,5,True,Medicine,Biology,2165243599,Bo Li,8388007.0,Nanxi Zhang,87041990.0,You‐Gan Wang,2057470473.0,A. George,1884674.0,A. Reverter,2027086158.0,Yutao Li,,,,,,,,,,,,,,,
5d819d0949692635e73368f8879a3b2ab0462974,https://www.semanticscholar.org/paper/5d819d0949692635e73368f8879a3b2ab0462974,"Comprehensive survey of deep learning in remote sensing: theories, tools, and challenges for the community","Abstract. In recent years, deep learning (DL), a rebranding of neural networks (NNs), has risen to the top in numerous areas, namely computer vision (CV), speech recognition, and natural language processing. Whereas remote sensing (RS) possesses a number of unique challenges, primarily related to sensors and applications, inevitably RS draws from many of the same theories as CV, e.g., statistics, fusion, and machine learning, to name a few. This means that the RS community should not only be aware of advancements such as DL, but also be leading researchers in this area. Herein, we provide the most comprehensive survey of state-of-the-art RS DL research. We also review recent new developments in the DL field that can be used in DL for RS. Namely, we focus on theories, tools, and challenges for the RS community. Specifically, we focus on unsolved challenges and opportunities as they relate to (i) inadequate data sets, (ii) human-understandable solutions for modeling physical phenomena, (iii) big data, (iv) nontraditional heterogeneous data sources, (v) DL architectures and learning algorithms for spectral, spatial, and temporal data, (vi) transfer learning, (vii) an improved theoretical understanding of DL systems, (viii) high barriers to entry, and (ix) training and optimizing the DL.",2017,417,390,14,True,Computer Science,Engineering,145672842,J. Ball,152900419.0,Derek T. Anderson,2863960.0,Chee Seng Chan,,,,,,,,,,,,,,,,,,,,,
820e6cb426966329827ddcad567e844b6b5ca91d,https://www.semanticscholar.org/paper/820e6cb426966329827ddcad567e844b6b5ca91d,Automatic classification of two‐dimensional gel electrophoresis pictures by heuristic clustering analysis: A step toward machine learning,"The interpretation of two‐dimensional gel electrophoresis (2‐DGE) profiles can be facilitated by artificial intelligence and machine learning programs. We have incorporated into our 2‐DGE computer analysis system (termed MELANIE‐Medical Electrophoresis Analysis Interactive Expert system) a program which automatically classifies 2‐DGE patterns using heuristic clustering analysis. This program is a step toward machine learning. In this publication, we describe the classification method and the preliminary results obtained with liver biopsy electrophoretograms. Heuristic clustering is also compared to other classification techniques.",1988,7,78,0,False,Chemistry,Medicine,2990689,R. Appel,2788244.0,D. Hochstrasser,1388341580.0,C. Roch,2011603.0,M. Funk,1947126727.0,A. Muller,69006985.0,C. Pellegrini,,,,,,,,,,,,,,,
198c08b8d7fba77458cb6484268528e975727d8b,https://www.semanticscholar.org/paper/198c08b8d7fba77458cb6484268528e975727d8b,Machine learning application in MOOCs: Dropout prediction,"Massive Open Online Course(MOOC) is undergoing explosive growth recently, both the number of MOOC platforms and courses are increasing dramatically during these years. One of the major concerns in MOOC is high dropout rate, we study dropout prediction in MOOCs, using student's learning activities data in a period of time to measure how likely students would drop out in next couple of days. We collect 39 courses data from XuetangX platform, which is based on the open source Edx platform. Using supervised classification approach in the machine learning field, we achieve 89% accuracy in dropout prediction task with gradient boosting decision tree model. We describe details in drop out prediction framework, including data extraction from Edx platform, data preprocessing, feature engineering and performance test on several supervised classification models.",2016,10,59,5,False,Computer Science,,2118675149,Jiajun Liang,2151086786.0,Chao Li,2149971996.0,Li Zheng,,,,,,,,,,,,,,,,,,,,,
a100b4b380aab33d7b1f41a738151328862dff7f,https://www.semanticscholar.org/paper/a100b4b380aab33d7b1f41a738151328862dff7f,New Algorithms for Learning Incoherent and Overcomplete Dictionaries,"In sparse recovery we are given a matrix $A$ (the dictionary) and a vector of the form $A X$ where $X$ is sparse, and the goal is to recover $X$. This is a central notion in signal processing, statistics and machine learning. But in applications such as sparse coding, edge detection, compression and super resolution, the dictionary $A$ is unknown and has to be learned from random examples of the form $Y = AX$ where $X$ is drawn from an appropriate distribution --- this is the dictionary learning problem. In most settings, $A$ is overcomplete: it has more columns than rows. This paper presents a polynomial-time algorithm for learning overcomplete dictionaries; the only previously known algorithm with provable guarantees is the recent work of Spielman, Wang and Wright who gave an algorithm for the full-rank case, which is rarely the case in applications. Our algorithm applies to incoherent dictionaries which have been a central object of study since they were introduced in seminal work of Donoho and Huo. In particular, a dictionary is $\mu$-incoherent if each pair of columns has inner product at most $\mu / \sqrt{n}$. The algorithm makes natural stochastic assumptions about the unknown sparse vector $X$, which can contain $k \leq c \min(\sqrt{n}/\mu \log n, m^{1/2 -\eta})$ non-zero entries (for any $\eta > 0$). This is close to the best $k$ allowable by the best sparse recovery algorithms even if one knows the dictionary $A$ exactly. Moreover, both the running time and sample complexity depend on $\log 1/\epsilon$, where $\epsilon$ is the target accuracy, and so our algorithms converge very quickly to the true dictionary. Our algorithm can also tolerate substantial amounts of noise provided it is incoherent with respect to the dictionary (e.g., Gaussian). In the noisy setting, our running time and sample complexity depend polynomially on $1/\epsilon$, and this is necessary.",2013,63,200,21,False,Computer Science,Mathematics,145563465,Sanjeev Arora,144804200.0,Rong Ge,1690962.0,Ankur Moitra,,,,,,,,,,,,,,,,,,,,,
d80f949ebb04760fdff4bcb35180a48268324512,https://www.semanticscholar.org/paper/d80f949ebb04760fdff4bcb35180a48268324512,Object-Based Image Classification of Summer Crops with Machine Learning Methods,"The strategic management of agricultural lands involves crop field monitoring each year. Crop discrimination via remote sensing is a complex task, especially if different crops have a similar spectral response and cropping pattern. In such cases, crop identification could be improved by combining object-based image analysis and advanced machine learning methods. In this investigation, we evaluated the C4.5 decision tree, logistic regression (LR), support vector machine (SVM) and multilayer perceptron (MLP) neural network methods, both as single classifiers and combined in a hierarchical classification, for the mapping of nine major summer crops (both woody and herbaceous) from ASTER satellite images captured in two different dates. Each method was built with different combinations of spectral and textural features obtained after the segmentation of the remote images in an object-based framework. As single classifiers, MLP and SVM obtained maximum overall accuracy of 88%, slightly higher than LR (86%) and notably higher than C4.5 (79%). The SVM+SVM classifier (best method) improved these results to 89%. In most cases, the hierarchical classifiers considerably increased the accuracy of the most poorly classified class (minimum sensitivity). The SVM+SVM method offered a significant improvement in classification accuracy for all of the studied crops compared to the conventional decision tree classifier, ranging between 4% for safflower and 29% for corn, which suggests the application of object-based image analysis and advanced machine learning methods in complex crop classification tasks.",2014,57,137,4,True,Computer Science,,145147081,J. Peña,1740647.0,Pedro Antonio Gutiérrez,1388386495.0,C. Hervás‐Martínez,145345598.0,J. Six,32189810.0,R. Plant,1396985901.0,F. López-Granados,,,,,,,,,,,,,,,
b205a8a4063dbd5815ead1be17e6ffcfd2c48a6d,https://www.semanticscholar.org/paper/b205a8a4063dbd5815ead1be17e6ffcfd2c48a6d,A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle,"As machine learning (ML) increasingly affects people and society, awareness of its potential unwanted consequences has also grown. To anticipate, prevent, and mitigate undesirable downstream consequences, it is critical that we understand when and how harm might be introduced throughout the ML life cycle. In this paper, we provide a framework that identifies seven distinct potential sources of downstream harm in machine learning, spanning data collection, development, and deployment. In doing so, we aim to facilitate more productive and precise communication around these issues, as well as more direct, application-grounded ways to mitigate them.",2019,48,77,8,True,Computer Science,Mathematics,46537606,Harini Suresh,1724429.0,J. Guttag,,,,,,,,,,,,,,,,,,,,,,,
a03472a07ac2ef5b5b03358d074d2891c8fba144,https://www.semanticscholar.org/paper/a03472a07ac2ef5b5b03358d074d2891c8fba144,Learning Reward Machines for Partially Observable Reinforcement Learning,"Reward Machines (RMs), originally proposed for specifying problems in Reinforcement Learning (RL), provide a structured, automata-based representation of a reward function that allows an agent to decompose problems into subproblems that can be efficiently learned using off-policy learning. Here we show that RMs can be learned from experience, instead of being specified by the user, and that the resulting problem decomposition can be used to effectively solve partially observable RL problems. We pose the task of learning RMs as a discrete optimization problem where the objective is to find an RM that decomposes the problem into a set of subproblems such that the combination of their optimal memoryless policies is an optimal policy for the original problem. We show the effectiveness of this approach on three partially observable domains, where it significantly outperforms A3C, PPO, and ACER, and discuss its advantages, limitations, and broader potential.",2019,46,61,11,False,Computer Science,,15316342,Rodrigo Toro Icarte,1396422950.0,Ethan Waldie,1758085.0,Toryn Q. Klassen,2682734.0,R. Valenzano,41036745.0,Margarita P. Castro,1683896.0,Sheila A. McIlraith,,,,,,,,,,,,,,,
598123f88874d17b1f82c5da64ff855649d7787d,https://www.semanticscholar.org/paper/598123f88874d17b1f82c5da64ff855649d7787d,CNN-based image analysis for malaria diagnosis,"Malaria is a major global health threat. The standard way of diagnosing malaria is by visually examining blood smears for parasite-infected red blood cells under the microscope by qualified technicians. This method is inefficient and the diagnosis depends on the experience and the knowledge of the person doing the examination. Automatic image recognition technologies based on machine learning have been applied to malaria blood smears for diagnosis before. However, the practical performance has not been sufficient so far. This study proposes a new and robust machine learning model based on a convolutional neural network (CNN) to automatically classify single cells in thin blood smears on standard microscope slides as either infected or uninfected. In a ten-fold cross-validation based on 27,578 single cell images, the average accuracy of our new 16-layer CNN model is 97.37%. A transfer learning model only achieves 91.99% on the same images. The CNN model shows superiority over the transfer learning model in all performance indicators such as sensitivity (96.99% vs 89.00%), specificity (97.75% vs 94.98%), precision (97.73% vs 95.12%), F1 score (97.36% vs 90.24%), and Matthews correlation coefficient (94.75% vs 85.25%).",2016,24,161,6,False,Computer Science,,145203716,Zhaohui Liang,2053159893.0,Andrew Powell,2874897.0,I. Ersoy,1919030.0,M. Poostchi,34763478.0,K. Silamut,1921638.0,K. Palaniappan,,2075394111.0,Peng Guo,47412240.0,M. A. Hossain,1721328.0,Sameer Kiran Antani,3444718.0,R. Maude,6743849.0,Xiangji Huang,144230620.0,Stefan Jaeger,145116486.0,G. Thoma
3b9d6390ca28e742013e3b6b493d03d8d635bf7e,https://www.semanticscholar.org/paper/3b9d6390ca28e742013e3b6b493d03d8d635bf7e,Multiple instance learning with generalized support vector machines,"In pattern classification it is usually assumed that a training set of labeled patterns is available. Multiple-Instance Learning (MIL) generalizes this problem setting by making weaker assumptions about the labeling information. While each pattern is still believed to possess a true label, training labels are associated with sets or bags of patterns rather than individual patterns. More formally, given is a set of patterns x1, ...,xn grouped into bags X1, ..., Xm, with Xj = {xi : i ∈ Ij} and Ij ⊆ {1, ..., n}. With each bag Xj is associated a label Yj ∈ {−1, 1}. These labels are interpreted in the following way: if a bag has a negative label Yj = −1, all patterns in that bag inherit the negative label. If on the other hand, Yj = 1, then at least one pattern xi ∈ Xj is a positive example of the underlying concept. The MIL scenario has many interesting applications: One prominent application is the classification of molecules in the context of drug design (Dietterich, Lathrop, & LozanoPerez 1997). Here, each molecule is represented by a bag of possible conformations. Another application is in image retrieval where images can be viewed as bags of local image patches (Maron & Ratan 1998) or image regions. Algorithms for the MIL problem were first presented in (Dietterich, Lathrop, & Lozano-Perez 1997; Auer 1997; Long & Tan 1996). These methods (and analytical results) are based on hypothesis classes consisting of axisaligned rectangles. Similarly, methods developed subsequently (e.g., (Maron & Lozano-Perez 1998; Zhang & Goldman 2002)) have focused on specially tailored machine learning algorithms that do not compare favorably in the limiting case of bags of size 1 (the standard classification setting). A notable exception is (Ramon & Raedt 2000).",2002,12,113,18,False,Computer Science,,2054883307,Stuart Andrews,143936663.0,Thomas Hofmann,1765700.0,Ioannis Tsochantaridis,,,,,,,,,,,,,,,,,,,,,
63c469ae1655cd6954e9efacbdc7253a7bdb6da7,https://www.semanticscholar.org/paper/63c469ae1655cd6954e9efacbdc7253a7bdb6da7,Bringing Machine Learning and Compositional Semantics Together,"Computational semantics has long been considered a field divided between logical and statistical approaches, but this divide is rapidly eroding with the development of statistical models that learn compositional semantic theories from corpora and databases. This review presents a simple discriminative learning framework for defining such models and relating them to logical theories. Within this framework, we discuss the task of learning to map utterances to logical forms (semantic parsing) and the task of learning from denotations with logical forms as latent variables. We also consider models that use distributed (e.g., vector) representations rather than logical ones, showing that these can be considered part of the same overall framework for understanding meaning and structural complexity.",2015,112,69,5,False,Computer Science,,145419642,Percy Liang,144922861.0,Christopher Potts,,,,,,,,,,,,,,,,,,,,,,,
95aef2d99334420731593bb392e6397c48d722a0,https://www.semanticscholar.org/paper/95aef2d99334420731593bb392e6397c48d722a0,Prediction of MicroRNA-Disease Associations Based on Social Network Analysis Methods,"MicroRNAs constitute an important class of noncoding, single-stranded, ~22 nucleotide long RNA molecules encoded by endogenous genes. They play an important role in regulating gene transcription and the regulation of normal development. MicroRNAs can be associated with disease; however, only a few microRNA-disease associations have been confirmed by traditional experimental approaches. We introduce two methods to predict microRNA-disease association. The first method, KATZ, focuses on integrating the social network analysis method with machine learning and is based on networks derived from known microRNA-disease associations, disease-disease associations, and microRNA-microRNA associations. The other method, CATAPULT, is a supervised machine learning method. We applied the two methods to 242 known microRNA-disease associations and evaluated their performance using leave-one-out cross-validation and 3-fold cross-validation. Experiments proved that our methods outperformed the state-of-the-art methods.",2015,67,144,2,True,Biology,Medicine,144268946,Q. Zou,2108952705.0,Jinjin Li,40300673.0,Qingqi Hong,144906697.0,Ziyu Lin,2108408362.0,Yun Wu,2108701882.0,Hua Shi,,144250293.0,Y. Ju,,,,,,,,,,,,
8cf7496c3303fbc4b74ccc6ccba135be3b94aca2,https://www.semanticscholar.org/paper/8cf7496c3303fbc4b74ccc6ccba135be3b94aca2,Classifying Single-Trial EEG During Motor Imagery by Iterative Spatio-Spectral Patterns Learning (ISSPL),"In most current motor-imagery-based brain-computer interfaces (BCIs), machine learning is carried out in two consecutive stages: feature extraction and feature classification. Feature extraction has focused on automatic learning of spatial filters, with little or no attention being paid to optimization of parameters for temporal filters that still require time-consuming, ad hoc manual tuning. In this paper, we present a new algorithm termed iterative spatio-spectral patterns learning (ISSPL) that employs statistical learning theory to perform automatic learning of spatio-spectral filters. In ISSPL, spectral filters and the classifier are simultaneously parameterized for optimization to achieve good generalization performance. A detailed derivation and theoretical analysis of ISSPL are given. Experimental results on two datasets show that the proposed algorithm can correctly identify the discriminative frequency bands, demonstrating the algorithm's superiority over contemporary approaches in classification performance.",2008,32,164,16,False,Computer Science,Medicine,39533001,Wei Wu,1782783.0,Xiaorong Gao,145031714.0,Bo Hong,145834126.0,Shangkai Gao,,,,,,,,,,,,,,,,,,,
6a060a59e0595ca487d89f70281dcc8a40fd36f6,https://www.semanticscholar.org/paper/6a060a59e0595ca487d89f70281dcc8a40fd36f6,The promise of machine learning in predicting treatment outcomes in psychiatry,"For many years, psychiatrists have tried to understand factors involved in response to medications or psychotherapies, in order to personalize their treatment choices. There is now a broad and growing interest in the idea that we can develop models to personalize treatment decisions using new statistical approaches from the field of machine learning and applying them to larger volumes of data. In this pursuit, there has been a paradigm shift away from experimental studies to confirm or refute specific hypotheses towards a focus on the overall explanatory power of a predictive model when tested on new, unseen datasets. In this paper, we review key studies using machine learning to predict treatment outcomes in psychiatry, ranging from medications and psychotherapies to digital interventions and neurobiological treatments. Next, we focus on some new sources of data that are being used for the development of predictive models based on machine learning, such as electronic health records, smartphone and social media data, and on the potential utility of data from genetics, electrophysiology, neuroimaging and cognitive testing. Finally, we discuss how far the field has come towards implementing prediction tools in real‐world clinical practice. Relatively few retrospective studies to‐date include appropriate external validation procedures, and there are even fewer prospective studies testing the clinical feasibility and effectiveness of predictive models. Applications of machine learning in psychiatry face some of the same ethical challenges posed by these techniques in other areas of medicine or computer science, which we discuss here. In short, machine learning is a nascent but important approach to improve the effectiveness of mental health care, and several prospective clinical studies suggest that it may be working already.",2021,239,68,2,False,Medicine,,6609752,A. Chekroud,82934036.0,Julia Bondar,145171115.0,Jaime Delgadillo,2659843.0,Gavin Doherty,83024519.0,Akash R. Wasil,38565406.0,M. Fokkema,,34221966.0,Z. Cohen,145763736.0,D. Belgrave,4423584.0,R. DeRubeis,2046648.0,R. Iniesta,5672681.0,D. Dwyer,6047002.0,Karmel W. Choi,,
bb774b249ceca4ab8aa964f0f32336aac801f698,https://www.semanticscholar.org/paper/bb774b249ceca4ab8aa964f0f32336aac801f698,SUPPORT VECTOR MACHINE-A Survey,"Support vector machine (SVM) is one of the most important machine learning algorithms that has been implemented mostly in pattern recognition problem, for e.g. classifying the network traffic and also in image processing for recognition . Lots of research is going on in this technique for the improvement of Qos (quality of service) and in security perspective. The latest works in this field have proved that SVM performs better than other network traffic classifier in terms of generalization of problem. This paper presents a theoretical aspect of SVM, its concepts and its applications overview.",2012,18,95,4,False,Computer Science,,143745269,A. Pradhan,67059695.0,S. Model,,,,,,,,,,,,,,,,,,,,,,,
6bb476f85f913786220afd3a34f56b3282396270,https://www.semanticscholar.org/paper/6bb476f85f913786220afd3a34f56b3282396270,Low-Power Circuits for Brain–Machine Interfaces,"This paper presents work on ultra-low-power circuits for brain–machine interfaces with applications for paralysis prosthetics, stroke, Parkinson's disease, epilepsy, prosthetics for the blind, and experimental neuroscience systems. The circuits include a micropower neural amplifier with adaptive power biasing for use in multi-electrode arrays; an analog linear decoding and learning architecture for data compression; low-power radio-frequency (RF) impedance-modulation circuits for data telemetry that minimize power consumption of implanted systems in the body; a wireless link for efficient power transfer; mixed-signal system integration for efficiency, robustness, and programmability; and circuits for wireless stimulation of neurons with power-conserving sleep modes and awake modes. Experimental results from chips that have stimulated and recorded from neurons in the zebra finch brain and results from RF power-link, RF data-link, electrode-recording and electrode-stimulating systems are presented. Simulations of analog learning circuits that have successfully decoded prerecorded neural signals from a monkey brain are also presented.",2008,35,98,6,True,Computer Science,Medicine,1994245,R. Sarpeshkar,2719728.0,W. Wattanapanitch,2489215.0,Scott K. Arfin,2542919.0,B. Rapoport,2432757.0,S. Mandal,48564101.0,M. Baker,,2200355.0,M. Fee,145299648.0,S. Musallam,2189155.0,R. Andersen,,,,,,,,
43407db991197f51bef75f8f858041651f3207d6,https://www.semanticscholar.org/paper/43407db991197f51bef75f8f858041651f3207d6,Using Rule-Based Machine Learning for Candidate Disease Gene Prioritization and Sample Classification of Cancer Gene Expression Data,"Microarray data analysis has been shown to provide an effective tool for studying cancer and genetic diseases. Although classical machine learning techniques have successfully been applied to find informative genes and to predict class labels for new samples, common restrictions of microarray analysis such as small sample sizes, a large attribute space and high noise levels still limit its scientific and clinical applications. Increasing the interpretability of prediction models while retaining a high accuracy would help to exploit the information content in microarray data more effectively. For this purpose, we evaluate our rule-based evolutionary machine learning systems, BioHEL and GAssist, on three public microarray cancer datasets, obtaining simple rule-based models for sample classification. A comparison with other benchmark microarray sample classifiers based on three diverse feature selection algorithms suggests that these evolutionary learning techniques can compete with state-of-the-art methods like support vector machines. The obtained models reach accuracies above 90% in two-level external cross-validation, with the added value of facilitating interpretation by using only combinations of simple if-then-else rules. As a further benefit, a literature mining analysis reveals that prioritizations of informative genes extracted from BioHEL’s classification rule sets can outperform gene rankings obtained from a conventional ensemble feature selection in terms of the pointwise mutual information between relevant disease terms and the standardized names of top-ranked genes.",2012,152,107,3,True,Biology,Medicine,1806197,E. Glaab,1697337.0,J. Bacardit,145890843.0,J. Garibaldi,1712183.0,N. Krasnogor,,,,,Computer Science,,,,,,,,,,,,,,
