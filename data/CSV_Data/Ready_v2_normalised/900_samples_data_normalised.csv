paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,fieldsOfStudy/1,fieldsOfStudy/2,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name
167e1359943b96b9e92ee73db1df69a1f65d731d,https://www.semanticscholar.org/paper/167e1359943b96b9e92ee73db1df69a1f65d731d,A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts,"Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as ""thumbs up"" or ""thumbs down"". To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.",2004,26,3692,378,True,Computer Science,144865353,B. Pang,145810617.0,Lillian Lee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a3461eaf51016f9d6e85ea47173b27e019e801c4,https://www.semanticscholar.org/paper/a3461eaf51016f9d6e85ea47173b27e019e801c4,State of the Art,"We are concerned with the inference (induction) of theories (hypotheses) from observations (data). This problem is common to philosophy (Aristotle 1988), statistical inference (Casella & Berger 2001) and machine learning (Mitchell 1997, Agluin & Smith 1983). We constrain ourselves only to the latter two frameworks. Within machine-learning, we further concentrate on its subfield called inductive logic programming (Nienhuys-Cheng & de Wolf 1997). Whereas in statistics we namely concentrate on evaluating hypotheses, in machine learning we study ways of constructing the theories. From the theoretical viewpoint, however, the construction is also viewed as a selection of a hypothesis from an a priori given set. Unlike in statistics, however, the range of considered hypotheses is usually large so that hypotheses cannot by inspected individually by a human. Such a set of hypotheses may be conveniently viewed as (equivalent to) a language L H generated by a certain formal grammar. Every hypothesis H ∈ L H induces a mapping h : X → O where X is a predefined (usually countable) set of instances (which we also call the domain of L H) and O is a set usually assumed to be finite and its elements called classes. Very often, O has just two elements. The assigned mapping gives the hypothesis its meaning (semantics). The usual formalization of the concept learning task is then as follows. Let there be a hypothesis C ∈ L H called the target concept and let n examples (x 1 , c(x 1)),(x 2 , c(x 2)),... ,(x n , c(x n))= S drawn from a predefined distribution D X on X be provided to the algorithm L called the learner (S is called a sample). We ask L to output an hypothesis H ∈ L H such that a specified error function Err(H, C) is minimized with respect to D X. The error function may be defined as e.g. Err(H, C) = 0 if H ≡ C (i.e. h(x) = c(x) ∀x ∈ X) and Err(H, C) = 1 otherwise, that is, irrespectively of the distribution D X. We would thus require the learner to exactly identify the target concept. This would be close to the theoretical framework of identification in the limit (Gold 1967), which, roughly said, demands that the learner converges to the correct hypothesis in the limit as n → ∞. Such a requirement is however very rigid and does not comply to the …",1997,67,5105,213,True,,2087814893,Markus Voelter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a34e35dbbc6911fa7b94894dffdc0076a261b6f0,https://www.semanticscholar.org/paper/a34e35dbbc6911fa7b94894dffdc0076a261b6f0,Neural Networks and the Bias/Variance Dilemma,"Feedforward neural networks trained by error backpropagation are examples of nonparametric regression estimators. We present a tutorial on nonparametric inference and its relation to neural networks, and we use the statistical viewpoint to highlight strengths and weaknesses of neural models. We illustrate the main points with some recognition experiments involving artificial data as well as handwritten numerals. In way of conclusion, we suggest that current-generation feedforward neural networks are largely inadequate for difficult problems in machine perception and machine learning, regardless of parallel-versus-serial hardware or other implementation issues. Furthermore, we suggest that the fundamental challenges in neural modeling are about representation rather than learning per se. This last point is supported by additional experiments with handwritten numerals.",1992,111,3607,137,False,Computer Science,3194361,S. Geman,2246319.0,E. Bienenstock,2330895.0,R. Doursat,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43d2ed5c3c55c1100450cd74dc1031afa24d37b2,https://www.semanticscholar.org/paper/43d2ed5c3c55c1100450cd74dc1031afa24d37b2,Collective Classification in Network Data,"Many real-world applications produce networked data such as the world-wide web (hypertext documents connected via hyperlinks), social networks (for example, people connected by friendship links), communication networks (computers connected via communication links) and biological networks (for example, protein interaction networks). A recent focus in machine learning research has been to extend traditional machine learning classification techniques to classify nodes in such networks. In this article, we provide a brief introduction to this area of research and how it has progressed during the past decade. We introduce four of the most widely used inference algorithms for classifying networked data and empirically compare them on both synthetic and real-world data.",2008,88,2471,556,True,Computer Science,40655309,P. Sen,1686834.0,Galileo Namata,2696727.0,M. Bilgic,1746034.0,L. Getoor,153701431.0,B. Gallagher,1397398770.0,Tina Eliassi-Rad,,,,,,,,,,,,,,,,,,,,,,
7ef26fb13e7b8d7555b6f58af141609535f7e28e,https://www.semanticscholar.org/paper/7ef26fb13e7b8d7555b6f58af141609535f7e28e,A review of classification algorithms for EEG-based brain–computer interfaces: a 10 year update,"Objective. Most current electroencephalography (EEG)-based brain–computer interfaces (BCIs) are based on machine learning algorithms. There is a large diversity of classifier types that are used in this field, as described in our 2007 review paper. Now, approximately ten years after this review publication, many new algorithms have been developed and tested to classify EEG signals in BCIs. The time is therefore ripe for an updated review of EEG classification algorithms for BCIs. Approach. We surveyed the BCI and machine learning literature from 2007 to 2017 to identify the new classification approaches that have been investigated to design BCIs. We synthesize these studies in order to present such algorithms, to report how they were used for BCIs, what were the outcomes, and to identify their pros and cons. Main results. We found that the recently designed classification algorithms for EEG-based BCIs can be divided into four main categories: adaptive classifiers, matrix and tensor classifiers, transfer learning and deep learning, plus a few other miscellaneous classifiers. Among these, adaptive classifiers were demonstrated to be generally superior to static ones, even with unsupervised adaptation. Transfer learning can also prove useful although the benefits of transfer learning remain unpredictable. Riemannian geometry-based methods have reached state-of-the-art performances on multiple BCI problems and deserve to be explored more thoroughly, along with tensor-based methods. Shrinkage linear discriminant analysis and random forests also appear particularly useful for small training samples settings. On the other hand, deep learning methods have not yet shown convincing improvement over state-of-the-art BCI methods. Significance. This paper provides a comprehensive overview of the modern classification algorithms used in EEG-based BCIs, presents the principles of these methods and guidelines on when and how to use them. It also identifies a number of challenges to further advance EEG classification in BCI.",2018,346,985,71,True,Physics,2890785,F. Lotte,1765001.0,L. Bougrain,145683892.0,A. Cichocki,48021716.0,Maureen Clerc,3276441.0,M. Congedo,1792962.0,A. Rakotomamonjy,Medicine,Computer Science,1783082.0,F. Yger,,,,,,,,,,,,,,,,,,
fc7a5018c590332b02e077ca056bdf8597d4cc9a,https://www.semanticscholar.org/paper/fc7a5018c590332b02e077ca056bdf8597d4cc9a,DATA CLASSIFICATION USING SUPPORT VECTOR MACHINE,"Classification is one of the most important tasks for different application such as text categorization, tone recognition, image classification, micro-array gene expression, proteins structure predictions, data Classification etc. Most of the existing supervised classification methods are based on traditional statistics, which can provide ideal results when sample size is tending to infinity. However, only finite samples can be acquired in practice. In this paper, a novel learning method, Support Vector Machine (SVM), is applied on different data (Diabetes data, Heart Data, Satellite Data and Shuttle data) which have two or multi class. SVM, a powerful machine method developed from statistical learning and has made significant achievement in some field. Introduced in the early 90’s, they led to an explosion of interest in machine learning. The foundations of SVM have been developed by Vapnik and are gaining popularity in field of machine learning due to many attractive features and promising empirical performance. SVM method does not suffer the limitations of data dimensionality and limited samples [1] & [2]. In our experiment, the support vectors, which are critical for classification, are obtained by learning from the training samples. In this paper we have shown the comparative results using different kernel functions for all data samples.",2009,6,386,21,False,Computer Science,153610425,D. Srivastava,70455528.0,L. Bhambhu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f,https://www.semanticscholar.org/paper/7b4f3d0e4e2486a8d5d3f8e00549cf9a117bf88f,Sequence Transduction with Recurrent Neural Networks,"Many machine learning tasks can be expressed as the transformation---or \emph{transduction}---of input sequences into output sequences: speech recognition, machine translation, protein secondary structure prediction and text-to-speech to name but a few. One of the key challenges in sequence transduction is learning to represent both the input and output sequences in a way that is invariant to sequential distortions such as shrinking, stretching and translating. Recurrent neural networks (RNNs) are a powerful sequence learning architecture that has proven capable of learning such representations. However RNNs traditionally require a pre-defined alignment between the input and output sequences to perform transduction. This is a severe limitation since \emph{finding} the alignment is the most difficult aspect of many sequence transduction problems. Indeed, even determining the length of the output sequence is often challenging. This paper introduces an end-to-end, probabilistic sequence transduction system, based entirely on RNNs, that is in principle able to transform any input sequence into any finite, discrete output sequence. Experimental results for phoneme recognition are provided on the TIMIT speech corpus.",2012,21,1144,201,False,Computer Science,1753223,A. Graves,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,
3a84214cb69ea0b34352285029f368b75718c32b,https://www.semanticscholar.org/paper/3a84214cb69ea0b34352285029f368b75718c32b,Understanding of a convolutional neural network,"The term Deep Learning or Deep Neural Network refers to Artificial Neural Networks (ANN) with multi layers. Over the last few decades, it has been considered to be one of the most powerful tools, and has become very popular in the literature as it is able to handle a huge amount of data. The interest in having deeper hidden layers has recently begun to surpass classical methods performance in different fields; especially in pattern recognition. One of the most popular deep neural networks is the Convolutional Neural Network (CNN). It take this name from mathematical linear operation between matrixes called convolution. CNN have multiple layers; including convolutional layer, non-linearity layer, pooling layer and fully-connected layer. The convolutional and fully-connected layers have parameters but pooling and non-linearity layers don't have parameters. The CNN has an excellent performance in machine learning problems. Specially the applications that deal with image data, such as largest image classification data set (Image Net), computer vision, and in natural language processing (NLP) and the results achieved were very amazing. In this paper we will explain and define all the elements and important issues related to CNN, and how these elements work. In addition, we will also state the parameters that effect CNN efficiency. This paper assumes that the readers have adequate knowledge about both machine learning and artificial neural network.",2017,14,1314,100,False,Computer Science,147999774,Saad Albawi,37517325.0,T. Mohammed,1410550919.0,Saad Al-Zawi,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d1b9a3b11e6c9571a1553556f82b605b2b4baec3,https://www.semanticscholar.org/paper/d1b9a3b11e6c9571a1553556f82b605b2b4baec3,Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures,"Machine-learning (ML) algorithms are increasingly utilized in privacy-sensitive applications such as predicting lifestyle choices, making medical diagnoses, and facial recognition. In a model inversion attack, recently introduced in a case study of linear classifiers in personalized medicine by Fredrikson et al., adversarial access to an ML model is abused to learn sensitive genomic information about individuals. Whether model inversion attacks apply to settings outside theirs, however, is unknown. We develop a new class of model inversion attack that exploits confidence values revealed along with predictions. Our new attacks are applicable in a variety of settings, and we explore two in depth: decision trees for lifestyle surveys as used on machine-learning-as-a-service systems and neural networks for facial recognition. In both cases confidence values are revealed to those with the ability to make prediction queries to models. We experimentally show attacks that are able to estimate whether a respondent in a lifestyle survey admitted to cheating on their significant other and, in the other context, show how to recover recognizable images of people's faces given only their name and access to the ML model. We also initiate experimental exploration of natural countermeasures, investigating a privacy-aware decision tree training algorithm that is a simple variant of CART learning, as well as revealing only rounded confidence values. The lesson that emerges is that one can avoid these kinds of MI attacks with negligible degradation to utility.",2015,36,1549,137,False,Computer Science,2623167,Matt Fredrikson,1680133.0,S. Jha,1707461.0,T. Ristenpart,,,,,,,,,,,,,,,,,,,,,,,,,,,,
043f084e379a44608c470059c2aa174a323e9774,https://www.semanticscholar.org/paper/043f084e379a44608c470059c2aa174a323e9774,Counterfactual Fairness,"Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.",2017,42,888,107,False,Mathematics,1940272,Matt J. Kusner,48678411.0,Joshua R. Loftus,2052380526.0,Chris Russell,2187716.0,Ricardo Silva,,,,,Computer Science,Psychology,,,,,,,,,,,,,,,,,,,,
e4a85af3f5dc41e13dc2cae9ee851953709b764e,https://www.semanticscholar.org/paper/e4a85af3f5dc41e13dc2cae9ee851953709b764e,Solving the quantum many-body problem with artificial neural networks,"Machine learning and quantum physics Elucidating the behavior of quantum interacting systems of many particles remains one of the biggest challenges in physics. Traditional numerical methods often work well, but some of the most interesting problems leave them stumped. Carleo and Troyer harnessed the power of machine learning to develop a variational approach to the quantum many-body problem (see the Perspective by Hush). The method performed at least as well as state-of-the-art approaches, setting a benchmark for a prototypical two-dimensional problem. With further development, it may well prove a valuable piece in the quantum toolbox. Science, this issue p. 602; see also p. 580 A machine-learning approach sets a computational benchmark for a prototypical two-dimensional problem. The challenge posed by the many-body problem in quantum physics originates from the difficulty of describing the nontrivial correlations encoded in the exponential complexity of the many-body wave function. Here we demonstrate that systematic machine learning of the wave function can reduce this complexity to a tractable computational form for some notable cases of physical interest. We introduce a variational representation of quantum states based on artificial neural networks with a variable number of hidden neurons. A reinforcement-learning scheme we demonstrate is capable of both finding the ground state and describing the unitary time evolution of complex interacting quantum systems. Our approach achieves high accuracy in describing prototypical interacting spins models in one and two dimensions.",2016,48,1183,75,True,Physics,50666189,G. Carleo,1752096.0,M. Troyer,,,,,,,,,Computer Science,Medicine,,,,,,,,,,,,,,,,,,,,
a42ca00fc188beb5586ad4c7108b70aeb5317da0,https://www.semanticscholar.org/paper/a42ca00fc188beb5586ad4c7108b70aeb5317da0,Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms,"Many different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA's standard distribution, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classification performance often much better than using standard selection and hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.",2012,43,1223,134,False,Computer Science,143928655,C. Thornton,144661829.0,F. Hutter,2470869.0,H. Hoos,1388404060.0,Kevin Leyton-Brown,,,,,,,,,,,,,,,,,,,,,,,,,,
a85e512d8845bd007b0866b4a97e8341463f8190,https://www.semanticscholar.org/paper/a85e512d8845bd007b0866b4a97e8341463f8190,Scalable Nearest Neighbor Algorithms for High Dimensional Data,"For many computer vision and machine learning problems, large training sets are key for good performance. However, the most computationally expensive part of many computer vision and machine learning algorithms consists of finding nearest neighbor matches to high dimensional vectors that represent the training data. We propose new algorithms for approximate nearest neighbor matching and evaluate and compare them with previous algorithms. For matching high dimensional features, we find two algorithms to be the most efficient: the randomized k-d forest and a new algorithm proposed in this paper, the priority search k-means tree. We also propose a new algorithm for matching binary features by searching multiple hierarchical clustering trees and show it outperforms methods typically used in the literature. We show that the optimal nearest neighbor algorithm and its parameters depend on the data set characteristics and describe an automated configuration procedure for finding the best algorithm to search a particular data set. In order to scale to very large data sets that would otherwise not fit in the memory of a single machine, we propose a distributed nearest neighbor matching framework that can be used with any of the algorithms described in the paper. All this research has been released as an open source library called fast library for approximate nearest neighbors (FLANN), which has been incorporated into OpenCV and is now one of the most popular libraries for nearest neighbor matching.",2014,65,1209,118,True,Computer Science,2658890,Marius Muja,35238678.0,D. Lowe,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
31af4b8793e93fd35e89569ccd663ae8777f0072,https://www.semanticscholar.org/paper/31af4b8793e93fd35e89569ccd663ae8777f0072,The Netflix Prize,"Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch. We briefly describe the challenge itself, review related work and efforts, and summarize visible progress to date. Other potential uses of the data are outlined, including its application to the KDD Cup 2007.",2007,6,2065,192,False,Engineering,2113543585,J. Bennett,47511653.0,S. Lanning,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44bb1605c4ab8a8ce2764fa20424f6a148101ca4,https://www.semanticscholar.org/paper/44bb1605c4ab8a8ce2764fa20424f6a148101ca4,ROC Graphs: Notes and Practical Considerations for Researchers,"Receiver Operating Characteristics (ROC) graphs are a useful technique for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been increasingly adopted in the machine learning and data mining research communities. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. This article serves both as a tutorial introduction to ROC graphs and as a practical guide for using them in research.",2007,35,2070,216,False,Computer Science,145421658,Tom Fawcett,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f46714d200d69eb9cb5cce176297b89a3f5e3a2c,https://www.semanticscholar.org/paper/f46714d200d69eb9cb5cce176297b89a3f5e3a2c,An Introduction to Convolutional Neural Networks,"The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. 
This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.",2015,21,1079,104,False,Computer Science,1399833554,K. O’Shea,2053923268.0,Ryan Nash,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ccf6a69a7f33bcf052aa7def176d3b9de495beb7,https://www.semanticscholar.org/paper/ccf6a69a7f33bcf052aa7def176d3b9de495beb7,Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings,"The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.",2016,47,1842,279,False,Computer Science,2843215,Tolga Bolukbasi,2782886.0,Kai-Wei Chang,145085305.0,James Y. Zou,1699322.0,Venkatesh Saligrama,2186481.0,A. Kalai,,,Mathematics,,,,,,,,,,,,,,,,,,,,,
427b168f490b56716f22b129ac93aba5425ea08f,https://www.semanticscholar.org/paper/427b168f490b56716f22b129ac93aba5425ea08f,Training linear SVMs in linear time,"Linear Support Vector Machines (SVMs) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification, word-sense disambiguation, and drug design. These applications involve a large number of examples n as well as a large number of features N, while each example has only s << N non-zero features. This paper presents a Cutting Plane Algorithm for training linear SVMs that provably has training time 0(s,n) for classification problems and o(sn log (n))for ordinal regression problems. The algorithm is based on an alternative, but equivalent formulation of the SVM optimization problem. Empirically, the Cutting-Plane Algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets.",2006,25,2147,338,False,Mathematics,1680188,T. Joachims,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
d079a2f877f554e00f71a6975435d8325987bdf5,https://www.semanticscholar.org/paper/d079a2f877f554e00f71a6975435d8325987bdf5,Return of Frustratingly Easy Domain Adaptation,"Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data have labels, including some that perform very well despite being ``frustratingly easy'' to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efficient method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. Even though it is extraordinarily simple--it can be implemented in four lines of Matlab code--CORAL performs remarkably well in extensive evaluations on standard benchmark datasets.",2015,40,1170,226,True,Computer Science,2636783,Baochen Sun,33221685.0,Jiashi Feng,2903226.0,Kate Saenko,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a96e508a94c37ef847b172e7d31b5bbe25629cbb,https://www.semanticscholar.org/paper/a96e508a94c37ef847b172e7d31b5bbe25629cbb,"Data Mining: Concepts and Techniques, 3rd edition","The book Knowledge Discovery in Databases, edited by Piatetsky-Shapiro and Frawley [PSF91], is an early collection of research papers on knowledge discovery from data. The book Advances in Knowledge Discovery and Data Mining, edited by Fayyad, Piatetsky-Shapiro, Smyth, and Uthurusamy [FPSSe96], is a collection of later research results on knowledge discovery and data mining. There have been many data mining books published in recent years, including Predictive Data Mining by Weiss and Indurkhya [WI98], Data Mining Solutions: Methods and Tools for Solving Real-World Problems by Westphal and Blaxton [WB98], Mastering Data Mining: The Art and Science of Customer Relationship Management by Berry and Linofi [BL99], Building Data Mining Applications for CRM by Berson, Smith, and Thearling [BST99], Data Mining: Practical Machine Learning Tools and Techniques by Witten and Frank [WF05], Principles of Data Mining (Adaptive Computation and Machine Learning) by Hand, Mannila, and Smyth [HMS01], The Elements of Statistical Learning by Hastie, Tibshirani, and Friedman [HTF01], Data Mining: Introductory and Advanced Topics by Dunham, and Data Mining: Multimedia, Soft Computing, and Bioinformatics by Mitra and Acharya [MA03]. There are also books containing collections of papers on particular aspects of knowledge discovery, such as Machine Learning and Data Mining: Methods and Applications edited by Michalski, Brakto, and Kubat [MBK98], and Relational Data Mining edited by Dzeroski and Lavrac [De01], as well as many tutorial notes on data mining in major database, data mining and machine learning conferences.",2006,736,2831,253,False,Computer Science,145325584,Jiawei Han,46833537.0,M. Kamber,145525190.0,J. Pei,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b57c54350769ffa59ff57f79ee5aad918844d298,https://www.semanticscholar.org/paper/b57c54350769ffa59ff57f79ee5aad918844d298,Differentially Private Empirical Risk Minimization,"Privacy-preserving machine learning algorithms are crucial for the increasingly common setting in which personal data, such as medical or financial records, are analyzed. We provide general techniques to produce privacy-preserving approximations of classifiers learned via (regularized) empirical risk minimization (ERM). These algorithms are private under the ε-differential privacy definition due to Dwork et al. (2006). First we apply the output perturbation ideas of Dwork et al. (2006), to ERM classification. Then we propose a new method, objective perturbation, for privacy-preserving machine learning algorithm design. This method entails perturbing the objective function before optimizing over classifiers. If the loss and regularizer satisfy certain convexity and differentiability criteria, we prove theoretical results showing that our algorithms preserve privacy, and provide generalization bounds for linear and nonlinear kernels. We further present a privacy-preserving technique for tuning the parameters in general machine learning algorithms, thereby providing end-to-end privacy guarantees for the training process. We apply these results to produce privacy-preserving analogues of regularized logistic regression and support vector machines. We obtain encouraging results from evaluating their performance on real demographic and benchmark data sets. Our results show that both theoretically and empirically, objective perturbation is superior to the previous state-of-the-art, output perturbation, in managing the inherent tradeoff between privacy and learning performance.",2009,59,1159,166,False,Medicine,38120884,Kamalika Chaudhuri,1806678.0,C. Monteleoni,9208982.0,A. Sarwate,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
b8d7788f25dfaf0f9fe2e6c441d75ca7cd3bc09a,https://www.semanticscholar.org/paper/b8d7788f25dfaf0f9fe2e6c441d75ca7cd3bc09a,Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution,"Feature selection, as a preprocessing step to machine learning, is effective in reducing dimensionality, removing irrelevant data, increasing learning accuracy, and improving result comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection methods with respect to efficiency and effectiveness. In this work, we introduce a novel concept, predominant correlation, and propose a fast filter method which can identify relevant features as well as redundancy among relevant features without pairwise correlation analysis. The efficiency and effectiveness of our method is demonstrated through extensive comparisons with other methods using real-world data of high dimensionality",2003,32,2380,215,False,Computer Science,143676604,Lei Yu,2146397025.0,Huan Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
03bf05bcb5fc5ea98c737c3aeaa330e047901b34,https://www.semanticscholar.org/paper/03bf05bcb5fc5ea98c737c3aeaa330e047901b34,Experimental design,"Maximizing data information requires careful selection, termed design, of the points at which data are observed. Experimental design is reviewed here for broad classes of data collection and analysis problems, including: fractioning techniques based on orthogonal arrays, Latin hypercube designs and their variants for computer experimentation, efficient design for data mining and machine learning applications, and sequential design for active learning. © 2012 Wiley Periodicals, Inc.",2012,159,1211,65,False,Computer Science,143887093,J. Morgan,35946980.0,Xinwei Deng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9257779eed46107bcdce9f4dc86298572ff466ce,https://www.semanticscholar.org/paper/9257779eed46107bcdce9f4dc86298572ff466ce,Automated learning of decision rules for text categorization,"We describe the results of extensive experiments using optimized rule-based induction methods on large document collections. The goal of these methods is to discover automatically classification patterns that can be used for general document categorization or personalized filtering of free text. Previous reports indicate that human-engineered rule-based systems, requiring many man-years of developmental efforts, have been successfully built to “read” documents and assign topics to them. We show that machine-generated decision rules appear comparable to human performance, while using the identical rule-based representation. In comparison with other machine-learning techniques, results on a key benchmark from the Reuters collection show a large gain in performance, from a previously reported 67% recall/precision breakeven point to 80.5%. In the context of a very high-dimensional feature space, several methodological alternatives are examined, including universal versus local dictionaries, and binary versus frequency-related features.",1994,45,970,46,False,Computer Science,145272844,C. Apté,68982679.0,Fred J. Damerau,145700185.0,S. Weiss,,,,,,,,,,,,,,,,,,,,,,,,,,,,
885af28a751553be48a25b411a5d492767d4cf65,https://www.semanticscholar.org/paper/885af28a751553be48a25b411a5d492767d4cf65,Ensemble Classifiers for Steganalysis of Digital Media,"Today, the most accurate steganalysis methods for digital media are built as supervised classifiers on feature vectors extracted from the media. The tool of choice for the machine learning seems to be the support vector machine (SVM). In this paper, we propose an alternative and well-known machine learning tool-ensemble classifiers implemented as random forests-and argue that they are ideally suited for steganalysis. Ensemble classifiers scale much more favorably w.r.t. the number of training examples and the feature dimensionality with performance comparable to the much more complex SVMs. The significantly lower training complexity opens up the possibility for the steganalyst to work with rich (high-dimensional) cover models and train on larger training sets-two key elements that appear necessary to reliably detect modern steganographic algorithms. Ensemble classification is portrayed here as a powerful developer tool that allows fast construction of steganography detectors with markedly improved detection accuracy across a wide range of embedding methods. The power of the proposed framework is demonstrated on three steganographic methods that hide messages in JPEG images.",2012,57,898,72,True,Computer Science,1808384,Jan Kodovský,1751812.0,J. Fridrich,37127008.0,V. Holub,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9d4bb6ec511c5dd4c6c97224b59cf4cdf4dc0746,https://www.semanticscholar.org/paper/9d4bb6ec511c5dd4c6c97224b59cf4cdf4dc0746,The class imbalance problem: A systematic study,"In machine learning problems, differences in prior class probabilities -- or class imbalances -- have been reported to hinder the performance of some standard classifiers, such as decision trees. This paper presents a systematic study aimed at answering three different questions. First, we attempt to understand the nature of the class imbalance problem by establishing a relationship between concept complexity, size of the training set and class imbalance level. Second, we discuss several basic re-sampling or cost-modifying methods previously proposed to deal with the class imbalance problem and compare their effectiveness. The results obtained by such methods on artificial domains are linked to results in real-world domains. Finally, we investigate the assumption that the class imbalance problem does not only affect decision tree systems but also affects other classification systems such as Neural Networks and Support Vector Machines.",2002,18,2546,116,False,Mathematics,1743642,N. Japkowicz,144980086.0,Shaju Stephen,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
bae3eda9605700b14237f4d04652ab6759c68eef,https://www.semanticscholar.org/paper/bae3eda9605700b14237f4d04652ab6759c68eef,"Artificial intelligence - a modern approach, 2nd Edition","Artificial IntelligenceArtificial Intelligence: A Modern Approach 2Nd Ed.Introduction to Machine LearningArtificial IntelligenceArtificial Intelligence: A Modern Approach, eBook, Global EditionIntroduction to Artificial IntelligenceModern Approaches in Machine Learning and Cognitive Science: A WalkthroughArtificial Intelligence: Pearson New International EditionArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachFundamentals of the New Artificial IntelligenceMultiagent SystemsArtificial IntelligenceArtificial IntelligenceThe Hundred-page Machine Learning BookArtificial IntelligenceArtificial IntelligenceArtificial IntelligenceDistributed Artificial IntelligenceArtificial Intelligence For BeginnersParadigms of Artificial Intelligence ProgrammingHuman CompatibleHuman CompatibleARTIFICIAL INTELLIGENCEArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachDo the Right ThingArtificial IntelligenceArtificial Intelligence : a Modern ApproachArtificial IntelligenceIntelligent Help Systems for UNIXArtificial IntelligenceArtificial IntelligenceArtificial Intelligence a Modern ApproachArtificial IntelligenceArtificial IntelligenceArtificial Intelligence for Human Computer Interaction: A Modern Approach",2003,0,1975,198,False,Computer Science,145107462,Stuart J. Russell,2784519.0,Peter Norvig,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7f57e9939560562727344c1c987416285ef76cda,https://www.semanticscholar.org/paper/7f57e9939560562727344c1c987416285ef76cda,Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition,"Machine learning is enabling a myriad innovations, including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack, particularly when used in applications where physical security or safety is at risk. In this paper, we focus on facial biometric systems, which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are physically realizable and inconspicuous, and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks, which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm, the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems, but we also demonstrate how similar techniques can be used in black-box scenarios, as well as to avoid face detection.",2016,45,1128,83,True,Computer Science,36301492,Mahmood Sharif,38181360.0,Sruti Bhagavatula,41224057.0,Lujo Bauer,1746214.0,M. Reiter,,,,,,,,,,,,,,,,,,,,,,,,,,
317794c81f54371dda5950a5ee7a41ed10298ab2,https://www.semanticscholar.org/paper/317794c81f54371dda5950a5ee7a41ed10298ab2,"How to Grow a Mind: Statistics, Structure, and Abstraction","In coming to understand the world—in learning concepts, acquiring language, and grasping causal relations—our minds make inferences that appear to go far beyond the data available. How do we do it? This review describes recent approaches to reverse-engineering human learning and cognitive development and, in parallel, engineering more humanlike machine learning systems. Computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought: How does abstract knowledge guide learning and reasoning from sparse data? What forms does our knowledge take, across different domains and tasks? And how is that abstract knowledge itself acquired?",2011,82,1376,57,False,Computer Science,1763295,J. Tenenbaum,145300792.0,Charles Kemp,1799860.0,T. Griffiths,144002017.0,Noah D. Goodman,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
e86f71ca2948d17b003a5f068db1ecb2b77827f7,https://www.semanticscholar.org/paper/e86f71ca2948d17b003a5f068db1ecb2b77827f7,Concrete Problems in AI Safety,"Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (""avoiding side effects"" and ""avoiding reward hacking""), an objective function that is too expensive to evaluate frequently (""scalable supervision""), or undesirable behavior during the learning process (""safe exploration"" and ""distributional shift""). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",2016,173,1387,76,False,Computer Science,2698777,Dario Amodei,37232298.0,C. Olah,5164568.0,J. Steinhardt,145791315.0,P. Christiano,47971768.0,J. Schulman,30415265.0,Dandelion Mané,,,,,,,,,,,,,,,,,,,,,,
0a289dd59b8043c0fbe3a4d1ae59055476ddb3ff,https://www.semanticscholar.org/paper/0a289dd59b8043c0fbe3a4d1ae59055476ddb3ff,Ensemble Methods: Foundations and Algorithms,"An up-to-date, self-contained introduction to a state-of-the-art machine learning approach, Ensemble Methods: Foundations and Algorithms shows how these accurate methods are used in real-world tasks. It gives you the necessary groundwork to carry out further research in this evolving field. After presenting background and terminology, the book covers the main algorithms and theories, including Boosting, Bagging, Random Forest, averaging and voting schemes, the Stacking method, mixture of experts, and diversity measures. It also discusses multiclass extension, noise tolerance, error-ambiguity and bias-variance decompositions, and recent progress in information theoretic diversity. Moving on to more advanced topics, the author explains how to achieve better performance through ensemble pruning and how to generate better clustering results by combining multiple clusterings. In addition, he describes developments of ensemble methods in semi-supervised learning, active learning, cost-sensitive learning, class-imbalance learning, and comprehensibility enhancement.",2012,0,1183,44,False,Computer Science,145624000,Zhi-Hua Zhou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
455d9a4ff96561d543acbcb2aa81d6cd8fcd20df,https://www.semanticscholar.org/paper/455d9a4ff96561d543acbcb2aa81d6cd8fcd20df,Trends & Controversies: Support Vector Machines,"My first exposure to Support Vector Machines came this spring when heard Sue Dumais present impressive results on text categorization using this analysis technique. This issue's collection of essays should help familiarize our readers with this interesting new racehorse in the Machine Learning stable. Bernhard Scholkopf, in an introductory overview, points out that a particular advantage of SVMs over other learning algorithms is that it can be analyzed theoretically using concepts from computational learning theory, and at the same time can achieve good performance when applied to real problems. Examples of these real-world applications are provided by Sue Dumais, who describes the aforementioned text-categorization problem, yielding the best results to date on the Reuters collection, and Edgar Osuna, who presents strong results on application to face detection. Our fourth author, John Platt, gives us a practical guide and a new technique for implementing the algorithm efficiently.",1998,86,2627,111,False,Computer Science,1716902,Marti A. Hearst,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ad3c82ada3ff848bb36bade1d90820c2e465b2d7,https://www.semanticscholar.org/paper/ad3c82ada3ff848bb36bade1d90820c2e465b2d7,Feature Selection,"Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity-based, information-theoretical-based, sparse-learning-based, and statistical-based methods. To facilitate and promote the research in this community, we also present an open source feature selection repository that consists of most of the popular feature selection algorithms (http://featureselection.asu.edu/). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.",2016,191,1239,46,True,Computer Science,2040455,Jundong Li,3161399.0,Kewei Cheng,2893721.0,Suhang Wang,2775559.0,Fred Morstatter,39690948.0,Robert P. Trevino,1736632.0,Jiliang Tang,,,145896397.0,Huan Liu,,,,,,,,,,,,,,,,,,
10f919b1a5161b560504c225cfb2d1b3a4768f80,https://www.semanticscholar.org/paper/10f919b1a5161b560504c225cfb2d1b3a4768f80,"Artificial intelligence in healthcare: past, present and future","Artificial intelligence (AI) aims to mimic human cognitive functions. It is bringing a paradigm shift to healthcare, powered by increasing availability of healthcare data and rapid progress of analytics techniques. We survey the current status of AI applications in healthcare and discuss its future. AI can be applied to various types of healthcare data (structured and unstructured). Popular AI techniques include machine learning methods for structured data, such as the classical support vector machine and neural network, and the modern deep learning, as well as natural language processing for unstructured data. Major disease areas that use AI tools include cancer, neurology and cardiology. We then review in more details the AI applications in stroke, in the three major areas of early detection and diagnosis, treatment, as well as outcome prediction and prognosis evaluation. We conclude with discussion about pioneer AI systems, such as IBM Watson, and hurdles for real-life deployment of AI.",2017,86,1413,36,True,Medicine,67092021,F. Jiang,2117937034.0,Yong Jiang,1976425918.0,Hui Zhi,1974599.0,Yi Dong,144966716.0,Hao Li,36156845.0,Sufeng Ma,Computer Science,,119918227.0,Yilong Wang,47454309.0,Q. Dong,46829048.0,Haipeng Shen,2108094216.0,Yongjun Wang,,,,,,,,,,,,
5e095981ebf4d389e9356bd56e59e0ade1b42e88,https://www.semanticscholar.org/paper/5e095981ebf4d389e9356bd56e59e0ade1b42e88,"2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text","The 2010 i2b2/VA Workshop on Natural Language Processing Challenges for Clinical Records presented three tasks: a concept extraction task focused on the extraction of medical concepts from patient reports; an assertion classification task focused on assigning assertion types for medical problem concepts; and a relation classification task focused on assigning relation types that hold between medical problems, tests, and treatments. i2b2 and the VA provided an annotated reference standard corpus for the three tasks. Using this reference standard, 22 systems were developed for concept extraction, 21 for assertion classification, and 16 for relation classification. These systems showed that machine learning approaches could be augmented with rule-based systems to determine concepts, assertions, and relations. Depending on the task, the rule-based systems can either provide input for machine learning or post-process the output of machine learning. Ensembles of classifiers, information from unlabeled data, and external knowledge sources can help when the training data are inadequate.",2011,43,1010,82,True,Computer Science,1723337,Özlem Uzuner,10208174.0,B. South,1807069.0,Shuying Shen,1807331.0,S. Duvall,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
7547fd7c5e4bc3b8b8bf714583684ff187e8a382,https://www.semanticscholar.org/paper/7547fd7c5e4bc3b8b8bf714583684ff187e8a382,An assessment of support vector machines for land cover classification,"The support vector machine (SVM) is a group of theoretically superior machine learning algorithms. It was found competitive with the best available machine learning algorithms in classifying high-dimensional data sets. This paper gives an introduction to the theoretical development of the SVM and an experimental evaluation of its accuracy, stability and training speed in deriving land cover classifications from satellite images. The SVM was compared to three other popular classifiers, including the maximum likelihood classifier (MLC), neural network classifiers (NNC) and decision tree classifiers (DTC). The impacts of kernel configuration on the performance of the SVM and of the selection of training data and input variables on the four classifiers were also evaluated in this experiment.",2002,59,1609,91,False,Computer Science,3343280,Chengquan Huang,1693428.0,L. Davis,145181457.0,J. Townshend,,,,,,,Geology,,,,,,,,,,,,,,,,,,,,,
0407b605b8f55db72e2545586bfe8e946b691b70,https://www.semanticscholar.org/paper/0407b605b8f55db72e2545586bfe8e946b691b70,An Empirical Investigation of Catastrophic Forgeting in Gradient-Based Neural Networks,"Catastrophic forgetting is a problem faced by many machine learning models and algorithms. When trained on one task, then trained on a second task, many machine learning models ""forget"" how to perform the first task. This is widely believed to be a serious problem for neural networks. Here, we investigate the extent to which the catastrophic forgetting problem occurs for modern neural networks, comparing both established and recent gradient-based training algorithms and activation functions. We also examine the effect of the relationship between the first task and the second task on catastrophic forgetting. We find that it is always best to train using the dropout algorithm--the dropout algorithm is consistently best at adapting to the new task, remembering the old task, and has the best tradeoff curve between these two extremes. We find that different tasks and relationships between tasks result in very different rankings of activation function performance. This suggests the choice of activation function should always be cross-validated.",2013,21,837,69,False,Computer Science,153440022,Ian J. Goodfellow,153583218.0,Mehdi Mirza,2058614620.0,Xia Da,1760871.0,Aaron C. Courville,1751762.0,Yoshua Bengio,,,Mathematics,,,,,,,,,,,,,,,,,,,,,
eec471897375942fd690b736c2753bb19d907273,https://www.semanticscholar.org/paper/eec471897375942fd690b736c2753bb19d907273,"Gradient boosting machines, a tutorial","Gradient boosting machines are a family of powerful machine-learning techniques that have shown considerable success in a wide range of practical applications. They are highly customizable to the particular needs of the application, like being learned with respect to different loss functions. This article gives a tutorial introduction into the methodology of gradient boosting methods with a strong focus on machine learning aspects of modeling. A theoretical information is complemented with descriptive examples and illustrations which cover all the stages of the gradient boosting model design. Considerations on handling the model complexity are discussed. Three practical examples of gradient boosting applications are presented and comprehensively analyzed.",2013,76,1134,59,True,Computer Science,2551434,Alexey Natekin,143873832.0,A. Knoll,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
ade03d0c772c35dc8e865bdb41d7bc54d5b782d1,https://www.semanticscholar.org/paper/ade03d0c772c35dc8e865bdb41d7bc54d5b782d1,kernlab - An S4 Package for Kernel Methods in R,"kernlab is an extensible package for kernel-based machine learning methods in R. It takes advantage of R's new S4 ob ject model and provides a framework for creating and using kernel-based algorithms. The package contains dot product primitives (kernels), implementations of support vector machines and the relevance vector machine, Gaussian processes, a ranking algorithm, kernel PCA, kernel CCA, and a spectral clustering algorithm. Moreover it provides a general purpose quadratic programming solver, and an incomplete Cholesky decomposition method.",2004,37,1621,72,True,Computer Science,1713164,Alexandros Karatzoglou,116865041.0,A. Smola,1764952.0,K. Hornik,2144516.0,A. Zeileis,,,,,,,,,,,,,,,,,,,,,,,,,,
759d9a6c9206c366a8d94a06f4eb05659c2bb7f2,https://www.semanticscholar.org/paper/759d9a6c9206c366a8d94a06f4eb05659c2bb7f2,Toward Open Set Recognition,"To date, almost all experimental evaluations of machine learning-based recognition algorithms in computer vision have taken the form of “closed set” recognition, whereby all testing classes are known at training time. A more realistic scenario for vision applications is “open set” recognition, where incomplete knowledge of the world is present at training time, and unknown classes can be submitted to an algorithm during testing. This paper explores the nature of open set recognition and formalizes its definition as a constrained minimization problem. The open set recognition problem is not well addressed by existing algorithms because it requires strong generalization. As a step toward a solution, we introduce a novel “1-vs-set machine,” which sculpts a decision space from the marginal distances of a 1-class or binary SVM with a linear kernel. This methodology applies to several different applications in computer vision where open set recognition is a challenging problem, including object recognition and face verification. We consider both in this work, with large scale cross-dataset experiments performed over the Caltech 256 and ImageNet sets, as well as face matching experiments performed over the Labeled Faces in the Wild set. The experiments highlight the effectiveness of machines adapted for open set evaluation compared to existing 1-class and binary SVMs for the same tasks.",2013,57,754,102,False,Medicine,2613438,W. Scheirer,145603848.0,A. Rocha,27469806.0,Archana Sapkota,32163276.0,T. Boult,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
938f6ef7eed095919e6a482c7f1836a01d62db4b,https://www.semanticscholar.org/paper/938f6ef7eed095919e6a482c7f1836a01d62db4b,Google Vizier: A Service for Black-Box Optimization,"Any sufficiently complex system acts as a black box when it becomes easier to experiment with than to understand. Hence, black-box optimization has become increasingly important as systems have become more complex. In this paper we describe Google Vizier, a Google-internal service for performing black-box optimization that has become the de facto parameter tuning engine at Google. Google Vizier is used to optimize many of our machine learning models and other systems, and also provides core capabilities to Google's Cloud Machine Learning HyperTune subsystem. We discuss our requirements, infrastructure design, underlying algorithms, and advanced features such as transfer learning and automated early stopping that the service provides.",2017,38,580,74,True,Computer Science,145973657,D. Golovin,22695907.0,Benjamin Solnik,3316330.0,Subhodeep Moitra,2942286.0,G. Kochanski,2056044.0,J. Karro,1733143.0,D. Sculley,,,,,,,,,,,,,,,,,,,,,,
310ea531640728702fce6c743c1dd680a23d2ef4,https://www.semanticscholar.org/paper/310ea531640728702fce6c743c1dd680a23d2ef4,Feature Selection for Classification: A Review,"Nowadays, the growth of the high-throughput technologies has resulted in exponential growth in the harvested data with respect to both dimensionality and sample size. The trend of this growth of the UCI machine learning repository is shown in Figure 1. Efficient and effective management of these data becomes increasing challenging. Traditionally manual management of these datasets to be impractical. Therefore, data mining and machine learning techniques were developed to automatically discover knowledge and recognize ...",2014,88,931,45,False,Computer Science,1736632,Jiliang Tang,2523108.0,Salem Alelyani,38746648.0,Huan Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93cb06180743fa648d844b9e7883b62468921c84,https://www.semanticscholar.org/paper/93cb06180743fa648d844b9e7883b62468921c84,Pattern Recognition and Neural Networks,"From the Publisher: Pattern recognition has long been studied in relation to many different (and mainly unrelated) applications, such as remote sensing, computer vision, space research, and medical imaging. In this book Professor Ripley brings together two crucial ideas in pattern recognition; statistical methods and machine learning via neural networks. Unifying principles are brought to the fore, and the author gives an overview of the state of the subject. Many examples are included to illustrate real problems in pattern recognition and how to overcome them.This is a self-contained account, ideal both as an introduction for non-specialists readers, and also as a handbook for the more expert reader.",1996,113,2856,63,True,Computer Science,2122942,B. Ripley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80196cdfcd0c6ce2953bf65a7f019971e2026386,https://www.semanticscholar.org/paper/80196cdfcd0c6ce2953bf65a7f019971e2026386,IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures,"In this work we aim to solve a large collection of tasks using a single reinforcement learning agent with a single set of parameters. A key challenge is to handle the increased amount of data and extended training time. We have developed a new distributed agent IMPALA (Importance Weighted Actor-Learner Architecture) that not only uses resources more efficiently in single-machine training but also scales to thousands of machines without sacrificing data efficiency or resource utilisation. We achieve stable learning at high throughput by combining decoupled acting and learning with a novel off-policy correction method called V-trace. We demonstrate the effectiveness of IMPALA for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the DeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our results show that IMPALA is able to achieve better performance than previous agents with less data, and crucially exhibits positive transfer between tasks as a result of its multi-task approach.",2018,41,1038,208,False,Computer Science,2311318,Lasse Espeholt,2794457.0,Hubert Soyer,1708654.0,R. Munos,34838386.0,K. Simonyan,3255983.0,Volodymyr Mnih,2056968992.0,Tom Ward,Mathematics,,2895238.0,Yotam Doron,9559485.0,Vlad Firoiu,3367786.0,Tim Harley,2768462.0,Iain Dunning,34313265.0,S. Legg,2645384.0,K. Kavukcuoglu,,,,,,,,
79f2626046fdc56edfaca840874e355cac734b9a,https://www.semanticscholar.org/paper/79f2626046fdc56edfaca840874e355cac734b9a,Ad click prediction: a view from the trenches,"Predicting ad click-through rates (CTR) is a massive-scale learning problem that is central to the multi-billion dollar online advertising industry. We present a selection of case studies and topics drawn from recent experiments in the setting of a deployed CTR prediction system. These include improvements in the context of traditional supervised learning based on an FTRL-Proximal online learning algorithm (which has excellent sparsity and convergence properties) and the use of per-coordinate learning rates. We also explore some of the challenges that arise in a real-world system that may appear at first to be outside the domain of traditional machine learning research. These include useful tricks for memory savings, methods for assessing and visualizing performance, practical methods for providing confidence estimates for predicted probabilities, calibration methods, and methods for automated management of features. Finally, we also detail several directions that did not turn out to be beneficial for us, despite promising results elsewhere in the literature. The goal of this paper is to highlight the close relationship between theoretical advances and practical engineering in this industrial setting, and to show the depth of challenges that appear when applying traditional machine learning methods in a complex dynamic system.",2013,39,817,55,True,Computer Science,145057514,H. B. McMahan,144510728.0,Gary Holt,1733143.0,D. Sculley,2114084357.0,Michael Young,49236095.0,D. Ebner,36185845.0,Julian Grady,,,145945637.0,Lan Nie,2054375101.0,Todd Phillips,143698521.0,Eugene Davydov,145973657.0,D. Golovin,7489841.0,S. Chikkerur,144645397.0,Dan Liu,145233583.0,M. Wattenberg,103056458.0,A. M. Hrafnkelsson,67119094.0,T. Boulos,143702704.0,J. Kubica
6d5965a76f88a8ebab4fc9c43a3ae2630628966a,https://www.semanticscholar.org/paper/6d5965a76f88a8ebab4fc9c43a3ae2630628966a,Learning and evaluating classifiers under sample selection bias,"Classifier learning methods commonly assume that the training data consist of randomly drawn examples from the same distribution as the test examples about which the learned model is expected to make predictions. In many practical situations, however, this assumption is violated, in a problem known in econometrics as sample selection bias. In this paper, we formalize the sample selection bias problem in machine learning terms and study analytically and experimentally how a number of well-known classifier learning methods are affected by it. We also present a bias correction method that is particularly useful for classifier evaluation under sample selection bias.",2004,22,795,57,False,Computer Science,1735228,B. Zadrozny,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a9763afda62e960c35c80681f805ddecbef14a92,https://www.semanticscholar.org/paper/a9763afda62e960c35c80681f805ddecbef14a92,Images of Organization,"Preface Part I. An Overview Introduction Part II. Some Images of Organization 2. Mechanization Takes Command: Organizations as Machines Machines, Mechanical Thinking, and the Rise of Bureaucratic Organization The Origins of Mechanistic Organization Classical Management Theory: Designing bureaucratic organizations Scientific Management Strengths and Limitations of the Machine Metaphor 3. Nature Intervenes: Organizations as Organisms Discovering Organizational Needs Recognizing the Importance of Environment: Organizations as Open Systems Contingency Theory: Adapting Organization to Environment The Variety of the Species Contingency Theory: Promoting Organizational Health and Development Natural Selection: The Population-Ecology View of Organizations Organizational Ecology: The Creation of Shared Futures Strengths and Limitations of the Organismic Metaphor 4. Learning and Self-Organization: Organizations as Brains Images of the Brain Organizations as Information Processing Brains Creating Learning Organizations Cybernetics, Learning, and Learning to Learn Can Organizations Learn to Learn? Guidelines for ""Learning Organizations"" Organizations as Holographic Brains Principles of Holographic Design Strengths and Limitations of the Brain Metaphors 5. Creating Social Realty: Organizations as Cultures Culture and Organization Organization as a Cultural Phenomenon Organization and Cultural Context Corporate Cultures and Subcultures Creating Organizational Reality Culture: Rule Following or Enactment? Organization: The enactment of a Shared Reality Strengths and Limitations of the Cultural Metaphor 6. Interests, Conflict, and Power: Organizations as Political Systems Organizations as Systems of Government Organizations as Systems of Political Activity Analyzing Interests Understanding Conflict Exploring Power Managing Pluralist Organizations Strengths and Limitations of the Political Metaphor 7. Exploring Plato's Cave: Organizations as Psychic Prisons The Trap of Favored Ways of Thinking Organization and the Unconscious Organization and Repressed Sexuality Organization and the Patriarchal Family Organization, Death, and Immortality Organization and Anxiety Organization, Dolls, and Teddy Bears Organization, Shadow, and Archetype The Unconscious: A Creative and Destructive Force Strengths and Limitations of the Psychic Prison Metaphor 8. Unfolding Logics of Change: Organization as Flux and Transformation Autopoiesis: Rethinking Relations With the Environment Enactment as a Form of Narcissism: Organizations Interact With Projections of Themselves Identity and Closure: Egocentrism Versus Systemic Wisdom Shifting ""Attractors"": The Logic of Chaos and Complexity Managing in the Midst of Complexity Loops, Not Lines: The Logic of Mutual Causality Contradiction and Crisis: The Logic of Dialectical Change Dialectical Analysis: How Opposing Forces Drive Change The Dialectics of Management Strengths and Limitations of the Flux and Transformation Metaphor 9. The Ugly Face: Organizations as Instruments of Domination Organization as Domination How Organizations Use and Exploit Their Employees Organization, Class, and Control Work Hazards, Occupational Disease, and Industrial Accidents Workaholism and Social and Mental Stress Organizational Politics and the Radicalized Organization Multinationals and the World Economy The Multinationals as World Powers Multinationals: A Record of Exploitation? Strengths and Limitations of the Domination Metaphor Part III. Implications For Practice 10. The Challenge of Metaphor Metaphors Create Ways of Seeing and Shaping Organizational Life Seeing, Thinking, and Acting in New Ways 11. Reading and Shaping Organizational Life The Multicom Case Interpreting Multicom Developing and Detailed Reading and ""Storyline"" Multicom From Another View ""Reading"" and Emergent Intelligence 12. Postscript Bibliographic Notes Introduction The Machine Metaphor The Organismic Metaphor The Brain Metaphor The Culture Metaphor The Political Metaphor The Psychic Prison Metaphor The Flux and Transformation Metaphor The Domination Metaphor The Challenge of Metaphor Reading and Shaping Organizational Life Postscript Bibliography",1988,1,6782,435,False,Medicine,49811299,J. Alexander,2053884612.0,G. Morgan,,,,,,,,,Psychology,Sociology,,,,,,,,,,,,,,,,,,,,
e211ec0fdaee8bec696475eaffae05af32222b9b,https://www.semanticscholar.org/paper/e211ec0fdaee8bec696475eaffae05af32222b9b,Semantics derived automatically from language corpora contain human-like biases,"Machines learn what people know implicitly AlphaGo has demonstrated that a machine can learn how to do things that people spend many years of concentrated study learning, and it can rapidly learn how to do them better than any human can. Caliskan et al. now show that machines can learn word associations from written texts and that these associations mirror those learned by humans, as measured by the Implicit Association Test (IAT) (see the Perspective by Greenwald). Why does this matter? Because the IAT has predictive value in uncovering the association between concepts, such as pleasantness and flowers or unpleasantness and insects. It can also tease out attitudes and beliefs—for example, associations between female names and family or male names and career. Such biases may not be expressed explicitly, yet they can prove influential in behavior. Science, this issue p. 183; see also p. 133 Computers can learn which words go together more or less often and can thus mimic human performance on a test of implicit bias. Machine learning is a means to derive artificial intelligence by discovering patterns in existing data. Here, we show that applying machine learning to ordinary human language results in human-like semantic biases. We replicated a spectrum of known biases, as measured by the Implicit Association Test, using a widely used, purely statistical machine-learning model trained on a standard corpus of text from the World Wide Web. Our results indicate that text corpora contain recoverable and accurate imprints of our historic biases, whether morally neutral as toward insects or flowers, problematic as toward race or gender, or even simply veridical, reflecting the status quo distribution of gender with respect to careers or first names. Our methods hold promise for identifying and addressing sources of bias in culture, including technology.",2016,75,1514,183,True,Medicine,144537437,Aylin Caliskan,145315445.0,J. Bryson,47735253.0,A. Narayanan,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
0c91d5305ad34814b631d4a642bb0535a2e066ea,https://www.semanticscholar.org/paper/0c91d5305ad34814b631d4a642bb0535a2e066ea,Feature selection based on mutual information,"The application of machine learning models such as support vector machine (SVM) and artificial neural networks (ANN) in predicting reservoir properties has been effective in the recent years when compared with the traditional empirical methods. Despite that the machine learning models suffer a lot in the faces of uncertain data which is common characteristics of well log dataset. The reason for uncertainty in well log dataset includes a missing scale, data interpretation and measurement error problems. Feature Selection aimed at selecting feature subset that is relevant to the predicting property. In this paper a feature selection based on mutual information criterion is proposed, the strong point of this method relies on the choice of threshold based on statistically sound criterion for the typical greedy feedforward method of feature selection. Experimental results indicate that the proposed method is capable of improving the performance of the machine learning models in terms of prediction accuracy and reduction in training time.",2015,21,740,55,True,Computer Science,2065588825,Muhammad Aliyu Sulaiman,2808327.0,J. Labadin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
864e7db59f2ccfec1ee9f6eba79566ac7b0634df,https://www.semanticscholar.org/paper/864e7db59f2ccfec1ee9f6eba79566ac7b0634df,Convolutional Pose Machines,"Pose Machines provide a sequential prediction framework for learning rich implicit spatial models. In this work we show a systematic design for how convolutional networks can be incorporated into the pose machine framework for learning image features and image-dependent spatial models for the task of pose estimation. The contribution of this paper is to implicitly model long-range dependencies between variables in structured prediction tasks such as articulated pose estimation. We achieve this by designing a sequential architecture composed of convolutional networks that directly operate on belief maps from previous stages, producing increasingly refined estimates for part locations, without the need for explicit graphical model-style inference. Our approach addresses the characteristic difficulty of vanishing gradients during training by providing a natural learning objective function that enforces intermediate supervision, thereby replenishing back-propagated gradients and conditioning the learning procedure. We demonstrate state-of-the-art performance and outperform competing methods on standard benchmarks including the MPII, LSP, and FLIC datasets.",2016,47,2180,294,True,Computer Science,2797981,Shih-En Wei,20569810.0,V. Ramakrishna,1733113.0,T. Kanade,1774867.0,Yaser Sheikh,,,,,,,,,,,,,,,,,,,,,,,,,,
b8012351bc5ebce4a4b3039bbbba3ce393bc3315,https://www.semanticscholar.org/paper/b8012351bc5ebce4a4b3039bbbba3ce393bc3315,An empirical evaluation of deep architectures on problems with many factors of variation,"Recently, several learning algorithms relying on models with deep architectures have been proposed. Though they have demonstrated impressive performance, to date, they have only been evaluated on relatively simple problems such as digit recognition in a controlled environment, for which many machine learning algorithms already report reasonable results. Here, we present a series of experiments which indicate that these models show promise in solving harder learning problems that exhibit many factors of variation. These models are compared with well-established algorithms such as Support Vector Machines and single hidden-layer feed-forward neural networks.",2007,13,1032,106,False,Computer Science,1777528,H. Larochelle,1761978.0,D. Erhan,1760871.0,Aaron C. Courville,32837403.0,J. Bergstra,1751762.0,Yoshua Bengio,,,,,,,,,,,,,,,,,,,,,,,,
3bc4736f9b8512043ed47357a81f26b93a1204b6,https://www.semanticscholar.org/paper/3bc4736f9b8512043ed47357a81f26b93a1204b6,Semi-supervised learning with graphs,"In traditional machine learning approaches to classification, one uses only a labeled set to train the classifier. Labeled instances however are often difficult, expensive, or time consuming to obtain, as they require the efforts of experienced human annotators. Meanwhile unlabeled data may be relatively easy to collect, but there has been few ways to use them. Semi-supervised learning addresses this problem by using large amount of unlabeled data, together with the labeled data, to build better classifiers. Because semi-supervised learning requires less human effort and gives higher accuracy, it is of great interest both in theory and in practice. 
We present a series of novel semi-supervised learning approaches arising from a graph representation, where labeled and unlabeled instances are represented as vertices, and edges encode the similarity between instances. They address the following questions: How to use unlabeled data? (label propagation); What is the probabilistic interpretation? (Gaussian fields and harmonic functions); What if we can choose labeled data? (active learning); How to construct good graphs? (hyperparameter learning); How to work with kernel machines like SVM? (graph kernels); How to handle complex data like sequences? (kernel conditional random fields); How to handle scalability and induction? (harmonic mixtures). An extensive literature review is included at the end.",2005,136,636,63,False,Computer Science,1832364,Xiaojin Zhu,1739581.0,J. Lafferty,145903504.0,R. Rosenfeld,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0ef7d9e618cbb507d69f8ebcdc60b8a1f3135bff,https://www.semanticscholar.org/paper/0ef7d9e618cbb507d69f8ebcdc60b8a1f3135bff,Solving large scale linear prediction problems using stochastic gradient descent algorithms,"Linear prediction methods, such as least squares for regression, logistic regression and support vector machines for classification, have been extensively used in statistics and machine learning. In this paper, we study stochastic gradient descent (SGD) algorithms on regularized forms of linear prediction methods. This class of methods, related to online algorithms such as perceptron, are both efficient and very simple to implement. We obtain numerical rate of convergence for such algorithms, and discuss its implications. Experiments on text data will be provided to demonstrate numerical and statistical consequences of our theoretical findings.",2004,10,1047,117,False,Mathematics,2117881943,Tong Zhang,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
b8e37682c847844a4b5c4851239fdc3357d5577b,https://www.semanticscholar.org/paper/b8e37682c847844a4b5c4851239fdc3357d5577b,Lecture Notes in Artificial Intelligence,"LNAI was established in the mid-1980s as a topical subseries of LNCS focusing on artificial intelligence. This subseries is devoted to the publication of state-of-the-art research results in artificial intelligence, at a high level and in both printed and electronic versions making use of the well-established LNCS publication machinery. As with the LNCS mother series, proceedings and postproceedings are at the core of LNAI; however, all other sublines are available for LNAI as well. The topics in LNAI include automated reasoning, automated programming, algorithms, knowledge representation, agent-based systems, intelligent systems, expert systems, machine learning, natural-language processing, machine vision, robotics, search systems, knowledge discovery, data mining, and related programming languages.",1999,2,3369,6,False,Computer Science,145050036,P. Brézillon,1755699.0,P. Bouquet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ec76f55da5c6df30f6e4c9e4945bd3304d508ef7,https://www.semanticscholar.org/paper/ec76f55da5c6df30f6e4c9e4945bd3304d508ef7,Fuzzy support vector machines,"A support vector machine (SVM) learns the decision surface from two distinct classes of the input points. In many applications, each input point may not be fully assigned to one of these two classes. In this paper, we apply a fuzzy membership to each input point and reformulate the SVMs such that different input points can make different contributions to the learning of decision surface. We call the proposed method fuzzy SVMs (FSVMs).",2002,10,1336,157,False,Mathematics,2146245769,Chun-fu Lin,9437199.0,Sheng-de Wang,,,,,,,,,Computer Science,Medicine,,,,,,,,,,,,,,,,,,,,
b3b3c562a45d7710d6f62ad8f210ebca9a47d23f,https://www.semanticscholar.org/paper/b3b3c562a45d7710d6f62ad8f210ebca9a47d23f,Who should fix this bug?,"Open source development projects typically support an open bug repository to which both developers and users can report bugs. The reports that appear in this repository must be triaged to determine if the report is one which requires attention and if it is, which developer will be assigned the responsibility of resolving the report. Large open source developments are burdened by the rate at which new bug reports appear in the bug repository. In this paper, we present a semi-automated approach intended to ease one part of this process, the assignment of reports to a developer. Our approach applies a machine learning algorithm to the open bug repository to learn the kinds of reports each developer resolves. When a new report arrives, the classifier produced by the machine learning technique suggests a small number of developers suitable to resolve the report. With this approach, we have reached precision levels of 57% and 64% on the Eclipse and Firefox development projects respectively. We have also applied our approach to the gcc open source development with less positive results. We describe the conditions under which the approach is applicable and also report on the lessons we learned about applying machine learning to repositories used in open source development.",2006,23,986,93,False,Computer Science,2226695,J. Anvik,47799990.0,L. Hiew,1739674.0,G. Murphy,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29650544fded20dd5b2fc49f60f9a3ad30d0e275,https://www.semanticscholar.org/paper/29650544fded20dd5b2fc49f60f9a3ad30d0e275,Speech Recognition Using Deep Neural Networks: A Systematic Review,"Over the past decades, a tremendous amount of research has been done on the use of machine learning for speech processing applications, especially speech recognition. However, in the past few years, research has focused on utilizing deep learning for speech-related applications. This new area of machine learning has yielded far better results when compared to others in a variety of applications including speech, and thus became a very attractive area of research. This paper provides a thorough examination of the different studies that have been conducted since 2006, when deep learning first arose as a new area of machine learning, for speech applications. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 174 papers published between the years 2006 and 2018. The results provided in this paper shed light on the trends of research in this area as well as bring focus to new research topics.",2019,226,418,14,True,Computer Science,2513768,A. B. Nassif,144304225.0,I. Shahin,73774606.0,Imtinan B. Attili,2063215.0,Mohammad Azzeh,40241708.0,K. Shaalan,,,,,,,,,,,,,,,,,,,,,,,,
10b496ad48513f8585aa56f2c682159357858960,https://www.semanticscholar.org/paper/10b496ad48513f8585aa56f2c682159357858960,Understanding Data Augmentation for Classification: When to Warp?,"In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.",2016,23,668,14,True,Computer Science,2442657,Sebastien C. Wong,3010116.0,A. Gatt,2851301.0,V. Stamatescu,1877198.0,M. McDonnell,,,,,,,,,,,,,,,,,,,,,,,,,,
77703a2783f64dfceb638aa9eebd9c9c501bb835,https://www.semanticscholar.org/paper/77703a2783f64dfceb638aa9eebd9c9c501bb835,The Case against Accuracy Estimation for Comparing Induction Algorithms,"We analyze critically the use of classi cation accuracy to compare classi ers on natural data sets, providing a thorough investigation using ROC analysis, standard machine learning algorithms, and standard benchmark data sets. The results raise serious concerns about the use of accuracy for comparing classi ers and draw into question the conclusions that can be drawn from such studies. In the course of the presentation, we describe and demonstrate what we believe to be the proper use of ROC analysis for comparative studies in machine learning research. We argue that this methodology is preferable both for making practical choices and for drawing scienti c conclusions.",1998,22,1205,52,False,Computer Science,1752722,F. Provost,145421658.0,Tom Fawcett,1726733.0,Ron Kohavi,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cc1cad12521b5aab43fdda5b4dec67586aef1f87,https://www.semanticscholar.org/paper/cc1cad12521b5aab43fdda5b4dec67586aef1f87,Kernel Methods for Relation Extraction,"We present an application of kernel methods to extracting relations from unstructured natural language sources. We introduce kernels defined over shallow parse representations of text, and design efficient algorithms for computing the kernels. We use the devised kernels in conjunction with Support Vector Machine and Voted Perceptron learning algorithms for the task of extracting person-affiliation and organization-location relations from text. We experimentally evaluate the proposed methods and compare them with feature-based learning algorithms, with promising results.",2002,41,1167,71,True,Computer Science,3190501,D. Zelenko,2939759.0,Chinatsu Aone,49754061.0,A. Richardella,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e75b3c12da067552fda910a5bbed8b4d0e82dbcb,https://www.semanticscholar.org/paper/e75b3c12da067552fda910a5bbed8b4d0e82dbcb, Neural Network Methods for Natural Language Processing,"Neural networks are a family of powerful machine learning models. This book focuses on the application of neural network models to natural language data. The first half of the book (Parts I and II) covers the basics of supervised machine learning and feed-forward neural networks, the basics of working with machine learning over language data, and the use of vector-based rather than symbolic representations for words. It also covers the computation-graph abstraction, which allows to easily define and train arbitrary neural networks, and is the basis behind the design of contemporary neural network software libraries.The second part of the book (Parts III and IV) introduces more specialized neural network architectures, including 1D convolutional neural networks, recurrent neural networks, conditioned-generation models, and attention-based models. These architectures and techniques are the driving force behind state-of-the-art algorithms for machine translation, syntactic parsing, and many other applications. Finally, we also discuss tree-shaped networks, structured prediction, and the prospects of multi-task learning.",2017,330,497,31,True,Computer Science,2089067,Yoav Goldberg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0a5ff7336879c99513dca6fce6ef44984ebf3f55,https://www.semanticscholar.org/paper/0a5ff7336879c99513dca6fce6ef44984ebf3f55,Clipper: A Low-Latency Online Prediction Serving System,"Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment. 
In this paper, we introduce Clipper, a general-purpose low-latency prediction serving system. Interposing between end-user applications and a wide range of machine learning frameworks, Clipper introduces a modular architecture to simplify model deployment across frameworks and applications. Furthermore, by introducing caching, batching, and adaptive model selection techniques, Clipper reduces prediction latency and improves prediction throughput, accuracy, and robustness without modifying the underlying machine learning frameworks. We evaluate Clipper on four common machine learning benchmark datasets and demonstrate its ability to meet the latency, accuracy, and throughput demands of online serving applications. Finally, we compare Clipper to the TensorFlow Serving system and demonstrate that we are able to achieve comparable throughput and latency while enabling model composition and online learning to improve accuracy and render more robust predictions.",2016,73,397,74,False,Computer Science,50564124,D. Crankshaw,2153692009.0,Xin Wang,40916418.0,Giulio Zhou,143666627.0,M. Franklin,49988044.0,Joseph E. Gonzalez,144467753.0,I. Stoica,,,,,,,,,,,,,,,,,,,,,,
f8b012720a2322dcf4ed9ac4d61d6be11d9ebd10,https://www.semanticscholar.org/paper/f8b012720a2322dcf4ed9ac4d61d6be11d9ebd10,Concepts of Artificial Intelligence for Computer-Assisted Drug Discovery.,"Artificial intelligence (AI), and, in particular, deep learning as a subcategory of AI, provides opportunities for the discovery and development of innovative drugs. Various machine learning approaches have recently (re)emerged, some of which may be considered instances of domain-specific AI which have been successfully employed for drug discovery and design. This review provides a comprehensive portrayal of these machine learning techniques and of their applications in medicinal chemistry. After introducing the basic principles, alongside some application notes, of the various machine learning algorithms, the current state-of-the art of AI-assisted pharmaceutical discovery is discussed, including applications in structure- and ligand-based virtual screening, de novo drug design, physicochemical and pharmacokinetic property prediction, drug repurposing, and related aspects. Finally, several challenges and limitations of the current methods are summarized, with a view to potential future directions for AI-assisted drug discovery and design.",2019,618,286,2,True,Chemistry,2150439478,Xin Yang,2115568943.0,Yifei Wang,2060877077.0,R. Byrne,144522872.0,G. Schneider,144824105.0,Sheng-yong Yang,,,Medicine,,,,,,,,,,,,,,,,,,,,,
ac12c9b9e35e58b55d85a97c47886a7371c14afa,https://www.semanticscholar.org/paper/ac12c9b9e35e58b55d85a97c47886a7371c14afa,Data mining in bioinformatics using Weka,"UNLABELLED
The Weka machine learning workbench provides a general-purpose environment for automatic classification, regression, clustering and feature selection-common data mining problems in bioinformatics research. It contains an extensive collection of machine learning algorithms and data pre-processing methods complemented by graphical user interfaces for data exploration and the experimental comparison of different machine learning techniques on the same problem. Weka can process data given in the form of a single relational table. Its main objectives are to (a) assist users in extracting useful information from data and (b) enable them to easily identify a suitable algorithm for generating an accurate predictive model from it.AVAILABILITY http://www.cs.waikato.ac.nz/ml/weka.",2004,13,896,67,True,Medicine,143713826,Eibe Frank,118860642.0,M. Hall,33614647.0,Leonard E. Trigg,144282963.0,G. Holmes,9419406.0,I. Witten,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
55e36d6b45c91a0daa49234bd47b856470d6825c,https://www.semanticscholar.org/paper/55e36d6b45c91a0daa49234bd47b856470d6825c,Identifying Sarcasm in Twitter: A Closer Look,"Sarcasm transforms the polarity of an apparently positive or negative utterance into its opposite. We report on a method for constructing a corpus of sarcastic Twitter messages in which determination of the sarcasm of each message has been made by its author. We use this reliable corpus to compare sarcastic utterances in Twitter to utterances that express positive or negative attitudes without sarcasm. We investigate the impact of lexical and pragmatic factors on machine learning effectiveness for identifying sarcastic utterances and we compare the performance of machine learning techniques and human judges on this task. Perhaps unsurprisingly, neither the human judges nor the machine learning techniques perform very well.",2011,15,590,55,False,Computer Science,1398275867,Roberto I. González-Ibáñez,2295928.0,S. Muresan,2468444.0,N. Wacholder,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c4a422669ec9b6a60b05d2d2595314008a5fb419,https://www.semanticscholar.org/paper/c4a422669ec9b6a60b05d2d2595314008a5fb419,Comparing support vector machines with Gaussian kernels to radial basis function classifiers,"The support vector (SV) machine is a novel type of learning machine, based on statistical learning theory, which contains polynomial classifiers, neural networks, and radial basis function (RBF) networks as special cases. In the RBF case, the SV algorithm automatically determines centers, weights, and threshold that minimize an upper bound on the expected test error. The present study is devoted to an experimental comparison of these machines with a classical approach, where the centers are determined by X-means clustering, and the weights are computed using error backpropagation. We consider three machines, namely, a classical RBF machine, an SV machine with Gaussian kernel, and a hybrid system with the centers determined by the SV method and the weights trained by error backpropagation. Our results show that on the United States postal service database of handwritten digits, the SV machine achieves the highest recognition accuracy, followed by the hybrid system. The SV approach is thus not only theoretically well-founded but also superior in a practical application.",1997,24,1348,48,True,Computer Science,1707625,B. Schölkopf,38817267.0,K. Sung,2676309.0,C. Burges,1804489.0,F. Girosi,1770745.0,P. Niyogi,1685292.0,T. Poggio,,,50560492.0,V. Vapnik,,,,,,,,,,,,,,,,,,
86e5827087e11dc929d592ee7b3d7581fc48265e,https://www.semanticscholar.org/paper/86e5827087e11dc929d592ee7b3d7581fc48265e,Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN,"Machine learning has been used to detect new malware in recent years, while malware authors have strong motivation to attack such algorithms. Malware authors usually have no access to the detailed structures and parameters of the machine learning models used by malware detection systems, and therefore they can only perform black-box attacks. This paper proposes a generative adversarial network (GAN) based algorithm named MalGAN to generate adversarial malware examples, which are able to bypass black-box machine learning based detection models. MalGAN uses a substitute detector to fit the black-box malware detection system. A generative network is trained to minimize the generated adversarial examples' malicious probabilities predicted by the substitute detector. The superiority of MalGAN over traditional gradient based adversarial example generation algorithms is that MalGAN is able to decrease the detection rate to nearly zero and make the retraining based defensive method against adversarial examples hard to work.",2017,32,383,45,False,Computer Science,2146241447,Weiwei Hu,143692919.0,Ying Tan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0ea2f1f5c470c4947b48bbd21245fb327282f3b4,https://www.semanticscholar.org/paper/0ea2f1f5c470c4947b48bbd21245fb327282f3b4,Stock market's price movement prediction with LSTM neural networks,"Predictions on stock market prices are a great challenge due to the fact that it is an immensely complex, chaotic and dynamic environment. There are many studies from various areas aiming to take on that challenge and Machine Learning approaches have been the focus of many of them. There are many examples of Machine Learning algorithms been able to reach satisfactory results when doing that type of prediction. This article studies the usage of LSTM networks on that scenario, to predict future trends of stock prices based on the price history, alongside with technical analysis indicators. For that goal, a prediction model was built, and a series of experiments were executed and theirs results analyzed against a number of metrics to assess if this type of algorithm presents and improvements when compared to other Machine Learning methods and investment strategies. The results that were obtained are promising, getting up to an average of 55.9% of accuracy when predicting if the price of a particular stock is going to go up or not in the near future.",2017,21,398,23,False,Computer Science,2112887403,David M. Q. Nelson,38964525.0,Adriano M. Pereira,153714464.0,Renato A. de Oliveira,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3335c340c20609b4e6de481c9eaf67ecd6c960dc,https://www.semanticscholar.org/paper/3335c340c20609b4e6de481c9eaf67ecd6c960dc,Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science,"As the field of data science continues to grow, there will be an ever-increasing demand for tools that make machine learning accessible to non-experts. In this paper, we introduce the concept of tree-based pipeline optimization for automating one of the most tedious parts of machine learning--pipeline design. We implement an open source Tree-based Pipeline Optimization Tool (TPOT) in Python and demonstrate its effectiveness on a series of simulated and real-world benchmark data sets. In particular, we show that TPOT can design machine learning pipelines that provide a significant improvement over a basic machine learning analysis while requiring little to no input nor prior knowledge from the user. We also address the tendency for TPOT to design overly complex pipelines by integrating Pareto optimization, which produces compact pipelines without sacrificing classification accuracy. As such, this work represents an important step toward fully automating machine learning pipeline design.",2016,22,355,48,True,Computer Science,3297552,Randal S. Olson,39248319.0,Nathan Bartley,1800213.0,R. Urbanowicz,152512193.0,J. Moore,,,,,,,,,,,,,,,,,,,,,,,,,,
b69df93991a1f5a712b20e832f5b0281acb3153b,https://www.semanticscholar.org/paper/b69df93991a1f5a712b20e832f5b0281acb3153b,Kernel Methods in Computational Biology,"Modern machine learning techniques are proving to be extremely valuable for the analysis of data in computational biology problems. One branch of machine learning, kernel methods, lends itself particularly well to the difficult aspects of biological data, which include high dimensionality (as in microarray measurements), representation as discrete and structured data (as in DNA or amino acid sequences), and the need to combine heterogeneous sources of information. This book provides a detailed overview of current research in kernel methods and their applications to computational biology.Following three introductory chapters -- an introduction to molecular and computational biology, a short review of kernel methods that focuses on intuitive concepts rather than technical details, and a detailed survey of recent applications of kernel methods in computational biology -- the book is divided into three sections that reflect three general trends in current research. The first part presents different ideas for the design of kernel functions specifically adapted to various biological data; the second part covers different approaches to learning from heterogeneous data; and the third part offers examples of successful applications of support vector machine methods.",2003,0,946,31,True,Computer Science,1707625,B. Schölkopf,34628173.0,K. Tsuda,152303545.0,Jean-Philippe Vert,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2323173a0bddac0dd2586b17a2f3ac33f401c45c,https://www.semanticscholar.org/paper/2323173a0bddac0dd2586b17a2f3ac33f401c45c,Nearest-Neighbor Methods in Learning and Vision: Theory and Practice (Neural Information Processing),"Regression and classification methods based on similarity of the input to stored examples have not been widely used in applications involving very large sets of high-dimensional data. Recent advances in computational geometry and machine learning, however, may alleviate the problems in using these methods on large data sets. This volume presents theoretical and practical discussions of nearest-neighbor (NN) methods in machine learning and examines computer vision as an application domain in which the benefit of these advanced methods is often dramatic. It brings together contributions from researchers in theory of computation, machine learning, and computer vision with the goals of bridging the gaps between disciplines and presenting state-of-the-art methods for emerging applications.The contributors focus on the importance of designing algorithms for NN search, and for the related classification, regression, and retrieval tasks, that remain efficient even as the number of points or the dimensionality of the data grows very large. The book begins with two theoretical chapters on computational geometry and then explores ways to make the NN approach practicable in machine learning applications where the dimensionality of the data and the size of the data sets make the naive methods for NN search prohibitively expensive. The final chapters describe successful applications of an NN algorithm, locality-sensitive hashing (LSH), to vision tasks.",2006,32,572,22,False,Computer Science,2490189,Gregory Shakhnarovich,1753210.0,Trevor Darrell,1688317.0,P. Indyk,,,,,,,,,,,,,,,,,,,,,,,,,,,,
