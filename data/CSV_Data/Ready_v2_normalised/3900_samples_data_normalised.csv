paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/1,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name,authors/34/authorId,authors/34/name,authors/35/authorId,authors/35/name
e2f3534b26fd37c86629d47e4647193ddac31ef3,https://www.semanticscholar.org/paper/e2f3534b26fd37c86629d47e4647193ddac31ef3,Ozone ensemble forecast with machine learning algorithms,"[1] We apply machine learning algorithms to perform sequential aggregation of ozone forecasts. The latter rely on a multimodel ensemble built for ozone forecasting with the modeling system Polyphemus. The ensemble simulations are obtained by changes in the physical parameterizations, the numerical schemes, and the input data to the models. The simulations are carried out for summer 2001 over western Europe in order to forecast ozone daily peaks and ozone hourly concentrations. On the basis of past observations and past model forecasts, the learning algorithms produce a weight for each model. A convex or linear combination of the model forecasts is then formed with these weights. This process is repeated for each round of forecasting and is therefore called sequential aggregation. The aggregated forecasts demonstrate good results; for instance, they always show better performance than the best model in the ensemble and they even compete against the best constant linear combination. In addition, the machine learning algorithms come with theoretical guarantees with respect to their performance, that hold for all possible sequences of observations, even nonstochastic ones. Our study also demonstrates the robustness of the methods. We therefore conclude that these aggregation methods are very relevant for operational forecasts.",2009,40,74,3,True,Computer Science,1850643.0,V. Mallet,1806997.0,Gilles Stoltz,104864725.0,B. Mauricette,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ebbc6951ea54ecdc20452ce3d44020e23b87116f,https://www.semanticscholar.org/paper/ebbc6951ea54ecdc20452ce3d44020e23b87116f,A Path for Translation of Machine Learning Products into Healthcare Delivery,"Despite enormous enthusiasm, machine learning models are rarely translated into clinical care and there is minimal evidence of clinical or economic impact. New conference venues and academic journals have emerged to promote the proliferating research; however, the translational path remains unclear. This review undertakes the first in-depth study to identify how machine learning models that ingest structured electronic health record data can be applied to clinical decision support tasks and translated into clinical practice. The authors complement their own work with the experience of 21 machine learning products that address problems across clinical domains and across geographic populations. Four phases of translation emerge: design and develop, evaluate and validate, diffuse and scale, and continuing monitoring and maintenance. The review highlights the varying approaches taken across each phase by teams building machine learning products and presents a discussion of challenges and opportunities. The translational path and associated findings are instructive to researchers and developers building machine learning products, policy makers regulating machine learning products, and health system leaders who are considering adopting a machine learning product.",2020,120,52,1,True,,47057856.0,M. Sendak,1610930464.0,Joshua D'Arcy,1752628613.0,S. Kashyap,145866390.0,M. Gao,48448064.0,M. Nichols,145820969.0,Kristin M Corey,2076928049.0,W. Ratliff,12308037.0,S. Balu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
00b918abefa15a3ef3b87ba2164522ab1ed64938,https://www.semanticscholar.org/paper/00b918abefa15a3ef3b87ba2164522ab1ed64938,Computational Paralinguistics,"This book presents the methods, tools and techniques that are currently being used to recognise (automatically) the affect, emotion, personality and everything else beyond linguistics (paralinguistics) expressed by or embedded in human speech and language.It is the first book to provide such a systematic survey of paralinguistics in speech and language processing. The technology described has evolved mainly from automatic speech and speaker recognition and processing, but also takes into account recent developments within speech signal processing, machine intelligence and data mining.Moreover, the book offers a hands-on approach by integrating actual data sets, software, and open-source utilities which will make the book invaluable as a teaching tool and similarly useful for those professionals already in the field.Key features:Provides an integrated presentation of basic research (in phonetics/linguistics and humanities) with state-of-the-art engineering approaches for speech signal processing and machine intelligence.Explains the history and state of the art of all of the sub-fields which contribute to the topic of computational paralinguistics.C overs the signal processing and machine learning aspects of the actual computational modelling of emotion and personality and explains the detection process from corpus collection to feature extraction and from model testing to system integration.Details aspects of real-world system integration including distribution, weakly supervised learning and confidence measures.Outlines machine learning approaches including static, dynamic and contextsensitive algorithms for classification and regression.Includes a tutorial on freely available toolkits, such as the open-source openEAR toolkit for emotion and affect recognition co-developed by one of the authors, and a listing of standard databases and feature sets used in the field to allow for immediate experimentation enabling the reader to build an emotion detection model on an existing corpus.",2013,0,217,17,False,Computer Science,145411696.0,Björn Schuller,1745089.0,A. Batliner,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66edb2a8d33db2d133d3a3c8c032a06a95c6cd3b,https://www.semanticscholar.org/paper/66edb2a8d33db2d133d3a3c8c032a06a95c6cd3b,Hyperparameter optimization with approximate gradient,"Most models in machine learning contain at least one hyperparameter to control for model complexity. Choosing an appropriate set of hyperparameters is both crucial in terms of model accuracy and computationally challenging. In this work we propose an algorithm for the optimization of continuous hyperparameters using inexact gradient information. An advantage of this method is that hyperparameters can be updated before model parameters have fully converged. We also give sufficient conditions for the global convergence of this method, based on regularity conditions of the involved functions and summability of errors. Finally, we validate the empirical performance of this method on the estimation of regularization constants of L2-regularized logistic regression and kernel Ridge regression. Empirical benchmarks indicate that our approach is highly competitive with respect to state of the art methods.",2016,40,254,44,False,Computer Science,2570016.0,Fabian Pedregosa,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ffe0dc8492bf9dd1e433fefe60b0dcd9d27152df,https://www.semanticscholar.org/paper/ffe0dc8492bf9dd1e433fefe60b0dcd9d27152df,Flexible and efficient Gaussian process models for machine learning,"Gaussian process (GP) models are widely used to perform Bayesian nonlinear regression and classification tasks that are central to many machine learning problems. A GP is nonparametric, meaning that the complexity of the model grows as more data points are received. Another attractive feature is the behaviour of the error bars. They naturally grow in regions away from training data where we have high uncertainty about the interpolating function. In their standard form GPs have several limitations, which can be divided into two broad categories: computational difficulties for large data sets, and restrictive modelling assumptions for complex data sets. This thesis addresses various aspects of both of these problems. The training cost for a GP has 0(N3) complexity, where N is the number of training data points. This is due to an inversion of the N x N covariance matrix. In this thesis we develop several new techniques to reduce this complexity to 0(NM2), where M is a user chosen number much smaller than N. The sparse approximation we use is based on a set of M 'pseudo-inputs' which are optimised together with hyperparameters at training time. We develop a further approximation based on clustering inputs that can be seen as a mixture of local and global approximations. Standard GPs assume a uniform noise variance. We use our sparse approximation described above as a way of relaxing this assumption. By making a modification of the sparse covariance function, we can model input dependent noise. To handle high dimensional data sets we use supervised linear dimensionality reduction. As another extension of the standard GP, we relax the Gaussianity assumption of the process by learning a nonlinear transformation of the output space. All these techniques further increase the applicability of GPs to real complex data sets. We present empirical comparisons of our algorithms with various competing techniques, and suggest problem dependent strategies to follow in practice.",2007,77,138,26,False,Computer Science,2081889.0,Edward Snelson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
431a1a620b762750ac92b35d97de67169eb8069c,https://www.semanticscholar.org/paper/431a1a620b762750ac92b35d97de67169eb8069c,DLAU: A Scalable Deep Learning Accelerator Unit on FPGA,"As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. However, the size of the networks becomes increasingly large scale due to the demands of the practical applications, which poses significant challenge to construct a high performance implementations of deep learning neural networks. In order to improve the performance as well as to maintain the low power cost, in this paper we design deep learning accelerator unit (DLAU), which is a scalable accelerator architecture for large-scale deep learning networks using field-programmable gate array (FPGA) as the hardware prototype. The DLAU accelerator employs three pipelined processing units to improve the throughput and utilizes tile techniques to explore locality for deep learning applications. Experimental results on the state-of-the-art Xilinx FPGA board demonstrate that the DLAU accelerator is able to achieve up to  $36.1 {\times }$  speedup comparing to the Intel Core2 processors, with the power consumption at 234 mW.",2016,11,191,15,True,Computer Science,2144446650.0,Chao Wang,46350220.0,Lei Gong,2116044910.0,Qi Yu,47056905.0,Xi Li,1410066063.0,Yuan Xie,8453780.0,Xuehai Zhou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c2407ecdc03eba2f5f964ba1fa944a6db96e42a0,https://www.semanticscholar.org/paper/c2407ecdc03eba2f5f964ba1fa944a6db96e42a0,Learning from a learning thermostat: lessons for intelligent systems for the home,"Everyday systems and devices in the home are becoming smarter. In order to better understand the challenges of deploying an intelligent system in the home, we studied the experience of living with an advanced thermostat, the Nest. The Nest utilizes machine learning, sensing, and networking technology, as well as eco-feedback features. We conducted interviews with 23 participants, ten of whom also participated in a three-week diary study. Our findings show that while the Nest was well-received overall, the intelligent features of the Nest were not perceived to be as useful or intuitive as expected, in particular due to the system's inability to understand the intent behind sensed behavior and users' difficulty in understanding how the Nest works. A number of participants developed workarounds for the shortcomings they encountered. Based on our observations, we propose three avenues for future development of interactive intelligent technologies for the home: exception flagging, incidental intelligibility, and constrained engagement.",2013,30,275,21,False,Computer Science,2044103.0,Rayoung Yang,1725336.0,Mark W. Newman,,,,,,,,,,,,,Engineering,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bc386debfedf3b16101b6c3274485cea78ad6bb7,https://www.semanticscholar.org/paper/bc386debfedf3b16101b6c3274485cea78ad6bb7,Machine Learning for Precision Medicine.,"Precision medicine is an emerging approach to clinical research and patient care that focuses on understanding and treating disease by integrating multimodal or 'multi-omics' data from an individual to make patient-tailored decisions. With the large and complex datasets generated using precision medicine diagnostic approaches, novel techniques to process and understand these complex data were needed. At the same time, computer science has progressed rapidly to develop techniques that enable the storage, processing, and analysis of these complex datasets, a feat that traditional statistics and early computing technologies could not accomplish. Machine learning, a branch of artificial intelligence, is a computer science methodology that aims to identify complex patterns in data that can be used to make predictions or classifications on new unseen data or for advanced exploratory data analysis. Machine learning analysis of precision medicine's multimodal data allows for broad analysis of large datasets and ultimately a greater understanding of human health and disease. This review focuses on machine learning utilization for precision medicine's ""big data"", in the context of genetics, genomics, and beyond.",2020,42,52,0,False,Biology,145933120.0,S. MacEachern,144578371.0,N. Forkert,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c9e92e16a391688230b1c07b68caa11b733dc5ba,https://www.semanticscholar.org/paper/c9e92e16a391688230b1c07b68caa11b733dc5ba,Deoxyfluorination with Sulfonyl Fluorides: Navigating Reaction Space with Machine Learning.,"Through fine-tuning of reagent and base structure, sulfonyl fluorides can efficiently fluorinate diverse classes of alcohols. We show that machine learning can map the intricate reaction landscape and enable accurate prediction of high-yielding conditions for untested substrates.",2018,2,118,1,False,Chemistry,39330771.0,M. K. Nielsen,8504486.0,Derek T Ahneman,40812964.0,O. Riera,3599914.0,A. Doyle,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3664afc0363ea024446997896ae31df145c8338c,https://www.semanticscholar.org/paper/3664afc0363ea024446997896ae31df145c8338c,Scaling the mobile millennium system in the cloud,"We report on our experience scaling up the Mobile Millennium traffic information system using cloud computing and the Spark cluster computing framework. Mobile Millennium uses machine learning to infer traffic conditions for large metropolitan areas from crowdsourced data, and Spark was specifically designed to support such applications. Many studies of cloud computing frameworks have demonstrated scalability and performance improvements for simple machine learning algorithms. Our experience implementing a real-world machine learning-based application corroborates such benefits, but we also encountered several challenges that have not been widely reported. These include: managing large parameter vectors, using memory efficiently, and integrating with the application's existing storage infrastructure. This paper describes these challenges and the changes they required in both the Spark framework and the Mobile Millennium software. While we focus on a system for traffic estimation, we believe that the lessons learned are applicable to other machine learning-based applications.",2011,30,75,7,False,Computer Science,144023658.0,Timothy Hunter,46756560.0,Teodor Mihai Moldovan,143834867.0,M. Zaharia,2100728.0,Samy Merzgui,3376832.0,Justin Ma,143666627.0,M. Franklin,1689992.0,P. Abbeel,1705102.0,A. Bayen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
de2be42659be5c43c1a992b5d7fe6daf14e571dd,https://www.semanticscholar.org/paper/de2be42659be5c43c1a992b5d7fe6daf14e571dd,AID: A Benchmark Data Set for Performance Evaluation of Aerial Scene Classification,"Aerial scene classification, which aims to automatically label an aerial image with a specific semantic category, is a fundamental problem for understanding high-resolution remote sensing imagery. In recent years, it has become an active task in the remote sensing area, and numerous algorithms have been proposed for this task, including many machine learning and data-driven approaches. However, the existing data sets for aerial scene classification, such as UC-Merced data set and WHU-RS19, contain relatively small sizes, and the results on them are already saturated. This largely limits the development of scene classification algorithms. This paper describes the Aerial Image data set (AID): a large-scale data set for aerial scene classification. The goal of AID is to advance the state of the arts in scene classification of remote sensing images. For creating AID, we collect and annotate more than 10000 aerial scene images. In addition, a comprehensive review of the existing aerial scene classification techniques as well as recent widely used deep learning methods is given. Finally, we provide a performance analysis of typical aerial scene classification and deep learning approaches on AID, which can be served as the baseline results on this benchmark.",2016,100,876,248,True,Computer Science,39943835.0,Gui-Song Xia,49268477.0,Jingwen Hu,144322708.0,Fan Hu,2276155.0,Baoguang Shi,145905113.0,X. Bai,2798207.0,Y. Zhong,9802604.0,Liang-pei Zhang,7828998.0,Xiaoqiang Lu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
adfb8b2e9e002c536d68eb4dbd0c5fbca2694a6a,https://www.semanticscholar.org/paper/adfb8b2e9e002c536d68eb4dbd0c5fbca2694a6a,Low-Power Neuromorphic Hardware for Signal Processing Applications: A review of architectural and system-level design approaches,"Machine learning has emerged as the dominant tool for implementing complex cognitive tasks that require supervised, unsupervised, and reinforcement learning. While the resulting machines have demonstrated in some cases even superhuman performance, their energy consumption has often proved to be prohibitive in the absence of costly supercomputers. Most state-of-the-art machine-learning solutions are based on memoryless models of neurons. This is unlike the neurons in the human brain that encode and process information using temporal information in spike events. The different computing principles underlying biological neurons and how they combine together to efficiently process information is believed to be a key factor behind their superior efficiency compared to current machine-learning systems.",2019,41,77,3,False,Computer Science,9214677.0,B. Rajendran,145428675.0,A. Sebastian,2587435.0,M. Schmuker,1753812.0,N. Srinivasa,2977652.0,E. Eleftheriou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2b73cefdc68471ec4a9eee3aa653b86f46abc10e,https://www.semanticscholar.org/paper/2b73cefdc68471ec4a9eee3aa653b86f46abc10e,Human-Centric Justification of Machine Learning Predictions,"Human decision makers in many domains can make use of predictions made by machine learning models in their decision making process, but the usability of these predictions is limited if the human is unable to justify his or her trust in the prediction. We propose a novel approach to producing justifications that is geared towards users without machine learning expertise, focusing on domain knowledge and on human reasoning, and utilizing natural language generation. Through a task-based experiment, we show that our approach significantly helps humans to correctly decide whether or not predictions are accurate, and significantly increases their satisfaction with the justification.",2017,43,72,9,True,Computer Science,20402453.0,Or Biran,145590324.0,K. McKeown,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eb777433ae75f71aee623e0eb957ebaa26e54f2a,https://www.semanticscholar.org/paper/eb777433ae75f71aee623e0eb957ebaa26e54f2a,Classification of Phishing Email Using Random Forest Machine Learning Technique,"Phishing is one of the major challenges faced by the world of e-commerce today. Thanks to phishing attacks, billions of dollars have been lost by many companies and individuals. In 2012, an online report put the loss due to phishing attack at about $1.5 billion. This global impact of phishing attacks will continue to be on the increase and thus requires more efficient phishing detection techniques to curb the menace. This paper investigates and reports the use of random forest machine learning algorithm in classification of phishing attacks, with the major objective of developing an improved phishing email classifier with better prediction accuracy and fewer numbers of features. From a dataset consisting of 2000 phishing and ham emails, a set of prominent phishing email features (identified from the literature) were extracted and used by the machine learning algorithm with a resulting classification accuracy of 99.7% and low false negative (FN) and false positive (FP) rates.",2014,23,123,3,True,Mathematics,2555593.0,A. A. Akinyelu,1703538.0,A. Adewumi,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36c6f6f5c54e05b3d18b7e8825d2da8e859de43a,https://www.semanticscholar.org/paper/36c6f6f5c54e05b3d18b7e8825d2da8e859de43a,Fault Diagnosis for Rotating Machinery Using Vibration Measurement Deep Statistical Feature Learning,"Fault diagnosis is important for the maintenance of rotating machinery. The detection of faults and fault patterns is a challenging part of machinery fault diagnosis. To tackle this problem, a model for deep statistical feature learning from vibration measurements of rotating machinery is presented in this paper. Vibration sensor signals collected from rotating mechanical systems are represented in the time, frequency, and time-frequency domains, each of which is then used to produce a statistical feature set. For learning statistical features, real-value Gaussian-Bernoulli restricted Boltzmann machines (GRBMs) are stacked to develop a Gaussian-Bernoulli deep Boltzmann machine (GDBM). The suggested approach is applied as a deep statistical feature learning tool for both gearbox and bearing systems. The fault classification performances in experiments using this approach are 95.17% for the gearbox, and 91.75% for the bearing system. The proposed approach is compared to such standard methods as a support vector machine, GRBM and a combination model. In experiments, the best fault classification rate was detected using the proposed model. The results show that deep learning with statistical feature extraction has an essential improvement potential for diagnosing rotating machinery faults.",2016,51,166,2,True,Computer Science,39923498.0,Chuan Li,143901620.0,Réne-Vinicio Sánchez,40446868.0,G. Zurita,1403032235.0,Mariela Cerrada-Lozada,144069762.0,Diego Cabrera,,,,,,,Medicine,Engineering,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
32ad092013a7f8a7aed54e1d187d12f8e88ef67b,https://www.semanticscholar.org/paper/32ad092013a7f8a7aed54e1d187d12f8e88ef67b,Machine health monitoring with LSTM networks,"Effective machine health monitoring systems are critical to modern manufacturing systems and industries. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, sensory data that is a kind of sequential data can not serve as direct meaningful representations for machine conditions due to its noise, varying length and irregular sampling. A majority of previous models focus on feature extraction/fusion methods that involve expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, representation learning from raw data has been redefined. Among deep learning models, Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data. Therefore, LSTMs is able to work on the sensory data of machine condition. Here, the first study about a empirical evaluation of LSTMs-based machine health monitoring systems is presented. A real life tool wear test is introduced. Basic and deep LSTMs are designed to predict the actual tool wear based on raw sensory data. The experimental results have shown that our models, especially deep LSTMs, are able to outperform several state-of-arts baseline methods.",2016,31,121,9,False,Computer Science,49832912.0,Rui Zhao,49605588.0,Jinjiang Wang,35374692.0,Ruqiang Yan,144067957.0,K. Mao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98024b18f7e78d9a3568b67336d9aa81321a7c42,https://www.semanticscholar.org/paper/98024b18f7e78d9a3568b67336d9aa81321a7c42,Distributed stochastic optimization and learning,"We consider the problem of distributed stochastic optimization, where each of several machines has access to samples from the same source distribution, and the goal is to jointly optimize the expected objective w.r.t. the source distribution, minimizing: (1) overall runtime; (2) communication costs; (3) number of samples used. We study this problem systematically, highlighting fundamental limitations, and differences versus distributed consensus problems where each machine has a different, independent, objective. We show how the best known guarantees are obtained by an accelerated mini-batched SGD approach, and contrast the runtime and sample costs of the approach with those of other distributed optimization algorithms.",2014,32,131,3,True,Computer Science,1768909.0,O. Shamir,1706280.0,Nathan Srebro,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f4eb3e0ee8e0e6e842d1b855bb6ef22dbc098e0,https://www.semanticscholar.org/paper/5f4eb3e0ee8e0e6e842d1b855bb6ef22dbc098e0,NLP Techniques for Term Extraction and Ontology Population,"This chapter investigates NLP techniques for ontology population, using a combination of rule-based approaches and machine learning. We describe a method for term recognition using linguistic and statistical techniques, making use of contextual information to bootstrap learning. We then investigate how term recognition techniques can be useful for the wider task of information extraction, making use of similarity metrics and contextual information. We describe two tools we have developed which make use of contextual information to help the development of rules for named entity recognition. Finally, we evaluate our ontology-based information extraction results using a novel technique we have developed which makes use of similarity-based metrics first developed for term recognition.",2008,46,149,8,False,Computer Science,2144272.0,D. Maynard,121704297.0,Yaoyong Li,48304048.0,Wim Peters,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
72c16b9622725a2c9b3395247c4499bd24bb72ea,https://www.semanticscholar.org/paper/72c16b9622725a2c9b3395247c4499bd24bb72ea,Record linkage: similarity measures and algorithms,"This tutorial provides a comprehensive and cohesive overview of the key research results in the area of record linkage methodologies and algorithms for identifying approximate duplicate records, and available tools for this purpose. It encompasses techniques introduced in several communities including databases, information retrieval, statistics and machine learning. It aims to identify similarities and differences across the techniques as well as their merits and limitations.",2006,53,344,15,False,Computer Science,1721062.0,N. Koudas,1770124.0,Sunita Sarawagi,145860176.0,D. Srivastava,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
110210b51263b82f75ce62457d989586ed6d11da,https://www.semanticscholar.org/paper/110210b51263b82f75ce62457d989586ed6d11da,Improving Unmanned Aerial Vehicle Remote Sensing-Based Rice Nitrogen Nutrition Index Prediction with Machine Learning,"Optimizing nitrogen (N) management in rice is crucial for China’s food security and sustainable agricultural development. Nondestructive crop growth monitoring based on remote sensing technologies can accurately assess crop N status, which may be used to guide the in-season site-specific N recommendations. The fixed-wing unmanned aerial vehicle (UAV)-based remote sensing is a low-cost, easy-to-operate technology for collecting spectral reflectance imagery, an important data source for precision N management. The relationships between many vegetation indices (VIs) derived from spectral reflectance data and crop parameters are known to be nonlinear. As a result, nonlinear machine learning methods have the potential to improve the estimation accuracy. The objective of this study was to evaluate five different approaches for estimating rice (Oryza sativa L.) aboveground biomass (AGB), plant N uptake (PNU), and N nutrition index (NNI) at stem elongation (SE) and heading (HD) stages in Northeast China: (1) single VI (SVI); (2) stepwise multiple linear regression (SMLR); (3) random forest (RF); (4) support vector machine (SVM); and (5) artificial neural networks (ANN) regression. The results indicated that machine learning methods improved the NNI estimation compared to VI-SLR and SMLR methods. The RF algorithm performed the best for estimating NNI (R2 = 0.94 (SE) and 0.96 (HD) for calibration and 0.61 (SE) and 0.79 (HD) for validation). The root mean square errors (RMSEs) were 0.09, and the relative errors were <10% in all the models. It is concluded that the RF machine learning regression can significantly improve the estimation of rice N status using UAV remote sensing. The application machine learning methods offers a new opportunity to better use remote sensing data for monitoring crop growth conditions and guiding precision crop management. More studies are needed to further improve these machine learning-based models by combining both remote sensing data and other related soil, weather, and management information for applications in precision N and crop management.",2020,92,80,5,True,Computer Science,1491595275.0,H. Zha,1953258.0,Y. Miao,2118914363.0,Tiantian Wang,2144463030.0,Yue Li,2155705606.0,Jing Zhang,2152378596.0,Wei-Wei Sun,1491554147.0,Zhengqi Feng,3480624.0,K. Kusnierek,Environmental Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0eb2e4a205a628ab059cab41d3b772f614ad29f2,https://www.semanticscholar.org/paper/0eb2e4a205a628ab059cab41d3b772f614ad29f2,Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines,"To allow the hidden units of a restricted Boltzmann machine to model the transformation between two successive images, Memisevic and Hinton (2007) introduced three-way multiplicative interactions that use the intensity of a pixel in the first image as a multiplicative gain on a learned, symmetric weight between a pixel in the second image and a hidden unit. This creates cubically many parameters, which form a three-dimensional interaction tensor. We describe a low-rank approximation to this interaction tensor that uses a sum of factors, each of which is a three-way outer product. This approximation allows efficient learning of transformations between larger image patches. Since each factor can be viewed as an image filter, the model as a whole learns optimal filter pairs for efficiently representing transformations. We demonstrate the learning of optimal filter pairs from various synthetic and real image sequences. We also show how learning about image transformations allows the model to perform a simple visual analogy task, and we show how a completely unsupervised network trained on transformations perceives multiple motions of transparent dot patterns in the same way as humans.",2010,24,278,26,False,Mathematics,1710604.0,R. Memisevic,1695689.0,Geoffrey E. Hinton,,,,,,,,,,,,,Computer Science,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47a89286020180225e10a03f99ffc3c697ef841f,https://www.semanticscholar.org/paper/47a89286020180225e10a03f99ffc3c697ef841f,Machine Learning from Schools about Energy Efficiency,"We use high-frequency panel data on electricity consumption to study the effectiveness of energy efficiency upgrades in K–12 schools in California. Using a panel fixed effects approach, we find that these upgrades deliver between 12% and 86% of expected savings, depending on specification and treatment of outliers. Using machine learning to inform our specification choice, we estimate a narrower range: 52%–98%, with a central estimate of 60%. These results imply that upgrades are performing less well than ex ante predictions on average, although we can reject some of the very low realization rates found in prior work.",2017,88,75,12,True,Engineering,72160326.0,Fiona Burlig,2714446.0,C. Knittel,38020488.0,D. Rapson,101077316.0,Mar Reguant,93362972.0,Catherine Wolfram,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
32c4542c5c094cface182a46c58cc537c8e1568c,https://www.semanticscholar.org/paper/32c4542c5c094cface182a46c58cc537c8e1568c,OpinionMiner: a novel machine learning system for web opinion mining and extraction,"Merchants selling products on the Web often ask their customers to share their opinions and hands-on experiences on products they have purchased. Unfortunately, reading through all customer reviews is difficult, especially for popular items, the number of reviews can be up to hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision. The OpinionMiner system designed in this work aims to mine customer reviews of a product and extract high detailed product entities on which reviewers express their opinions. Opinion expressions are identified and opinion orientations for each recognized product entity are classified as positive or negative. Different from previous approaches that employed rule-based or statistical techniques, we propose a novel machine learning approach built under the framework of lexicalized HMMs. The approach naturally integrates multiple important linguistic features into automatic learning. In this paper, we describe the architecture and main components of the system. The evaluation of the proposed method is presented based on processing the online product reviews from Amazon and other publicly available datasets.",2009,13,317,15,False,Computer Science,37497345.0,Wei Jin,27216167.0,H. H. Ho,1748081.0,R. Srihari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94cb8e3a285b64e95bd199bbdef26330754a640f,https://www.semanticscholar.org/paper/94cb8e3a285b64e95bd199bbdef26330754a640f,A Low-Power Processor With Configurable Embedded Machine-Learning Accelerators for High-Order and Adaptive Analysis of Medical-Sensor Signals,"Low-power sensing technologies have emerged for acquiring physiologically indicative patient signals. However, to enable devices with high clinical value, a critical requirement is the ability to analyze the signals to extract specific medical information. Yet given the complexities of the underlying processes, signal analysis poses numerous challenges. Data-driven methods based on machine learning offer distinct solutions, but unfortunately the computations are not well supported by traditional DSP. This paper presents a custom processor that integrates a CPU with configurable accelerators for discriminative machine-learning functions. A support-vector-machine accelerator realizes various classification algorithms as well as various kernel functions and kernel formulations, enabling range of points within an accuracy-versus-energy and -memory trade space. An accelerator for embedded active learning enables prospective adaptation of the signal models by utilizing sensed data for patient-specific customization, while minimizing the effort from human experts. The prototype is implemented in 130-nm CMOS and operates from 1.2 V-0.55 V (0.7 V for SRAMs). Medical applications for EEG-based seizure detection and ECG-based cardiac-arrhythmia detection are demonstrated using clinical data, while consuming 273 μJ and 124 μJ per detection, respectively; this represents 62.4&times; and 144.7&times; energy reduction compared to an implementation based on the CPU. A patient-adaptive cardiac-arrhythmia detector is also demonstrated, reducing the analysis-effort required for model customization by 20 &times;.",2013,37,146,11,False,Computer Science,2145186104.0,Kyong-Ho Lee,145020569.0,N. Verma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23accf0617f67c385ecf1d9276b89e5dc45b6892,https://www.semanticscholar.org/paper/23accf0617f67c385ecf1d9276b89e5dc45b6892,A Study of Machine Learning in Wireless Sensor Network,"Within this Paper, a concept of machine learning strategies suggested. In this investigation to address the design issues in WSNs is introduced. As can be viewed within this paper, countless endeavors have induced up to now; several layout issues in wireless sensor networks have been remedied employing numerous machine learning strategies. Utilizing machine learning based algorithms in WSNs need to deem numerous constraints, for instance, minimal sources of the network application that really needs distinct events to be tracked as well as other operational and non-operational aspects. Index Terms – Wireless Sensor Network, Machine Learning, Supervised Machine Learning, Unsupervised Machine Learning.",2017,29,39,1,True,Computer Science,9102599.0,Z. A. Khan,47389780.0,A. Samad,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fc6fa502b2d81845ac555e7bfaf8e2d9bc24905a,https://www.semanticscholar.org/paper/fc6fa502b2d81845ac555e7bfaf8e2d9bc24905a,Forgotten Siblings: Unifying Attacks on Machine Learning and Digital Watermarking,"Machine learning is increasingly used in securitycritical applications, such as autonomous driving, face recognition, and malware detection. Most learning methods, however, have not been designed with security in mind and thus are vulnerable to different types of attacks. This problem has motivated the research field of adversarial machine learning that is concerned with attacking and defending learning methods. Concurrently, a separate line of research has tackled a very similar problem: In digital watermarking, a pattern is embedded in a signal in the presence of an adversary. As a consequence, this research field has also extensively studied techniques for attacking and defending watermarking methods. The two research communities have worked in parallel so far, unnoticeably developing similar attack and defense strategies. This paper is a first effort to bring these communities together. To this end, we present a unified notation of blackbox attacks against machine learning and watermarking. To demonstrate its efficacy, we apply concepts from watermarking to machine learning and vice versa. We show that countermeasures from watermarking can mitigate recent model-extraction attacks and, similarly, that techniques for hardening machine learning can fend off oracle attacks against watermarks. We further demonstrate a novel threat for watermarking schemes based on recent deep learning attacks from adversarial learning. Our work provides a conceptual link between two research fields and thereby opens novel directions for improving the security of both, machine learning and digital watermarking.",2018,70,49,4,False,Computer Science,47118838.0,Erwin Quiring,79405068.0,Dan Arp,144825749.0,K. Rieck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
952da12326891b0a96f29a73b19b20b27a76f9aa,https://www.semanticscholar.org/paper/952da12326891b0a96f29a73b19b20b27a76f9aa,Distributed Machine Learning with a Serverless Architecture,"The need to scale up machine learning, in the presence of a rapid growth of data both in volume and in variety, has sparked broad interests to develop distributed machine learning systems, typically based on parameter servers. However, since these systems are based on a dedicated cluster of physical or virtual machines, they have posed non-trivial cluster management overhead to machine learning practitioners and data scientists. In addition, there exists an inherent mismatch between the dynamically varying resource demands during a model training job and the inflexible resource provisioning model of current cluster-based systems.In this paper, we propose SIREN, an asynchronous distributed machine learning framework based on the emerging serverless architecture, with which stateless functions can be executed in the cloud without the complexity of building and maintaining virtual machine infrastructures. With SIREN, we are able to achieve a higher level of parallelism and elasticity by using a swarm of stateless functions, each working on a different batch of data, while greatly reducing system configuration overhead. Furthermore, we propose a scheduler based on Deep Reinforcement Learning to dynamically control the number and memory size of the stateless functions that should be used in each training epoch. The scheduler learns from the training process itself, in pursuit for the minimum possible training time given a cost. With our real-world prototype implementation on AWS Lambda, extensive experimental results have shown that SIREN can reduce model training time by up to 44%, as compared to traditional machine learning training benchmarks on AWS EC2 at the same cost.",2019,16,64,9,False,Computer Science,39483391.0,Hao Wang,1714907.0,Di Niu,91269142.0,Baochun Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b107a64c9dc343ac35231c7959090bbc3059203f,https://www.semanticscholar.org/paper/b107a64c9dc343ac35231c7959090bbc3059203f,Distributed Statistical Machine Learning in Adversarial Settings,"We consider the distributed statistical learning problem over decentralized systems that are prone to adversarial attacks. This setup arises in many practical applications, including Google's Federated Learning. Formally, we focus on a decentralized system that consists of a parameter server and m working machines; each working machine keeps N/m data samples, where N is the total number of samples. In each iteration, up to q of the m working machines suffer Byzantine faults -- a faulty machine in the given iteration behaves arbitrarily badly against the system and has complete knowledge of the system. Additionally, the sets of faulty machines may be different across iterations. Our goal is to design robust algorithms such that the system can learn the underlying true parameter, which is of dimension d, despite the interruption of the Byzantine attacks. In this paper, based on the geometric median of means of the gradients, we propose a simple variant of the classical gradient descent method. We show that our method can tolerate q Byzantine failures up to 2(1+ε)q ≤ for an arbitrarily small but fixed constant ε > 0. The parameter estimate converges in O(log N) rounds with an estimation error on the order of max{√dq/N, √d/N, which is larger than the minimax-optimal error rate √d/N in the centralized and failure-free setting by at most a factor of √q. The total computational complexity of our algorithm is of O((Nd/m) log N) at each working machine and O(md + kd log3 N) at the central server, and the total communication cost is of O(m d log N). We further provide an application of our general results to the linear regression problem. A key challenge arises in the above problem is that Byzantine failures create arbitrary and unspecified dependency among the iterations and the aggregated gradients. To handle this issue in the analysis, we prove that the aggregated gradient, as a function of model parameter, converges uniformly to the true gradient function.",2017,38,78,5,False,Computer Science,51310474.0,Yudong Chen,2255869.0,Lili Su,47883294.0,Jiaming Xu,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8589aa697cd170c793c4c729b81b6f6dfacb012c,https://www.semanticscholar.org/paper/8589aa697cd170c793c4c729b81b6f6dfacb012c,MLCapsule: Guarded Offline Deployment of Machine Learning as a Service,"Machine Learning as a Service (MLaaS) is a popular and convenient way to access a trained machine learning (ML) model trough an API. However, if the user’s input is sensitive, sending it to the server is not an option. Equally, the service provider does not want to share the model by sending it to the client for protecting its intellectual property and pay-per-query business model. As a solution, we propose MLCapsule, a guarded offline deployment of MLaaS. MLCapsule executes the machine learning model locally on the user’s client and therefore the data never leaves the client. Meanwhile, we show that MLCapsule is able to offer the service provider the same level of control and security of its model as the commonly used server-side execution. Beyond protecting against direct model access, we demonstrate that MLCapsule allows for implementing defenses against advanced attacks on machine learning models such as model stealing, reverse engineering and membership inference.",2018,52,61,5,True,Computer Science,2257711.0,L. Hanzlik,2145954003.0,Yang Zhang,39221858.0,Kathrin Grosse,66697271.0,A. Salem,49799275.0,Maximilian Augustin,144588806.0,M. Backes,1739548.0,Mario Fritz,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f3a435472d92a3e9ef4acfb49a3dcdd02fa87242,https://www.semanticscholar.org/paper/f3a435472d92a3e9ef4acfb49a3dcdd02fa87242,Support Vector Machines with Applications,"Support vector machines (SVMs) appeared in the early nineties as optimal margin classiers in the context of Vapnikis statistical learning theory. Since then SVMs have been successfully applied to real-world data analysis problems, often providing improved results compared with other techniques. The SVMs operate within the framework of regularization theory by minimizing an empirical risk in a well-posed and consistent way. A clear advantage of the support vector approach is that sparse solutions to classi- cation and regression problems are usually obtained: only a few samples are involved in the determination of the classication or regression functions. This fact facilitates the application of SVMs to problems that involve a large amount of data, such as text processing and bioinformatics tasks. This paper is intended as an introduction to SVMs and their applications, emphasizing their key features. In addition, some algorithmic extensions and illustrative real-world applications of SVMs are shown.",2006,162,185,7,True,Mathematics,1747176.0,Javier M. Moguerza,2149636456.0,A. Muñoz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a4a6011cd378adb86b168f51ce4cb144207ec354,https://www.semanticscholar.org/paper/a4a6011cd378adb86b168f51ce4cb144207ec354,Malware Classification with Deep Convolutional Neural Networks,"In this paper, we propose a deep learning framework for malware classification. There has been a huge increase in the volume of malware in recent years which poses a serious security threat to financial institutions, businesses and individuals. In order to combat the proliferation of malware, new strategies are essential to quickly identify and classify malware samples so that their behavior can be analyzed. Machine learning approaches are becoming popular for classifying malware, however, most of the existing machine learning methods for malware classification use shallow learning algorithms (e.g. SVM). Recently, Convolutional Neural Networks (CNN), a deep learning approach, have shown superior performance compared to traditional learning algorithms, especially in tasks such as image classification. Motivated by this success, we propose a CNN-based architecture to classify malware samples. We convert malware binaries to grayscale images and subsequently train a CNN for classification. Experiments on two challenging malware classification datasets, Malimg and Microsoft malware, demonstrate that our method achieves better than the state-of-the-art performance. The proposed method achieves 98.52% and 99.97% accuracy on the Malimg and Microsoft datasets respectively.",2018,18,166,9,False,Computer Science,9543926.0,Mahmoud Kalash,2532612.0,Mrigank Rochan,34775043.0,N. Mohammed,2866780.0,Neil D. B. Bruce,46396571.0,Yang Wang,2670601.0,F. Iqbal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cc365ecf5e244c044837d365b7212e300867cac5,https://www.semanticscholar.org/paper/cc365ecf5e244c044837d365b7212e300867cac5,Secure Federated Transfer Learning,"Machine learning relies on the availability of a vast amount of data for training. However, in reality, most data are scattered across different organizations and cannot be easily integrated under many legal and practical constraints. In this paper, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical models under a data federation. The federation allows knowledge to be shared without compromising user privacy, and enables complimentary knowledge to be transferred in the network. As a result, a target-domain party can build more flexible and powerful models by leveraging rich labels from a source-domain party. A secure transfer cross validation approach is also proposed to guard the FTL performance under the federation. The framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the nonprivacy-preserving approach. This framework is very flexible and can be effectively adapted to various secure multi-party machine learning tasks.",2018,35,101,13,False,Computer Science,1614034792.0,Yang Liu,11573257.0,Tianjian Chen,153096457.0,Qiang Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c55c7e0203f3add64ac3d3f60943ae201907ed68,https://www.semanticscholar.org/paper/c55c7e0203f3add64ac3d3f60943ae201907ed68,Accelerating Federated Learning via Momentum Gradient Descent,"Federated learning (FL) provides a communication-efficient approach to solve machine learning problems concerning distributed data, without sending raw data to a central server. However, existing works on FL only utilize first-order gradient descent (GD) and do not consider the preceding iterations to gradient update which can potentially accelerate convergence. In this article, we consider momentum term which relates to the last iteration. The proposed momentum federated learning (MFL) uses momentum gradient descent (MGD) in the local update step of FL system. We establish global convergence properties of MFL and derive an upper bound on MFL convergence rate. Comparing the upper bounds on MFL and FL convergence rates, we provide conditions in which MFL accelerates the convergence. For different machine learning models, the convergence performance of MFL is evaluated based on experiments with MNIST and CIFAR-10 datasets. Simulation results confirm that MFL is globally convergent and further reveal significant convergence improvement over FL.",2019,42,124,15,True,Computer Science,,Wei Liu,2146026799.0,Li Chen,1809404.0,Yunfei Chen,50550029.0,Wenyi Zhang,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fef3f5bac9a7b859f0c113c1689596a1ab80cfa9,https://www.semanticscholar.org/paper/fef3f5bac9a7b859f0c113c1689596a1ab80cfa9,Adversarial Examples Are a Natural Consequence of Test Error in Noise,"Over the last few years, the phenomenon of adversarial examples --- maliciously constructed inputs that fool trained machine learning models --- has captured the attention of the research community, especially when the adversary is restricted to small modifications of a correctly handled input. Less surprisingly, image classifiers also lack human-level performance on randomly corrupted images, such as images with additive Gaussian noise. In this paper we provide both empirical and theoretical evidence that these are two manifestations of the same underlying phenomenon, establishing close connections between the adversarial robustness and corruption robustness research programs. This suggests that improving adversarial robustness should go hand in hand with improving performance in the presence of more general and realistic image corruptions. Based on our results we recommend that future adversarial defenses consider evaluating the robustness of their methods to distributional shift with benchmarks such as Imagenet-C.",2019,40,243,21,False,Computer Science,46516638.0,Nic Ford,2058362.0,J. Gilmer,2483738.0,Nicholas Carlini,8132903.0,E. D. Cubuk,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a245a5b0f11a15dc2787d9abe9ec02d643ee6de0,https://www.semanticscholar.org/paper/a245a5b0f11a15dc2787d9abe9ec02d643ee6de0,A Machine Learning Architecture for Optimizing Web Search Engines,"Indexing systems for the World Wide Web, such as Lycos and Alta Vista, play an essential role in making the Web useful and usable. These systems are based on Information Retrieval methods for indexing plain text documents, but also include heuristics for adjusting their document rankings based on the special HTML structure of Web documents. In this paper, we describe a wide range of such heuristics|including a novel one inspired by reinforcement learning techniques for propagating rewards through a graph|which can be used to a ect a search engine's rankings. We then demonstrate a system which learns to combine these heuristics automatically, based on feedback collected unintrusively from users, resulting in much improved rankings.",1999,18,163,7,False,Computer Science,3214276.0,J. Boyan,1758106.0,D. Freitag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bb88e9db1cad92a79044e94ad06c827502cf840b,https://www.semanticscholar.org/paper/bb88e9db1cad92a79044e94ad06c827502cf840b,Paraphrase acquisition via crowdsourcing and machine learning,"To paraphrase means to rewrite content while preserving the original meaning. Paraphrasing is important in fields such as text reuse in journalism, anonymizing work, and improving the quality of customer-written reviews. This article contributes to paraphrase acquisition and focuses on two aspects that are not addressed by current research: (1) acquisition via crowdsourcing, and (2) acquisition of passage-level samples. The challenge of the first aspect is automatic quality assurance; without such a means the crowdsourcing paradigm is not effective, and without crowdsourcing the creation of test corpora is unacceptably expensive for realistic order of magnitudes. The second aspect addresses the deficit that most of the previous work in generating and evaluating paraphrases has been conducted using sentence-level paraphrases or shorter; these short-sample analyses are limited in terms of application to plagiarism detection, for example. We present the Webis Crowd Paraphrase Corpus 2011 (Webis-CPC-11), which recently formed part of the PAN 2010 international plagiarism detection competition. This corpus comprises passage-level paraphrases with 4067 positive samples and 3792 negative samples that failed our criteria, using Amazon's Mechanical Turk for crowdsourcing. In this article, we review the lessons learned at PAN 2010, and explain in detail the method used to construct the corpus. The empirical contributions include machine learning experiments to explore if passage-level paraphrases can be identified in a two-class classification problem using paraphrase similarity features, and we find that a k-nearest-neighbor classifier can correctly distinguish between paraphrased and nonparaphrased samples with 0.980 precision at 0.523 recall. This result implies that just under half of our samples must be discarded (remaining 0.477 fraction), but our cost analysis shows that the automation we introduce results in a 18% financial saving and over 100 hours of time returned to the researchers when repeating a similar corpus design. On the other hand, when building an unrelated corpus requiring, say, 25% training data for the automated component, we show that the financial outcome is cost neutral, while still returning over 70 hours of time to the researchers. The work presented here is the first to join the paraphrasing and plagiarism communities.",2013,68,85,16,False,Computer Science,3087610.0,Steven Burrows,3046200.0,Martin Potthast,144146081.0,Benno Stein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49d51ca06ed21a81d85489acc207cedc98c5dafe,https://www.semanticscholar.org/paper/49d51ca06ed21a81d85489acc207cedc98c5dafe,Preimage Problem in Kernel-Based Machine Learning,"While the nonlinear mapping from the input space to the feature space is central in kernel methods, the reverse mapping from the feature space back to the input space is also of primary interest. This is the case in many applications, including kernel principal component analysis (PCA) for signal and image denoising. Unfortunately, it turns out that the reverse mapping generally does not exist and only a few elements in the feature space have a valid preimage in the input space. The preimage problem consists of finding an approximate solution by identifying data in the input space based on their corresponding features in the high dimensional feature space. It is essentially a dimensionality-reduction problem, and both have been intimately connected in their historical evolution, as studied in this article.",2011,53,92,0,True,Computer Science,1703806.0,P. Honeine,145664777.0,C. Richard,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c1ba2fd31016c3c52f28890bfa2b14567c6fa2e9,https://www.semanticscholar.org/paper/c1ba2fd31016c3c52f28890bfa2b14567c6fa2e9,Reconciling modern machine learning and the bias-variance trade-off,"The question of generalization in machine learning---how algorithms are able to learn predictors from a training sample to make accurate predictions out-of-sample---is revisited in light of the recent breakthroughs in modern machine learning technology. The classical approach to understanding generalization is based on bias-variance trade-offs, where model complexity is carefully calibrated so that the fit on the training sample reflects performance out-of-sample. However, it is now common practice to fit highly complex models like deep neural networks to data with (nearly) zero training error, and yet these interpolating predictors are observed to have good out-of-sample accuracy even for noisy data. How can the classical understanding of generalization be reconciled with these observations from modern machine learning practice? In this paper, we bridge the two regimes by exhibiting a new ""double descent"" risk curve that extends the traditional U-shaped bias-variance curve beyond the point of interpolation. Specifically, the curve shows that as soon as the model complexity is high enough to achieve interpolation on the training sample---a point that we call the ""interpolation threshold""---the risk of suitably chosen interpolating predictors from these models can, in fact, be decreasing as the model complexity increases, often below the risk achieved using non-interpolating models. The double descent risk curve is demonstrated for a broad range of models, including neural networks and random forests, and a mechanism for producing this behavior is posited.",2018,23,120,14,False,Computer Science,145520115.0,Mikhail Belkin,143724861.0,Daniel J. Hsu,143791100.0,Siyuan Ma,151213231.0,Soumik Mandal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43b094cc2aa3935cae3a5fecdd5eb57b36d7e784,https://www.semanticscholar.org/paper/43b094cc2aa3935cae3a5fecdd5eb57b36d7e784,Knowledge Discovery in Databases,"From the Publisher: Knowledge Discovery in Databases brings together current research on the exciting problem of discovering useful and interesting knowledge in databases. It spans many different approaches to discovery, including inductive learning, bayesian statistics, semantic query optimization, knowledge acquisition for expert systems, information theory, and fuzzy 1 sets. The rapid growth in the number and size of databases creates a need for tools and techniques for intelligent data understanding. Relationships and patterns in data may enable a manufacturer to discover the cause of a persistent disk failure or the reason for consumer complaints. But today's databases hide their secrets beneath a cover of overwhelming detail. The task of uncovering these secrets is called ""discovery in databases."" This loosely defined subfield of machine learning is concerned with discovery from large amounts of possible uncertain data. Its techniques range from statistics to the use of domain knowledge to control search. Following an overview of knowledge discovery in databases, thirty technical chapters are grouped in seven parts which cover discovery of quantitative laws, discovery of qualitative laws, using knowledge in discovery, data summarization, domain specific discovery methods, integrated and multi-paradigm systems, and methodology and application issues. An important thread running through the collection is reliance on domain knowledge, starting with general methods and progressing to specialized methods where domain knowledge is built in. Gregory Piatetski-Shapiro is Senior Member of Technical Staff and Principal Investigator of the Knowledge Discovery Project at GTELaboratories. William Frawley is Principal Member of Technical Staff at GTE and Principal Investigator of the Learning in Expert Domains Project.",1991,0,1796,21,False,Computer Science,69851191.0,Gregory Piateski,101904886.0,W. Frawley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3cf9f206f1c6185ced288e2611a7f2bb36dbd6e8,https://www.semanticscholar.org/paper/3cf9f206f1c6185ced288e2611a7f2bb36dbd6e8,Learning the unified kernel machines for classification,"Kernel machines have been shown as the state-of-the-art learning techniques for classification. In this paper, we propose a novel general framework of learning the Unified Kernel Machines (UKM) from both labeled and unlabeled data. Our proposed framework integrates supervised learning, semi-supervised kernel learning, and active learning in a unified solution. In the suggested framework, we particularly focus our attention on designing a new semi-supervised kernel learning method, i.e., Spectral Kernel Learning (SKL), which is built on the principles of kernel target alignment and unsupervised kernel design. Our algorithm is related to an equivalent quadratic programming problem that can be efficiently solved. Empirical results have shown that our method is more effective and robust to learn the semi-supervised kernels than traditional approaches. Based on the framework, we present a specific paradigm of unified kernel machines with respect to Kernel Logistic Regresions (KLR), i.e., Unified Kernel Logistic Regression (UKLR). We evaluate our proposed UKLR classification scheme in comparison with traditional solutions. The promising results show that our proposed UKLR paradigm is more effective than the traditional classification approaches.",2006,33,72,6,False,Mathematics,1741126.0,S. Hoi,1785083.0,Michael R. Lyu,33794424.0,E. Chang,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66f816f950a09e62523640d3d38944e1ad88c86f,https://www.semanticscholar.org/paper/66f816f950a09e62523640d3d38944e1ad88c86f,The problem of tuning metaheuristics: as seen from the machine learning perspective,"A metaheuristic is a generic algorithmic template that can be used for finding high quality solutions of hard combinatorial optimization problems. To arrive at a functioning algorithm, a metaheuristic needs to be configured: typically some modules need to be instantiated and some parameters need to be tuned. We call these two problems ""structural"" and ""parametric"" tuning, respectively. More generally, we refer to the combination of the two problems as ""tuning"". Tuning is crucial to metaheuristics optimization both in academic research and for practical applications. Nevertheless, a precise definition of the tuning problem is missing in the literature. In this thesis, we show that the problem of tuning a metaheuristic can be described and solved as a machine learning problem. Using the machine learning perspective, we are able to provide a formal definition of the tuning problem. Moreover, we propose F-Race, a generic metaheuristic tuning algorithm. Our machine learning perspective also allows us to highlight some flaws in current metaheuristics research methodologies. Based on this discussion, we propose some methodological guidelines for future empirical analysis in metaheuristics research. The thesis also contains an experimental analysis of F-Race and some examples of practical applications.",2004,0,140,14,False,Computer Science,1690903.0,M. Birattari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98ab48f161d867c903dc01cd0f0e69d989f39221,https://www.semanticscholar.org/paper/98ab48f161d867c903dc01cd0f0e69d989f39221,A Survey of Machine Learning Applications for Energy-Efficient Resource Management in Cloud Computing Environments,"Ensuring energy efficiency in data centers is a crucial objective in modern cloud computing because it reduces operating costs and complies with the goals of green computing. Researchers strive to develop optimal policies for resource management in the cloud, which has many components such as virtual machine placement, task scheduling, workload consolidation, and so on. Machine learning has a major role to play in these efforts. In this paper, we provide a detailed survey of recent works in the literature which have employed machine learning (ML) to offer solutions for energy efficiency in cloud computing environments. We also present a comparative classification of the proposed methods. Furthermore, we enrich this survey by studying non-ML proposals to energy conservation in data centers, and also how ML has been applied towards other objectives in the cloud.",2015,41,41,0,False,Computer Science,2065333430.0,Mehmet C. Demirci,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3dacce6baae86dd74467e5187907b65ce1c8ca49,https://www.semanticscholar.org/paper/3dacce6baae86dd74467e5187907b65ce1c8ca49,A survey of surveys on the use of visualization for interpreting machine learning models,"Research in machine learning has become very popular in recent years, with many types of models proposed to comprehend and predict patterns and trends in data originating from different domains. As these models get more and more complex, it also becomes harder for users to assess and trust their results, since their internal operations are mostly hidden in black boxes. The interpretation of machine learning models is currently a hot topic in the information visualization community, with results showing that insights from machine learning models can lead to better predictions and improve the trustworthiness of the results. Due to this, multiple (and extensive) survey articles have been published recently trying to summarize the high number of original research papers published on the topic. But there is not always a clear definition of what these surveys cover, what is the overlap between them, which types of machine learning models they deal with, or what exactly is the scenario that the readers will find in each of them. In this article, we present a meta-analysis (i.e. a “survey of surveys”) of manually collected survey papers that refer to the visual interpretation of machine learning models, including the papers discussed in the selected surveys. The aim of our article is to serve both as a detailed summary and as a guide through this survey ecosystem by acquiring, cataloging, and presenting fundamental knowledge of the state of the art and research opportunities in the area. Our results confirm the increasing trend of interpreting machine learning with visualizations in the past years, and that visualization can assist in, for example, online training processes of deep learning models and enhancing trust into machine learning. However, the question of exactly how this assistance should take place is still considered as an open challenge of the visualization community.",2020,101,60,3,True,Computer Science,52197250.0,Angelos Chatzimparmpas,47758081.0,R. M. Martins,2810989.0,Ilir Jusufi,2569160.0,A. Kerren,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d5d7b3c75c5a7bbc605236e7c722ecfb2cf8824e,https://www.semanticscholar.org/paper/d5d7b3c75c5a7bbc605236e7c722ecfb2cf8824e,iNNvestigate neural networks!,"In recent years, deep neural networks have revolutionized many application domains of machine learning and are key components of many critical decision or predictive processes. Therefore, it is crucial that domain specialists can understand and analyze actions and pre- dictions, even of the most complex neural network architectures. Despite these arguments neural networks are often treated as black boxes. In the attempt to alleviate this short- coming many analysis methods were proposed, yet the lack of reference implementations often makes a systematic comparison between the methods a major effort. The presented library iNNvestigate addresses this by providing a common interface and out-of-the- box implementation for many analysis methods, including the reference implementation for PatternNet and PatternAttribution as well as for LRP-methods. To demonstrate the versatility of iNNvestigate, we provide an analysis of image classifications for variety of state-of-the-art neural network architectures.",2018,35,245,15,False,Computer Science,153628742.0,M. Alber,3633358.0,S. Lapuschkin,1997650.0,P. Seegerer,21810423.0,M. Hägele,33075217.0,Kristof T. Schütt,144535526.0,G. Montavon,1699054.0,W. Samek,145034054.0,K. Müller,Mathematics,,2389602.0,Sven Dähne,2113697.0,Pieter-Jan Kindermans,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5d54f61732367e4cb2bbd86845d1f8bdad4c68b1,https://www.semanticscholar.org/paper/5d54f61732367e4cb2bbd86845d1f8bdad4c68b1,Automated Text Categorization Using Support Vector Machine,"In this paper, we study the use of support vector machine in text categorization. Unlike other machine learning techniques , it allows easy incorporation of new documents into an existing trained system. Moreover, dimension reduction, which is usually imperative, now becomes optional. Thus, SVM adapts eeciently in dynamic environments that require frequent additions to the document collection. Empirical results on the Reuters-22173 collection are also discussed.",1998,14,138,6,False,Computer Science,145193332.0,J. Kwok,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ffab12aeb2717c251a4ce1df118d6741fb06617f,https://www.semanticscholar.org/paper/ffab12aeb2717c251a4ce1df118d6741fb06617f,A Primer on the Signature Method in Machine Learning,"In these notes, we wish to provide an introduction to the signature method, focusing on its basic theoretical properties and recent numerical applications. 
The notes are split into two parts. The first part focuses on the definition and fundamental properties of the signature of a path, or the path signature. We have aimed for a minimalistic approach, assuming only familiarity with classical real analysis and integration theory, and supplementing theory with straightforward examples. We have chosen to focus in detail on the principle properties of the signature which we believe are fundamental to understanding its role in applications. We also present an informal discussion on some of its deeper properties and briefly mention the role of the signature in rough paths theory, which we hope could serve as a light introduction to rough paths for the interested reader. 
The second part of these notes discusses practical applications of the path signature to the area of machine learning. The signature approach represents a non-parametric way for extraction of characteristic features from data. The data are converted into a multi-dimensional path by means of various embedding algorithms and then processed for computation of individual terms of the signature which summarise certain information contained in the data. The signature thus transforms raw data into a set of features which are used in machine learning tasks. We will review current progress in applications of signatures to machine learning problems.",2016,29,121,19,False,Mathematics,3029003.0,I. Chevyrev,3362051.0,A. Kormilitzin,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
148de9bf06862825290d6801728758bc5c6aa72b,https://www.semanticscholar.org/paper/148de9bf06862825290d6801728758bc5c6aa72b,Personalized Federated Learning using Hypernetworks,"Personalized federated learning is tasked with training machine learning models for multiple clients, each with its own data distribution. The goal is to train personalized models in a collaborative way while accounting for data disparities across clients and reducing communication costs. We propose a novel approach to this problem using hypernetworks, termed pFedHN for personalized Federated HyperNetworks. In this approach, a central hypernetwork model is trained to generate a set of models, one model for each client. This architecture provides effective parameter sharing across clients, while maintaining the capacity to generate unique and diverse personal models. Furthermore, since hypernetwork parameters are never transmitted, this approach decouples the communication cost from the trainable model size. We test pFedHN empirically in several personalized federated learning challenges and find that it outperforms previous methods. Finally, since hypernetworks share information across clients we show that pFedHN can generalize better to new clients whose distributions differ from any client observed during training.",2021,64,72,13,False,Computer Science,1587627172.0,Aviv Shamsian,90227282.0,Aviv Navon,2645055.0,Ethan Fetaya,1732280.0,Gal Chechik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eb57423ec2673dc9f880938643fa422966b4464e,https://www.semanticscholar.org/paper/eb57423ec2673dc9f880938643fa422966b4464e,Stochastic Synapses Enable Efficient Brain-Inspired Learning Machines,"Recent studies have shown that synaptic unreliability is a robust and sufficient mechanism for inducing the stochasticity observed in cortex. Here, we introduce Synaptic Sampling Machines (S2Ms), a class of neural network models that uses synaptic stochasticity as a means to Monte Carlo sampling and unsupervised learning. Similar to the original formulation of Boltzmann machines, these models can be viewed as a stochastic counterpart of Hopfield networks, but where stochasticity is induced by a random mask over the connections. Synaptic stochasticity plays the dual role of an efficient mechanism for sampling, and a regularizer during learning akin to DropConnect. A local synaptic plasticity rule implementing an event-driven form of contrastive divergence enables the learning of generative models in an on-line fashion. S2Ms perform equally well using discrete-timed artificial units (as in Hopfield networks) or continuous-timed leaky integrate and fire neurons. The learned representations are remarkably sparse and robust to reductions in bit precision and synapse pruning: removal of more than 75% of the weakest connections followed by cursory re-learning causes a negligible performance loss on benchmark classification tasks. The spiking neuron-based S2Ms outperform existing spike-based unsupervised learners, while potentially offering substantial advantages in terms of power and complexity, and are thus promising models for on-line learning in brain-inspired hardware.",2015,113,113,6,True,Medicine,1734355.0,E. Neftci,1986004.0,B. Pedroni,145940386.0,S. Joshi,1401178735.0,Maruan Al-Shedivat,2702388.0,G. Cauwenberghs,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15f237083076aa64071e5e71a7f7d708b4ae447d,https://www.semanticscholar.org/paper/15f237083076aa64071e5e71a7f7d708b4ae447d,Guest Column: A Survey of Quantum Learning Theory,"This paper surveys quantum learning theory: the theoretical aspects of machine learning using quantum computers. We describe the main results known for three models of learning: exact learning from membership queries, and Probably Approximately Correct (PAC) and agnostic learning from classical or quantum examples.",2017,89,95,5,True,Computer Science,145480730.0,Srinivasan Arunachalam,1863449.0,R. D. Wolf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bf2a55df3647f793b489d79032fd1268d0bfdb7a,https://www.semanticscholar.org/paper/bf2a55df3647f793b489d79032fd1268d0bfdb7a,Ensemble Positive Unlabeled Learning for Disease Gene Identification,"An increasing number of genes have been experimentally confirmed in recent years as causative genes to various human diseases. The newly available knowledge can be exploited by machine learning methods to discover additional unknown genes that are likely to be associated with diseases. In particular, positive unlabeled learning (PU learning) methods, which require only a positive training set P (confirmed disease genes) and an unlabeled set U (the unknown candidate genes) instead of a negative training set N, have been shown to be effective in uncovering new disease genes in the current scenario. Using only a single source of data for prediction can be susceptible to bias due to incompleteness and noise in the genomic data and a single machine learning predictor prone to bias caused by inherent limitations of individual methods. In this paper, we propose an effective PU learning framework that integrates multiple biological data sources and an ensemble of powerful machine learning classifiers for disease gene identification. Our proposed method integrates data from multiple biological sources for training PU learning classifiers. A novel ensemble-based PU learning method EPU is then used to integrate multiple PU learning classifiers to achieve accurate and robust disease gene predictions. Our evaluation experiments across six disease groups showed that EPU achieved significantly better results compared with various state-of-the-art prediction methods as well as ensemble learning classifiers. Through integrating multiple biological data sources for training and the outputs of an ensemble of PU learning classifiers for prediction, we are able to minimize the potential bias and errors in individual data sources and machine learning algorithms to achieve more accurate and robust disease gene predictions. In the future, our EPU method provides an effective framework to integrate the additional biological and computational resources for better disease gene predictions.",2014,57,89,3,True,Biology,2119185265.0,Peng Yang,39952499.0,Xiaoli Li,1689393.0,H. Chua,145367091.0,C. Kwoh,1794527.0,See-Kiong Ng,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d6cad3d5a14dccbc7e468e449704eac11722bfcd,https://www.semanticscholar.org/paper/d6cad3d5a14dccbc7e468e449704eac11722bfcd,A Survey of Learning Causality with Data,"This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from—or the same as—the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.",2018,202,196,8,True,Computer Science,2773849.0,Ruocheng Guo,144842921.0,Lu Cheng,2040455.0,Jundong Li,144974208.0,P. R. Hahn,38746648.0,Huan Liu,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f3d06c31170eff41aa54394d1e5c767d631db864,https://www.semanticscholar.org/paper/f3d06c31170eff41aa54394d1e5c767d631db864,Human computation,"Until the middle of the 20th century, a reader would have stumbled against the phrase “Human Computation” because, at that time, computers were humans carrying out calculations, not machines. Back then, a special issue on “Machine Computation” would have aroused much interest. Nowadays, things are the other way around: A reader is likely to stumble against the phrase “Human Computation” because it is, nowadays, common knowledge that machines outperform human beings in a wide range of tasks; one might even wonder how humans could contribute to computations in a useful manner! Indeed, many human skills are far away from being fully taken over by machines. For example, reading comprehension, image recognition, or finding heuristic solutions for complex computational tasks like the traveling salesman problem still is beyond the capabilities of machines. Such tasks still are within humans’ reserved domain. It therefore seems natural that combining both the skills of humans and of machines can result in a higher problem solving competence both in quantity and quality. This insight paves the way for “Human Computation” as we know it today. This special issue introduces “Human Computation” through presentations of current research projects. The first article, “Mobile Learning in Environmental CitizenScience:An initial survey of current practice inGermany”, reports on a survey of mobile learning among environmental citizen science projects. This first article offers a good overview of why projects of very different types rely on “Citizen Science”, a form of “Human Computation”. The second article, “Design and Implementation of a Platform for the Citizen Science Project Migraine Radar”, describes a Citizen Science platform based on a software",2018,0,236,12,False,Computer Science,1767012.0,François Bry,3039259.0,Clemens Schefels,2408458.0,Christoph Wieser,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c7e9f331e99cefdf9d692f716f5e9d5316d4f4e4,https://www.semanticscholar.org/paper/c7e9f331e99cefdf9d692f716f5e9d5316d4f4e4,Crowdfunding support tools: predicting success & failure,"Creative individuals increasingly rely on online crowdfunding platforms to crowdsource funding for new ventures. For novice crowdfunding project creators, however, there are few resources to turn to for assistance in the planning of crowdfunding projects. We are building a tool for novice project creators to get feedback on their project designs. One component of this tool is a comparison to existing projects. As such, we have applied a variety of machine learning classifiers to learn the concept of a successful online crowdfunding project at the time of project launch. Currently our classifier can predict with roughly 68% accuracy, whether a project will be successful or not. The classification results will eventually power a prediction segment of the proposed feedback tool. Future work involves turning the results of the machine learning algorithms into human-readable content and integrating this content into the feedback tool.",2013,13,200,17,False,Computer Science,94378170.0,M. Greenberg,144893701.0,B. Pardo,2066148405.0,K. Hariharan,145003123.0,E. Gerber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
03057ea57d9f2d9bbc8a141d51f76d5bbc715234,https://www.semanticscholar.org/paper/03057ea57d9f2d9bbc8a141d51f76d5bbc715234,Using fast weights to improve persistent contrastive divergence,"The most commonly used learning algorithm for restricted Boltzmann machines is contrastive divergence which starts a Markov chain at a data point and runs the chain for only a few iterations to get a cheap, low variance estimate of the sufficient statistics under the model. Tieleman (2008) showed that better learning can be achieved by estimating the model's statistics using a small set of persistent ""fantasy particles"" that are not reinitialized to data points after each weight update. With sufficiently small weight updates, the fantasy particles represent the equilibrium distribution accurately but to explain why the method works with much larger weight updates it is necessary to consider the interaction between the weight updates and the Markov chain. We show that the weight updates force the Markov chain to mix fast, and using this insight we develop an even faster mixing chain that uses an auxiliary set of ""fast weights"" to implement a temporary overlay on the energy landscape. The fast weights learn rapidly but also decay rapidly and do not contribute to the normal energy landscape that defines the model.",2009,16,302,36,False,Mathematics,2957517.0,T. Tieleman,1695689.0,Geoffrey E. Hinton,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27f6cdf98d1b7d1bb012462630b1231cae7c0312,https://www.semanticscholar.org/paper/27f6cdf98d1b7d1bb012462630b1231cae7c0312,Machine Learning Markets,"Prediction markets show considerable promise for developing flexible mechanisms for machine learning. Here, machine learning markets for multivariate systems are defined, and a utility-based framework is established for their analysis. This differs from the usual approach of defining static betting functions. It is shown that such markets can implement model combination methods used in machine learning, such as product of expert and mixture of expert approaches as equilibrium pricing models, by varying agent utility functions. They can also implement models composed of local potentials, and message passing methods. Prediction markets also allow for more flexible combinations, by combining multiple different utility functions. Conversely, the market mechanisms implement inference in the relevant probabilistic models. This means that market mechanism can be utilized for implementing parallelized model building and inference for probabilistic modelling.",2011,28,41,6,False,Computer Science,1728216.0,A. Storkey,,,,,,,,,,,,,,,Economics,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0cae9c0a6c57e64d2dbdd5c574e435dd33622d96,https://www.semanticscholar.org/paper/0cae9c0a6c57e64d2dbdd5c574e435dd33622d96,Identifying Nontechnical Power Loss via Spatial and Temporal Deep Learning,"Fraud detection in electricity consumption is a major challenge for power distribution companies. While many pattern recognition techniques have been applied to identify electricity theft, they often require extensive handcrafted feature engineering. Instead, through deep layers of transformation, nonlinearity, and abstraction, Deep Learning (DL) automatically extracts key features from data. In this paper, we design spatial and temporal deep learning solutions to identify nontechnical power losses (NTL), including Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) and Stacked Autoencoder. These models are evaluated in a modified IEEE 123-bus test feeder. For the same tests, we also conduct comparison experiments using three conventional machine learning approaches: Random Forest, Decision Trees and shallow Neural Networks. Experimental results demonstrate that the spatiotemporal deep learning approaches outperform conventional machine learning approaches.",2016,43,41,3,False,Computer Science,2065974931.0,Rajendra Rana Bhat,8855888.0,R. Trevizan,2066155100.0,Rahul Sengupta,2108672703.0,Xiaolin Li,144018178.0,A. Bretas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d6d58e490704b4b2124e85a0451af26a349452ba,https://www.semanticscholar.org/paper/d6d58e490704b4b2124e85a0451af26a349452ba,Crack Shape Reconstruction in Eddy Current Testing Using Machine Learning Systems for Regression,"Nondestructive testing techniques for the diagnosis of defects in solid materials can follow three steps, i.e., detection, location, and characterization. The solutions currently on the market allow for good detection and location of defects, but their characterization in terms of the exact determination of defect shape and dimensions is still an open question. This paper proposes a method for the reliable estimation of crack shape and dimensions in conductive materials using a suitable nondestructive instrument based on the eddy current principle and machine learning system postprocessing. After the design and tuning stages, a performance comparison between the two machine learning systems [artificial neural network (ANN) and support vector machine (SVM)] was carried out. An experimental validation carried out on a number of specimens with different known cracks confirmed the suitability of the proposed approach for defect characterization.",2008,23,109,5,False,Engineering,1988731.0,A. Bernieri,35222607.0,L. Ferrigno,2878948.0,M. Laracca,2922536.0,M. Molinara,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9f1ac1a1f79e8a829d0acf3a3bf35ed1512d3e53,https://www.semanticscholar.org/paper/9f1ac1a1f79e8a829d0acf3a3bf35ed1512d3e53,"Modeling, Clustering, and Segmenting Video with Mixtures of Dynamic Textures","A dynamic texture is a spatio-temporal generative model for video, which represents video sequences as observations from a linear dynamical system. This work studies the mixture of dynamic textures, a statistical model for an ensemble of video sequences that is sampled from a finite collection of visual processes, each of which is a dynamic texture. An expectation-maximization (EM) algorithm is derived for learning the parameters of the model, and the model is related to previous works in linear systems, machine learning, time- series clustering, control theory, and computer vision. Through experimentation, it is shown that the mixture of dynamic textures is a suitable representation for both the appearance and dynamics of a variety of visual processes that have traditionally been challenging for computer vision (for example, fire, steam, water, vehicle and pedestrian traffic, and so forth). When compared with state-of-the-art methods in motion segmentation, including both temporal texture methods and traditional representations (for example, optical flow or other localized motion representations), the mixture of dynamic textures achieves superior performance in the problems of clustering and segmenting video of such processes.",2008,89,399,43,True,Computer Science,3651407.0,Antoni B. Chan,1699559.0,N. Vasconcelos,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
421d7f83356fdcdf190865325d4aa638b0e9c39f,https://www.semanticscholar.org/paper/421d7f83356fdcdf190865325d4aa638b0e9c39f,Statistical Pattern Recognition,"This chapter introduces the subject of statistical pattern recognition (SPR). It starts by considering how features are defined and emphasizes that the nearest neighbor algorithm achieves error rates comparable with those of an ideal Bayes’ classifier. The concepts of an optimal number of features, representativeness of the training data, and the need to avoid overfitting to the training data are stressed. The chapter shows that methods such as the support vector machine and artificial neural networks are subject to these same training limitations, although each has its advantages. For neural networks, the multilayer perceptron architecture and back-propagation algorithm are described. The chapter distinguishes between supervised and unsupervised learning, demonstrating the advantages of the latter and showing how methods such as clustering and principal components analysis fit into the SPR framework. The chapter also defines the receiver operating characteristic, which allows an optimum balance between false positives and false negatives to be achieved.",2003,1,1709,165,False,Computer Science,2107436317.0,J. Davis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a2c7d81e5956b38eb296b079ce4f116083d2bfd9,https://www.semanticscholar.org/paper/a2c7d81e5956b38eb296b079ce4f116083d2bfd9,Compositional Fairness Constraints for Graph Embeddings,"Learning high-quality node embeddings is a key building block for machine learning models that operate on graph data, such as social networks and recommender systems. However, existing graph embedding techniques are unable to cope with fairness constraints, e.g., ensuring that the learned representations do not correlate with certain attributes, such as age or gender. Here, we introduce an adversarial framework to enforce fairness constraints on graph embeddings. Our approach is compositional---meaning that it can flexibly accommodate different combinations of fairness constraints during inference. For instance, in the context of social recommendations, our framework would allow one user to request that their recommendations are invariant to both their age and gender, while also allowing another user to request invariance to just their age. Experiments on standard knowledge graph and recommender system benchmarks highlight the utility of our proposed framework.",2019,39,120,27,False,Computer Science,26418299.0,A. Bose,49437682.0,William L. Hamilton,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a0ed5261ddce22f4e764111b41ec7571e1b76173,https://www.semanticscholar.org/paper/a0ed5261ddce22f4e764111b41ec7571e1b76173,Sparse convex optimization methods for machine learning,"Convex optimization is at the core of many of today’s analysis tools for large datasets, and in particular machine learning methods. In this thesis we will study the general setting of optimizing (minimizing) a convex function over a compact convex domain. In the first part of this thesis, we study a simple iterative approximation algorithm for that class of optimization problems, based on the classical method by Frank & Wolfe. The algorithm only relies on supporting hyperplanes to the function that we need to optimize. In each iteration, we move slightly towards a point which (approximately) minimizes the linear function given by the supporting hyperplane at the current point, where the minimum is taken over the original optimization domain. In contrast to gradient-descent-type methods, this algorithm does not need any projection steps in order to stay inside the optimization domain. Our framework generalizes the sparse greedy algorithm of Frank & Wolfe and its recent primal-dual analysis by Clarkson (and the low-rank SDP approach by Hazan) to arbitrary compact convex domains. Analogously, we give a convergence proof guaranteeing e-small error — which in our context is the duality gap — after O( 1e ) iterations. This method allows us to understand the sparsity of approximate solutions for any `1-regularized convex optimization problem (and for optimization over the simplex), expressed as a function of the approximation quality. Here we obtain matching upper and lower bounds of Θ ( 1 e ) for the sparsity. The same bounds apply to low-rank semidefinite optimization with bounded trace, showing that rank O ( 1 e ) is best possible here as well. For some classes of geometric optimization problems, our algorithm has a simple geometric interpretation, which is also known as the coreset concept. Here we will study linear classifiers such as support vector machines (SVM) and perceptrons, as well as general distance computations between convex hulls (or polytopes). Here the framework will allow us to understand the sparsity of SVM solutions, here being the number of support vectors, in terms of the required approximation quality.",2011,167,82,18,False,Computer Science,2456863.0,Martin Jaggi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d27c7569fdbcbb57ff511f5293e32b547acca7b3,https://www.semanticscholar.org/paper/d27c7569fdbcbb57ff511f5293e32b547acca7b3,An Equivalence Between Sparse Approximation and Support Vector Machines,"This article shows a relationship between two different approximation techniques: the support vector machines (SVM), proposed by V. Vapnik (1995) and a sparse approximation scheme that resembles the basis pursuit denoising algorithm (Chen, 1995; Chen, Donoho, & Saunders, 1995). SVM is a technique that can be derived from the structural risk minimization principle (Vapnik, 1982) and can be used to estimate the parameters of several different approximation schemes, including radial basis functions, algebraic and trigonometric polynomials, B-splines, and some forms of multilayer perceptrons. Basis pursuit denoising is a sparse approximation technique in which a function is reconstructed by using a small number of basis functions chosen from a large set (the dictionary). We show that if the data are noiseless, the modified version of basis pursuit denoising proposed in this article is equivalent to SVM in the following sense: if applied to the same data set, the two techniques give the same solution, which is obtained by solving the same quadratic programming problem. In the appendix, we present a derivation of the SVM technique in the framework of regularization theory, rather than statistical learning theory, establishing a connection between SVM, sparse approximation, and regularization theory.",1998,60,580,46,True,Medicine,1804489.0,F. Girosi,,,,,,,,,,,,,,,Mathematics,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c08db078d5dd093134383352f650968846de5b17,https://www.semanticscholar.org/paper/c08db078d5dd093134383352f650968846de5b17,Detecting Stealthy False Data Injection Using Machine Learning in Smart Grid,"Aging power industries, together with the increase in demand from industrial and residential customers, are the main incentive for policy makers to define a road map to the next-generation power system called the smart grid. In the smart grid, the overall monitoring costs will be decreased, but at the same time, the risk of cyber attacks might be increased. Recently, a new type of attacks (called the stealth attack) has been introduced, which cannot be detected by the traditional bad data detection using state estimation. In this paper, we show how normal operations of power networks can be statistically distinguished from the case under stealthy attacks. We propose two machine-learning-based techniques for stealthy attack detection. The first method utilizes supervised learning over labeled data and trains a distributed support vector machine (SVM). The design of the distributed SVM is based on the alternating direction method of multipliers, which offers provable optimality and convergence rate. The second method requires no training data and detects the deviation in measurements. In both methods, principal component analysis is used to reduce the dimensionality of the data to be processed, which leads to lower computation complexities. The results of the proposed detection methods on IEEE standard test systems demonstrate the effectiveness of both schemes.",2013,44,312,21,False,Computer Science,1684409.0,Mohammad Esmalifalak,2116204721.0,Lanchao Liu,1845448.0,N. Nguyen,2027592.0,Rong Zheng,145169163.0,Zhu Han,,,,,,,Engineering,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3db5fcb595492dcd64663c00d56f004dfafa689c,https://www.semanticscholar.org/paper/3db5fcb595492dcd64663c00d56f004dfafa689c,A Fair Comparison of Graph Neural Networks for Graph Classification,"Experimental reproducibility and replicability are critical topics in machine learning. Authors have often raised concerns about their lack in scientific publications to improve the quality of the field. Recently, the graph representation learning field has attracted the attention of a wide research community, which resulted in a large stream of works. As such, several Graph Neural Network models have been developed to effectively tackle graph classification. However, experimental procedures often lack rigorousness and are hardly reproducible. Motivated by this, we provide an overview of common practices that should be avoided to fairly compare with the state of the art. To counter this troubling trend, we ran more than 47000 experiments in a controlled and uniform framework to re-evaluate five popular models across nine common benchmarks. Moreover, by comparing GNNs with structure-agnostic baselines we provide convincing evidence that, on some datasets, structural information has not been exploited yet. We believe that this work can contribute to the development of the graph learning field, by providing a much needed grounding for rigorous evaluations of graph classification models.",2019,34,227,25,False,Computer Science,41216883.0,Federico Errica,51308344.0,Marco Podda,3224102.0,D. Bacciu,41231471.0,A. Micheli,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61394599ed0aabe04b724c7ca3a778825c7e776f,https://www.semanticscholar.org/paper/61394599ed0aabe04b724c7ca3a778825c7e776f,Struck: Structured Output Tracking with Kernels,"Adaptive tracking-by-detection methods are widely used in computer vision for tracking arbitrary objects. Current approaches treat the tracking problem as a classification task and use online learning techniques to update the object model. However, for these updates to happen one needs to convert the estimated object position into a set of labelled training examples, and it is not clear how best to perform this intermediate step. Furthermore, the objective for the classifier (label prediction) is not explicitly coupled to the objective for the tracker (estimation of object position). In this paper, we present a framework for adaptive visual object tracking based on structured output prediction. By explicitly allowing the output space to express the needs of the tracker, we avoid the need for an intermediate classification step. Our method uses a kernelised structured output support vector machine (SVM), which is learned online to provide adaptive tracking. To allow our tracker to run at high frame rates, we (a) introduce a budgeting mechanism that prevents the unbounded growth in the number of support vectors that would otherwise occur during tracking, and (b) show how to implement tracking on the GPU. Experimentally, we show that our algorithm is able to outperform state-of-the-art trackers on various benchmark videos. Additionally, we show that we can easily incorporate additional features and kernels into our framework, which results in increased tracking performance.",2016,61,1482,302,True,Medicine,1837057.0,Sam Hare,143777501.0,S. Golodetz,1741702.0,Amir Saffari,143729959.0,Vibhav Vineet,37535930.0,Ming-Ming Cheng,2445538.0,S. Hicks,143635540.0,Philip H. S. Torr,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5536b61896dd4be21f4ea1ed486b7c9950b23527,https://www.semanticscholar.org/paper/5536b61896dd4be21f4ea1ed486b7c9950b23527,Scalable training of deep learning machines by incremental block training with intra-block parallel optimization and blockwise model-update filtering,"We present a new approach to scalable training of deep learning machines by incremental block training with intra-block parallel optimization to leverage data parallelism and blockwise model-update filtering to stabilize learning process. By using an implementation on a distributed GPU cluster with an MPI-based HPC machine learning framework to coordinate parallel job scheduling and collective communication, we have trained successfully deep bidirectional long short-term memory (LSTM) recurrent neural networks (RNNs) and fully-connected feed-forward deep neural networks (DNNs) for large vocabulary continuous speech recognition on two benchmark tasks, namely 309-hour Switchboard-I task and 1,860-hour ""Switch-board+Fisher"" task. We achieve almost linear speedup up to 16 GPU cards on LSTM task and 64 GPU cards on DNN task, with either no degradation or improved recognition accuracy in comparison with that of running a traditional mini-batch based stochastic gradient descent training on a single GPU.",2016,42,132,21,False,Computer Science,153819461.0,Kai Chen,2316043.0,Qiang Huo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aa6f2ee57d2e5b385f7993eccfb2af5347f26ea9,https://www.semanticscholar.org/paper/aa6f2ee57d2e5b385f7993eccfb2af5347f26ea9,Machine Learning Detection of Bell Nonlocality in Quantum Many-Body Systems.,"Machine learning, the core of artificial intelligence and big data science, is one of today's most rapidly growing interdisciplinary fields. Recently, machine learning tools and techniques have been adopted to tackle intricate quantum many-body problems. In this Letter, we introduce machine learning techniques to the detection of quantum nonlocality in many-body systems, with a focus on the restricted-Boltzmann-machine (RBM) architecture. Using reinforcement learning, we demonstrate that RBM is capable of finding the maximum quantum violations of multipartite Bell inequalities with given measurement settings. Our results build a novel bridge between computer-science-based machine learning and quantum many-body nonlocality, which will benefit future studies in both areas.",2017,107,43,1,True,Physics,5204254.0,D. Deng,,,,,,,,,,,,,,,Computer Science,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6ba6b4da6802fa8cc49e683a285bff54a6a211aa,https://www.semanticscholar.org/paper/6ba6b4da6802fa8cc49e683a285bff54a6a211aa,Participation Is not a Design Fix for Machine Learning,"This paper critiques popular modes of participation in design practice and machine learning. It examines three existing kinds of participation in design practice and machine learning participation as work, participation as consultation, and as participation as justice – to argue that the machine learning community must become attuned to possibly exploitative and extractive forms of community involvement and shift away from the prerogatives of context independent scalability. Cautioning against “participation washing”, it argues that the notion of “participation” should be expanded to acknowledge more subtle, and possibly exploitative, forms of community involvement in participatory machine learning design. Specifically, it suggests that it is imperative to recognize design participation as work; to ensure that participation as consultation is context-specific; and that participation as justice must be genuine and long term. The paper argues that such a development can only be scaffolded by a new epistemology around design harms, including, but not limited to, in machine learning. To facilitate such a development, the paper suggests developing we argue that developing a cross-sectoral database of design participation failures that is cross-referenced with socio-structural dimensions and highlights “edge cases” that can and must be learned from.",2020,70,68,8,True,Computer Science,98216895.0,Mona Sloane,2175081.0,E. Moss,91647691.0,O. Awomolo,1719253.0,Laura Forlano,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26ed4e574c19dbac7119c951922df49cc7cab661,https://www.semanticscholar.org/paper/26ed4e574c19dbac7119c951922df49cc7cab661,Combined Fault Location and Classification for Power Transmission Lines Fault Diagnosis With Integrated Feature Extraction,"Accurate and timely diagnosis of transmission line faults is key for reliable operations of power systems. Existing fault-diagnosis methods rely on expert knowledge or extensive feature extraction, which is also highly dependent on expert knowledge. Additionally, most methods for fault diagnosis of transmission lines require multiple separate subalgorithms for fault classification and location performing each function independently and sequentially. In this research, an integrated framework combining fault classification and location is proposed by applying an innovative machine-learning algorithm: the summation-wavelet extreme learning machine (SW-ELM) that integrates feature extraction in the learning process. As a further contribution, an extension of the SW-ELM, i.e., the summation-Gaussian extreme learning machine (SG-ELM), is proposed and successfully applied to transmission line fault diagnosis. SG-ELM is fully self-learning and does not require ad-hoc feature extraction, making it deployable with minimum expert subjectivity. The developed framework is applied to three transmission-line topologies without any prior parameter tuning or ad-hoc feature extraction. Evaluations on a simulated dataset show that the proposed method can diagnose faults within a single cycle, remain immune to fault resistance and inception angle variation, and deliver high accuracy for both tasks of fault diagnosis: fault type classification and fault location estimation.",2018,37,130,1,False,Computer Science,2143408209.0,Yannan Chen,2757308.0,Olga Fink,2704481.0,G. Sansavini,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ff7a293e95c0d44582b7625ee2233916f15cb361,https://www.semanticscholar.org/paper/ff7a293e95c0d44582b7625ee2233916f15cb361,Knowledge discovery from data streams,"Since the beginning of the Internet age and the increased use of ubiquitous computing devices, the large volume and continuous flow of distributed data have imposed new constraints on the design of learning algorithms. Exploring how to extract knowledge structures from evolving and time-changing data, Knowledge Discovery from Data Streams presents a coherent overview of state-of-the-art research in learning from data streams. The book covers the fundamentals that are imperative to understanding data streams and describes important applications, such as TCP/IP traffic, GPS data, sensor networks, and customer click streams. It also addresses several challenges of data mining in the future, when stream mining will be at the core of many applications. These challenges involve designing useful and efficient data mining solutions applicable to real-world problems. In the appendix, the author includes examples of publicly available software and online data sets. This practical, up-to-date book focuses on the new requirements of the next generation of data mining. Although the concepts presented in the text are mainly about data streams, they also are valid for different areas of machine learning and data mining.",2009,148,859,81,True,Computer Science,143931014.0,João Gama,83889546.0,J. Aguilar-Ruiz,2274294.0,R. Klinkenberg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d0c03d8b3bffd0eec216297bc3762d5ea5da00f,https://www.semanticscholar.org/paper/6d0c03d8b3bffd0eec216297bc3762d5ea5da00f,Combining Generative and Discriminative Representation Learning for Lung CT Analysis With Convolutional Restricted Boltzmann Machines,"The choice of features greatly influences the performance of a tissue classification system. Despite this, many systems are built with standard, predefined filter banks that are not optimized for that particular application. Representation learning methods such as restricted Boltzmann machines may outperform these standard filter banks because they learn a feature description directly from the training data. Like many other representation learning methods, restricted Boltzmann machines are unsupervised and are trained with a generative learning objective; this allows them to learn representations from unlabeled data, but does not necessarily produce features that are optimal for classification. In this paper we propose the convolutional classification restricted Boltzmann machine, which combines a generative and a discriminative learning objective. This allows it to learn filters that are good both for describing the training data and for classification. We present experiments with feature learning for lung texture classification and airway detection in CT images. In both applications, a combination of learning objectives outperformed purely discriminative or generative learning, increasing, for instance, the lung tissue classification accuracy by 1 to 8 percentage points. This shows that discriminative learning can help an otherwise unsupervised feature learner to learn filters that are optimized for classification.",2016,47,97,3,True,Computer Science,51256193.0,Gijs van Tulder,32895376.0,Marleen de Bruijne,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bc69383a7d46cbaf80b5b5ef902a3dccf23df696,https://www.semanticscholar.org/paper/bc69383a7d46cbaf80b5b5ef902a3dccf23df696,TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning,"TF.Learn is a high-level Python module for distributed machine learning inside TensorFlow. It provides an easy-to-use Scikit-learn style interface to simplify the process of creating, configuring, training, evaluating, and experimenting a machine learning model. TF.Learn integrates a wide range of state-of-art machine learning algorithms built on top of TensorFlow's low level APIs for small to large-scale supervised and unsupervised problems. This module focuses on bringing machine learning to non-specialists using a general-purpose high-level language as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment. Emphasis is put on ease of use, performance, documentation, and API consistency.",2016,14,59,5,False,Computer Science,46556630.0,Yuan Tang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1904d633fca15140e35d893637232803b6dde6d9,https://www.semanticscholar.org/paper/1904d633fca15140e35d893637232803b6dde6d9,Learning under Concept Drift: A Review,"Concept drift describes unforeseeable changes in the underlying distribution of streaming data over time. Concept drift research involves the development of methodologies and techniques for drift detection, understanding, and adaptation. Data analysis has revealed that machine learning in a concept drift environment will result in poor learning results if the drift is not addressed. To help researchers identify which research topics are significant and how to apply related techniques in data analysis tasks, it is necessary that a high quality, instructive review of current research developments and trends in the concept drift field is conducted. In addition, due to the rapid development of concept drift in recent years, the methodologies of learning under concept drift have become noticeably systematic, unveiling a framework which has not been mentioned in literature. This paper reviews over 130 high quality publications in concept drift related research areas, analyzes up-to-date developments in methodologies and techniques, and establishes a framework of learning under concept drift including three main components: concept drift detection, concept drift understanding, and concept drift adaptation. This paper lists and discusses 10 popular synthetic datasets and 14 publicly available benchmark datasets used for evaluating the performance of learning algorithms aiming at handling concept drift. Also, concept drift related research directions are covered and discussed. By providing state-of-the-art knowledge, this survey will directly support researchers in their understanding of research developments in the field of learning under concept drift.",2019,148,401,36,True,Computer Science,144864069.0,Jie Lu,1471737704.0,Anjin Liu,46279367.0,Fan Dong,2056183624.0,Feng Gu,143931014.0,João Gama,46266495.0,Guangquan Zhang,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d2ca63b70a5f5b8da617fe5f44a234c489c83518,https://www.semanticscholar.org/paper/d2ca63b70a5f5b8da617fe5f44a234c489c83518,Machine learning versus statistical modeling,"This is a discussion of the following papers: “Probability estimation with machine learning methods for dichotomous and multicategory outcome: Theory” by Jochen Kruppa, Yufeng Liu, Gérard Biau, Michael Kohler, Inke R. König, James D. Malley, and Andreas Ziegler; and “Probability estimation with machine learning methods for dichotomous and multicategory outcome: Applications” by Jochen Kruppa, Yufeng Liu, Hans‐Christian Diener, Theresa Holste, Christian Weimar, Inke R. König, and Andreas Ziegler.",2014,19,50,1,False,Medicine,1751504.0,A. Boulesteix,144323802.0,M. Schmid,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f24fa8f9bb1d28019bec34e09f8618f002ca4af9,https://www.semanticscholar.org/paper/f24fa8f9bb1d28019bec34e09f8618f002ca4af9,On the Pitfalls of Using Arbiter-PUFs as Building Blocks,"Physical unclonable functions (PUFs) have emerged as a promising solution for securing resource-constrained embedded devices such as RFID tokens. PUFs use the inherent physical differences of every chip to either securely authenticate the chip or generate cryptographic keys without the need of nonvolatile memory. However, PUFs have shown to be vulnerable to model building attacks if the attacker has access to challenge and response pairs. In these model building attacks, machine learning is used to determine the internal parameters of the PUF to build an accurate software model. Nevertheless, PUFs are still a promising building block and several protocols and designs have been proposed that are believed to be resistant against machine learning attacks. In this paper, we take a closer look at two such protocols, one based on reverse fuzzy extractors and one based on pattern matching. We show that it is possible to attack these protocols using machine learning despite the fact that an attacker does not have access to direct challenge and response pairs. The introduced attacks demonstrate that even highly obfuscated responses can be used to attack PUF protocols. Hence, this paper shows that even protocols in which it would be computationally infeasible to compute enough challenge and response pairs for a direct machine learning attack can be attacked using machine learning.",2015,22,84,19,False,Computer Science,4277384.0,G. Becker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
