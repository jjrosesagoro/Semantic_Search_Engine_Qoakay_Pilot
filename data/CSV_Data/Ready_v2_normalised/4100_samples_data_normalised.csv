paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,fieldsOfStudy/2
5ed4617d39833a8dd8e931282ca2fcee136db634,https://www.semanticscholar.org/paper/5ed4617d39833a8dd8e931282ca2fcee136db634,Unsupervised Generative Modeling Using Matrix Product States,"Generative modeling, which learns joint probability distribution from data and generates samples according to it, is an important task in machine learning and artificial intelligence. Inspired by probabilistic interpretation of quantum physics, we propose a generative model using matrix product states, which is a tensor network originally proposed for describing (particularly one-dimensional) entangled quantum states. Our model enjoys efficient learning analogous to the density matrix renormalization group method, which allows dynamically adjusting dimensions of the tensors and offers an efficient direct sampling approach for generative tasks. We apply our method to generative modeling of several standard datasets including the Bars and Stripes, random binary patterns and the MNIST handwritten digits to illustrate the abilities, features and drawbacks of our model over popular generative models such as Hopfield model, Boltzmann machines and generative adversarial networks. Our work sheds light on many interesting directions of future exploration on the development of quantum-inspired algorithms for unsupervised machine learning, which are promisingly possible to be realized on quantum devices.",2017,74,178,21,True,Computer Science,Physics,114687692,Zhaoyu Han,2152809604.0,Jun Wang,143911167.0,H. Fan,2152508799.0,Lei Wang,1410544411.0,Pan Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics
fb48b584ed52284db257ca438c2a3a40e6550c44,https://www.semanticscholar.org/paper/fb48b584ed52284db257ca438c2a3a40e6550c44,Machine learning in heart failure: ready for prime time,"Purpose of review The aim of this review is to present an up-to-date overview of the application of machine learning methods in heart failure including diagnosis, classification, readmissions and medication adherence. Recent findings Recent studies have shown that the application of machine learning techniques may have the potential to improve heart failure outcomes and management, including cost savings by improving existing diagnostic and treatment support systems. Recently developed deep learning methods are expected to yield even better performance than traditional machine learning techniques in performing complex tasks by learning the intricate patterns hidden in big medical data. Summary The review summarizes the recent developments in the application of machine and deep learning methods in heart failure management.",2017,30,51,1,False,Medicine,,32299082,S. Awan,2470423.0,Ferdous Sohel,39242730.0,F. Sanfilippo,1698675.0,Bennamoun,144084518.0,G. Dwivedi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d4893f7b4d0adbbfd2b3025df3502ab7e902dd79,https://www.semanticscholar.org/paper/d4893f7b4d0adbbfd2b3025df3502ab7e902dd79,Random Feature Expansions for Deep Gaussian Processes,"The composition of multiple Gaussian Processes as a Deep Gaussian Process (DGP) enables a deep probabilistic nonparametric approach to flexibly tackle complex machine learning problems with sound quantification of uncertainty. Existing inference approaches for DGP models have limited scalability and are notoriously cumbersome to construct. In this work we introduce a novel formulation of DGPs based on random feature expansions that we train using stochastic variational inference. This yields a practical learning framework which significantly advances the state-of-the-art in inference for DGPs, and enables accurate quantification of uncertainty. We extensively showcase the scalability and performance of our proposal on several datasets with up to 8 million observations, and various DGP architectures with up to 30 hidden layers.",2016,47,115,14,False,Computer Science,Mathematics,3428811,Kurt Cutajar,30561807.0,Edwin V. Bonilla,143822502.0,P. Michiardi,3138895.0,M. Filippone,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f7f3c904cfa555bc55d65b4cf40e4a73c09190a7,https://www.semanticscholar.org/paper/f7f3c904cfa555bc55d65b4cf40e4a73c09190a7,Active Task Selection for Lifelong Machine Learning,"In a lifelong learning framework, an agent acquires knowledge incrementally over consecutive learning tasks, continually building upon its experience. Recent lifelong learning algorithms have achieved nearly identical performance to batch multi-task learning methods while reducing learning time by three orders of magnitude. In this paper, we further improve the scalability of lifelong learning by developing curriculum selection methods that enable an agent to actively select the next task to learn in order to maximize performance on future learning tasks. We demonstrate that active task selection is highly reliable and effective, allowing an agent to learn high performance models using up to 50% fewer tasks than when the agent has no control over the task order. We also explore a variant of transfer learning in the lifelong learning setting in which the agent can focus knowledge acquisition toward a particular target task.",2013,20,62,10,True,Computer Science,,12114845,P. Ruvolo,144020269.0,Eric Eaton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
771479c18b586eafae21baf262a220aaa7b2eef6,https://www.semanticscholar.org/paper/771479c18b586eafae21baf262a220aaa7b2eef6,Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images,"Object detection in very high resolution optical remote sensing images is a fundamental problem faced for remote sensing image analysis. Due to the advances of powerful feature representations, machine-learning-based object detection is receiving increasing attention. Although numerous feature representations exist, most of them are handcrafted or shallow-learning-based features. As the object detection task becomes more challenging, their description capability becomes limited or even impoverished. More recently, deep learning algorithms, especially convolutional neural networks (CNNs), have shown their much stronger feature representation power in computer vision. Despite the progress made in nature scene images, it is problematic to directly use the CNN feature for object detection in optical remote sensing images because it is difficult to effectively deal with the problem of object rotation variations. To address this problem, this paper proposes a novel and effective approach to learn a rotation-invariant CNN (RICNN) model for advancing the performance of object detection, which is achieved by introducing and learning a new rotation-invariant layer on the basis of the existing CNN architectures. However, different from the training of traditional CNN models that only optimizes the multinomial logistic regression objective, our RICNN model is trained by optimizing a new objective function via imposing a regularization constraint, which explicitly enforces the feature representations of the training samples before and after rotating to be mapped close to each other, hence achieving rotation invariance. To facilitate training, we first train the rotation-invariant layer and then domain-specifically fine-tune the whole RICNN network to further boost the performance. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.",2016,51,1085,91,False,Computer Science,,2152127024,Gong Cheng,2895041.0,P. Zhou,7181955.0,Junwei Han,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ceb2386daea9d831e89ea0328bb6b89054c26dea,https://www.semanticscholar.org/paper/ceb2386daea9d831e89ea0328bb6b89054c26dea,Machine Learning Configuration Interaction.,"We propose the concept of machine learning configuration interaction (MLCI) whereby an artificial neural network is trained on-the-fly to predict important new configurations in an iterative selected configuration interaction procedure. We demonstrate that the neural network can discriminate between important and unimportant configurations, that it has not been trained on, much better than by chance. MLCI is then used to find compact wave functions for carbon monoxide at both stretched and equilibrium geometries. We also consider the multireference problem of the water molecule with elongated bonds. Results are contrasted with those from other ways of selecting configurations: first-order perturbation, random selection, and Monte Carlo configuration interaction. Compared with these other serial calculations, this prototype MLCI is competitive in its accuracy, converges in significantly fewer iterations than the stochastic approaches, and requires less time for the higher-accuracy computations.",2018,52,44,1,True,Computer Science,Medicine,33524193,J. P. Coe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Physics
2b4f69447df8ee8f44e53ba254734bfd570c7450,https://www.semanticscholar.org/paper/2b4f69447df8ee8f44e53ba254734bfd570c7450,Machine Learning Prediction of Cancer Cell Sensitivity to Drugs Based on Genomic and Chemical Properties,"Predicting the response of a specific cancer to a therapy is a major goal in modern oncology that should ultimately lead to a personalised treatment. High-throughput screenings of potentially active compounds against a panel of genomically heterogeneous cancer cell lines have unveiled multiple relationships between genomic alterations and drug responses. Various computational approaches have been proposed to predict sensitivity based on genomic features, while others have used the chemical properties of the drugs to ascertain their effect. In an effort to integrate these complementary approaches, we developed machine learning models to predict the response of cancer cell lines to drug treatment, quantified through IC50 values, based on both the genomic features of the cell lines and the chemical properties of the considered drugs. Models predicted IC50 values in a 8-fold cross-validation and an independent blind test with coefficient of determination R2 of 0.72 and 0.64 respectively. Furthermore, models were able to predict with comparable accuracy (R2 of 0.61) IC50s of cell lines from a tissue not used in the training stage. Our in silico models can be used to optimise the experimental design of drug-cell screenings by estimating a large proportion of missing IC50 values rather than experimentally measuring them. The implications of our results go beyond virtual drug screening design: potentially thousands of drugs could be probed in silico to systematically test their potential efficacy as anti-tumour agents based on their structure, thus providing a computational framework to identify new drug repositioning opportunities as well as ultimately be useful for personalized medicine by linking the genomic traits of patients to drug sensitivity.",2012,46,361,10,True,Computer Science,Biology,143817725,M. Menden,1841722.0,Francesco Iorio,145959971.0,M. Garnett,2321694.0,U. McDermott,1714039.0,C. Benes,9998035.0,P. Ballester,1389786323.0,J. Sáez-Rodríguez,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Medicine
22588ac839cd1a8d0c1021b2a5172dc531f13416,https://www.semanticscholar.org/paper/22588ac839cd1a8d0c1021b2a5172dc531f13416,Artificial Intelligence for Games,"AI and Games Introduction What Is AI? Model of Game AI Algorithms, Data Structures, and Representations On the Website Layout of the Book Game AI The Complexity Fallacy The Kind of AI in Games Speed and Memory The AI Engine Techniques Movement The Basics of Movement Algorithms Kinematic Movement Algorithms Steering Behaviors Combining Steering Behaviors Predicting Physics Jumping Coordinated Movement Motor Control Movement in the Third Dimension Pathfinding The Pathfinding Graph Dijkstra A* World Representations Improving on A* Hierarchical Pathfinding Other Ideas in Pathfinding Continuous Time Pathfinding Movement Planning Decision Making Overview of Decision Making Decision Trees State Machines Behavior Trees Fuzzy Logic Markov Systems Goal-Oriented Behavior Rule-Based Systems Blackboard Architectures Scripting Action Execution Tactical and Strategic AI Waypoint Tactics Tactical Analyses Tactical Pathfinding Coordinated Action Learning Learning Basics Parameter Modification Action Prediction Decision Learning Naive Bayes Classifiers Decision Tree Learning Reinforcement Learning Artificial Neural Networks Board Games Game Theory Minimaxing Transposition Tables and Memory Memory-Enhanced Test Algorithms Opening Books and Other Set Plays Further Optimizations Turn-Based Strategy Games Supporting Technologies Execution Management Scheduling Anytime Algorithms Level of Detail World Interfacing Communication Getting Knowledge Efficiently Event Managers Polling Stations Sense Management Tools and Content Creation Knowledge for Pathfinding and Waypoint Tactics Knowledge for Movement Knowledge for Decision Making The Toolchain Designing Game AI Designing Game AI The Design Shooters Driving Real-Time Strategy Sports Turn-Based Strategy Games AI-Based Game Genres Teaching Characters Flocking and Herding Games Appendix Books, Periodicals, and Papers Games",2006,73,504,43,False,Computer Science,,2909681,I. Millington,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
247b527f0a071eed4e5c43dda90b52fb01cd3eef,https://www.semanticscholar.org/paper/247b527f0a071eed4e5c43dda90b52fb01cd3eef,A review of multi-instance learning assumptions,"Abstract Multi-instance (MI) learning is a variant of inductive machine learning, where each learning example contains a bag of instances instead of a single feature vector. The term commonly refers to the supervised setting, where each bag is associated with a label. This type of representation is a natural fit for a number of real-world learning scenarios, including drug activity prediction and image classification, hence many MI learning algorithms have been proposed. Any MI learning method must relate instances to bag-level class labels, but many types of relationships between instances and class labels are possible. Although all early work in MI learning assumes a specific MI concept class known to be appropriate for a drug activity prediction domain; this ‘standard MI assumption’ is not guaranteed to hold in other domains. Much of the recent work in MI learning has concentrated on a relaxed view of the MI problem, where the standard MI assumption is dropped, and alternative assumptions are considered instead. However, often it is not clearly stated what particular assumption is used and how it relates to other assumptions that have been proposed. In this paper, we aim to clarify the use of alternative MI assumptions by reviewing the work done in this area.",2010,58,315,33,True,Computer Science,,40289577,James R. Foulds,143713826.0,Eibe Frank,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2dae631935d29f75bab8ca122d324b93574b28de,https://www.semanticscholar.org/paper/2dae631935d29f75bab8ca122d324b93574b28de,Geophysical inversion versus machine learning in inverse problems,"Geophysical inversion and machine learning both provide solutions for inverse problems in which we estimate model parameters from observations. Geophysical inversions such as impedance inversion, amplitude-variation-with-offset inversion, and traveltime tomography are commonly used in the industry to yield physical properties from measured seismic data. Machine learning, a data-driven approach, has become popular during the past decades and is useful for solving such inverse problems. An advantage of machine learning methods is that they can be implemented without knowledge of physical equations or theories. The challenges of machine learning lie in acquiring enough training data and selecting relevant parameters, which are essential in obtaining a good quality model. In this study, we compare geophysical inversion and machine learning approaches in solving inverse problems and show similarities and differences of these approaches in a mathematical form and numerical tests. Both methods aid in solving ill-posed and nonlinear problems and use similar optimization techniques. We take reflectivity inversion as an example of the inverse problem. We apply geophysical inversion based on the least-squares method and artificial neural networks as a machine learning approach to solve reflectivity inversion using 2D synthetic data sets and 3D field data sets. A neural network with multiple hidden layers successfully generates the nonlinear mapping function to predict reflectivity. For this inverse problem, we test different L1 regularizers for both approaches. L1 regularization alleviates effects of noise in seismic traces and enhances sparsity, especially in the least-squares method. The 2D synthetic wedge model and field data examples show that neural networks yield high spatial resolution.",2018,26,68,3,False,Computer Science,,2107910408,Yuji Kim,97944579.0,N. Nakata,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dd02246d76d9dfe9d40b5d7974f0c6eb1b3485ce,https://www.semanticscholar.org/paper/dd02246d76d9dfe9d40b5d7974f0c6eb1b3485ce,FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare,"With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.",2019,62,251,22,True,Computer Science,,2109360525,Yiqiang Chen,1519290245.0,Jindong Wang,1786336.0,Chaohui Yu,101001846.0,Wen Gao,2106593912.0,Xin Qin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4731023f7fe031afd5cce991d7157197a5cceb06,https://www.semanticscholar.org/paper/4731023f7fe031afd5cce991d7157197a5cceb06,Applicability of statistical learning algorithms in groundwater quality modeling,"Four algorithms are outlined, each of which has interesting features for predicting contaminant levels in groundwater. Artificial neural networks (ANN), support vector machines (SVM), locally weighted projection regression (LWPR), and relevance vector machines (RVM) are utilized as surrogates for a relatively complex and time‐consuming mathematical model to simulate nitrate concentration in groundwater at specified receptors. Nitrates in the application reported in this paper are due to on‐ground nitrogen loadings from fertilizers and manures. The practicability of the four learning machines in this work is demonstrated for an agriculture‐dominated watershed where nitrate contamination of groundwater resources exceeds the maximum allowable contaminant level at many locations. Cross‐validation and bootstrapping techniques are used for both training and performance evaluation. Prediction results of the four learning machines are rigorously assessed using different efficiency measures to ensure their generalization ability. Prediction results show the ability of learning machines to build accurate models with strong predictive capabilities and hence constitute a valuable means for saving effort in groundwater contamination modeling and improving model performance.",2005,102,128,8,False,Engineering,Geology,145768793,A. Khalil,2208935.0,M. Almasri,38543517.0,M. McKee,145034068.0,J. Kaluarachchi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86bf4e4eb3087fff0dcaf9d0c0bc00c36fd2d11b,https://www.semanticscholar.org/paper/86bf4e4eb3087fff0dcaf9d0c0bc00c36fd2d11b,Towards human-guided machine learning,"Automated Machine Learning (AutoML) systems are emerging that automatically search for possible solutions from a large space of possible kinds of models. Although fully automated machine learning is appropriate for many applications, users often have knowledge that supplements and constraints the available data and solutions. This paper proposes human-guided machine learning (HGML) as a hybrid approach where a user interacts with an AutoML system and tasks it to explore different problem settings that reflect the user's knowledge about the data available. We present: 1) a task analysis of HGML that shows the tasks that a user would want to carry out, 2) a characterization of two scientific publications, one in neuroscience and one in political science, in terms of how the authors would search for solutions using an AutoML system, 3) requirements for HGML based on those characterizations, and 4) an assessment of existing AutoML systems in terms of those requirements.",2019,44,50,5,True,Computer Science,,145526918,Y. Gil,143755437.0,James Honaker,2118928002.0,Shikhar Gupta,2146277142.0,Yibo Ma,1405498945.0,Vito D'Orazio,1398926410.0,D. Garijo,2066310557.0,Shruti Gadewar,50513690.0,Qifan Yang,1721831.0,N. Jahanshad,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e3eaf3c461114bc34675b0aa33e48ac0be003451,https://www.semanticscholar.org/paper/e3eaf3c461114bc34675b0aa33e48ac0be003451,The random forest algorithm for statistical learning,"Random forests (Breiman, 2001, Machine Learning 45: 5–32) is a statistical- or machine-learning algorithm for prediction. In this article, we introduce a corresponding new command, rforest. We overview the random forest algorithm and illustrate its use with two examples: The first example is a classification problem that predicts whether a credit card holder will default on his or her debt. The second example is a regression problem that predicts the logscaled number of shares of online news articles. We conclude with a discussion that summarizes key points demonstrated in the examples.",2020,10,108,2,True,Computer Science,,1815604,M. Schonlau,151197773.0,Rosie Yuyan Zou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
771c14df5fbe14ace4b7f68c2fdc5d3526e4b4ca,https://www.semanticscholar.org/paper/771c14df5fbe14ace4b7f68c2fdc5d3526e4b4ca,Memristive Boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning,"The Boltzmann machine is a massively parallel computational model capable of solving a broad class of combinatorial optimization problems. In recent years, it has been successfully applied to training deep machine learning models on massive datasets. High performance implementations of the Boltzmann machine using GPUs, MPI-based HPC clusters, and FPGAs have been proposed in the literature. Regrettably, the required all-to-all communication among the processing units limits the performance of these efforts. This paper examines a new class of hardware accelerators for large-scale combinatorial optimization and deep learning based on memristive Boltzmann machines. A massively parallel, memory-centric hardware accelerator is proposed based on recently developed resistive RAM (RRAM) technology. The proposed accelerator exploits the electrical properties of RRAm to realize in situ, fine-grained parallel computation within memory arrays, thereby eliminating the need for exchanging data between the memory cells and the computational units. Two classical optimization problems, graph partitioning and boolean satisfiability, and a deep belief network application are mapped onto the proposed hardware. As compared to a multicore system, the proposed accelerator achieves 57x higher performance and 25x lower energy with virtually no loss in the quality of the solution to the optimization problems. The memristive accelerator is also compared against an RRAM based processing-in-memory (PIM) system, with respective performance and energy improvements of 6.89x and 5.2x.",2016,92,171,12,False,Computer Science,,1797114,M. N. Bojnordi,1787439.0,Engin Ipek,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0cf494b6c250f72763bea8031ee82441fc51b1d4,https://www.semanticscholar.org/paper/0cf494b6c250f72763bea8031ee82441fc51b1d4,When Machine Learning Meets Privacy,"The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.",2021,180,33,1,True,Computer Science,,2155440032,Bo Liu,145633124.0,Ming Ding,40221713.0,Sina Shaham,145492472.0,W. Rahayu,1803792.0,F. Farokhi,1740858.0,Zihuai Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
69212cb4c6ea3e770152a82e60b7b52997278787,https://www.semanticscholar.org/paper/69212cb4c6ea3e770152a82e60b7b52997278787,Soft Architecture Machines,"This book is an offspring of Negroponte's ""The Architecture Machine, "" published by The MIT Press in 1970. As is usually the case where computer systems are involved, the new generation is several orders of magnitude more powerful than even its remarkably mind-extending parent. The last few years have represented a ""passing from an idiom to a reality, following (not necessarily consciously) notions set down in ""The Architecture Machine"" with an uncanny precision. The prognostications of hardware enumerated in wanton fantasy have been achieved and even superseded in the actual Architecture Machine of 1972.""The general assumption of this new book is that the architect is an unnecessary and even detrimental middleman between individual, continuously changing needs and the continuous incorporation of those needs into the built environment. The book proposes a new kind of architecture without architects, and even without surrogate architects.The first chapter sets forth generally what is involved in learning to understand both the makings of intelligence and the making of architecture. It reveals polarities in attitudes toward thinking about thinking, and it appraises techniques--real and potential--that lead to meaningful thought about the process.A more direct analysis of architectural design activities is presented in the second chapter. Its goal is to achieve a closer coupling between man and machine, and it proposes sidestepping the traditional division of labor in which man and machine are assigned tasks that they are supposed to be respectively better at. Instead, a joint venture model is suggested: man and machine are treated as equal partners, even as candid good friends.The third chapter moves beyond the architect--beyond the need for an outside designer's intervention between our needs and their fulfillment. It asserts that each individual can be the best architect for his own needs and does not require a paternalistic human or mechanical architect to dictate his final decisions.The last chapter--furthest out of all--looks toward a distant future not only beyond the architect but beyond architecture as we know it. Here architecture machines are not simply used as aids in the design of buildings--they serve as buildings in themselves. Man will live in living, intelligent machines or cognitive physical environments that can immediately respond to his needs or wishes or whims. The possibilities are unlimited and a challenge to any imagination.",1976,0,292,8,False,Engineering,,2687459,N. Negroponte,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46f87a8bae08e872e3200987e3ba9d01237b46c2,https://www.semanticscholar.org/paper/46f87a8bae08e872e3200987e3ba9d01237b46c2,A Quality Control Model with Learning Effects,"Abstract We present a model that extends a variant of the classic quality control/machine maintenance model by adding the concept of quality-based learning. The extension captures the idea that operators of a production process may be able to discover and eliminate defects in the system if, during an inspection, they find the process to be “out of control”. Thus, the distinguishing feature of the model is that one inspects the process not only for the purpose of riring the machine, but also in the hope that the machine will be caught in the act of producing defective output, so that a source of problems is uncovered and eliminated. The paper provides a characterization of optimal inspection policies and suggest the managerial implications: Ignoring the learning benefits of inspection and quality control activities may lead to underinvestment in quality improvement activities, which, in turn, may hinder both cost and quality competitiveness.",1988,17,113,5,False,Computer Science,,2405534,Charles H. Fine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68544f3f58f06ada5d3ac34ec2ea4decfc39b131,https://www.semanticscholar.org/paper/68544f3f58f06ada5d3ac34ec2ea4decfc39b131,High-dimensional regression adjustments in randomized experiments,"Significance As datasets get larger and more complex, there is a growing interest in using machine-learning methods to enhance scientific analysis. In many settings, considerable work is required to make standard machine-learning methods useful for specific scientific applications. We find, however, that in the case of treatment effect estimation with randomized experiments, regression adjustments via machine-learning methods designed to minimize test set error directly induce efficient estimates of the average treatment effect. Thus, machine-learning methods can be used out of the box for this task, without any special-case adjustments. We study the problem of treatment effect estimation in randomized experiments with high-dimensional covariate information and show that essentially any risk-consistent regression adjustment can be used to obtain efficient estimates of the average treatment effect. Our results considerably extend the range of settings where high-dimensional regression adjustments are guaranteed to provide valid inference about the population average treatment effect. We then propose cross-estimation, a simple method for obtaining finite-sample–unbiased treatment effect estimates that leverages high-dimensional regression adjustments. Our method can be used when the regression model is estimated using the lasso, the elastic net, subset selection, etc. Finally, we extend our analysis to allow for adaptive specification search via cross-validation and flexible nonparametric regression adjustments with machine-learning methods such as random forests or neural networks.",2016,65,84,8,True,Mathematics,Computer Science,3160667,Stefan Wager,24091672.0,Wenfei Du,2110315433.0,Jonathan E. Taylor,1761784.0,R. Tibshirani,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Medicine
25ad1c0a40278dd2fcb0d31d4f16d4a58a24528f,https://www.semanticscholar.org/paper/25ad1c0a40278dd2fcb0d31d4f16d4a58a24528f,An Overview of Genetic Algorithms,"Presents an overview of the field of genetic algorithms, pioneered in the field of natural adaptive systems and simulated in software. They are shown as representing a novel optimization strategy which is receiving much attention. In machine learning they are a component of classifier systems which are able to extract rules from data. The algorithms discussed are based on the principles of population genetics and biology.",1992,1,333,0,False,,,2947941,J. Galletly,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a8c6c4bfb8d60355f699b05cae0e0c27cc5b38f7,https://www.semanticscholar.org/paper/a8c6c4bfb8d60355f699b05cae0e0c27cc5b38f7,Progress In Incremental Machine Learning,"We will describe recent developments in a system for machine learning that we’ve been working on for some time (Sol 86, Sol 89). It is meant to be a \Scientist’s Assistant"" of great power and versatility in many areas of science and mathematics. It difiers from other ambitious work in this area in that we are not so much interested in knowledge itself, as we are in how it is acquired - how machines may learn. To start ofi, the system will learn to solve two very general kinds of problems. Most, but perhaps not all problems in science and engineering are of these two kinds. The flrst kind is Function Inversion. These are the P and NP problems of computational complexity theory. They include theorem proving, solution of equations, symbolic integration, etc. The second kind of problem is Time Limited Optimization. Inductive inference of all kinds, surface reconstruction, and image restoration are a few examples of this kind of problem. Designing an automobile in 6 months satisfying certain speciflcations and having minimal cost, is another. In the following discussion, we will be using the term \Probability"" in a special sense: i.e. the estimate given by the best probabilistic model for the available data that we can flnd in the available time. Our system starts out with a small set of Problem Solving Techniques (PSTs) and a simple General Conditional Probability Distribution (GCPD). When the system is given a problem, the description of this problem is the \Condition"" for the GCPD. Its output is a probability distribution on PSTs - the likelihood that each of them will solve the problem by time t. It uses these PSTs and their associated probability distributions to solve the flrst problem. Next, it executes its Update Algorithm: The PSTs are modifled, new ones may be added, some may be deleted. The GCPD is modifled. These",2003,13,55,5,False,Mathematics,,1727567,R. Solomonoff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97a3726b3f9395c8919c6271540d87d1c44e10ac,https://www.semanticscholar.org/paper/97a3726b3f9395c8919c6271540d87d1c44e10ac,Deep feature synthesis: Towards automating data science endeavors,"In this paper, we develop the Data Science Machine, which is able to derive predictive models from raw data automatically. To achieve this automation, we first propose and develop the Deep Feature Synthesis algorithm for automatically generating features for relational datasets. The algorithm follows relationships in the data to a base field, and then sequentially applies mathematical functions along that path to create the final feature. Second, we implement a generalizable machine learning pipeline and tune it using a novel Gaussian Copula process based approach. We entered the Data Science Machine in 3 data science competitions that featured 906 other data science teams. Our approach beats 615 teams in these data science competitions. In 2 of the 3 competitions we beat a majority of competitors, and in the third, we achieved 94% of the best competitor's score. In the best case, with an ongoing competition, we beat 85.6% of the teams and achieved 95.7% of the top submissions score.",2015,19,256,32,True,Computer Science,,1398945328,James Max Kanter,1803567.0,K. Veeramachaneni,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea,https://www.semanticscholar.org/paper/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea,"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications","Generative adversarial networks (GANs) are a hot research topic recently. GANs have been widely studied since 2014, and a large number of algorithms have been proposed. However, there is few comprehensive study explaining the connections among different GANs variants, and how they have evolved. In this paper, we attempt to provide a review on various GANs methods from the perspectives of algorithms, theory, and applications. Firstly, the motivations, mathematical representations, and structure of most GANs algorithms are introduced in details. Furthermore, GANs have been combined with other machine learning algorithms for specific applications, such as semi-supervised learning, transfer learning, and reinforcement learning. This paper compares the commonalities and differences of these GANs methods. Secondly, theoretical issues related to GANs are investigated. Thirdly, typical applications of GANs in image processing and computer vision, natural language processing, music, speech and audio, medical field, and data science are illustrated. Finally, the future open research problems for GANs are pointed out.",2020,465,252,14,True,Computer Science,Mathematics,143987790,Jie Gui,1757186.0,Zhenan Sun,145868454.0,Yonggang Wen,143719920.0,D. Tao,2778556.0,Jieping Ye,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46d47481a8fb29b058b8d7c9939a9df91694784f,https://www.semanticscholar.org/paper/46d47481a8fb29b058b8d7c9939a9df91694784f,SVM multiregression for nonlinear channel estimation in multiple-input multiple-output systems,"This paper addresses the problem of multiple-input multiple-output (MIMO) frequency nonselective channel estimation. We develop a new method for multiple variable regression estimation based on Support Vector Machines (SVMs): a state-of-the-art technique within the machine learning community for regression estimation. We show how this new method, which we call M-SVR, can be efficiently applied. The proposed regression method is evaluated in a MIMO system under a channel estimation scenario, showing its benefits in comparison to previous proposals when nonlinearities are present in either the transmitter or the receiver sides of the MIMO system.",2004,42,230,28,False,Computer Science,Mathematics,50509649,M. S. Fernández,1400677573.0,M. Prado-Cumplido,1385756446.0,J. Arenas-García,1388508441.0,F. Pérez-Cruz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86da6a1bf62ce8c94252c7772246f20106d8caf2,https://www.semanticscholar.org/paper/86da6a1bf62ce8c94252c7772246f20106d8caf2,Predicting Multiple Metrics for Queries: Better Decisions Enabled by Machine Learning,"One of the most challenging aspects of managing a very large data warehouse is identifying how queries will behave before they start executing. Yet knowing their performance characteristics --- their runtimes and resource usage --- can solve two important problems. First, every database vendor struggles with managing unexpectedly long-running queries. When these long-running queries can be identified before they start, they can be rejected or scheduled when they will not cause extreme resource contention for the other queries in the system. Second, deciding whether a system can complete a given workload in a given time period (or a bigger system is necessary) depends on knowing the resource requirements of the queries in that workload. We have developed a system that uses machine learning to accurately predict the performance metrics of database queries whose execution times range from milliseconds to hours. For training and testing our system, we used both real customer queries and queries generated from an extended set of TPC-DS templates. The extensions mimic queries that caused customer problems. We used these queries to compare how accurately different techniques predict metrics such as elapsed time, records used, disk I/Os, and message bytes. The most promising technique was not only the most accurate, but also predicted these metrics simultaneously and using only information available prior to query execution. We validated the accuracy of this machine learning technique on a number of HP Neoview configurations. We were able to predict individual query elapsed time within 20% of its actual time for 85% of the test queries. Most importantly, we were able to correctly identify both the short and long-running (up to two hour) queries to inform workload management and capacity planning.",2009,23,314,24,False,Computer Science,,1701816,A. Ganapathi,2121201.0,H. Kuno,1725067.0,U. Dayal,1766403.0,J. Wiener,143608596.0,A. Fox,1694621.0,Michael I. Jordan,1701130.0,D. Patterson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7da1bb2a14bf043753469aa740a41478d04ec83e,https://www.semanticscholar.org/paper/7da1bb2a14bf043753469aa740a41478d04ec83e,Biostatistics,"Bayesian modeling and inference, high-dimensional data analysis, statistical genetics and genomics, bioinformatics, informatics, statistical and machine learning, spatial and spatio-temporal modeling, time series analysis, survival data analysis, longitudinal data analysis, network analysis, causal inference, comparative effectiveness studies, model selection, epidemic modeling, and syndromic surveillance.",2005,5,235,24,True,,,2036256,J. Cavanaugh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80949267f588ac406e2169b3b98ece573ed17da8,https://www.semanticscholar.org/paper/80949267f588ac406e2169b3b98ece573ed17da8,A feature agnostic approach for glaucoma detection in OCT volumes,"Optical coherence tomography (OCT) based measurements of retinal layer thickness, such as the retinal nerve fibre layer (RNFL) and the ganglion cell with inner plexiform layer (GCIPL) are commonly employed for the diagnosis and monitoring of glaucoma. Previously, machine learning techniques have relied on segmentation-based imaging features such as the peripapillary RNFL thickness and the cup-to-disc ratio. Here, we propose a deep learning technique that classifies eyes as healthy or glaucomatous directly from raw, unsegmented OCT volumes of the optic nerve head (ONH) using a 3D Convolutional Neural Network (CNN). We compared the accuracy of this technique with various feature-based machine learning algorithms and demonstrated the superiority of the proposed deep learning based method. Logistic regression was found to be the best performing classical machine learning technique with an AUC of 0.89. In direct comparison, the deep learning approach achieved a substantially higher AUC of 0.94 with the additional advantage of providing insight into which regions of an OCT volume are important for glaucoma detection. Computing Class Activation Maps (CAM), we found that the CNN identified neuroretinal rim and optic disc cupping as well as the lamina cribrosa (LC) and its surrounding areas as the regions significantly associated with the glaucoma classification. These regions anatomically correspond to the well established and commonly used clinical markers for glaucoma diagnosis such as increased cup volume, cup diameter, and neuroretinal rim thinning at the superior and inferior segments.",2018,42,109,8,False,Computer Science,Mathematics,2428309,S. Maetschke,1992686.0,B. Antony,66193516.0,H. Ishikawa,31452828.0,Rahil Garvani,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Medicine
dd456b62e4961a832d9020e7d546c6efedbe4de3,https://www.semanticscholar.org/paper/dd456b62e4961a832d9020e7d546c6efedbe4de3,Machine learning for many-body physics: The case of the Anderson impurity model,"Machine learning methods are applied to finding the Green's function of the Anderson impurity model, a basic model system of quantum many-body condensed-matter physics. Different methods of parametrizing the Green's function are investigated; a representation in terms of Legendre polynomials is found to be superior due to its limited number of coefficients and its applicability to state of the art methods of solution. The dependence of the errors on the size of the training set is determined. The results indicate that a machine learning approach to dynamical mean-field theory may be feasible.",2014,35,98,1,True,Physics,Mathematics,93638590,L. Arsenault,1398945311.0,A. Lopez-Bezanilla,11615881.0,O. A. V. Lilienfeld,5796209.0,A. Millis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
031548b9beb9e9411da1da0dfdff0ed4ffa447d2,https://www.semanticscholar.org/paper/031548b9beb9e9411da1da0dfdff0ed4ffa447d2,Neural Decoder for Topological Codes.,"We present an algorithm for error correction in topological codes that exploits modern machine learning techniques. Our decoder is constructed from a stochastic neural network called a Boltzmann machine, of the type extensively used in deep learning. We provide a general prescription for the training of the network and a decoding strategy that is applicable to a wide variety of stabilizer codes with very little specialization. We demonstrate the neural decoder numerically on the well-known two-dimensional toric code with phase-flip errors.",2016,21,126,3,True,Physics,Medicine,3422999,G. Torlai,3422513.0,R. Melko,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science
5b5cc77898a71a1386734584ceef4070263b8d03,https://www.semanticscholar.org/paper/5b5cc77898a71a1386734584ceef4070263b8d03,ParlAI: A Dialog Research Software Platform,"We introduce ParlAI (pronounced “par-lay”), an open-source software platform for dialog research implemented in Python, available at http://parl.ai. Its goal is to provide a unified framework for sharing, training and testing dialog models; integration of Amazon Mechanical Turk for data collection, human evaluation, and online/reinforcement learning; and a repository of machine learning models for comparing with others’ models, and improving upon existing architectures. Over 20 tasks are supported in the first release, including popular datasets such as SQuAD, bAbI tasks, MCTest, WikiQA, QACNN, QADailyMail, CBT, bAbI Dialog, Ubuntu, OpenSubtitles and VQA. Several models are integrated, including neural models such as memory networks, seq2seq and attentive LSTMs.",2017,25,256,38,True,Computer Science,,143622869,Alexander H. Miller,11636339.0,Will Feng,1746610.0,Dhruv Batra,1713934.0,Antoine Bordes,2064150446.0,Adam Fisch,8553015.0,Jiasen Lu,153432684.0,Devi Parikh,145183709.0,J. Weston,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
51bb0b430daf33779c6c1b21ce9f888ea11f2c67,https://www.semanticscholar.org/paper/51bb0b430daf33779c6c1b21ce9f888ea11f2c67,Machine learning for autonomous crystal structure identification.,"We present a machine learning technique to discover and distinguish relevant ordered structures from molecular simulation snapshots or particle tracking data. Unlike other popular methods for structural identification, our technique requires no a priori description of the target structures. Instead, we use nonlinear manifold learning to infer structural relationships between particles according to the topology of their local environment. This graph-based approach yields unbiased structural information which allows us to quantify the crystalline character of particles near defects, grain boundaries, and interfaces. We demonstrate the method by classifying particles in a simulation of colloidal crystallization, and show that our method identifies structural features that are missed by standard techniques.",2017,58,71,2,False,Computer Science,Medicine,3757323,Wesley F. Reinhart,1773729.0,Andrew W. Long,15035314.0,Michael P. Howard,2424441.0,Andrew L. Ferguson,2318633.0,A. Panagiotopoulos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
076f59364df347c72e42b8de21c3976c8818622f,https://www.semanticscholar.org/paper/076f59364df347c72e42b8de21c3976c8818622f,Comment on “Predicting reaction performance in C–N cross-coupling using machine learning”,"Ahneman et al. (Reports, 13 April 2018) applied machine learning models to predict C–N cross-coupling reaction yields. The models use atomic, electronic, and vibrational descriptors as input features. However, the experimental design is insufficient to distinguish models trained on chemical features from those trained solely on random-valued features in retrospective and prospective test scenarios, thus failing classical controls in machine learning.",2018,13,66,0,False,Computer Science,Medicine,7935819,Kangway V Chuang,2780351.0,Michael J. Keiser,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97230c259ce3a6dc1ff1b83371aa2815793f8d4c,https://www.semanticscholar.org/paper/97230c259ce3a6dc1ff1b83371aa2815793f8d4c,Biomimetic Hybrid Feedback Feedforward Neural-Network Learning Control,"This brief presents a biomimetic hybrid feedback feedforward neural-network learning control (NNLC) strategy inspired by the human motor learning control mechanism for a class of uncertain nonlinear systems. The control structure includes a proportional-derivative controller acting as a feedback servo machine and a radial-basis-function (RBF) NN acting as a feedforward predictive machine. Under the sufficient constraints on control parameters, the closed-loop system achieves semiglobal practical exponential stability, such that an accurate NN approximation is guaranteed in a local region along recurrent reference trajectories. Compared with the existing NNLC methods, the novelties of the proposed method include: 1) the implementation of an adaptive NN control to guarantee plant states being recurrent is not needed, since recurrent reference signals rather than plant states are utilized as NN inputs, which greatly simplifies the analysis and synthesis of the NNLC and 2) the domain of NN approximation can be determined a priori by the given reference signals, which leads to an easy construction of the RBF-NNs. Simulation results have verified the effectiveness of this approach.",2017,36,107,0,False,Computer Science,Medicine,1714827,Yongping Pan,1741040.0,Haoyong Yu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
354c0453f0db9cceea954cc0aa787e3093bcb920,https://www.semanticscholar.org/paper/354c0453f0db9cceea954cc0aa787e3093bcb920,Collaborative Machine Learning with Incentive-Aware Model Rewards,"Collaborative machine learning (ML) is an appealing paradigm to build high-quality ML models by training on the aggregated data from many parties. However, these parties are only willing to share their data when given enough incentives, such as a guaranteed fair reward based on their contributions. This motivates the need for measuring a party's contribution and designing an incentive-aware reward scheme accordingly. This paper proposes to value a party's reward based on Shapley value and information gain on model parameters given its data. Subsequently, we give each party a model as a reward. To formally incentivize the collaboration, we define some desirable properties (e.g., fairness and stability) which are inspired by cooperative game theory but adapted for our model reward that is uniquely freely replicable. Then, we propose a novel model reward scheme to satisfy fairness and trade off between the desirable properties via an adjustable parameter. The value of each party's model reward determined by our scheme is attained by injecting Gaussian noise to the aggregated training data with an optimized noise variance. We empirically demonstrate interesting properties of our scheme and evaluate its performance using synthetic and real-world datasets.",2020,27,44,4,False,Computer Science,Mathematics,2003246244,Rachael Hwee Ling Sim,72095066.0,Yehong Zhang,1682291.0,M. Chan,2003246280.0,Bryan Kian,2003246325.0,Hsiang Low,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c08338d1f19187d3c0b8edcce3beb9d9d61aa886,https://www.semanticscholar.org/paper/c08338d1f19187d3c0b8edcce3beb9d9d61aa886,Driver Distraction Detection Using Semi-Supervised Machine Learning,"Real-time driver distraction detection is the core to many distraction countermeasures and fundamental for constructing a driver-centered driver assistance system. While data-driven methods demonstrate promising detection performance, a particular challenge is how to reduce the considerable cost for collecting labeled data. This paper explored semi-supervised methods for driver distraction detection in real driving conditions to alleviate the cost of labeling training data. Laplacian support vector machine and semi-supervised extreme learning machine were evaluated using eye and head movements to classify two driver states: attentive and cognitively distracted. With the additional unlabeled data, the semi-supervised learning methods improved the detection performance (G-mean) by 0.0245, on average, over all subjects, as compared with the traditional supervised methods. As unlabeled training data can be collected from drivers' naturalistic driving records with little extra resource, semi-supervised methods, which utilize both labeled and unlabeled data, can enhance the efficiency of model development in terms of time and cost.",2016,56,129,4,False,Computer Science,,1776911,Tianchi Liu,2108850466.0,Yan Yang,145678691.0,G. Huang,2210504.0,Yong Kiang Yeo,145558868.0,Zhiping Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4e7a77326bc8fcf64943aab06c658c27ec28ec55,https://www.semanticscholar.org/paper/4e7a77326bc8fcf64943aab06c658c27ec28ec55,A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning,"We extend the well-known BFGS quasi-Newton method and its memory-limited variant LBFGS to the optimization of nonsmooth convex objectives. This is done in a rigorous fashion by generalizing three components of BFGS to subdifferentials: the local quadratic model, the identification of a descent direction, and the Wolfe line search conditions. We prove that under some technical conditions, the resulting subBFGS algorithm is globally convergent in objective function value. We apply its memory-limited variant (subLBFGS) to L2-regularized risk minimization with the binary hinge loss. To extend our algorithm to the multiclass and multilabel settings, we develop a new, efficient, exact line search algorithm. We prove its worst-case time complexity bounds, and show that our line search can also be used to extend a recently developed bundle method to the multiclass and multilabel settings. We also apply the direction-finding component of our algorithm to L1-regularized risk minimization with logistic loss. In all these contexts our methods perform comparable to or better than specialized state-of-the-art solvers on a number of publicly available data sets. An open source implementation of our algorithms is freely available.",2008,49,110,9,False,Mathematics,Computer Science,40565216,Jin Yu,145713876.0,S. Vishwanathan,2105506680.0,Simon Günter,1739396.0,N. Schraudolph,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fc8b3a7622ddf5ab88fe06de260898202cf06233,https://www.semanticscholar.org/paper/fc8b3a7622ddf5ab88fe06de260898202cf06233,Similarity-based machine learning methods for predicting drug-target interactions: a brief review,"Computationally predicting drug-target interactions is useful to select possible drug (or target) candidates for further biochemical verification. We focus on machine learning-based approaches, particularly similarity-based methods that use drug and target similarities, which show relationships among drugs and those among targets, respectively. These two similarities represent two emerging concepts, the chemical space and the genomic space. Typically, the methods combine these two types of similarities to generate models for predicting new drug-target interactions. This process is also closely related to a lot of work in pharmacogenomics or chemical biology that attempt to understand the relationships between the chemical and genomic spaces. This background makes the similarity-based approaches attractive and promising. This article reviews the similarity-based machine learning methods for predicting drug-target interactions, which are state-of-the-art and have aroused great interest in bioinformatics. We describe each of these methods briefly, and empirically compare these methods under a uniform experimental setting to explore their advantages and limitations.",2014,70,301,23,True,Computer Science,Medicine,2113454271,Hao Ding,2400256.0,Ichigaku Takigawa,1686589.0,Hiroshi Mamitsuka,7472263.0,Shanfeng Zhu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfcf66e4b22dc7671a5941e94e9d4afae75ba2f8,https://www.semanticscholar.org/paper/cfcf66e4b22dc7671a5941e94e9d4afae75ba2f8,The Cramer Distance as a Solution to Biased Wasserstein Gradients,"The Wasserstein probability metric has received much attention from the machine learning community. Unlike the Kullback-Leibler divergence, which strictly measures change in probability, the Wasserstein metric reflects the underlying geometry between outcomes. The value of being sensitive to this geometry has been demonstrated, among others, in ordinal regression and generative modelling, and most recently in reinforcement learning. In this paper we describe three natural properties of probability divergences that we believe reflect requirements from machine learning: sum invariance, scale sensitivity, and unbiased sample gradients. The Wasserstein metric possesses the first two properties but, unlike the Kullback-Leibler divergence, does not possess the third. We provide empirical evidence suggesting this is a serious issue in practice. Leveraging insights from probabilistic forecasting we propose an alternative to the Wasserstein metric, the Cramer distance. We show that the Cramer distance possesses all three desired properties, combining the best of the Wasserstein and Kullback-Leibler divergences. We give empirical results on a number of domains comparing these three divergences. To illustrate the practical relevance of the Cramer distance we design a new algorithm, the Cramer Generative Adversarial Network (GAN), and show that it has a number of desirable properties over the related Wasserstein GAN.",2017,38,268,48,False,Computer Science,Mathematics,1792298,Marc G. Bellemare,1841008.0,Ivo Danihelka,2605877.0,Will Dabney,14594344.0,S. Mohamed,40627523.0,Balaji Lakshminarayanan,7018631.0,Stephan Hoyer,1708654.0,R. Munos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24e250cb8a94742eed51dc2035fb41bddea2ceb9,https://www.semanticscholar.org/paper/24e250cb8a94742eed51dc2035fb41bddea2ceb9,Applying reinforcement learning towards automating resource allocation and application scalability in the cloud,"Public Infrastructure as a Service (IaaS) clouds such as Amazon, GoGrid and Rackspace deliver computational resources by means of virtualisation technologies. These technologies allow multiple independent virtual machines to reside in apparent isolation on the same physical host. Dynamically scaling applications running on IaaS clouds can lead to varied and unpredictable results because of the performance interference effects associated with co‐located virtual machines. Determining appropriate scaling policies in a dynamic non‐stationary environment is non‐trivial. One principle advantage exhibited by IaaS clouds over their traditional hosting counterparts is the ability to scale resources on‐demand. However, a problem arises concerning resource allocation as to which resources should be added and removed when the underlying performance of the resource is in a constant state of flux. Decision theoretic frameworks such as Markov Decision Processes are particularly suited to decision making under uncertainty. By applying a temporal difference, reinforcement learning algorithm known as Q‐learning, optimal scaling policies can be determined. Additionally, reinforcement learning techniques typically suffer from curse of dimensionality problems, where the state space grows exponentially with each additional state variable. To address this challenge, we also present a novel parallel Q‐learning approach aimed at reducing the time taken to determine optimal policies whilst learning online. Copyright © 2012 John Wiley & Sons, Ltd.",2013,38,202,18,True,Computer Science,,47862122,E. Barrett,48313838.0,E. Howley,2462471.0,J. Duggan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1eb7b1cafe1891712a4f764c78399a53182cdcd1,https://www.semanticscholar.org/paper/1eb7b1cafe1891712a4f764c78399a53182cdcd1,Rényi Fair Inference,"Machine learning algorithms have been increasingly deployed in critical automated decision-making systems that directly affect human lives. When these algorithms are solely trained to minimize the training/test error, they could suffer from systematic discrimination against individuals based on their sensitive attributes, such as gender or race. Recently, there has been a surge in machine learning society to develop algorithms for fair machine learning. In particular, several adversarial learning procedures have been proposed to impose fairness. Unfortunately, these algorithms either can only impose fairness up to linear dependence between the variables, or they lack computational convergence guarantees. In this paper, we use Renyi correlation as a measure of fairness of machine learning models and develop a general training framework to impose fairness. In particular, we propose a min-max formulation which balances the accuracy and fairness when solved to optimality. For the case of discrete sensitive attributes, we suggest an iterative algorithm with theoretical convergence guarantee for solving the proposed min-max problem. Our algorithm and analysis are then specialized to fair classification and fair clustering problems. To demonstrate the performance of the proposed Renyi fair inference framework in practice, we compare it with well-known existing methods on several benchmark datasets. Experiments indicate that the proposed method has favorable empirical performance against state-of-the-art approaches.",2020,61,40,2,False,Computer Science,,148009027,Sina Baharlouei,23638986.0,Maher Nouiehed,1800298.0,Meisam Razaviyayn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b7b77aa45142184a09449083bd2b6e09b58ddd0b,https://www.semanticscholar.org/paper/b7b77aa45142184a09449083bd2b6e09b58ddd0b,The Implicit Fairness Criterion of Unconstrained Learning,"We clarify what fairness guarantees we can and cannot expect to follow from unconstrained machine learning. Specifically, we characterize when unconstrained learning on its own implies group calibration, that is, the outcome variable is conditionally independent of group membership given the score. We show that under reasonable conditions, the deviation from satisfying group calibration is upper bounded by the excess risk of the learned score relative to the Bayes optimal score function. A lower bound confirms the optimality of our upper bound. Moreover, we prove that as the excess risk of the learned score decreases, it strongly violates separation and independence, two other standard fairness criteria. 
Our results show that group calibration is the fairness criterion that unconstrained learning implicitly favors. On the one hand, this means that calibration is often satisfied on its own without the need for active intervention, albeit at the cost of violating other criteria that are at odds with calibration. On the other hand, it suggests that we should be satisfied with calibration as a fairness criterion only if we are at ease with the use of unconstrained machine learning in a given application.",2018,42,59,6,False,Computer Science,,1748108610,Lydia T. Liu,3385674.0,Max Simchowitz,1775622.0,Moritz Hardt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3a2e75b97eae168a790732bd7662911e4e10bdd6,https://www.semanticscholar.org/paper/3a2e75b97eae168a790732bd7662911e4e10bdd6,Joint Feature Selection and Subspace Learning,"Dimensionality reduction is a very important topic in machine learning. It can be generally classified into two categories: feature selection and subspace learning. In the past decades, many methods have been proposed for dimensionality reduction. However, most of these works study feature selection and subspace learning independently. In this paper, we present a framework for joint feature selection and subspace learning. We reformulate the subspace learning problem and use L2,1-norm on the projection matrix to achieve row-sparsity, which leads to selecting relevant features and learning transformation simultaneously. We discuss two situations of the proposed framework, and present their optimization algorithms. Experiments on benchmark face recognition data sets illustrate that the proposed framework outperforms the state of the art methods overwhelmingly.",2011,38,194,21,False,Computer Science,,9937103,Quanquan Gu,2109640666.0,Z. Li,145325584.0,Jiawei Han,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d8db61577a021981ccf58d0c5ced167674b389c,https://www.semanticscholar.org/paper/6d8db61577a021981ccf58d0c5ced167674b389c,On-Device Machine Learning: An Algorithms and Learning Theory Perspective,"The predominant paradigm for using machine learning models on a device is to train a model in the cloud and perform inference using the trained model on the device. However, with increasing number of smart devices and improved hardware, there is interest in performing model training on the device. Given this surge in interest, a comprehensive survey of the field from a device-agnostic perspective sets the stage for both understanding the state-of-the-art and for identifying open challenges and future avenues of research. However, on-device learning is an expansive field with connections to a large number of related topics in AI and machine learning (including online learning, model adaptation, one/few-shot learning, etc.). Hence, covering such a large number of topics in a single survey is impractical. This survey finds a middle ground by reformulating the problem of on-device learning as resource constrained learning where the resources are compute and memory. This reformulation allows tools, techniques, and algorithms from a wide variety of research areas to be compared equitably. In addition to summarizing the state-of-the-art, the survey also identifies a number of challenges and next steps for both the algorithmic and theoretical aspects of on-device learning.",2019,210,60,4,False,Computer Science,Mathematics,3314219,Sauptik Dhar,3245791.0,Junyao Guo,48211043.0,Jiayi Liu,2347331.0,S. Tripathi,2820048.0,Unmesh Kurup,40225085.0,Mohak Shah,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1d4b4f1ca1e7492820411fd668f09984fefe8c3e,https://www.semanticscholar.org/paper/1d4b4f1ca1e7492820411fd668f09984fefe8c3e,Visual Analytics for Explainable Deep Learning,"Recently, deep learning has been advancing the state of the art in artificial intelligence to a new level, and humans rely on artificial intelligence techniques more than ever. However, even with such unprecedented advancements, the lack of explanation regarding the decisions made by deep learning models and absence of control over their internal processes act as major drawbacks in critical decision-making processes, such as precision medicine and law enforcement. In response, efforts are being made to make deep learning interpretable and controllable by humans. This article reviews visual analytics, information visualization, and machine learning perspectives relevant to this aim, and discusses potential challenges and future research directions.",2018,18,158,10,True,Computer Science,Mathematics,1795455,J. Choo,48641970.0,Shixia Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Medicine
cfa2646776405d50533055ceb1b7f050e9014dcb,https://www.semanticscholar.org/paper/cfa2646776405d50533055ceb1b7f050e9014dcb,Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions,"We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.",2011,38,1288,135,False,Computer Science,,2166511,R. Socher,143845796.0,Jeffrey Pennington,40150953.0,E. Huang,34699434.0,A. Ng,144783904.0,Christopher D. Manning,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5913cbd4d209311df06c7fdab7ba34b082098853,https://www.semanticscholar.org/paper/5913cbd4d209311df06c7fdab7ba34b082098853,A Comparative Study on Machine Learning Algorithms for Smart Manufacturing: Tool Wear Prediction Using Random Forests,"Manufacturers have faced an increasing need for the development of predictive models that predict mechanical failures and the remaining useful life (RUL) of manufacturing systems or components. Classical model-based or physics-based prognostics often require an in-depth physical understanding of the system of interest to develop closedform mathematical models. However, prior knowledge of system behavior is not always available, especially for complex manufacturing systems and processes. To complement model-based prognostics, data-driven methods have been increasingly applied to machinery prognostics and maintenance management, transforming legacy manufacturing systems into smart manufacturing systems with artificial intelligence. While previous research has demonstrated the effectiveness of data-driven methods, most of these prognostic methods are based on classical machine learning techniques, such as artificial neural networks (ANNs) and support vector regression (SVR). With the rapid advancement in artificial intelligence, various machine learning algorithms have been developed and widely applied in many engineering fields. The objective of this research is to introduce a random forests (RFs)-based prognostic method for tool wear prediction as well as compare the performance of RFs with feed-forward back propagation (FFBP) ANNs and SVR. Specifically, the performance of FFBP ANNs, SVR, and RFs are compared using an experimental data collected from 315 milling tests. Experimental results have shown that RFs can generate more accurate predictions than FFBP ANNs with a single hidden layer and SVR. [DOI: 10.1115/1.4036350]",2017,50,294,5,True,Engineering,,48198404,Dazhong Wu,26999030.0,Connor Jennings,2939300.0,J. Terpenny,1700762.0,R. Gao,1749112.0,S. Kumara,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
660ff427b97bda39a007687b777a3e1fae56be9d,https://www.semanticscholar.org/paper/660ff427b97bda39a007687b777a3e1fae56be9d,The production of prediction: What does machine learning want?,"Retail, media, finance, science, industry, security and government increasingly depend on predictions produced through techniques such as machine learning. How is it that machine learning can promise to predict with great specificity what differences matter or what people want in many different settings? We need, I suggest, an account of its generalization if we are to understand the contemporary production of prediction. This article maps the principal forms of material action, narrative and problematization that run across algorithmic modelling techniques such as logistic regression, decision trees and Naive Bayes classifiers. It highlights several interlinked modes of generalization that engender increasingly vast data infrastructures and platforms, and intensified mathematical and statistical treatments of differences. Such an account also points to some key sites of instability or problematization inherent to the process of generalization. If movement through data is becoming a principal intersection of power relations, economic value and valid knowledge, an account of the production of prediction might also help us begin to ask how its generalization potentially gives rise to new forms of agency, experience or individuations.",2015,34,122,10,False,Computer Science,,39822261,A. Mackenzie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bb414c09ace7083c41c1164f5de4a901ddd8f146,https://www.semanticscholar.org/paper/bb414c09ace7083c41c1164f5de4a901ddd8f146,Using Machine Learning To Predict Suitable Conditions for Organic Reactions,"Reaction condition recommendation is an essential element for the realization of computer-assisted synthetic planning. Accurate suggestions of reaction conditions are required for experimental validation and can have a significant effect on the success or failure of an attempted transformation. However, de novo condition recommendation remains a challenging and under-explored problem and relies heavily on chemists’ knowledge and experience. In this work, we develop a neural-network model to predict the chemical context (catalyst(s), solvent(s), reagent(s)), as well as the temperature most suitable for any particular organic reaction. Trained on ∼10 million examples from Reaxys, the model is able to propose conditions where a close match to the recorded catalyst, solvent, and reagent is found within the top-10 predictions 69.6% of the time, with top-10 accuracies for individual species reaching 80–90%. Temperature is accurately predicted within ±20 °C from the recorded temperature in 60–70% of test cases, with higher accuracy for cases with correct chemical context predictions. The utility of the model is illustrated through several examples spanning a range of common reaction classes. We also demonstrate that the model implicitly learns a continuous numerical embedding of solvent and reagent species that captures their functional similarity.",2018,48,156,3,True,Medicine,Computer Science,30996158,Hanyu Gao,12514946.0,Thomas J. Struble,13027820.0,Connor W. Coley,2107935841.0,Yuran Wang,143964245.0,W. Green,144050039.0,K. Jensen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c972d4a2f786f7537a2f0cc89a8b073983849756,https://www.semanticscholar.org/paper/c972d4a2f786f7537a2f0cc89a8b073983849756,Active Machine Learning for Consideration Heuristics,"We develop and test an active-machine-learning method to select questions adaptively when consumers use heuristic decision rules. The method tailors priors to each consumer based on a “configurator.” Subsequent questions maximize information about the decision heuristics (minimize expected posterior entropy). To update posteriors after each question, we approximate the posterior with a variational distribution and use belief propagation (iterative loops of Bayes updating). The method runs sufficiently fast to select new queries in under a second and provides significantly and substantially more information per question than existing methods based on random, market-based, or orthogonal-design questions. Synthetic data experiments demonstrate that adaptive questions provide close-to-optimal information and outperform existing methods even when there are response errors or “bad” priors. The basic algorithm focuses on conjunctive or disjunctive rules, but we demonstrate generalizations to more complex heuristics and to the use of previous-respondent data to improve consumer-specific priors. We illustrate the algorithm empirically in a Web-based survey conducted by an American automotive manufacturer to study vehicle consideration (872 respondents, 53 feature levels). Adaptive questions outperform market-based questions when estimating heuristic decision rules. Heuristic decision rules predict validation decisions better than compensatory rules.",2011,66,75,13,False,Computer Science,,2530415,Daria Dzyabura,2344635.0,J. Hauser,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ae5eb09b64347f1ac0531d5c1bd873b2357b8838,https://www.semanticscholar.org/paper/ae5eb09b64347f1ac0531d5c1bd873b2357b8838,StormDroid: A Streaminglized Machine Learning-Based System for Detecting Android Malware,"Mobile devices are especially vulnerable nowadays to malware attacks, thanks to the current trend of increased app downloads. Despite the significant security and privacy concerns it received, effective malware detection (MD) remains a significant challenge. This paper tackles this challenge by introducing a streaminglized machine learning-based MD framework, StormDroid: (i) The core of StormDroid is based on machine learning, enhanced with a novel combination of contributed features that we observed over a fairly large collection of data set; and (ii) we streaminglize the whole MD process to support large-scale analysis, yielding an efficient and scalable MD technique that observes app behaviors statically and dynamically. Evaluated on roughly 8,000 applications, our combination of contributed features improves MD accuracy by almost 10% compared with state-of-the-art antivirus systems; in parallel our streaminglized process, StormDroid, further improves efficiency rate by approximately three times than a single thread.",2016,42,143,12,False,Computer Science,,48847695,Sen Chen,2837434.0,Minhui Xue,3305706.0,Zhushou Tang,46265379.0,Lihua Xu,1741879.0,Haojin Zhu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
90ba5eb1021fdf05edbbcb1424c477d86dd3a216,https://www.semanticscholar.org/paper/90ba5eb1021fdf05edbbcb1424c477d86dd3a216,A Theory of Learning with Corrupted Labels,"It is usual in machine learning theory to assume that the training and testing sets comprise of draws from the same distribution. This is rarely, if ever, true and one must admit the presence of corruption. There are many different types of corruption that can arise and as of yet there is no general means to compare the relative ease of learning in these settings. Such results are necessary if we are to make informed economic decisions regarding the acquisition of data. Here we begin to develop an abstract framework for tackling these problems. We present a generic method for learning from a fixed, known, reconstructible corruption, along with an analyses of its statistical properties. We demonstrate the utility of our framework via concrete novel results in solving supervised learning problems wherein the labels are corrupted, such as learning with noisy labels, semi-supervised learning and learning with partial labels.",2017,56,57,8,False,Computer Science,Mathematics,2719890,Brendan van Rooyen,143957317.0,R. C. Williamson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fc53977508ecb94c7fc543484b1171c4fd0e2192,https://www.semanticscholar.org/paper/fc53977508ecb94c7fc543484b1171c4fd0e2192,Network Learning on the Connection Machine,"Connectionist networks are powerful techniques, inspired by the parallel architecture of the brain, for discovering intrinsic structures in data. However, they are not well suited for implementation on serial computers. In this paper, we discuss the first implementation of a connectionist learning algorithm, error back-propagation, on a fine-grained parallel computer, the Connection Machine. As an example of how the system can be used, we present a parallel implementation of NETtalk, a connectionist network that learns the mapping from English text to the pronunciation of that text. Currently, networks containing up to 16 million links can be simulated on the Connection Machine at speeds nearly twice that of the Cray-2. We found the major impediment to further speed-up to be the communications between processors, and not processor speed per se. We believe that the advantage for parallel computers will become even clearer as developments in parallel computing continue.",1987,16,82,7,False,Computer Science,,1717462,G. Blelloch,3140752.0,Charles R. Rosenberg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5037f4a5976c91ecc55ac033611bab673520fa6a,https://www.semanticscholar.org/paper/5037f4a5976c91ecc55ac033611bab673520fa6a,Machine Learned Sentence Selection Strategies for Query-Biased Summarization,"It has become standard for search engines to augment result lists with document summaries. Each document summary consists of a title, abstract, and a URL. In this work, we focus on the task of selecting relevant sentences for inclusion in the abstract. In particular, we investigate how machine learning-based approaches can effectively be applied to the problem. We analyze and evaluate several learning to rank approaches, such as ranking support vector machines (SVMs), support vector regression (SVR), and gradient boosted decision trees (GBDTs). Our work is the first to evaluate SVR and GBDTs for the sentence selection task. Using standard TREC test collections, we rigorously evaluate various aspects of the sentence selection problem. Our results show that the effectiveness of the machine learning approaches varies across collections with different characteristics. Furthermore, the results show that GBDTs provide a robust and powerful framework for the sentence selection task and significantly outperform SVR and ranking SVMs on several data sets.",2008,31,93,12,False,Computer Science,,1680617,Donald Metzler,143626870.0,T. Kanungo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d3a439ee786f7c8747635306c075420a9bd2aa5b,https://www.semanticscholar.org/paper/d3a439ee786f7c8747635306c075420a9bd2aa5b,Predictor correlation impacts machine learning algorithms: implications for genomic studies,"MOTIVATIONThe advent of high-throughput genomics has produced studies with large numbers of predictors (e.g. genome-wide association, microarray studies). Machine learning algorithms (MLAs) are a computationally efficient way to identify phenotype-associated variables in high-dimensional data. There are important results from mathematical theory and numerous practical results documenting their value. One attractive feature of MLAs is that many operate in a fully multivariate environment, allowing for small-importance variables to be included when they act cooperatively. However, certain properties of MLAs under conditions common in genomic-related data have not been well-studied--in particular, correlations among predictors pose a problem.RESULTS Using extensive simulation, we showed considering correlation within predictors is crucial in making valid inferences using variable importance measures (VIMs) from three MLAs: random forest (RF), conditional inference forest (CIF) and Monte Carlo logic regression (MCLR). Using a case-control illustration, we showed that the RF VIMs--even permutation-based--were less able to detect association than other algorithms at effect sizes encountered in complex disease studies. This reduction occurred when 'causal' predictors were correlated with other predictors, and was sharpest when RF tree building used the Gini index. Indeed, RF Gini VIMs are biased under correlation, dependent on predictor correlation strength/number and over-trained to random fluctuations in data when tree terminal node size was small. Permutation-based VIM distributions were less variable for correlated predictors and are unbiased, thus may be preferred when predictors are correlated. MLAs are a powerful tool for high-dimensional data analysis, but well-considered use of algorithms is necessary to draw valid conclusions.SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.",2009,27,132,4,True,Mathematics,Medicine,144031984,K. Nicodemus,1753856.0,J. Malley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science
8d904d49cb178def9a15fbea955d427d85cad2f5,https://www.semanticscholar.org/paper/8d904d49cb178def9a15fbea955d427d85cad2f5,Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models,"Interpretation and diagnosis of machine learning models have gained renewed interest in recent years with breakthroughs in new approaches. We present Manifold, a framework that utilizes visual analysis techniques to support interpretation, debugging, and comparison of machine learning models in a more transparent and interactive manner. Conventional techniques usually focus on visualizing the internal logic of a specific model type (i.e., deep neural networks), lacking the ability to extend to a more complex scenario where different model types are integrated. To this end, Manifold is designed as a generic framework that does not rely on or access the internal logic of the model and solely observes the input (i.e., instances or features) and the output (i.e., the predicted result and probability distribution). We describe the workflow of Manifold as an iterative process consisting of three major phases that are commonly involved in the model development and diagnosis process: inspection (hypothesis), explanation (reasoning), and refinement (verification). The visual components supporting these tasks include a scatterplot-based visual summary that overviews the models' outcome and a customizable tabular view that reveals feature discrimination. We demonstrate current applications of the framework on the classification and regression tasks and discuss other potential machine learning use scenarios where Manifold can be applied.",2018,44,131,7,True,Computer Science,Medicine,47540407,Jiawei Zhang,2153676199.0,Yang Wang,34890911.0,Piero Molino,2151534400.0,Lezhi Li,33449182.0,D. Ebert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics
562c09c112df56c5696c010d90a815d6018a86c8,https://www.semanticscholar.org/paper/562c09c112df56c5696c010d90a815d6018a86c8,Word Translation Without Parallel Data,"State-of-the-art methods for learning cross-lingual word embeddings have relied on bilingual dictionaries or parallel corpora. Recent studies showed that the need for parallel data supervision can be alleviated with character-level information. While these methods showed encouraging results, they are not on par with their supervised counterparts and are limited to pairs of languages sharing a common alphabet. In this work, we show that we can build a bilingual dictionary between two languages without using any parallel corpora, by aligning monolingual word embedding spaces in an unsupervised way. Without using any character information, our model even outperforms existing supervised methods on cross-lingual tasks for some language pairs. Our experiments demonstrate that our method works very well also for distant language pairs, like English-Russian or English-Chinese. We finally describe experiments on the English-Esperanto low-resource language pair, on which there only exists a limited amount of parallel data, to show the potential impact of our method in fully unsupervised machine translation. Our code, embeddings and dictionaries are publicly available.",2017,52,1237,350,False,Computer Science,,2480903,Alexis Conneau,1830914.0,Guillaume Lample,1706809.0,Marc'Aurelio Ranzato,8905591.0,Ludovic Denoyer,2065248680.0,Herv'e J'egou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26eb706ce9ece8fdff8707e6b558362fbec69895,https://www.semanticscholar.org/paper/26eb706ce9ece8fdff8707e6b558362fbec69895,FAIRVIS: Visual Analytics for Discovering Intersectional Bias in Machine Learning,"The growing capability and accessibility of machine learning has led to its application to many real-world domains and data about people. Despite the benefits algorithmic systems may bring, models can reflect, inject, or exacerbate implicit and explicit societal biases into their outputs, disadvantaging certain demographic subgroups. Discovering which biases a machine learning model has introduced is a great challenge, due to the numerous definitions of fairness and the large number of potentially impacted subgroups. We present FAIRVIS, a mixed-initiative visual analytics system that integrates a novel subgroup discovery technique for users to audit the fairness of machine learning models. Through FAIRVIS, users can apply domain knowledge to generate and investigate known subgroups, and explore suggested and similar subgroups. FAIRVIS's coordinated views enable users to explore a high-level overview of subgroup performance and subsequently drill down into detailed investigation of specific subgroups. We show how FAIRVIS helps to discover biases in two real datasets used in predicting income and recidivism. As a visual analytics system devoted to discovering bias in machine learning, FAIRVIS demonstrates how interactive visualization may help data scientists and the general public understand and create more equitable algorithmic systems.",2019,36,83,6,True,Computer Science,Mathematics,102477227,Ángel Alexander Cabrera,103260170.0,Will Epperson,10735510.0,Fred Hohman,1768057.0,Minsuk Kahng,144848816.0,Jamie H. Morgenstern,1793506.0,Duen Horng Chau,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6e46d8aa63db3285417c8ebb65340b5045ca106f,https://www.semanticscholar.org/paper/6e46d8aa63db3285417c8ebb65340b5045ca106f,Accelerating Machine Learning Inference with Probabilistic Predicates,"Classic query optimization techniques, including predicate pushdown, are of limited use for machine learning inference queries, because the user-defined functions (UDFs) which extract relational columns from unstructured inputs are often very expensive; query predicates will remain stuck behind these UDFs if they happen to require relational columns that are generated by the UDFs. In this work, we demonstrate constructing and applying probabilistic predicates to filter data blobs that do not satisfy the query predicate; such filtering is parametrized to different target accuracies. Furthermore, to support complex predicates and to avoid per-query training, we augment a cost-based query optimizer to choose plans with appropriate combinations of simpler probabilistic predicates. Experiments with several machine learning workloads on a big-data cluster show that query processing improves by as much as 10x.",2018,55,68,12,False,Computer Science,,2143370657,Yao Lu,2841893.0,Aakanksha Chowdhery,1741860.0,Srikanth Kandula,145647476.0,S. Chaudhuri,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13f542da0ca3aeb06873b495893f63b21662ef18,https://www.semanticscholar.org/paper/13f542da0ca3aeb06873b495893f63b21662ef18,Elastic Machine Learning Algorithms in Amazon SageMaker,"There is a large body of research on scalable machine learning (ML). Nevertheless, training ML models on large, continuously evolving datasets is still a difficult and costly undertaking for many companies and institutions. We discuss such challenges and derive requirements for an industrial-scale ML platform. Next, we describe the computational model behind Amazon SageMaker, which is designed to meet such challenges. SageMaker is an ML platform provided as part of Amazon Web Services (AWS), and supports incremental training, resumable and elastic learning as well as automatic hyperparameter optimization. We detail how to adapt several popular ML algorithms to its computational model. Finally, we present an experimental evaluation on large datasets, comparing SageMaker to several scalable, JVM-based implementations of ML algorithms, which we significantly outperform with regard to computation time and cost.",2020,73,72,1,False,Computer Science,,2941680,Edo Liberty,3386660.0,Zohar S. Karnin,144028698.0,Bing Xiang,1726063598.0,Laurence Rouesnel,3172811.0,B. Coskun,1701451.0,Ramesh Nallapati,2065033430.0,Julio Delgado,94237600.0,Amir Sadoughi,1726057031.0,Yury Astashonok,2792763.0,Piali Das,1726054029.0,Can Balioglu,31950623.0,Saswata Chakravarty,16700909.0,Madhav Jha,145021445.0,P. Gautier,38704631.0,D. Arpin,2166235.0,Tim Januschowski,2067154581.0,Valentin Flunkert,49416149.0,Bernie Wang,2113062.0,Jan Gasthaus,2066263165.0,Lorenzo Stella,26320653.0,Syama Sundar Rangapuram,144607961.0,David Salinas,2180399.0,Sebastian Schelter,46234526.0,Alex Smola,,,
3dbb621f1c35c659f3ce6efadad7aa16308fae13,https://www.semanticscholar.org/paper/3dbb621f1c35c659f3ce6efadad7aa16308fae13,Breast cancer histopathological image classification using Convolutional Neural Networks,"The performance of most conventional classification systems relies on appropriate data representation and much of the efforts are dedicated to feature engineering, a difficult and time-consuming process that uses prior expert domain knowledge of the data to create useful features. On the other hand, deep learning can extract and organize the discriminative information from the data, not requiring the design of feature extractors by a domain expert. Convolutional Neural Networks (CNNs) are a particular type of deep, feedforward network that have gained attention from research community and industry, achieving empirical successes in tasks such as speech recognition, signal processing, object recognition, natural language processing and transfer learning. In this paper, we conduct some preliminary experiments using the deep learning approach to classify breast cancer histopathological images from BreaKHis, a publicly dataset available at http://web.inf.ufpr.br/vri/breast-cancer-database. We propose a method based on the extraction of image patches for training the CNN and the combination of these patches for final classification. This method aims to allow using the high-resolution histopathological images from BreaKHis as input to existing CNN, avoiding adaptations of the model that can lead to a more complex and computationally costly architecture. The CNN performance is better when compared to previously reported results obtained by other machine learning models trained with hand-crafted textural descriptors. Finally, we also investigate the combination of different CNNs using simple fusion rules, achieving some improvement in recognition rates.",2016,33,559,41,False,Computer Science,,32786132,F. Spanhol,144925520.0,Luiz Oliveira,144518944.0,C. Petitjean,1804638.0,L. Heutte,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7044a87c6987554186471c2f9116aa53c1392be7,https://www.semanticscholar.org/paper/7044a87c6987554186471c2f9116aa53c1392be7,Arabic Named Entity Recognition using Optimized Feature Sets,"The Named Entity Recognition (NER) task has been garnering significant attention in NLP as it helps improve the performance of many natural language processing applications. In this paper, we investigate the impact of using different sets of features in two discriminative machine learning frameworks, namely, Support Vector Machines and Conditional Random Fields using Arabic data. We explore lexical, contextual and morphological features on eight standardized data-sets of different genres. We measure the impact of the different features in isolation, rank them according to their impact for each named entity class and incrementally combine them in order to infer the optimal machine learning approach and feature set. Our system yields a performance of Fβ=1-measure=83.5 on ACE 2003 Broadcast News data.",2008,19,133,19,True,Computer Science,,1788883,Yassine Benajiba,1700007.0,Mona T. Diab,143752702.0,Paolo Rosso,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b34c6081aac87d4d9f659c8f342c05ce7b835bba,https://www.semanticscholar.org/paper/b34c6081aac87d4d9f659c8f342c05ce7b835bba,Continuous Prediction of Spontaneous Affect from Multiple Cues and Modalities in Valence-Arousal Space,"Past research in analysis of human affect has focused on recognition of prototypic expressions of six basic emotions based on posed data acquired in laboratory settings. Recently, there has been a shift toward subtle, continuous, and context-specific interpretations of affective displays recorded in naturalistic and real-world settings, and toward multimodal analysis and recognition of human affect. Converging with this shift, this paper presents, to the best of our knowledge, the first approach in the literature that: 1) fuses facial expression, shoulder gesture, and audio cues for dimensional and continuous prediction of emotions in valence and arousal space, 2) compares the performance of two state-of-the-art machine learning techniques applied to the target problem, the bidirectional Long Short-Term Memory neural networks (BLSTM-NNs), and Support Vector Machines for Regression (SVR), and 3) proposes an output-associative fusion framework that incorporates correlations and covariances between the emotion dimensions. Evaluation of the proposed approach has been done using the spontaneous SAL data from four subjects and subject-dependent leave-one-sequence-out cross validation. The experimental results obtained show that: 1) on average, BLSTM-NNs outperform SVR due to their ability to learn past and future context, 2) the proposed output-associative fusion framework outperforms feature-level and model-level fusion by modeling and learning correlations and patterns between the valence and arousal dimensions, and 3) the proposed system is well able to reproduce the valence and arousal ground truth obtained from human coders.",2011,72,443,33,True,Psychology,Computer Science,1752913,M. Nicolaou,1781916.0,H. Gunes,145387780.0,M. Pantic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d5eef7e4f0b2a4ddf90330f5a0b71e70f164b6cf,https://www.semanticscholar.org/paper/d5eef7e4f0b2a4ddf90330f5a0b71e70f164b6cf,The support vector decomposition machine,"In machine learning problems with tens of thousands of features and only dozens or hundreds of independent training examples, dimensionality reduction is essential for good learning performance. In previous work, many researchers have treated the learning problem in two separate phases: first use an algorithm such as singular value decomposition to reduce the dimensionality of the data set, and then use a classification algorithm such as naïve Bayes or support vector machines to learn a classifier. We demonstrate that it is possible to combine the two goals of dimensionality reduction and classification into a single learning objective, and present a novel and efficient algorithm which optimizes this objective directly. We present experimental results in fMRI analysis which show that we can achieve better learning performance and lower-dimensional representations than two-phase approaches can.",2006,15,58,4,True,Mathematics,Computer Science,144637670,Francisco Pereira,21889436.0,Geoffrey J. Gordon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3ae21b55af86937d56e60ca1181d3f330e4f5881,https://www.semanticscholar.org/paper/3ae21b55af86937d56e60ca1181d3f330e4f5881,Predicting structured objects with support vector machines,"Machine Learning today offers a broad repertoire of methods for classification and regression. But what if we need to predict complex objects like trees, orderings, or alignments? Such problems arise naturally in natural language processing, search engines, and bioinformatics. The following explores a generalization of Support Vector Machines (SVMs) for such complex prediction problems.",2009,44,109,12,True,Computer Science,,1680188,T. Joachims,143936663.0,Thomas Hofmann,1740159.0,Yisong Yue,3166569.0,C. Yu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49051605a56a9c82a2401f96c3471312d00552d9,https://www.semanticscholar.org/paper/49051605a56a9c82a2401f96c3471312d00552d9,A Novel PCA-Firefly Based XGBoost Classification Model for Intrusion Detection in Networks Using GPU,"The enormous popularity of the internet across all spheres of human life has introduced various risks of malicious attacks in the network. The activities performed over the network could be effortlessly proliferated, which has led to the emergence of intrusion detection systems. The patterns of the attacks are also dynamic, which necessitates efficient classification and prediction of cyber attacks. In this paper we propose a hybrid principal component analysis (PCA)-firefly based machine learning model to classify intrusion detection system (IDS) datasets. The dataset used in the study is collected from Kaggle. The model first performs One-Hot encoding for the transformation of the IDS datasets. The hybrid PCA-firefly algorithm is then used for dimensionality reduction. The XGBoost algorithm is implemented on the reduced dataset for classification. A comprehensive evaluation of the model is conducted with the state of the art machine learning approaches to justify the superiority of our proposed approach. The experimental results confirm the fact that the proposed model performs better than the existing machine learning models.",2020,32,168,1,True,Computer Science,,71424255,S. Bhattacharya,2127823435.0,S. S,29919430.0,P. Maddikunta,46234199.0,Rajesh Kaluri,144704227.0,Saurabh Singh,11041265.0,T. Gadekallu,2474250.0,M. Alazab,51230514.0,U. Tariq,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18939eadc9c4460c8385e0591cde214a1ead067b,https://www.semanticscholar.org/paper/18939eadc9c4460c8385e0591cde214a1ead067b,Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks,"The field of defense strategies against adversarial attacks has significantly grown over the last years, but progress is hampered as the evaluation of adversarial defenses is often insufficient and thus gives a wrong impression of robustness. Many promising defenses could be broken later on, making it difficult to identify the state-of-the-art. Frequent pitfalls in the evaluation are improper tuning of hyperparameters of the attacks, gradient obfuscation or masking. In this paper we first propose two extensions of the PGD-attack overcoming failures due to suboptimal step size and problems of the objective function. We then combine our novel attacks with two complementary existing ones to form a parameter-free, computationally affordable and user-independent ensemble of attacks to test adversarial robustness. We apply our ensemble to over 50 models from papers published at recent top machine learning and computer vision venues. In all except one of the cases we achieve lower robust test accuracy than reported in these papers, often by more than $10\%$, identifying several broken defenses.",2020,58,653,225,False,Computer Science,Mathematics,39171784,Francesco Croce,143610806.0,Matthias Hein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cff7b1b98da6de583bf2d5ffd496c2e6d70a794c,https://www.semanticscholar.org/paper/cff7b1b98da6de583bf2d5ffd496c2e6d70a794c,From DFT to machine learning: recent approaches to materials science–a review,"Recent advances in experimental and computational methods are increasing the quantity and complexity of generated data. This massive amount of raw data needs to be stored and interpreted in order to advance the materials science field. Identifying correlations and patterns from large amounts of complex data is being performed by machine learning algorithms for decades. Recently, the materials science community started to invest in these methodologies to extract knowledge and insights from the accumulated data. This review follows a logical sequence starting from density functional theory as the representative instance of electronic structure methods, to the subsequent high-throughput approach, used to generate large amounts of data. Ultimately, data-driven strategies which include data mining, screening, and machine learning techniques, employ the data generated. We show how these approaches to modern computational materials science are being used to uncover complexities and design novel materials with enhanced properties. Finally, we point to the present research problems, challenges, and potential future perspectives of this new exciting field.",2019,587,294,2,False,Physics,,11898127,G. R. Schleder,93993846.0,A. C. M. Padilha,152541090.0,C. M. Acosta,144194651.0,M. Costa,145385217.0,A. Fazzio,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fceddfc62c6104a205f8553588f16ca6e0ea0b3c,https://www.semanticscholar.org/paper/fceddfc62c6104a205f8553588f16ca6e0ea0b3c,Education 4.0 — Fostering student's performance with machine learning methods,"Educational activity is increasingly moving online and course contents are becoming available in digital format. This enables data collection and the use of data for analyzing learning process. For the 4th Revolution in Education, an active and interactive presence of students contributes to a higher learning quality. Machine Learning techniques recently have shown impressive development steps of the use of data analysis and predictions. However, it has been far less used for assessing the learning quality. For this paper we conducted analysis based on neural networks, support vector machine, decision trees and cluster analysis to estimate student's performance at examination and shape the next generation's talent for Industry 4.0 skills.",2017,18,68,3,False,Computer Science,,30710053,M. Ciolacu,3242843.0,A. Tehrani,47377858.0,Rick Beer,2085317493.0,Heribert Popp,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d2d79513f32c4d09b6255b18514d7ad07ebf43fe,https://www.semanticscholar.org/paper/d2d79513f32c4d09b6255b18514d7ad07ebf43fe,Explainable artificial intelligence: A survey,"In the last decade, with availability of large datasets and more computing power, machine learning systems have achieved (super)human performance in a wide variety of tasks. Examples of this rapid development can be seen in image recognition, speech analysis, strategic game planning and many more. The problem with many state-of-the-art models is a lack of transparency and interpretability. The lack of thereof is a major drawback in many applications, e.g. healthcare and finance, where rationale for model's decision is a requirement for trust. In the light of these issues, explainable artificial intelligence (XAI) has become an area of interest in research community. This paper summarizes recent developments in XAI in supervised learning, starts a discussion on its connection with artificial general intelligence, and gives proposals for further research directions.",2018,28,478,24,False,Computer Science,,1395592010,Filip Karlo Dosilovic,35167635.0,Mario Brčič,1791663.0,N. Hlupic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16f05470e01a0c6fd7e925f77d48302bbf872189,https://www.semanticscholar.org/paper/16f05470e01a0c6fd7e925f77d48302bbf872189,Online Algorithms for Rent-Or-Buy with Expert Advice,"We study the use of predictions by multiple experts (such as machine learning algorithms) to improve the performance of online algorithms. In particular, we consider the classical rent-or-buy problem (also called ski rental), and obtain algorithms that provably improve their performance over the adversarial scenario by using these predictions. We also prove matching lower bounds to show that our algorithms are the best possible, and perform experiments to empirically validate their performance in practice.",2019,20,86,6,False,Computer Science,,144979147,Sreenivas Gollapudi,1715972.0,Debmalya Panigrahi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c45d0d50c44af507f694cb3ae0debd76c560e364,https://www.semanticscholar.org/paper/c45d0d50c44af507f694cb3ae0debd76c560e364,Understanding from Machine Learning Models,"Simple idealized models seem to provide more understanding than opaque, complex, and hyper-realistic models. However, an increasing number of scientists are going in the opposite direction by utilizing opaque machine learning models to make predictions and draw inferences, suggesting that scientists are opting for models that have less potential for understanding. Are scientists trading understanding for some other epistemic or pragmatic good when they choose a machine learning model? Or are the assumptions behind why minimal models provide understanding misguided? In this article, using the case of deep neural networks, I argue that it is not the complexity or black box nature of a model that limits how much understanding the model provides. Instead, it is a lack of scientific and empirical evidence supporting the link that connects a model to the target phenomenon that primarily prohibits understanding.",2020,81,50,1,True,Computer Science,,49503692,E. Sullivan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
784b018c87c7dcbbe772374e45d5191bae9938ee,https://www.semanticscholar.org/paper/784b018c87c7dcbbe772374e45d5191bae9938ee,Hyperbolic Graph Neural Networks,"Learning from graph-structured data is an important task in machine learning and artificial intelligence, for which Graph Neural Networks (GNNs) have shown great promise. Motivated by recent advances in geometric representation learning, we propose a novel GNN architecture for learning representations on Riemannian manifolds with differentiable exponential and logarithmic maps. We develop a scalable algorithm for modeling the structural properties of graphs, comparing Euclidean and hyperbolic geometry. In our experiments, we show that hyperbolic GNNs can lead to substantial improvements on various benchmark datasets.",2019,52,156,20,False,Computer Science,Mathematics,2144831836,Qi Liu,1729762.0,Maximilian Nickel,1743722.0,Douwe Kiela,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bd0cb6f62619649616316ca3c1348f568c63a852,https://www.semanticscholar.org/paper/bd0cb6f62619649616316ca3c1348f568c63a852,A survey on measuring indirect discrimination in machine learning,"Nowadays, many decisions are made using predictive models built on historical data.Predictive models may systematically discriminate groups of people even if the computing process is fair and well-intentioned. Discrimination-aware data mining studies how to make predictive models free from discrimination, when historical data, on which they are built, may be biased, incomplete, or even contain past discriminatory decisions. Discrimination refers to disadvantageous treatment of a person based on belonging to a category rather than on individual merit. In this survey we review and organize various discrimination measures that have been used for measuring discrimination in data, as well as in evaluating performance of discrimination-aware predictive models. We also discuss related measures from other disciplines, which have not been used for measuring discrimination, but potentially could be suitable for this purpose. We computationally analyze properties of selected measures. We also review and discuss measuring procedures, and present recommendations for practitioners. The primary target audience is data mining, machine learning, pattern recognition, statistical modeling researchers developing new methods for non-discriminatory predictive modeling. In addition, practitioners and policy makers would use the survey for diagnosing potential discrimination by predictive models.",2015,44,128,7,False,Computer Science,Mathematics,1740809,I. Žliobaitė,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34c062e2b8a3f6421b9f4ff22f115a36d4aba823,https://www.semanticscholar.org/paper/34c062e2b8a3f6421b9f4ff22f115a36d4aba823,A Dataset and a Technique for Generalized Nuclear Segmentation for Computational Pathology,"Nuclear segmentation in digital microscopic tissue images can enable extraction of high-quality features for nuclear morphometrics and other analysis in computational pathology. Conventional image processing techniques, such as Otsu thresholding and watershed segmentation, do not work effectively on challenging cases, such as chromatin-sparse and crowded nuclei. In contrast, machine learning-based segmentation can generalize across various nuclear appearances. However, training machine learning algorithms requires data sets of images, in which a vast number of nuclei have been annotated. Publicly accessible and annotated data sets, along with widely agreed upon metrics to compare techniques, have catalyzed tremendous innovation and progress on other image classification problems, particularly in object recognition. Inspired by their success, we introduce a large publicly accessible data set of hematoxylin and eosin (H&E)-stained tissue images with more than 21000 painstakingly annotated nuclear boundaries, whose quality was validated by a medical doctor. Because our data set is taken from multiple hospitals and includes a diversity of nuclear appearances from several patients, disease states, and organs, techniques trained on it are likely to generalize well and work right out-of-the-box on other H&E-stained images. We also propose a new metric to evaluate nuclear segmentation results that penalizes object- and pixel-level errors in a unified manner, unlike previous metrics that penalize only one type of error. We also propose a segmentation technique based on deep learning that lays a special emphasis on identifying the nuclear boundaries, including those between the touching or overlapping nuclei, and works well on a diverse set of test images.",2017,51,469,107,False,Computer Science,Medicine,2119734444,Neeraj Kumar,3200813.0,R. Verma,2109948052.0,Sanuj Sharma,2061041305.0,S. Bhargava,1927113.0,Abhishek Vahadane,2049437.0,A. Sethi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
053f4d6715a4dba6f8103456fc1bb5fd6a5266c4,https://www.semanticscholar.org/paper/053f4d6715a4dba6f8103456fc1bb5fd6a5266c4,Ensemble Distillation for Robust Model Fusion in Federated Learning,"Federated Learning (FL) is a machine learning setting where many devices collaboratively train a machine learning model while keeping the training data decentralized. In most of the current training schemes the central model is refined by averaging the parameters of the server model and the updated parameters from the client side. However, directly averaging model parameters is only possible if all models have the same structure and size, which could be a restrictive constraint in many scenarios. In this work we investigate more powerful and more flexible aggregation schemes for FL. Specifically, we propose ensemble distillation for model fusion, i.e. training the central classifier through unlabeled data on the outputs of the models from the clients. This knowledge distillation technique mitigates privacy risk and cost to the same extent as the baseline FL algorithms, but allows flexible aggregation over heterogeneous client models that can differ e.g. in size, numerical precision or structure. We show in extensive empirical experiments on various CV/NLP datasets (CIFAR-10/100, ImageNet, AG News, SST2) and settings (heterogeneous models/data) that the server model can be trained much faster, requiring fewer communication rounds than any existing FL technique so far.",2020,86,250,52,False,Computer Science,Mathematics,145724662,Tao Lin,2069275317.0,Lingjing Kong,2127057.0,Sebastian U. Stich,2456863.0,Martin Jaggi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
