paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,fieldsOfStudy/3
f6227e4c1caf47da99955b61253984bfbb0eddf8,https://www.semanticscholar.org/paper/f6227e4c1caf47da99955b61253984bfbb0eddf8,Benchmark Data Set for in Silico Prediction of Ames Mutagenicity,"Up to now, publicly available data sets to build and evaluate Ames mutagenicity prediction tools have been very limited in terms of size and chemical space covered. In this report we describe a new unique public Ames mutagenicity data set comprising about 6500 nonconfidential compounds (available as SMILES strings and SDF) together with their biological activity. Three commercial tools (DEREK, MultiCASE, and an off-the-shelf Bayesian machine learner in Pipeline Pilot) are compared with four noncommercial machine learning implementations (Support Vector Machines, Random Forests, k-Nearest Neighbors, and Gaussian Processes) on the new benchmark data set.",2009,8,241,9,False,Computer Science,Medicine,39960184,K. Hansen,2459012.0,S. Mika,34954622.0,T. Schroeter,2079588955.0,A. Sutter,14270207.0,A. T. Laak,1390062673.0,T. Steger-Hartmann,34305015.0,N. Heinrich,145034054.0,K. Müller,,,,,,,,,,,,
56453a88588732bbb9975166e019b052c4fcc0a7,https://www.semanticscholar.org/paper/56453a88588732bbb9975166e019b052c4fcc0a7,Estimating crop yields with deep learning and remotely sensed data,"This paper describes Illinois corn yield estimation using deep learning and another machine learning, SVR. Deep learning is a technique that has been attracting attention in recent years of machine learning, it is possible to implement using the Caffe. High accuracy estimation of crop yield is very important from the viewpoint of food security. However, since every country prepare data inhomogeneously, the implementation of the crop model in all regions is difficult. Deep learning is possible to extract important features for estimating the object from the input data, so it can be expected to reduce dependency of input data. The network model of two InnerProductLayer was the best algorithm in this study, achieving RMSE of 6.298 (standard value). This study highlights the advantages of deep learning for agricultural yield estimating.",2015,13,137,9,False,Computer Science,,46944179,Kentaro Kuwata,1721111.0,R. Shibasaki,,,,,,,,,,,,,,,,,,,,,,,,
4467bf31acec51141c4cb799e6cebbb8ef7150ec,https://www.semanticscholar.org/paper/4467bf31acec51141c4cb799e6cebbb8ef7150ec,Adoption of Machine Learning Techniques in Ecology and Earth Science,"The natural sciences, such as ecology and earth science, study complex interactions between biotic and abiotic systems in order to infer understanding and make predictions. Machine-learning-based methods have an advantage over traditional statistical methods in studying these systems because the former do not impose unrealistic assumptions (such as linearity), are capable of inferring missing data, and can reduce long-term expert annotation burden. Thus, a wider adoption of machine learning methods in ecology and earth science has the potential to greatly accelerate the pace and quality of science. Despite these advantages, machine learning techniques have not had wide spread adoption in ecology and earth science. This is largely due to 1) a lack of communication and collaboration between the machine learning research community and natural scientists, 2) a lack of easily accessible tools and services, and 3) the requirement for a robust training and test data set. These impediments can be overcome through financial support for collaborative work and the development of tools and services facilitating ML use. Natural scientists who have not yet used machine learning methods can be introduced to these techniques through Random Forest, a method that is easy to implement and performs well. This manuscript will 1) briefly describe several popular ML methods and their application to ecology and earth science, 2) discuss why ML methods are underutilized in natural science, and 3) propose solutions for barriers preventing wider ML adoption.",2016,230,91,4,True,Computer Science,,2058930,A. Thessen,,,,,,,,,,,,,,,,,,,,,,,,,,
0d678ce457ad13e0d13a96cd502cc9da0ae95dcd,https://www.semanticscholar.org/paper/0d678ce457ad13e0d13a96cd502cc9da0ae95dcd,Experimental Machine Learning of Quantum States.,"Quantum information technologies provide promising applications in communication and computation, while machine learning has become a powerful technique for extracting meaningful structures in ""big data."" A crossover between quantum information and machine learning represents a new interdisciplinary area stimulating progress in both fields. Traditionally, a quantum state is characterized by quantum-state tomography, which is a resource-consuming process when scaled up. Here we experimentally demonstrate a machine-learning approach to construct a quantum-state classifier for identifying the separability of quantum states. We show that it is possible to experimentally train an artificial neural network to efficiently learn and classify quantum states, without the need of obtaining the full information of the states. We also show how adding a hidden layer of neurons to the neural network can significantly boost the performance of the state classifier. These results shed new light on how classification of quantum states can be achieved with limited resources, and represent a step towards machine-learning-based applications in quantum information processing.",2017,47,93,0,True,Medicine,Physics,2111014047,Jun Gao,6891618.0,Lu-Feng Qiao,66183707.0,Zhi-Qiang Jiao,2109387083.0,Yue-Chi Ma,50989843.0,Cheng-Qiu Hu,51012274.0,Ruo-Jing Ren,8026905.0,Ai-Lin Yang,2109238434.0,Hao Tang,Computer Science,145666876.0,M. Yung,3398360.0,Xian-min Jin,,,,,,,
330dda431e0343a96f9d630a0b4ee526bd93ad11,https://www.semanticscholar.org/paper/330dda431e0343a96f9d630a0b4ee526bd93ad11,Domain Adaptation for Visual Applications: A Comprehensive Survey,"The aim of this paper is to give an overview of domain adaptation and transfer learning with a specific view on visual applications. After a general motivation, we first position domain adaptation in the larger transfer learning problem. Second, we try to address and analyze briefly the state-of-the-art methods for different types of scenarios, first describing the historical shallow methods, addressing both the homogeneous and the heterogeneous domain adaptation methods. Third, we discuss the effect of the success of deep convolutional architectures which led to new type of domain adaptation methods that integrate the adaptation within the deep architecture. Fourth, we overview the methods that go beyond image categorization, such as object detection or image segmentation, video analyses or learning visual attributes. Finally, we conclude the paper with a section where we relate domain adaptation to other machine learning solutions.",2017,286,373,14,False,Computer Science,,1808423,G. Csurka,,,,,,,,,,,,,,,,,,,,,,,,,,
1683ffc189d16b616131c300f45af87602d211f7,https://www.semanticscholar.org/paper/1683ffc189d16b616131c300f45af87602d211f7,Fast context-aware recommendations with factorization machines,"The situation in which a choice is made is an important information for recommender systems. Context-aware recommenders take this information into account to make predictions. So far, the best performing method for context-aware rating prediction in terms of predictive accuracy is Multiverse Recommendation based on the Tucker tensor factorization model. However this method has two drawbacks: (1) its model complexity is exponential in the number of context variables and polynomial in the size of the factorization and (2) it only works for categorical context variables. On the other hand there is a large variety of fast but specialized recommender methods which lack the generality of context-aware methods. We propose to apply Factorization Machines (FMs) to model contextual information and to provide context-aware rating predictions. This approach results in fast context-aware recommendations because the model equation of FMs can be computed in linear time both in the number of context variables and the factorization size. For learning FMs, we develop an iterative optimization method that analytically finds the least-square solution for one parameter given the other ones. Finally, we show empirically that our approach outperforms Multiverse Recommendation in prediction quality and runtime.",2011,21,525,43,False,Computer Science,,2843982,Steffen Rendle,2382247.0,Zeno Gantner,1825333.0,C. Freudenthaler,1388781075.0,L. Schmidt-Thieme,,,,,,,,,,,,,,,,,,,,
9a28e015836560996fe1e406891eeee11a3449c1,https://www.semanticscholar.org/paper/9a28e015836560996fe1e406891eeee11a3449c1,Machine learning for spoken dialogue systems,"During the last decade, research in the field of Spoken Dialogue Systems (SDS) has experienced increasing growth. However, the design and optimization of SDS is not only about combin- ing speech and language processing systems such as Automatic Speech Recognition (ASR), parsers, Natural Language Gener- ation (NLG), and Text-to-Speech (TTS) synthesis systems. It also requires the development of dialogue strategies taking at least into account the performances of these subsystems (and others), the nature of the task (e.g. form filling, tutoring, robot control, or database search/browsing), and the user's behaviour (e.g. cooperativeness, expertise). Due to the great variability of these factors, reuse of previous hand-crafted designs is also made very difficult. For these reasons, statistical machine learn- ing (ML) methods applied to automatic SDS optimization have been a leading research area for the last few years. In this paper, we provide a short review of the field and of recent advances.",2007,42,126,5,False,Computer Science,,1782798,Oliver Lemon,1721354.0,O. Pietquin,,,,,,,,,,,,,,,,,,,,,,,,
700dd2b620c12b06ba47225752b300c2c8d8c31f,https://www.semanticscholar.org/paper/700dd2b620c12b06ba47225752b300c2c8d8c31f,Learning to Discover Social Circles in Ego Networks,"Our personal social networks are big and cluttered, and currently there is no good way to organize them. Social networking sites allow users to manually categorize their friends into social circles (e.g. 'circles' on Google+, and 'lists' on Facebook and Twitter), however they are laborious to construct and must be updated whenever a user's network grows. We define a novel machine learning task of identifying users' social circles. We pose the problem as a node clustering problem on a user's ego-network, a network of connections between her friends. We develop a model for detecting circles that combines network structure as well as user profile information. For each circle we learn its members and the circle-specific user profile similarity metric. Modeling node membership to multiple circles allows us to detect overlapping as well as hierarchically nested circles. Experiments show that our model accurately identifies circles on a diverse set of data from Facebook, Google+, and Twitter for all of which we obtain hand-labeled ground-truth.",2012,40,1403,146,False,Computer Science,,35660011,Julian McAuley,1702139.0,J. Leskovec,,,,,,,,,,,,,,,,,,,,,,,,
a1abe16a6bc50b1e06e0a23282105db367854188,https://www.semanticscholar.org/paper/a1abe16a6bc50b1e06e0a23282105db367854188,Combinatorial screening for new materials in unconstrained composition space with machine learning,"Typically, computational screens for new materials sharply constrain the compositional search space, structural search space, or both, for the sake of tractability. To lift these constraints, we construct a machine learning model from a database of thousands of density functional theory (DFT) calculations. The resulting model can predict the thermodynamic stability of arbitrary compositions without any other input and with six orders of magnitude less computer time than DFT. We use this model to scan roughly 1.6 million candidate compositions for novel ternary compounds (AxByCz), and predict 4500 new stable materials. Our method can be readily applied to other descriptors of interest to accelerate domain-specific materials discovery.",2014,54,433,5,False,Materials Science,,8839934,B. Meredig,2075308233.0,Amit Agrawal,8407652.0,S. Kirklin,39280442.0,J. Saal,1907763.0,J. Doak,2117429617.0,Alan J Thompson,2119017058.0,Kunpeng Zhang,143975793.0,A. Choudhary,,2088553.0,C. Wolverton,,,,,,,,,
b208cff55a44f9daa82972f81690be29a2677e2d,https://www.semanticscholar.org/paper/b208cff55a44f9daa82972f81690be29a2677e2d,A Differentiable Programming System to Bridge Machine Learning and Scientific Computing,"Scientific computing is increasingly incorporating the advancements in machine learning and the ability to work with large amounts of data. At the same time, machine learning models are becoming increasingly sophisticated and exhibit many features often seen in scientific computing, stressing the capabilities of machine learning frameworks. Just as the disciplines of scientific computing and machine learning have shared common underlying infrastructure in the form of numerical linear algebra, we now have the opportunity to further share new computational infrastructure, and thus ideas, in the form of Differentiable Programming. We describe Zygote, a Differentiable Programming system that is able to take gradients of general program structures. We implement this system in the Julia programming language. Our system supports almost all language constructs (control flow, recursion, mutation, etc.) and compiles high-performance code without requiring any user intervention or refactoring to stage computations. This enables an expressive programming model for deep learning, but more importantly, it enables us to incorporate a large ecosystem of libraries in our models in a straightforward way. We discuss our approach to automatic differentiation, including its support for advanced techniques such as mixed-mode, complex and checkpointed differentiation, and present several examples of differentiating programs.",2019,50,107,4,False,Computer Science,,34289387,Mike Innes,144397527.0,A. Edelman,47247177.0,Keno Fischer,150956309.0,C. Rackauckas,2377846.0,Elliot Saba,2543935.0,Viral B. Shah,90684986.0,Will Tebbutt,,,,,,,,,,,,,,
92ab9599524eccd753a5d5300f4001d13c543ce3,https://www.semanticscholar.org/paper/92ab9599524eccd753a5d5300f4001d13c543ce3,An Introduction to Machine Learning Communications Systems,"We introduce and motivate machine learning (ML) communications systems that aim to improve on and to even replace the vast expert knowledge in the field of communications using modern machine learning techniques. These have recently achieved breakthroughs in many different domains, but not yet in communications. By interpreting a communications system as an autoencoder, we develop a fundamental new way to think about radio communications system design as an end-to-end reconstruction optimization task that seeks to jointly optimize transmitter and receiver components in a single process. We further present the concept of Radio Transformer Networks (RTNs) as a means to incorporate expert domain knowledge in the ML model and study the application of convolutional neural networks (CNNs) on raw IQ time-series data for modulation classification. We conclude the paper with a deep discussion of open challenges and areas for future investigation.",2017,52,95,4,False,Computer Science,,1388350203,Tim O'Shea,1749686.0,J. Hoydis,,,,,,,,,,,,,,,,,,,,,,,,
ede72940ae0246a292d644bd3c7e0ebf1e12a01a,https://www.semanticscholar.org/paper/ede72940ae0246a292d644bd3c7e0ebf1e12a01a,Opportunities and Challenges for Machine Learning in Materials Science,"Advances in machine learning have impacted myriad areas of materials science, such as the discovery of novel materials and the improvement of molecular simulations, with likely many more important developments to come. Given the rapid changes in this field, it is challenging to understand both the breadth of opportunities and the best practices for their use. In this review, we address aspects of both problems by providing an overview of the areas in which machine learning has recently had significant impact in materials science, and then we provide a more detailed discussion on determining the accuracy and domain of applicability of some common types of machine learning models. Finally, we discuss some opportunities and challenges for the materials community to fully utilize the capabilities of machine learning.",2020,248,79,0,True,Materials Science,Physics,79150910,D. Morgan,46940104.0,R. Jacobs,,,,,,,,,,,,,,,,,,,,,,,,
d395c7b8d43faaa37d69506cad18eb6ec58e26d7,https://www.semanticscholar.org/paper/d395c7b8d43faaa37d69506cad18eb6ec58e26d7,A novel method for protein secondary structure prediction using dual‐layer SVM and profiles,"A high‐performance method was developed for protein secondary structure prediction based on the dual‐layer support vector machine (SVM) and position‐specific scoring matrices (PSSMs). SVM is a new machine learning technology that has been successfully applied in solving problems in the field of bioinformatics. The SVM's performance is usually better than that of traditional machine learning approaches. The performance was further improved by combining PSSM profiles with the SVM analysis. The PSSMs were generated from PSI‐BLAST profiles, which contain important evolution information. The final prediction results were generated from the second SVM layer output. On the CB513 data set, the three‐state overall per‐residue accuracy, Q3, reached 75.2%, while segment overlap (SOV) accuracy increased to 80.0%. On the CB396 data set, the Q3 of our method reached 74.0% and the SOV reached 78.1%. A web server utilizing the method has been constructed and is available at http://www.bioinfo.tsinghua.edu.cn/pmsvm. Proteins 2004;00:000–000. © 2004 Wiley‐Liss, Inc.",2004,30,195,12,False,Computer Science,Medicine,50115727,Jian Guo,2108276437.0,Hu Chen,2300991.0,Zhirong Sun,2153417.0,Yuanlie Lin,,,,,,,,,,,,,,,,,,,,
e377d9dd1eefa68f826261d82cb10665e04fe034,https://www.semanticscholar.org/paper/e377d9dd1eefa68f826261d82cb10665e04fe034,Accelerating crystal structure prediction by machine-learning interatomic potentials with active learning,"We propose a methodology for crystal structure prediction that is based on the evolutionary algorithm USPEX and the machine-learning interatomic potentials actively learning on-the-fly. Our methodology allows for an automated construction of an interatomic interaction model from scratch, replacing the expensive density functional theory (DFT) and giving a speedup of several orders of magnitude. Predicted low-energy structures are then tested on DFT, ensuring that our machine-learning model does not introduce any prediction error. We tested our methodology on prediction of crystal structures of carbon, high-pressure phases of sodium, and boron allotropes, including those that have more than 100 atoms in the primitive cell. All the the main allotropes have been reproduced, and a hitherto unknown 54-atom structure of boron has been predicted with very modest computational effort.",2018,89,134,1,True,Physics,,51019270,E. Podryabinkin,2144661717.0,E. Tikhonov,2810901.0,A. Shapeev,1793507.0,A. Oganov,,,,,,,,,,,,,,,,,,,,
ab3a1407179e67f18f81497f915d1b010a552092,https://www.semanticscholar.org/paper/ab3a1407179e67f18f81497f915d1b010a552092,A Survey on Behavior Recognition Using WiFi Channel State Information,"In this article, we present a survey of recent advances in passive human behavior recognition in indoor areas using the channel state information (CSI) of commercial WiFi systems. The movement of the human body parts cause changes in the wireless signal reflections, which result in variations in the CSI. By analyzing the data streams of CSIs for different activities and comparing them against stored models, human behavior can be recognized. This is done by extracting features from CSI data streams and using machine learning techniques to build models and classifiers. The techniques from the literature that are presented herein have great performance; however, instead of the machine learning techniques employed in these works, we propose to use deep learning techniques such as long-short term memory (LSTM) recurrent neural networking (RNN) and show the improved performance. We also discuss different challenges such as environment change, frame rate selection, and the multi-user scenario; and finally suggest possible directions for future work.",2017,14,203,41,False,Computer Science,,1732890,Siamak Yousefi,32062191.0,H. Narui,2494634.0,Sankalp Dayal,2490652.0,S. Ermon,1742726.0,S. Valaee,,,,,,,,,,,,,,,,,,
3bcdf9cc129d6e39d9ede590672b3f1ad41acd49,https://www.semanticscholar.org/paper/3bcdf9cc129d6e39d9ede590672b3f1ad41acd49,An explainable deep machine vision framework for plant stress phenotyping,"Significance Plant stress identification based on visual symptoms has predominately remained a manual exercise performed by trained pathologists, primarily due to the occurrence of confounding symptoms. However, the manual rating process is tedious, is time-consuming, and suffers from inter- and intrarater variabilities. Our work resolves such issues via the concept of explainable deep machine learning to automate the process of plant stress identification, classification, and quantification. We construct a very accurate model that can not only deliver trained pathologist-level performance but can also explain which visual symptoms are used to make predictions. We demonstrate that our method is applicable to a large variety of biotic and abiotic stresses and is transferable to other imaging conditions and plants. Current approaches for accurate identification, classification, and quantification of biotic and abiotic stresses in crop research and production are predominantly visual and require specialized training. However, such techniques are hindered by subjectivity resulting from inter- and intrarater cognitive variability. This translates to erroneous decisions and a significant waste of resources. Here, we demonstrate a machine learning framework’s ability to identify and classify a diverse set of foliar stresses in soybean [Glycine max (L.) Merr.] with remarkable accuracy. We also present an explanation mechanism, using the top-K high-resolution feature maps that isolate the visual symptoms used to make predictions. This unsupervised identification of visual symptoms provides a quantitative measure of stress severity, allowing for identification (type of foliar stress), classification (low, medium, or high stress), and quantification (stress severity) in a single framework without detailed symptom annotation by experts. We reliably identified and classified several biotic (bacterial and fungal diseases) and abiotic (chemical injury and nutrient deficiency) stresses by learning from over 25,000 images. The learned model is robust to input image perturbations, demonstrating viability for high-throughput deployment. We also noticed that the learned model appears to be agnostic to species, seemingly demonstrating an ability of transfer learning. The availability of an explainable model that can consistently, rapidly, and accurately identify and quantify foliar stresses would have significant implications in scientific research, plant breeding, and crop production. The trained model could be deployed in mobile platforms (e.g., unmanned air vehicles and automated ground scouts) for rapid, large-scale scouting or as a mobile application for real-time detection of stress by farmers and researchers.",2018,22,272,8,True,Computer Science,Medicine,34892652,Sambuddha Ghosal,47998550.0,David Blystone,152395021.0,Asheesh K Singh,3042938.0,B. Ganapathysubramanian,1712215532.0,Arti Singh,144016196.0,S. Sarkar,,,,,,,,,,,,,,,,
20966ec8b64dd7b713873c3a13e3d8e25d1d833f,https://www.semanticscholar.org/paper/20966ec8b64dd7b713873c3a13e3d8e25d1d833f,Land-Use Land-Cover Classification by Machine Learning Classifiers for Satellite Observations - A Review,"Rapid and uncontrolled population growth along with economic and industrial development, especially in developing countries during the late twentieth and early twenty-first centuries, have increased the rate of land-use/land-cover (LULC) change many times. Since quantitative assessment of changes in LULC is one of the most efficient means to understand and manage the land transformation, there is a need to examine the accuracy of different algorithms for LULC mapping in order to identify the best classifier for further applications of earth observations. In this article, six machine-learning algorithms, namely random forest (RF), support vector machine (SVM), artificial neural network (ANN), fuzzy adaptive resonance theory-supervised predictive mapping (Fuzzy ARTMAP), spectral angle mapper (SAM) and Mahalanobis distance (MD) were examined. Accuracy assessment was performed by using Kappa coefficient, receiver operational curve (RoC), index-based validation and root mean square error (RMSE). Results of Kappa coefficient show that all the classifiers have a similar accuracy level with minor variation, but the RF algorithm has the highest accuracy of 0.89 and the MD algorithm (parametric classifier) has the least accuracy of 0.82. In addition, the index-based LULC and visual cross-validation show that the RF algorithm (correlations between RF and normalised differentiation water index, normalised differentiation vegetation index and normalised differentiation built-up index are 0.96, 0.99 and 1, respectively, at 0.05 level of significance) has the highest accuracy level in comparison to the other classifiers adopted. Findings from the literature also proved that ANN and RF algorithms are the best LULC classifiers, although a non-parametric classifier like SAM (Kappa coefficient 0.84; area under curve (AUC) 0.85) has a better and consistent accuracy level than the other machine-learning algorithms. Finally, this review concludes that the RF algorithm is the best machine-learning LULC classifier, among the six examined algorithms although it is necessary to further test the RF algorithm in different morphoclimatic conditions in the future.",2020,110,218,4,True,Computer Science,,89374469,Swapan Talukdar,152612867.0,P. Singha,1756706678.0,Susanta Mahato,108164555.0,Shahfahad,40959887.0,Swades Pal,2352071.0,Y. Liou,2148758361.0,Atiqur Rahman,,,,,,,,,,,,,,
feb62bea49eae95fd1c616b840e4ca652fc06fed,https://www.semanticscholar.org/paper/feb62bea49eae95fd1c616b840e4ca652fc06fed,Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow,"We present a design study of the TensorFlow Graph Visualizer, part of the TensorFlow machine intelligence platform. This tool helps users understand complex machine learning architectures by visualizing their underlying dataflow graphs. The tool works by applying a series of graph transformations that enable standard layout techniques to produce a legible interactive diagram. To declutter the graph, we decouple non-critical nodes from the layout. To provide an overview, we build a clustered graph using the hierarchical structure annotated in the source code. To support exploration of nested structure on demand, we perform edge bundling to enable stable and responsive cluster expansion. Finally, we detect and highlight repeated structures to emphasize a model's modular composition. To demonstrate the utility of the visualizer, we describe example usage scenarios and report user feedback. Overall, users find the visualizer useful for understanding, debugging, and sharing the structures of their models.",2018,56,263,23,False,Computer Science,Medicine,8334069,Kanit Wongsuphasawat,2842148.0,D. Smilkov,49556437.0,James Wexler,2109357255.0,Jimbo Wilson,30415265.0,Dandelion Mané,40514522.0,Doug Fritz,1707347.0,Dilip Krishnan,1765169.0,F. Viégas,,145233583.0,M. Wattenberg,,,,,,,,,
7078de49e9f80a11d1c2f52f8a14bf95f5cacd34,https://www.semanticscholar.org/paper/7078de49e9f80a11d1c2f52f8a14bf95f5cacd34,Trustless Machine Learning Contracts; Evaluating and Exchanging Machine Learning Models on the Ethereum Blockchain,"Using blockchain technology, it is possible to create contracts that offer a reward in exchange for a trained machine learning model for a particular data set. This would allow users to train machine learning models for a reward in a trustless manner. The smart contract will use the blockchain to automatically validate the solution, so there would be no debate about whether the solution was correct or not. Users who submit the solutions won't have counterparty risk that they won't get paid for their work. Contracts can be created easily by anyone with a dataset, even programmatically by software agents. This creates a market where parties who are good at solving machine learning problems can directly monetize their skillset, and where any organization or software agent that has a problem to solve with AI can solicit solutions from all over the world. This will incentivize the creation of better machine learning models, and make AI more accessible to companies and software agents.",2018,17,73,12,False,Computer Science,,2073104718,A. B. Kurtulmus,123476763.0,K. Daniel,,,,,,,,,,,,,,,,,,,,,,,,
136dee73f203df2f4831994bf4f0c0a4ad2e764e,https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e,Ensemble Adversarial Training: Attacks and Defenses,"Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model's loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step. We further introduce Ensemble Adversarial Training, a technique that augments training data with perturbations transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with strong robustness to black-box attacks. In particular, our most robust model won the first round of the NIPS 2017 competition on Defenses against Adversarial Attacks. However, subsequent work found that more elaborate black-box attacks could significantly enhance transferability and reduce the accuracy of our models.",2017,63,1914,264,False,Mathematics,Computer Science,2444919,Florian Tramèr,145714153.0,A. Kurakin,1967156.0,Nicolas Papernot,1752788.0,D. Boneh,144061974.0,P. Mcdaniel,,,,,,,,,,,,,,,,,,
3e2da7c1c7dfc7960d1515b61f32fdc55359eea7,https://www.semanticscholar.org/paper/3e2da7c1c7dfc7960d1515b61f32fdc55359eea7,An open access repository of images on plant health to enable the development of mobile disease diagnostics through machine learning and crowdsourcing,"Human society needs to increase food production by an estimated 70% by 2050 to feed an expected population size that is predicted to be over 9 billion people. Currently infectious diseases reduce the potential yield by an average of 40% with many farmers in the developing world experiencing yield losses as high as 100%. Infectious diseases of crops are not new and historic examples such as the Irish Potato Famine of 1845-49 demonstrate this. But what is new is the widespread distribution of smartphones among crop growers around the world with an expected 5 billion smartphones by 2020. This offers the potential of turning the smartphone into a valuable tool for diverse communities growing food. One potential application is the development of mobile disease diagnostics through machine learning and crowdsourcing. Computer vision and machine learning have shown their potential to automatically classify images. To do this for plant diseases requires a training set that facilitates the development of the algorithms. Here we announce the release of >50,000 expertly curated images on healthy and infected leaves of crops plants through the existing platform www.PlantVillage.org. We describe both the data and the platform. These data are the beginning of an on-going, crowdsourcing effort to enable computer vision approaches to help solve the problem of yield losses in crop plants due to infectious diseases.",2015,47,494,60,False,Computer Science,,2068146094,David P. Hughes,3046313.0,M. Salathé,,,,,,,,,,,,,,,,,,,,,,,,
f1e0484607a57687da6f663954292b0c848141f1,https://www.semanticscholar.org/paper/f1e0484607a57687da6f663954292b0c848141f1,Adversarial Sensor Attack on LiDAR-based Perception in Autonomous Driving,"In Autonomous Vehicles (AVs), one fundamental pillar is perception,which leverages sensors like cameras and LiDARs (Light Detection and Ranging) to understand the driving environment. Due to its direct impact on road safety, multiple prior efforts have been made to study its the security of perception systems. In contrast to prior work that concentrates on camera-based perception, in this work we perform the first security study of LiDAR-based perception in AV settings, which is highly important but unexplored. We consider LiDAR spoofing attacks as the threat model and set the attack goal as spoofing obstacles close to the front of a victim AV. We find that blindly applying LiDAR spoofing is insufficient to achieve this goal due to the machine learning-based object detection process.Thus, we then explore the possibility of strategically controlling the spoofed attack to fool the machine learning model. We formulate this task as an optimization problem and design modeling methods for the input perturbation function and the objective function.We also identify the inherent limitations of directly solving the problem using optimization and design an algorithm that combines optimization and global sampling, which improves the attack success rates to around 75%. As a case study to understand the attack impact at the AV driving decision level, we construct and evaluate two attack scenarios that may damage road safety and mobility.We also discuss defense directions at the AV system, sensor, and machine learning model levels.",2019,52,245,21,True,Computer Science,Engineering,2146176464,Yulong Cao,2723309.0,Chaowei Xiao,51011036.0,Benjamin Cyr,51092355.0,Yimeng Zhou,2087289279.0,Wonseok Park,2921321.0,Sara Rampazzi,39645110.0,Qi Alfred Chen,144070916.0,Kevin Fu,Mathematics,3895596.0,Z. Morley Mao,,,,,,,,,
ff95dcec9098a66f0110b10b76618f1eee505f84,https://www.semanticscholar.org/paper/ff95dcec9098a66f0110b10b76618f1eee505f84,"A tutorial survey of architectures, algorithms, and applications for deep learning","In this invited paper, my overview material on the same topic as presented in the plenary overview session of APSIPA-2011 and the tutorial material presented in the same conference [1] are expanded and updated to include more recent developments in deep learning. The previous and the updated materials cover both theory and applications, and analyze its future directions. The goal of this tutorial survey is to introduce the emerging area of deep learning or hierarchical learning to the APSIPA community. Deep learning refers to a class of machine learning techniques, developed largely since 2006, where many stages of non-linear information processing in hierarchical architectures are exploited for pattern classification and for feature learning. In the more recent literature, it is also connected to representation learning, which involves a hierarchy of features or concepts where higher-level concepts are defined from lower-level ones and where the same lower-level concepts help to define higher-level ones. In this tutorial survey, a brief history of deep learning research is discussed first. Then, a classificatory scheme is developed to analyze and summarize major work reported in the recent deep learning literature. Using this scheme, I provide a taxonomy-oriented survey on the existing deep architectures and algorithms in the literature, and categorize them into three classes: generative, discriminative, and hybrid. Three representative deep architectures – deep autoencoders, deep stacking networks with their generalization to the temporal domain (recurrent networks), and deep neural networks (pretrained with deep belief networks) – one in each of the three classes, are presented in more detail. Next, selected applications of deep learning are reviewed in broad areas of signal and information processing including audio/speech, image/vision, multimodality, language modeling, natural language processing, and information retrieval. Finally, future directions of deep learning are discussed and analyzed.",2014,244,627,31,True,Computer Science,,144718788,L. Deng,,,,,,,,,,,,,,,,,,,,,,,,,,
9e6c798940c9998477a462b50e0a5b07259f1056,https://www.semanticscholar.org/paper/9e6c798940c9998477a462b50e0a5b07259f1056,PLANET: Massively Parallel Learning of Tree Ensembles with MapReduce,"Classification and regression tree learning on massive datasets is a common data mining task at Google, yet many state of the art tree learning algorithms require training data to reside in memory on a single machine. While more scalable implementations of tree learning have been proposed, they typically require specialized parallel computing architectures. In contrast, the majority of Google's computing infrastructure is based on commodity hardware. In this paper, we describe PLANET: a scalable distributed framework for learning tree models over large datasets. PLANET defines tree learning as a series of distributed computations, and implements each one using the MapReduce model of distributed computation. We show how this framework supports scalable construction of classification and regression trees, as well as ensembles of such models. We discuss the benefits and challenges of using a MapReduce compute cluster for tree learning, and demonstrate the scalability of this approach by applying it to a real world learning task from the domain of computational advertising.",2009,41,306,17,False,Computer Science,,34547779,Biswanath Panda,101285460.0,Josh Herbach,40632403.0,Sugato Basu,1692160.0,R. Bayardo,,,,,,,,,,,,,,,,,,,,
57b3f8df7020b67df71a96974adef8d5282ed396,https://www.semanticscholar.org/paper/57b3f8df7020b67df71a96974adef8d5282ed396,"11,001 New Features for Statistical Machine Translation","We use the Margin Infused Relaxed Algorithm of Crammer et al. to add a large number of new features to two machine translation systems: the Hiero hierarchical phrase-based translation system and our syntax-based translation system. On a large-scale Chinese-English translation task, we obtain statistically significant improvements of +1.5 Bleu and + 1.1 Bleu, respectively. We analyze the impact of the new features and the performance of the learning algorithm.",2009,43,220,25,True,Computer Science,,145287425,David Chiang,152971314.0,Kevin Knight,49337181.0,Wei Wang,,,,,,,,,,,,,,,,,,,,,,
006cb500fd0b25200e12eb5a024756aea3d569ed,https://www.semanticscholar.org/paper/006cb500fd0b25200e12eb5a024756aea3d569ed,Learning in a Large Function Space: Privacy-Preserving Mechanisms for SVM Learning,"The ubiquitous need for analyzing privacy-sensitive information—including health records, personal communications, product ratings and social network data—is driving significant interest in privacy-preserving data analysis across several research communities. This paper explores the release of Support Vector Machine (SVM) classifiers while preserving the privacy of training data. The SVM is a popular machine learning method that maps data to a high-dimensional feature space before learning a linear decision boundary. We present efficient mechanisms for finite-dimensional feature mappings and for (potentially infinite-dimensional) mappings with translation-invariant kernels. In the latter case, our mechanism borrows a technique from large-scale learning to learn in a finite-dimensional feature space whose inner-product uniformly approximates the desired feature space inner-product (the desired kernel) with high probability. Differential privacy is established using algorithmic stability, a property used in learning theory to bound generalization error. Utility—when the private classifier is pointwise close to the non-private classifier with high probability—is proven using smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. Finally we conclude with lower bounds on the differential privacy of any mechanism approximating the SVM.",2009,58,263,17,True,Mathematics,Computer Science,1868067,Benjamin I. P. Rubinstein,1745169.0,P. Bartlett,50055322.0,Ling Huang,2703784.0,N. Taft,,,,,,,,,,,,,,,,,,,,
06aa334b466e68704eef37d90202894f34f4ea4f,https://www.semanticscholar.org/paper/06aa334b466e68704eef37d90202894f34f4ea4f,Protein secondary structure prediction using logic-based machine learning,"Many attempts have been made to solve the problem of predicting protein secondary structure from the primary sequence but the best performance results are still disappointing. In this paper, the use of a machine learning algorithm which allows relational descriptions is shown to lead to improved performance. The Inductive Logic Programming computer program, Golem, was applied to learning secondary structure prediction rules for alpha/alpha domain type proteins. The input to the program consisted of 12 non-homologous proteins (1612 residues) of known structure, together with a background knowledge describing the chemical and physical properties of the residues. Golem learned a small set of rules that predict which residues are part of the alpha-helices--based on their positional relationships and chemical and physical properties. The rules were tested on four independent non-homologous proteins (416 residues) giving an accuracy of 81% (+/- 2%). This is an improvement, on identical data, over the previously reported result of 73% by King and Sternberg (1990, J. Mol. Biol., 216, 441-457) using the machine learning program PROMIS, and of 72% using the standard Garnier-Osguthorpe-Robson method. The best previously reported result in the literature for the alpha/alpha domain type is 76%, achieved using a neural net approach. Machine learning also has the advantage over neural network and statistical methods in producing more understandable results.",1992,2,137,1,False,Computer Science,,145147566,S. Muggleton,33654217.0,R. King,145410834.0,M. Sternberg,,,,,,,,,,,,,,,,,,,,,,
b2504b0b2a7e06eab02a3584dd46d94a3f05ffdf,https://www.semanticscholar.org/paper/b2504b0b2a7e06eab02a3584dd46d94a3f05ffdf,Conditional Neural Processes,"Deep neural networks excel at function approximation, yet they are typically trained from scratch for each new function. On the other hand, Bayesian methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly infer the shape of a new function at test time. Yet GPs are computationally expensive, and it can be hard to design appropriate priors. In this paper we propose a family of neural models, Conditional Neural Processes (CNPs), that combine the benefits of both. CNPs are inspired by the flexibility of stochastic processes such as GPs, but are structured as neural networks and trained via gradient descent. CNPs make accurate predictions after observing only a handful of training data points, yet scale to complex functions and large datasets. We demonstrate the performance and versatility of the approach on a range of canonical machine learning tasks, including regression, classification and image completion.",2018,34,370,93,False,Computer Science,Mathematics,3468254,M. Garnelo,2445250.0,Dan Rosenbaum,2772217.0,Chris J. Maddison,34505275.0,Tiago Ramalho,143810408.0,D. Saxton,1757629.0,M. Shanahan,1725303.0,Y. Teh,1748523.0,Danilo Jimenez Rezende,,143648071.0,S. Eslami,,,,,,,,,
be13051815e357c4963bb21546b301a336feca6a,https://www.semanticscholar.org/paper/be13051815e357c4963bb21546b301a336feca6a,Using Machine-Learning Methods for Musical Style Modeling,"The ability to construct a musical theory from examples presents a great intellectual challenge that, if successfully met, could foster a range of new creative applications. Inspired by this challenge, we sought to apply machine-learning methods to the problem of musical style modeling. Our work so far has produced examples of musical generation and applications to a computer-aided composition system. Machine learning consists of deriving a mathematical model, such as a set of stochastic rules, from a set of musical examples. The act of musical composition involves a highly structured mental process. Although it is complex and difficult to formalize, it is clearly far from being a random activity. Our research seeks to capture some of the regularity apparent in the composition process by using statistical and information theoretic tools to analyze musical pieces. The resulting models can be used for inference and prediction and, to a certain extent, to generate new works that imitate the style of the great masters.",2003,17,164,7,False,Computer Science,,2204186,S. Dubnov,2435162.0,G. Assayag,2251215.0,O. Lartillot,2455381.0,G. Bejerano,,,,,,,,,,,,,,,,,,,,
f98497d63a286637262c98e07d5325aa22ad2a7a,https://www.semanticscholar.org/paper/f98497d63a286637262c98e07d5325aa22ad2a7a,Analysis of Sparse Bayesian Learning,"The recent introduction of the 'relevance vector machine' has effectively demonstrated how sparsity may be obtained in generalised linear models within a Bayesian framework. Using a particular form of Gaussian parameter prior, 'learning' is the maximisation, with respect to hyperparameters, of the marginal likelihood of the data. This paper studies the properties of that objective function, and demonstrates that conditioned on an individual hyper-parameter, the marginal likelihood has a unique maximum which is computable in closed form. It is further shown that if a derived 'sparsity criterion' is satisfied, this maximum is exactly equivalent to 'pruning' the corresponding parameter from the model.",2001,9,301,33,True,Computer Science,Mathematics,33171556,Anita C. Faul,2831141.0,Michael E. Tipping,,,,,,,,,,,,,,,,,,,,,,,,
76d4b7fd734f987dc87c9aafdbcc7e1af99ad8a5,https://www.semanticscholar.org/paper/76d4b7fd734f987dc87c9aafdbcc7e1af99ad8a5,Learning to recognize patterns without a teacher,"An important problem in pattern recognition or signal detection is the recognition of a pattern that is completely characterized statistically except for a finite set of unknown parameters. If a machine is required to solve such a problem on a number of occasions, it is possible to take advantage of this repetition. One can design a machine that will extract more and more of the pertinent information about these unknown parameters as it recognizes the patterns and readjusts itself to be more selective to them; the machine improves in performance as it gains experience on the problem. This paper presents a model suitable for many such problems and evolves a solution in the form of a machine that ""learns"" to solve the problem without external aid. Such machines are said to ""learn without a teacher."" The Bayes solution to the model problem requires the computation of the a posteriori probability density of the unknown parameters. A recursive equation for this density is derived. This equation describes the structure of a relatively simple system of finite size that may be realized in a delay-feedback form. The application of the model and the synthesis of a learning system are illustrated by the derivation of a receiver for the detection of signals of unknown amplitude in white Gaussian noise.",1967,10,138,2,False,Computer Science,,2158281,S. Fralick,,,,,,,,,,,,,,,,,,,,,,,,,,
0165568bcc1a819c18564567f2ec15d859be2519,https://www.semanticscholar.org/paper/0165568bcc1a819c18564567f2ec15d859be2519,Cheap and Fast – But is it Good? Evaluating Non-Expert Annotations for Natural Language Tasks,"Human linguistic annotation is crucial for many natural language processing tasks but can be expensive and time-consuming. We explore the use of Amazon's Mechanical Turk system, a significantly cheaper and faster method for collecting annotations from a broad base of paid non-expert contributors over the Web. We investigate five tasks: affect recognition, word similarity, recognizing textual entailment, event temporal ordering, and word sense disambiguation. For all five, we show high agreement between Mechanical Turk non-expert annotations and existing gold standard labels provided by expert labelers. For the task of affect recognition, we also show that using non-expert labels for training machine learning algorithms can be as effective as using gold standard annotations from experts. We propose a technique for bias correction that significantly improves annotation quality on two tasks. We conclude that many large labeling tasks can be effectively designed and carried out in this method at a fraction of the usual expense.",2008,35,2195,170,True,Computer Science,,144621026,R. Snow,1401020033.0,Brendan T. O'Connor,1746807.0,Dan Jurafsky,34699434.0,A. Ng,,,,,,,,,,,,,,,,,,,,
56edaa1368ff4dfa45388e4be24fdfbded7d88a7,https://www.semanticscholar.org/paper/56edaa1368ff4dfa45388e4be24fdfbded7d88a7,A Primer on Neural Network Models for Natural Language Processing,"Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in fields such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.",2015,185,892,59,True,Computer Science,,2089067,Yoav Goldberg,,,,,,,,,,,,,,,,,,,,,,,,,,
4ec953de1331fe5f720320c9f2f82884b2512701,https://www.semanticscholar.org/paper/4ec953de1331fe5f720320c9f2f82884b2512701,Machine Learning Methods in Drug Discovery,"The advancements of information technology and related processing techniques have created a fertile base for progress in many scientific fields and industries. In the fields of drug discovery and development, machine learning techniques have been used for the development of novel drug candidates. The methods for designing drug targets and novel drug discovery now routinely combine machine learning and deep learning algorithms to enhance the efficiency, efficacy, and quality of developed outputs. The generation and incorporation of big data, through technologies such as high-throughput screening and high through-put computational analysis of databases used for both lead and target discovery, has increased the reliability of the machine learning and deep learning incorporated techniques. The use of these virtual screening and encompassing online information has also been highlighted in developing lead synthesis pathways. In this review, machine learning and deep learning algorithms utilized in drug discovery and associated techniques will be discussed. The applications that produce promising results and methods will be reviewed.",2020,101,63,0,True,Medicine,Computer Science,2026124178,Lauv Patel,51466154.0,T. Shukla,38820495.0,Xiuzhen Huang,2251733.0,D. Ussery,5954673.0,Shanzhi Wang,,,,,,,,,,,,,,,,,,
b9bf865c3cad373caa48a8328596394dad1ac0e4,https://www.semanticscholar.org/paper/b9bf865c3cad373caa48a8328596394dad1ac0e4,Artificial Neural Networks-Based Machine Learning for Wireless Networks: A Tutorial,"In order to effectively provide ultra reliable low latency communications and pervasive connectivity for Internet of Things (IoT) devices, next-generation wireless networks can leverage intelligent, data-driven functions enabled by the integration of machine learning (ML) notions across the wireless core and edge infrastructure. In this context, this paper provides a comprehensive tutorial that overviews how artificial neural networks (ANNs)-based ML algorithms can be employed for solving various wireless networking problems. For this purpose, we first present a detailed overview of a number of key types of ANNs that include recurrent, spiking, and deep neural networks, that are pertinent to wireless networking applications. For each type of ANN, we present the basic architecture as well as specific examples that are particularly important and relevant wireless network design. Such ANN examples include echo state networks, liquid state machine, and long short term memory. Then, we provide an in-depth overview on the variety of wireless communication problems that can be addressed using ANNs, ranging from communication using unmanned aerial vehicles to virtual reality applications over wireless networks as well as edge computing and caching. For each individual application, we present the main motivation for using ANNs along with the associated challenges while we also provide a detailed example for a use case scenario and outline future works that can be addressed using ANNs. In a nutshell, this paper constitutes the first holistic tutorial on the development of ANN-based ML techniques tailored to the needs of future wireless networks.",2017,245,479,16,False,Computer Science,,2107942948,Mingzhe Chen,2318575.0,Ursula Challita,145412074.0,W. Saad,1768333.0,Changchuan Yin,145118318.0,M. Debbah,,,,,,,,,,,,,,,,,,
18145e358d4d5cd5dab06558aca47b8ea21fadef,https://www.semanticscholar.org/paper/18145e358d4d5cd5dab06558aca47b8ea21fadef,Machine Learning Techniques for Civil Engineering Problems,"The growing volume of information databases presents opportunities for advanced data analysis techniques from machine learning (ML) research. Practical applications of ML are very different from theoretical or empirical studies, involving organizational and human aspects and various other constraints. Despite the importance of applied ML, little has been discussed in the general ML literature on this topic. In order to remedy this situation, I studied practical applications of ML and developed a proposal for a seven–step process that can guide practical applications of ML in engineering. The process is illustrated by relevant applications of ML in civil engineering. This illustration shows that the potential of ML has only begun to be explored but also cautions that in order to be successful, the application process must carefully address the issues related to the seven–step process.",1997,112,101,6,False,Computer Science,,2870501,Y. Reich,,,,,,,,,,,,,,,,,,,,,,,,,,
c7330852a07170cd0e6990f5fbde5fca12b6ccd6,https://www.semanticscholar.org/paper/c7330852a07170cd0e6990f5fbde5fca12b6ccd6,Mitigating Unwanted Biases with Adversarial Learning,"Machine learning is a tool for building models that accurately represent input training data. When undesired biases concerning demographic groups are in the training data, well-trained models will reflect those biases. We present a framework for mitigating such biases by including a variable for the group of interest and simultaneously learning a predictor and an adversary. The input to the network X, here text or census data, produces a prediction Y, such as an analogy completion or income bracket, while the adversary tries to model a protected variable Z, here gender or zip code. The objective is to maximize the predictor's ability to predict Y while minimizing the adversary's ability to predict Z. Applied to analogy completion, this method results in accurate predictions that exhibit less evidence of stereotyping Z. When applied to a classification task using the UCI Adult (Census) Dataset, it results in a predictive model that does not lose much accuracy while achieving very close to equality of odds (Hardt, et al., 2016). The method is flexible and applicable to multiple definitions of fairness as well as a wide range of gradient-based learning models, including both regression and classification tasks.",2018,11,761,99,True,Computer Science,Mathematics,11809518,B. Zhang,40640868.0,B. Lemoine,49501003.0,Margaret Mitchell,,,,,,,,,,,,,,,,,,,,,,
d65f8bb342f3a4fbf119bd2f822318741de3b567,https://www.semanticscholar.org/paper/d65f8bb342f3a4fbf119bd2f822318741de3b567,Comparing molecules and solids across structural and alchemical space.,"Evaluating the (dis)similarity of crystalline, disordered and molecular compounds is a critical step in the development of algorithms to navigate automatically the configuration space of complex materials. For instance, a structural similarity metric is crucial for classifying structures, searching chemical space for better compounds and materials, and driving the next generation of machine-learning techniques for predicting the stability and properties of molecules and materials. In the last few years several strategies have been designed to compare atomic coordination environments. In particular, the smooth overlap of atomic positions (SOAPs) has emerged as an elegant framework to obtain translation, rotation and permutation-invariant descriptors of groups of atoms, underlying the development of various classes of machine-learned inter-atomic potentials. Here we discuss how one can combine such local descriptors using a regularized entropy match (REMatch) approach to describe the similarity of both whole molecular and bulk periodic structures, introducing powerful metrics that enable the navigation of alchemical and structural complexities within a unified framework. Furthermore, using this kernel and a ridge regression method we can predict atomization energies for a database of small organic molecules with a mean absolute error below 1 kcal mol(-1), reaching an important milestone in the application of machine-learning techniques for the evaluation of molecular properties.",2015,101,387,6,True,Physics,Chemistry,153048885,Sandip De,3938091.0,A. Bartók,2559761.0,Gábor Csányi,1917770.0,M. Ceriotti,,,,,,,,,Medicine,,,,,,,,,,,Materials Science
2f91dbe76db2d377b8a08c58017883dda4b77a97,https://www.semanticscholar.org/paper/2f91dbe76db2d377b8a08c58017883dda4b77a97,Generalized SMO Algorithm for SVM-Based Multitask Learning,"Exploiting additional information to improve traditional inductive learning is an active research area in machine learning. In many supervised-learning applications, training data can be naturally separated into several groups, and incorporating this group information into learning may improve generalization. Recently, Vapnik proposed a general approach to formalizing such problems, known as “learning with structured data” and its support vector machine (SVM) based optimization formulation called SVM+. Liang and Cherkassky showed the connection between SVM+ and multitask learning (MTL) approaches in machine learning, and proposed an SVM-based formulation for MTL called SVM+MTL for classification. Training the SVM+MTL classifier requires the solution of a large quadratic programming optimization problem which scales as O(n3) with sample size n. So there is a need to develop computationally efficient algorithms for implementing SVM+MTL. This brief generalizes Platt's sequential minimal optimization (SMO) algorithm to the SVM+MTL setting. Empirical results show that, for typical SVM+MTL problems, the proposed generalized SMO achieves over 100 times speed-up, in comparison with general-purpose optimization routines.",2012,25,62,6,False,Computer Science,Medicine,2064272099,Feng Cai,145884505.0,V. Cherkassky,,,,,,,,,,,,,,,,,,,,,,,,
0c236e611a90018e84d9de23d1cff241354079be,https://www.semanticscholar.org/paper/0c236e611a90018e84d9de23d1cff241354079be,Automatically refining the wikipedia infobox ontology,"The combined efforts of human volunteers have recently extracted numerous facts from Wikipedia, storing them as machine-harvestable object-attribute-value triples in Wikipedia infoboxes. Machine learning systems, such as Kylin, use these infoboxes as training data, accurately extracting even more semantic knowledge from natural language text. But in order to realize the full power of this information, it must be situated in a cleanly-structured ontology. This paper introduces KOG, an autonomous system for refining Wikipedia's infobox-class ontology towards this end. We cast the problem of ontology refinement as a machine learning problem and solve it using both SVMs and a more powerful joint-inference approach expressed in Markov Logic Networks. We present experiments demonstrating the superiority of the joint-inference approach and evaluating other aspects of our system. Using these techniques, we build a rich ontology, integrating Wikipedia's infobox-class schemata with WordNet. We demonstrate how the resulting ontology may be used to enhance Wikipedia with improved query processing and other features.",2008,37,381,24,True,Computer Science,,2110920850,Fei Wu,1780531.0,Daniel S. Weld,,,,,,,,,,,,,,,,,,,,,,,,
2aff69adb95ddb6c766385acf439e9a19d45b20b,https://www.semanticscholar.org/paper/2aff69adb95ddb6c766385acf439e9a19d45b20b,Constraining Effective Field Theories with Machine Learning.,"We present powerful new analysis techniques to constrain effective field theories at the LHC. By leveraging the structure of particle physics processes, we extract extra information from Monte Carlo simulations, which can be used to train neural network models that estimate the likelihood ratio. These methods scale well to processes with many observables and theory parameters, do not require any approximations of the parton shower or detector response, and can be evaluated in microseconds. We show that they allow us to put significantly stronger bounds on dimension-six operators than existing methods, demonstrating their potential to improve the precision of the LHC legacy constraints.",2018,80,113,1,True,Medicine,Computer Science,32906304,J. Brehmer,11638962.0,K. Cranmer,1881041.0,Gilles Louppe,144701212.0,J. Pavez,,,,,,,,,Physics,,,,,,,,,,,Mathematics
e8b3c5e2cf19768b61a263ed4762db98be60c3cb,https://www.semanticscholar.org/paper/e8b3c5e2cf19768b61a263ed4762db98be60c3cb,Inductive logic programming - from machine learning to software engineering,"From the Publisher: Although Inductive Logic Programming (ILP) is generally thought of as a research area at the intersection of machine learning and computational logic, Bergadano and Gunetti propose that most of the research in ILP has in fact come from machine learning, particularly in the evolution of inductive reasoning from pattern recognition, through initial approaches to symbolic machine learning, to recent techniques for learning relational concepts. In this book they provide an extended, up-to-date survey of ILP, emphasizing methods and systems suitable for software engineering applications, including inductive program development, testing, and maintenance. Inductive Logic Programming includes a definition of the basic ILP problem and its variations (incremental, with queries, for multiple predicates and predicate invention capabilities), a description of bottom-up operators and techniques (such as least general generalization, inverse resolution, and inverse implication), an analysis of top-down methods (mainly MIS and FOIL-like systems), and a survey of methods and languages for specifying inductive bias. Logic Programming series",1995,0,126,18,False,Computer Science,,2080984,F. Bergadano,1792257.0,D. Gunetti,,,,,,,,,,,,,,,,,,,,,,,,
833c4ac0599f4b8c5f1ee6ea948ec675fbe56b15,https://www.semanticscholar.org/paper/833c4ac0599f4b8c5f1ee6ea948ec675fbe56b15,Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning,"Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of AI have been raised by influential thinkers. In spite of the recent impact of AI, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable AI systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable AI systems.",2019,57,169,7,False,Computer Science,,2925941,A. Garcez,145467467.0,M. Gori,2335532.0,L. Lamb,144077615.0,L. Serafini,145570895.0,Michael Spranger,1930235.0,S. Tran,,,,,,,,,,,,,,,,
ddacf4b9dea711d2ac50f0d6a29e62f3cd96bccb,https://www.semanticscholar.org/paper/ddacf4b9dea711d2ac50f0d6a29e62f3cd96bccb,Applications of support vector machines to speech recognition,"Recent work in machine learning has focused on models, such as the support vector machine (SVM), that automatically control generalization and parameterization as part of the overall optimization process. In this paper, we show that SVMs provide a significant improvement in performance on a static pattern classification task based on the Deterding vowel data. We also describe an application of SVMs to large vocabulary speech recognition and demonstrate an improvement in error rate on a continuous alphadigit task (OGI Alphadigits) and a large vocabulary conversational speech task (Switchboard). Issues related to the development and optimization of an SVM/HMM hybrid system are discussed.",2004,66,292,12,False,Computer Science,,1782807,A. Ganapathiraju,144170973.0,J. Hamaker,1744408.0,J. Picone,,,,,,,,,,,,,,,,,,,,,,
c27b5c53985996834540243b4c3173ba18efc386,https://www.semanticscholar.org/paper/c27b5c53985996834540243b4c3173ba18efc386,Machine Learning Algorithms in Bipedal Robot Control,"Over the past decades, machine learning techniques, such as supervised learning, reinforcement learning, and unsupervised learning, have been increasingly used in the control engineering community. Various learning algorithms have been developed to achieve autonomous operation and intelligent decision making for many complex and challenging control problems. One of such problems is bipedal walking robot control. Although still in their early stages, learning techniques have demonstrated promising potential to build adaptive control systems for bipedal robots. This paper gives a review of recent advances on the state-of-the-art learning algorithms and their applications to bipedal robot control. The effects and limitations of different learning techniques are discussed through a representative selection of examples from the literature. Guidelines for future research on learning control of bipedal robots are provided in the end.",2012,142,68,2,False,Computer Science,,2116951567,Shouyi Wang,1936810.0,W. Chaovalitwongse,1705222.0,Robert Babuška,,,,,,,,,,,,,,,,,,,,,,
9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f,https://www.semanticscholar.org/paper/9ebb28851b253817f9a0ea5ddc22b0fd9a934a2f,Deep Learning--based Text Classification,"Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.",2020,239,230,2,False,Computer Science,Mathematics,2164604,Shervin Minaee,2583391.0,Nal Kalchbrenner,49943757.0,E. Cambria,1620486779.0,Narjes Nikzad,89845455.0,M. Chenaghlu,1800422.0,Jianfeng Gao,,,,,,,,,,,,,,,,
775dc4bdfb51541acbeced051d2bd8ce0840367c,https://www.semanticscholar.org/paper/775dc4bdfb51541acbeced051d2bd8ce0840367c,"Temporal Sequence Learning, Prediction, and Control: A Review of Different Models and Their Relation to Biological Mechanisms","In this review, we compare methods for temporal sequence learning (TSL) across the disciplines machine-control, classical conditioning, neuronal models for TSL as well as spike-timing-dependent plasticity (STDP). This review introduces the most influential models and focuses on two questions: To what degree are reward-based (e.g., TD learning) and correlation-based (Hebbian) learning related? and How do the different models correspond to possibly underlying biological mechanisms of synaptic plasticity? We first compare the different models in an open-loop condition, where behavioral feedback does not alter the learning. Here we observe that reward-based and correlation-based learning are indeed very similar. Machine control is then used to introduce the problem of closed-loop control (e.g., actor-critic architectures). Here the problem of evaluative (rewards) versus nonevaluative (correlations) feedback from the environment will be discussed, showing that both learning approaches are fundamentally different in the closed-loop condition. In trying to answer the second question, we compare neuronal versions of the different learning architectures to the anatomy of the involved brain structures (basal-ganglia, thalamus, and cortex) and the molecular biophysics of glutamatergic and dopaminergic synapses. Finally, we discuss the different algorithms used to model STDP and compare them to reward-based learning rules. Certain similarities are found in spite of the strongly different timescales. Here we focus on the biophysics of the different calcium-release mechanisms known to be involved in STDP.",2005,353,222,9,True,Computer Science,Psychology,1714016,F. Wörgötter,2728662.0,B. Porr,,,,,,,,,,,,,Medicine,,,,,,,,,,,
46038cb1606041001be2f42b4e09f630d4b4147f,https://www.semanticscholar.org/paper/46038cb1606041001be2f42b4e09f630d4b4147f,On Challenges in Machine Learning Model Management,"The training, maintenance, deployment, monitoring, organization and documentation of machine learning (ML) models – in short model management – is a critical task in virtually all production ML use cases. Wrong model management decisions can lead to poor performance of a ML system and result in high maintenance cost. As both research on infrastructure as well as on algorithms is quickly evolving, there is a lack of understanding of challenges and best practices for ML model management. Therefore, this field is receiving increased attention in recent years, both from the data management as well as from the ML community. In this paper, we discuss a selection of ML use cases, develop an overview over conceptual, engineering, and data-related challenges arising in the management of the corresponding ML models, and point out future research directions.",2018,42,99,6,False,Computer Science,,2180399,Sebastian Schelter,2170760.0,F. Biessmann,2166235.0,Tim Januschowski,144607961.0,David Salinas,1792476.0,Stephan Seufert,72270481.0,Gyuri Szarvas,,,,,,,,,,,,,,,,
1890c124749d00cce965e0b9495eafe127e16a26,https://www.semanticscholar.org/paper/1890c124749d00cce965e0b9495eafe127e16a26,Chapter 11 Transfer Learning,"Transfer learning is the improvement of learning in a new task through the transfer of knowledge from a related task that has already been learned. While most machine learning algorithms are designed to address single tasks, the development of algorithms that facilitate transfer learning is a topic of ongoing interest in the machine-learning community. This chapter provides an introduction to the goals, formulations, and challenges of transfer learning. It surveys current research in this area, giving an overview of the state of the art and outlining the open problems. The survey covers transfer in both inductive learning and reinforcement learning, and discusses the issues of negative transfer and task mapping in depth.",2009,63,93,11,False,Computer Science,,1801209,Lisa A. Torrey,1734317.0,J. Shavlik,,,,,,,,,,,,,,,,,,,,,,,,
85f6caeba5514b5af83eb0e0309c6b9908e4aa5c,https://www.semanticscholar.org/paper/85f6caeba5514b5af83eb0e0309c6b9908e4aa5c,Comparison of Machine Learning Methods With Traditional Models for Use of Administrative Claims With Electronic Medical Records to Predict Heart Failure Outcomes,"Key Points Question Can prediction of patient outcomes in heart failure based on routinely collected claims data be improved with machine learning methods and incorporating linked electronic medical records? Findings In this prognostic study including records on 9502 patients, machine learning methods offered only limited improvement over logistic regression in predicting key outcomes in heart failure based on administrative claims. Inclusion of additional predictors from electronic medical records improved prediction for mortality, heart failure hospitalization, and loss in home days but not for high cost. Meaning Models based on claims-only predictors may achieve modest discrimination and accuracy in prediction of key patient outcomes in heart failure, and machine learning approaches and incorporation of additional predictors from electronic medical records may offer some improvement in risk prediction of select outcomes.",2020,28,118,1,True,Medicine,,49277759,R. Desai,1993121367.0,Shirley V. Wang,5942717.0,M. Vaduganathan,5466525.0,T. Evers,145876902.0,S. Schneeweiss,,,,,,,,,,,,,,,,,,
0b822de3ed689344862eecb5ad86c36eb2ff9de5,https://www.semanticscholar.org/paper/0b822de3ed689344862eecb5ad86c36eb2ff9de5,One-Class Classification with Extreme Learning Machine,"One-class classification problem has been investigated thoroughly for past decades. Among one of the most effective neural network approaches for one-class classification, autoencoder has been successfully applied for many applications. However, this classifier relies on traditional learning algorithms such as backpropagation to train the network, which is quite time-consuming. To tackle the slow learning speed in autoencoder neural network, we propose a simple and efficient one-class classifier based on extreme learning machine (ELM). The essence of ELM is that the hidden layer need not be tuned and the output weights can be analytically determined, which leads to much faster learning speed. The experimental evaluation conducted on several real-world benchmarks shows that the ELM based one-class classifier can learn hundreds of times faster than autoencoder and it is competitive over a variety of one-class classification methods.",2015,66,106,17,True,Computer Science,,2105528449,Qian Leng,144097734.0,H. Qi,145235303.0,Jun Miao,2111465410.0,Wentao Zhu,1807065.0,Guiping Su,,,,,,,,,,,,,,,,,,
55635aac4cd439a00356f83dad52bd8d7b0ea87e,https://www.semanticscholar.org/paper/55635aac4cd439a00356f83dad52bd8d7b0ea87e,A Survey on Curriculum Learning,"Curriculum learning (CL) is a training strategy that trains a machine learning model from easier data to harder data, which imitates the meaningful learning order in human curricula. As an easy-to-use plug-in, the CL strategy has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision and natural language processing etc. In this survey article, we comprehensively review CL from various aspects including motivations, definitions, theories, and applications. We discuss works on curriculum learning within a general CL framework, elaborating on how to design a manually predefined curriculum or an automatic curriculum. In particular, we summarize existing CL designs based on the general framework of <italic>Difficulty Measurer <inline-formula><tex-math notation=""LaTeX"">$+$</tex-math><alternatives><mml:math><mml:mo>+</mml:mo></mml:math><inline-graphic xlink:href=""wang-ieq1-3069908.gif""/></alternatives></inline-formula> Training Scheduler</italic> and further categorize the methodologies for automatic CL into four groups, i.e., Self-paced Learning, Transfer Teacher, RL Teacher, and Other Automatic CL. We also analyze principles to select different CL designs that may benefit practical applications. Finally, we present our insights on the relationships connecting CL and other machine learning concepts including transfer learning, meta-learning, continual learning and active learning, etc., then point out challenges in CL as well as potential future research directions deserving further investigations.",2021,153,75,4,True,Computer Science,Medicine,2153687490,Xin Wang,51310474.0,Yudong Chen,145583986.0,Wenwu Zhu,,,,,,,,,,,,,,,,,,,,,,
3b5505eaec8583a2dd98d72a84d95b9eff475a81,https://www.semanticscholar.org/paper/3b5505eaec8583a2dd98d72a84d95b9eff475a81,Few-shot Learning: A Survey,"The quest of `can machines think' and `can machines do what human do' are quests that drive the development of artificial intelligence. Although recent artificial intelligence succeeds in many data intensive applications, it still lacks the ability of learning from limited exemplars and fast generalizing to new tasks. To tackle this problem, one has to turn to machine learning, which supports the scientific study of artificial intelligence. Particularly, a machine learning problem called Few-Shot Learning (FSL) targets at this case. It can rapidly generalize to new tasks of limited supervised experience by turning to prior knowledge, which mimics human's ability to acquire knowledge from few examples through generalization and analogy. It has been seen as a test-bed for real artificial intelligence, a way to reduce laborious data gathering and computationally costly training, and antidote for rare cases learning. With extensive works on FSL emerging, we give a comprehensive survey for it. We first give the formal definition for FSL. Then we point out the core issues of FSL, which turns the problem from ""how to solve FSL"" to ""how to deal with the core issues"". Accordingly, existing works from the birth of FSL to the most recent published ones are categorized in a unified taxonomy, with thorough discussion of the pros and cons for different categories. Finally, we envision possible future directions for FSL in terms of problem setup, techniques, applications and theory, hoping to provide insights to both beginners and experienced researchers.",2019,0,114,6,False,Computer Science,,2115793087,Yaqing Wang,3259992.0,Quanming Yao,,,,,,,,,,,,,,,,,,,,,,,,
89c2a023e0eb3d46bfa9e849e77afb83d6d870f4,https://www.semanticscholar.org/paper/89c2a023e0eb3d46bfa9e849e77afb83d6d870f4,Machine learning and excited-state molecular dynamics,"Machine learning is employed at an increasing rate in the research field of quantum chemistry. While the majority of approaches target the investigation of chemical systems in their electronic ground state, the inclusion of light into the processes leads to electronically excited states and gives rise to several new challenges. Here, we survey recent advances for excited-state dynamics based on machine learning. In doing so, we highlight successes, pitfalls, challenges and future avenues for machine learning approaches for light-induced molecular processes.",2020,306,28,0,False,Computer Science,Physics,90050189,J. Westermayr,4850899.0,P. Marquetand,,,,,,,,,,,,,Mathematics,,,,,,,,,,,
69d0813dcefd3a8679656529855704b1eab9bf59,https://www.semanticscholar.org/paper/69d0813dcefd3a8679656529855704b1eab9bf59,Wrapping a MOOC: Student Perceptions of an Experiment in Blended Learning,"Although massive open online courses (MOOCs) are seen to be, and are in fact designed to be, stand-alone online courses, their introduction to the higher education landscape has expanded the space of possibilities for blended course designs (those that combine online and face-to-face learning experiences). Instead of replacing courses at higher education institutions, could MOOCs enhance those courses? This paper reports one such exploration, in which a Stanford University Machine Learning MOOC was integrated into a graduate course in machine learning at Vanderbilt University during the Fall 2012 semester. The blended course design, which leveraged a MOOC course and platform for lecturing, grading, and discussion, enabled the Vanderbilt instructor to lead an overload course in a topic much desired by students. The study shows that while students regarded some elements of the course positively, they had concerns about the coupling of online and in-class components of this particular blended course design. Analysis of student and instructor reflections on the course suggests dimensions for characterizing blended course designs that incorporate MOOCs, either in whole or in part. Given the reported challenges in this case study of integrating a MOOC in its entirety in an on-campus course, the paper advocates for more complex forms of blended learning in which course materials are drawn from multiple MOOCs, as well as from other online sources.",2013,39,302,17,False,Engineering,,52554014,D. Bruff,8993101.0,D. Fisher,2070908180.0,Karen McEwen,35098540.0,Blaine E. Smith,,,,,,,,,,,,,,,,,,,,
2d045aec8585cae8e5ccba56db1d64820cf73773,https://www.semanticscholar.org/paper/2d045aec8585cae8e5ccba56db1d64820cf73773,Comparing discriminating transformations and SVM for learning during multimedia retrieval,"On-line learning or ""relevance feedback"" techniques for multimedia information retrieval have been explored from many different points of view: from early heuristic-based feature weighting schemes to recently proposed optimal learning algorithms, probabilistic/Bayesian learning algorithms, boosting techniques, discriminant-EM algorithm, support vector machine, and other kernel-based learning machines. Based on a careful examination of the problem and a detailed analysis of the existing solutions, we propose several discriminating transforms as the learning machine during the user interaction. We argue that relevance feedback problem is best represented as a biased classification problem, or a (1+x)-class classification problem. Biased Discriminant Transform (BDT) is shown to outperform all the others. A kernel form is proposed to capture non-linearity in the class distributions.",2001,38,121,1,True,Computer Science,,40403107,X. Zhou,153652752.0,Thomas S. Huang,,,,,,,,,,,,,,,,,,,,,,,,
17b05e44253c7100290985d9af2237292f6afc9c,https://www.semanticscholar.org/paper/17b05e44253c7100290985d9af2237292f6afc9c,Multicategory ψ-Learning and Support Vector Machine: Computational Tools,"Many margin-based binary classification techniques such as support vector machine (SVM) and ψ-learning deliver high performance. An earlier article proposed a new multicategory ψ-learning methodology that shows great promise in generalization ability. However,ψ-learning is computationally difficult because it requires handling a nonconvex minimization problem. In this article, we propose two computational tools for multicategory ψ-learning. The first one is based on d.c. algorithms and solved by sequential quadratic programming, while the second one uses the outer approximation method, which yields the global minimizer via sequential concave minimization. Numerical examples show the proposed algorithms perform well.",2005,14,126,6,False,Mathematics,,46399637,Yufeng Liu,2266946.0,Xiaotong Shen,144163716.0,Hani Doss,,,,,,,,,,,,,,,,,,,,,,
b7fc718fb6237df4eed84ca47c5a461588a97282,https://www.semanticscholar.org/paper/b7fc718fb6237df4eed84ca47c5a461588a97282,Bioactive Molecule Prediction Using Extreme Gradient Boosting,"Following the explosive growth in chemical and biological data, the shift from traditional methods of drug discovery to computer-aided means has made data mining and machine learning methods integral parts of today’s drug discovery process. In this paper, extreme gradient boosting (Xgboost), which is an ensemble of Classification and Regression Tree (CART) and a variant of the Gradient Boosting Machine, was investigated for the prediction of biological activity based on quantitative description of the compound’s molecular structure. Seven datasets, well known in the literature were used in this paper and experimental results show that Xgboost can outperform machine learning algorithms like Random Forest (RF), Support Vector Machines (LSVM), Radial Basis Function Neural Network (RBFN) and Naïve Bayes (NB) for the prediction of biological activities. In addition to its ability to detect minority activity classes in highly imbalanced datasets, it showed remarkable performance on both high and low diversity datasets.",2016,34,155,2,True,Computer Science,Medicine,7552337,Ismail Babajide Mustapha,2689948.0,Faisal Saeed,,,,,,,,,,,,,,,,,,,,,,,,
508571db5d2f77c17d2829878bb1dc645010dda8,https://www.semanticscholar.org/paper/508571db5d2f77c17d2829878bb1dc645010dda8,A Comparative Analysis of Methods for Pruning Decision Trees,"In this paper, we address the problem of retrospectively pruning decision trees induced from data, according to a top-down approach. This problem has received considerable attention in the areas of pattern recognition and machine learning, and many distinct methods have been proposed in literature. We make a comparative study of six well-known pruning methods with the aim of understanding their theoretical foundations, their computational complexity, and the strengths and weaknesses of their formulation. Comments on the characteristics of each method are empirically supported. In particular, a wide experimentation performed on several data sets leads us to opposite conclusions on the predictive accuracy of simplified trees from some drawn in the literature. We attribute this divergence to differences in experimental designs. Finally, we prove and make use of a property of the reduced error pruning method to obtain an objective evaluation of the tendency to overprune/underprune observed in each method.",1997,27,554,35,False,Computer Science,,1700821,F. Esposito,1738657.0,D. Malerba,145467353.0,G. Semeraro,,,,,,,,,,,,,,,,,,,,,,
5ba7944dd68b0e18efad4ca11fb1475cdb0ff618,https://www.semanticscholar.org/paper/5ba7944dd68b0e18efad4ca11fb1475cdb0ff618,Toward Massive Machine Type Communications in Ultra-Dense Cellular IoT Networks: Current Issues and Machine Learning-Assisted Solutions,"The ever-increasing number of resource-constrained machine-type communication (MTC) devices is leading to the critical challenge of fulfilling diverse communication requirements in dynamic and ultra-dense wireless environments. Among different application scenarios that the upcoming 5G and beyond cellular networks are expected to support, such as enhanced mobile broadband (eMBB), massive machine type communications (mMTCs), and ultra-reliable and low latency communications (URLLCs), the mMTC brings the unique technical challenge of supporting a huge number of MTC devices in cellular networks, which is the main focus of this paper. The related challenges include quality of service (QoS) provisioning, handling highly dynamic and sporadic MTC traffic, huge signalling overhead, and radio access network (RAN) congestion. In this regard, this paper aims to identify and analyze the involved technical issues, to review recent advances, to highlight potential solutions and to propose new research directions. First, starting with an overview of mMTC features and QoS provisioning issues, we present the key enablers for mMTC in cellular networks. Along with the highlights on the inefficiency of the legacy random access (RA) procedure in the mMTC scenario, we then present the key features and channel access mechanisms in the emerging cellular IoT standards, namely, LTE-M and narrowband IoT (NB-IoT). Subsequently, we present a framework for the performance analysis of transmission scheduling with the QoS support along with the issues involved in short data packet transmission. Next, we provide a detailed overview of the existing and emerging solutions toward addressing RAN congestion problem, and then identify potential advantages, challenges, and use cases for the applications of emerging machine learning (ML) techniques in ultra-dense cellular networks. Out of several ML techniques, we focus on the application of low-complexity $Q$ -learning approach in the mMTC scenario along with the recent advances toward enhancing its learning performance and convergence. Finally, we discuss some open research challenges and promising future research directions.",2018,216,190,8,True,Computer Science,Engineering,1399927423,Shree Krishna Sharma,2107982675.0,Xianbin Wang,,,,,,,,,,,,,,,,,,,,,,,,
932709a41eee54f3eddbd3b3a7baf043c3ed33ec,https://www.semanticscholar.org/paper/932709a41eee54f3eddbd3b3a7baf043c3ed33ec,Learning-Based Model Predictive Control: Toward Safe Learning in Control,"Recent successes in the field of machine learning, as well as the availability of increased sensing and computational capabilities in modern control systems, have led to a growing interest in learning and data-driven control techniques. Model predictive control (MPC), as the prime methodology for constrained control, offers a significant opportunity to exploit the abundance of data in a reliable manner, particularly while taking safety constraints into account. This review aims at summarizing and categorizing previous research on learning-based MPC, i.e., the integration or combination of MPC with learning methods, for which we consider three main categories. Most of the research addresses learning for automatic improvement of the prediction model from recorded data. There is, however, also an increasing interest in techniques to infer the parameterization of the MPC controller, i.e., the cost and constraints, that lead to the best closed-loop performance. Finally, we discuss concepts that leverage MPC to augment learning-based controllers with constraint satisfaction properties.",2020,142,244,10,False,Computer Science,,9381839,Lukas Hewing,2359207.0,K. P. Wabersich,47761203.0,Marcel Menner,2176899.0,M. Zeilinger,,,,,,,,,,,,,,,,,,,,
03956f0d63c1a8a3c9192afc5d05781779858005,https://www.semanticscholar.org/paper/03956f0d63c1a8a3c9192afc5d05781779858005,Machine Learning Predictions of Molecular Properties: Accurate Many-Body Potentials and Nonlocality in Chemical Space,"Simultaneously accurate and efficient prediction of molecular properties throughout chemical compound space is a critical ingredient toward rational compound design in chemical and pharmaceutical industries. Aiming toward this goal, we develop and apply a systematic hierarchy of efficient empirical methods to estimate atomization and total energies of molecules. These methods range from a simple sum over atoms, to addition of bond energies, to pairwise interatomic force fields, reaching to the more sophisticated machine learning approaches that are capable of describing collective interactions between many atoms or bonds. In the case of equilibrium molecular geometries, even simple pairwise force fields demonstrate prediction accuracy comparable to benchmark energies calculated using density functional theory with hybrid exchange-correlation functionals; however, accounting for the collective many-body interactions proves to be essential for approaching the “holy grail” of chemical accuracy of 1 kcal/mol for both equilibrium and out-of-equilibrium geometries. This remarkable accuracy is achieved by a vectorized representation of molecules (so-called Bag of Bonds model) that exhibits strong nonlocality in chemical space. In addition, the same representation allows us to predict accurate electronic properties of molecules, such as their polarizability and molecular frontier orbital energies.",2015,28,509,6,False,Medicine,Physics,39960184,K. Hansen,3022604.0,Franziska Biegler,6781829.0,R. Ramakrishnan,6791798.0,Wiktor Pronobis,7847508.0,O. A. von Lilienfeld,145034054.0,K. Müller,2462983.0,A. Tkatchenko,,,,,,,,,,,,,,
dc77fb6c3b053095c74759f35e33029c0cd911fa,https://www.semanticscholar.org/paper/dc77fb6c3b053095c74759f35e33029c0cd911fa,Development and Validation of an Electronic Health Record–Based Machine Learning Model to Estimate Delirium Risk in Newly Hospitalized Patients Without Known Cognitive Impairment,"Key Points Question Can machine learning be used to predict incident delirium in newly hospitalized patients using only data available in the electronic health record shortly after admission? Findings In this cohort study, classification models were trained using 5 different machine learning algorithms on 14 227 hospital stays and validated on a prospective test set of 3996 hospital stays. The gradient boosting machine model performed best, with an area under the receiver operating characteristic curve of 0.855. Meaning Machine learning can accurately predict delirium risk using electronic health record data on admission and outperforms the nurse-administered prediction rules currently used.",2018,31,77,2,True,Medicine,,2064868963,Andrew Wong,47973433.0,Albert T. Young,2057099724.0,April S. Liang,145776427.0,R. Gonzales,6512927.0,V. Douglas,48901174.0,D. Hadley,,,,,,,,,,,,,,,,
239b2210b3fbc1f4b8246437a88a668bf9a0d2c0,https://www.semanticscholar.org/paper/239b2210b3fbc1f4b8246437a88a668bf9a0d2c0,An overview of classification algorithms for imbalanced datasets,"Unbalanced data set, a problem often found in real world application, can cause seriously negative effect on classification performance of machine learning algorithms. There have been many attempts at dealing with classification of unbalanced data sets. In this paper we present a brief review of existing solutions to the class-imbalance problem proposed both at the data and algorithmic levels. Even though a common practice to handle the problem of imbalanced data is to rebalance them artificially by oversampling and/or under-sampling, some researchers proved that modified support vector machine, rough set based minority class oriented rule learning methods, cost sensitive classifier perform good on imbalanced data set. We observed that current research in imbalance data problem is moving to",2012,45,289,12,False,,,70777243,Vaishali Ganganwar,,,,,,,,,,,,,,,,,,,,,,,,,,
ac0a59165ee2ac666b1880316eefe349b87f6ba0,https://www.semanticscholar.org/paper/ac0a59165ee2ac666b1880316eefe349b87f6ba0,Toward Interpretable Machine Learning: Transparent Deep Neural Networks and Beyond,"With the broader and highly successful usage of machine learning in industry and the sciences, there has been a growing demand for explainable AI. Interpretability and explanation methods for gaining a better understanding about the problem solving abilities and strategies of nonlinear Machine Learning such as Deep Learning (DL), LSTMs, and kernel methods are therefore receiving increased attention. In this work we aim to (1) provide a timely overview of this active emerging field and explain its theoretical foundations, (2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations, (3) outline best practice aspects i.e. how to best include interpretation methods into the standard usage of machine learning and (4) demonstrate successful usage of explainable AI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of machine learning.",2020,165,70,6,False,Computer Science,Mathematics,1699054,W. Samek,144535526.0,G. Montavon,3633358.0,S. Lapuschkin,51004625.0,Christopher J. Anders,145034054.0,K. Müller,,,,,,,,,,,,,,,,,,
8b20f103c1f20074fa35bd8fc41983964283acac,https://www.semanticscholar.org/paper/8b20f103c1f20074fa35bd8fc41983964283acac,Fictitious Self-Play in Extensive-Form Games,"Fictitious play is a popular game-theoretic model of learning in games. However, it has received little attention in practical applications to large problems. This paper introduces two variants of fictitious play that are implemented in behavioural strategies of an extensive-form game. The first variant is a full-width process that is realization equivalent to its normal-form counterpart and therefore inherits its convergence guarantees. However, its computational requirements are linear in time and space rather than exponential. The second variant, Fictitious Self-Play, is a machine learning framework that implements fictitious play in a sample-based fashion. Experiments in imperfect-information poker games compare our approaches and demonstrate their convergence to approximate Nash equilibria.",2015,36,170,23,False,Mathematics,Computer Science,2052354576,Johannes Heinrich,1975889.0,Marc Lanctot,145824029.0,David Silver,,,,,,,,,,,,,,,,,,,,,,
0e54e1d7ca6d795bb5e6bd9ad9291af46fbcaa72,https://www.semanticscholar.org/paper/0e54e1d7ca6d795bb5e6bd9ad9291af46fbcaa72,Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning,"Machine learning has started to be deployed in fields such as healthcare and finance, which propelled the need for and growth of privacy-preserving machine learning (PPML). We propose an actively secure four-party protocol (4PC), and a framework for PPML, showcasing its applications on four of the most widely-known machine learning algorithms -- Linear Regression, Logistic Regression, Neural Networks, and Convolutional Neural Networks. Our 4PC protocol tolerating at most one malicious corruption is practically efficient as compared to the existing works. We use the protocol to build an efficient mixed-world framework (Trident) to switch between the Arithmetic, Boolean, and Garbled worlds. Our framework operates in the offline-online paradigm over rings and is instantiated in an outsourced setting for machine learning. Also, we propose conversions especially relevant to privacy-preserving machine learning. The highlights of our framework include using a minimal number of expensive circuits overall as compared to ABY3. This can be seen in our technique for truncation, which does not affect the online cost of multiplication and removes the need for any circuits in the offline phase. Our B2A conversion has an improvement of $\mathbf{7} \times$ in rounds and $\mathbf{18} \times$ in the communication complexity. In addition to these, all of the special conversions for machine learning, e.g. Secure Comparison, achieve constant round complexity. The practicality of our framework is argued through improvements in the benchmarking of the aforementioned algorithms when compared with ABY3. All the protocols are implemented over a 64-bit ring in both LAN and WAN settings. Our improvements go up to $\mathbf{187} \times$ for the training phase and $\mathbf{158} \times$ for the prediction phase when observed over LAN and WAN.",2019,57,92,10,True,Computer Science,Mathematics,65831050,Rahul Rachuri,153456203.0,Ajith Suresh,,,,,,,,,,,,,,,,,,,,,,,,
2ea4a33a468958de14303daaaba2349d0ed07b73,https://www.semanticscholar.org/paper/2ea4a33a468958de14303daaaba2349d0ed07b73,Deterministic Boltzmann Learning Performs Steepest Descent in Weight-Space,"The Boltzmann machine learning procedure has been successfully applied in deterministic networks of analog units that use a mean field approximation to efficiently simulate a truly stochastic system (Peterson and Anderson 1987). This type of deterministic Boltzmann machine (DBM) learns much faster than the equivalent stochastic Boltzmann machine (SBM), but since the learning procedure for DBM's is only based on an analogy with SBM's, there is no existing proof that it performs gradient descent in any function, and it has only been justified by simulations. By using the appropriate interpretation for the way in which a DBM represents the probability of an output vector given an input vector, it is shown that the DBM performs steepest descent in the same function as the original SBM, except at rare discontinuities. A very simple way of forcing the weights to become symmetrical is also described, and this makes the DBM more biologically plausible than back-propagation (Werbos 1974; Parker 1985; Rumelhart et al. 1986).",1989,5,181,13,False,Computer Science,Mathematics,1695689,Geoffrey E. Hinton,,,,,,,,,,,,,,,,,,,,,,,,,,
462663b9075c11af4c4b24c85b013af91cb08ab7,https://www.semanticscholar.org/paper/462663b9075c11af4c4b24c85b013af91cb08ab7,Predictive analytics for chronic kidney disease using machine learning techniques,"Predictive analytics for healthcare using machine learning is a challenged task to help doctors decide the exact treatments for saving lives. In this paper, we present machine learning techniques for predicting the chronic kidney disease using clinical data. Four machine learning methods are explored including K-nearest neighbors (KNN), support vector machine (SVM), logistic regression (LR), and decision tree classifiers. These predictive models are constructed from chronic kidney disease dataset and the performance of these models are compared together in order to select the best classifier for predicting the chronic kidney disease.",2016,12,71,3,False,Computer Science,,9323606,Anusorn Charleonnan,30824028.0,Thipwan Fufaung,31260166.0,Tippawan Niyomwong,31032350.0,Wandee Chokchueypattanakit,31261376.0,Sathit Suwannawach,31369331.0,Nitat Ninchawee,,,,,,,,,,,,,,,,
bc183ee72b40416548937b9155b427a65e5ecbb2,https://www.semanticscholar.org/paper/bc183ee72b40416548937b9155b427a65e5ecbb2,Iterative Machine Teaching,"In this paper, we consider the problem of machine teaching, the inverse problem of machine learning. Different from traditional machine teaching which views the learners as batch algorithms, we study a new paradigm where the learner uses an iterative algorithm and a teacher can feed examples sequentially and intelligently based on the current performance of the learner. We show that the teaching complexity in the iterative case is very different from that in the batch case. Instead of constructing a minimal training set for learners, our iterative machine teaching focuses on achieving fast convergence in the learner model. Depending on the level of information the teacher has from the learner model, we design teaching algorithms which can provably reduce the number of teaching examples and achieve faster convergence than learning without teachers. We also validate our theoretical findings with extensive experiments on different data distribution and real image datasets.",2017,28,104,16,False,Computer Science,Mathematics,36326884,Weiyang Liu,144445933.0,Bo Dai,3162535.0,Ahmad Humayun,39367354.0,C. Tay,144136729.0,Chen Yu,2836466.0,Linda B. Smith,144177248.0,James M. Rehg,1779453.0,Le Song,,,,,,,,,,,,
86713aa23ad99039ba76a670797df40ad65a64b2,https://www.semanticscholar.org/paper/86713aa23ad99039ba76a670797df40ad65a64b2,An Introduction to Machine Learning,"In the last few years, machine learning (ML) and artificial intelligence have seen a new wave of publicity fueled by the huge and ever‐increasing amount of data and computational power as well as the discovery of improved learning algorithms. However, the idea of a computer learning some abstract concept from data and applying them to yet unseen situations is not new and has been around at least since the 1950s. Many of these basic principles are very familiar to the pharmacometrics and clinical pharmacology community. In this paper, we want to introduce the foundational ideas of ML to this community such that readers obtain the essential tools they need to understand publications on the topic. Although we will not go into the very details and theoretical background, we aim to point readers to relevant literature and put applications of ML in molecular biology as well as the fields of pharmacometrics and clinical pharmacology into perspective.",2020,93,64,1,True,Computer Science,Medicine,2383814,Solveig Badillo,49842626.0,B. Bánfai,3232090.0,F. Birzele,91987714.0,I. I. Davydov,2023123740.0,L. Hutchinson,1398629935.0,T. Kam-Thong,1436740047.0,Juliane Siebourg-Polster,3258307.0,Bernhard Steiert,,2108489886.0,J. Zhang,,,,,,,,,
2ee2592c95bf44aeb10439a14901ee761c99b846,https://www.semanticscholar.org/paper/2ee2592c95bf44aeb10439a14901ee761c99b846,Recent Advances in Example-Based Machine Translation,"I Foundations of EBMT.- 1 An Overview of EBMT.- 2 What is Example-Based Machine Translation?.- 3 Example-Based Machine Translation in a Controlled Environment.- 4 EBMT Seen as Case-based Reasoning.- II Run-time Approaches to EBMT.- 5 Formalizing Translation Memory.- 6 EBMT Using DP-Matching Between Word Sequences.- 7 A Hybrid Rule and Example-Based Method for Machine Translation.- 8 EBMT of POS-Tagged Sentences via Inductive Learning.- III Template-Driven EBMT.- 9 Learning Translation Templates from Bilingual Translation Examples.- 10 Clustered Transfer Rule Induction for Example-Based Translation.- 11 Translation Patterns, Linguistic Knowledge and Complexity in EBMT.- 12 Inducing Translation Grammars from Bracketed Alignments.- IV EBMT and Derivation Trees.- 13 Extracting Translation Knowledge from Parallel Corpora.- 14 Finding Translation Patterns from Dependency Structures.- 15 A Best-First Alignment Algorithm for Extraction of Transfer Mappings.- 16 Translating with Examples: The LFG-DOT Models of Translation.",2004,4,167,7,True,Computer Science,,93671213,M. Carl,144315616.0,Andy Way,1735272.0,Walter Daelemans,,,,,,,,,,,,,,,,,,,,,,
be26cdf0573bc8eee1119802e548dfaa2e401bdb,https://www.semanticscholar.org/paper/be26cdf0573bc8eee1119802e548dfaa2e401bdb,Overview of deep learning,"In recent years, deep learning has achieved great success in many fields, such as computer vision and natural language processing. Compared to traditional machine learning methods, deep learning has a strong learning ability and can make better use of datasets for feature extraction. Because of its practicability, deep learning becomes more and more popular for many researchers to do research works. In this paper, we mainly introduce some advanced neural networks of deep learning and their applications. Besides, we also discuss the limitations and prospects of deep learning.",2016,40,181,3,False,Computer Science,,31254825,Xuedan Du,2230979.0,Yinghao Cai,2117010531.0,Shuo Wang,2107887550.0,Leijie Zhang,,,,,,,,,,,,,,,,,,,,
9f4c8e1a6f93399eef8556218ac55840e1393105,https://www.semanticscholar.org/paper/9f4c8e1a6f93399eef8556218ac55840e1393105,Opportunities in Machine Learning for Healthcare,"Modern electronic health records (EHRs) provide data to answer clinically meaningful questions. The growing data in EHRs makes healthcare ripe for the use of machine learning. However, learning in a clinical setting presents unique challenges that complicate the use of common machine learning methodologies. For example, diseases in EHRs are poorly labeled, conditions can encompass multiple underlying endotypes, and healthy individuals are underrepresented. This article serves as a primer to illuminate these challenges and highlights opportunities for members of the machine learning community to contribute to healthcare.",2018,122,68,2,False,Computer Science,,2804918,M. Ghassemi,40466858.0,Tristan Naumann,145610328.0,Peter F. Schulam,143649421.0,Andrew Beam,2615814.0,R. Ranganath,,,,,,,,,,,,,,,,,,
