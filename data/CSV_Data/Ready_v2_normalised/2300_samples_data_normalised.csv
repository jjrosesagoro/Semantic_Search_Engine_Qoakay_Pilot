paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,fieldsOfStudy/1,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name
bf1a1f8f1c51500bb96055957c371825499841c3,https://www.semanticscholar.org/paper/bf1a1f8f1c51500bb96055957c371825499841c3,"What Can Machines Learn, and What Does It Mean for Occupations and the Economy?","Advances in machine learning (ML) are poised to transform numerous occupations and industries. This raises the question of which tasks will be most affected by ML. We apply the rubric evaluating task potential for ML in Brynjolfsson and Mitchell (2017) to build measures of ""Suitability for Machine Learning"" (SML) and apply it to 18,156 tasks in O*NET. We find that (i) ML affects different occupations than earlier automation waves; (ii) most occupations include at least some SML tasks; (iii) few occupations are fully automatable using ML; and (iv) realizing the potential of ML usually requires redesign of job task content.",2018,20,206,15,True,Computer Science,2841157,E. Brynjolfsson,40975594.0,Tom Michael Mitchell,144148548.0,Daniel Rock,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7b6dc4d999d1067ef9d442576264a42574888ed9,https://www.semanticscholar.org/paper/7b6dc4d999d1067ef9d442576264a42574888ed9,Machine Learning Interatomic Potentials as Emerging Tools for Materials Science,"Atomic‐scale modeling and understanding of materials have made remarkable progress, but they are still fundamentally limited by the large computational cost of explicit electronic‐structure methods such as density‐functional theory. This Progress Report shows how machine learning (ML) is currently enabling a new degree of realism in materials modeling: by “learning” electronic‐structure data, ML‐based interatomic potentials give access to atomistic simulations that reach similar accuracy levels but are orders of magnitude faster. A brief introduction to the new tools is given, and then, applications to some select problems in materials science are highlighted: phase‐change materials for memory devices; nanoparticle catalysts; and carbon‐based electrodes for chemical sensing, supercapacitors, and batteries. It is hoped that the present work will inspire the development and wider use of ML‐based interatomic potentials in diverse areas of materials research.",2019,166,219,0,True,Materials Science,2432235,Volker L. Deringer,143629921.0,M. Caro,2559761.0,Gábor Csányi,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
899db02ba28ef2479b5bea3e51627685be5b3865,https://www.semanticscholar.org/paper/899db02ba28ef2479b5bea3e51627685be5b3865,Deep Recurrent Neural Networks for Human Activity Recognition,"Adopting deep learning methods for human activity recognition has been effective in extracting discriminative features from raw input sequences acquired from body-worn sensors. Although human movements are encoded in a sequence of successive samples in time, typical machine learning methods perform recognition tasks without exploiting the temporal correlations between input data samples. Convolutional neural networks (CNNs) address this issue by using convolutions across a one-dimensional temporal sequence to capture dependencies among input data. However, the size of convolutional kernels restricts the captured range of dependencies between data samples. As a result, typical models are unadaptable to a wide range of activity-recognition configurations and require fixed-length input windows. In this paper, we propose the use of deep recurrent neural networks (DRNNs) for building recognition models that are capable of capturing long-range dependencies in variable-length input sequences. We present unidirectional, bidirectional, and cascaded architectures based on long short-term memory (LSTM) DRNNs and evaluate their effectiveness on miscellaneous benchmark datasets. Experimental results show that our proposed models outperform methods employing conventional machine learning, such as support vector machine (SVM) and k-nearest neighbors (KNN). Additionally, the proposed models yield better performance than other deep learning techniques, such as deep believe networks (DBNs) and CNNs.",2017,32,257,22,True,Computer Science,30050286,Abdulmajid Murad,1739676.0,Jae-Young Pyun,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4fd5672a30ec6a620556ccf8dc1d9e76fc67a5bf,https://www.semanticscholar.org/paper/4fd5672a30ec6a620556ccf8dc1d9e76fc67a5bf,Identification of novel antibacterial peptides by chemoinformatics and machine learning.,"The rise of antibiotic resistant pathogens is one of the most pressing global health issues. Discovery of new classes of antibiotics has not kept pace; new agents often suffer from cross-resistance to existing agents of similar structure. Short, cationic peptides with antimicrobial activity are essential to the host defenses of many organisms and represent a promising new class of antimicrobials. This paper reports the successful in silico screening for potent antibiotic peptides using a combination of QSAR and machine learning techniques. On the basis of initial high-throughput measurements of activity of over 1400 random peptides, artificial neural network models were built using QSAR descriptors and subsequently used to screen an in silico library of approximately 100,000 peptides. In vitro validation of the modeling showed 94% accuracy in identifying highly active peptides. The best peptides identified through screening were found to have activities comparable or superior to those of four conventional antibiotics and superior to the peptide most advanced in clinical development against a broad array of multiresistant human pathogens.",2009,32,242,7,False,Biology,2160852,C. Fjell,15888696.0,H. Jenssen,2458164.0,K. Hilpert,Medicine,2059932271.0,Warren A. Cheung,4550592.0,N. Panté,143696638.0,R. Hancock,145230547.0,A. Cherkasov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9a0f57d9be88ff5779a3a9877ce28cc8c61805e7,https://www.semanticscholar.org/paper/9a0f57d9be88ff5779a3a9877ce28cc8c61805e7,COVID-19 Future Forecasting Using Supervised Machine Learning Models,"Machine learning (ML) based forecasting mechanisms have proved their significance to anticipate in perioperative outcomes to improve the decision making on the future course of actions. The ML models have long been used in many application domains which needed the identification and prioritization of adverse factors for a threat. Several prediction methods are being popularly used to handle forecasting problems. This study demonstrates the capability of ML models to forecast the number of upcoming patients affected by COVID-19 which is presently considered as a potential threat to mankind. In particular, four standard forecasting models, such as linear regression (LR), least absolute shrinkage and selection operator (LASSO), support vector machine (SVM), and exponential smoothing (ES) have been used in this study to forecast the threatening factors of COVID-19. Three types of predictions are made by each of the models, such as the number of newly infected cases, the number of deaths, and the number of recoveries in the next 10 days. The results produced by the study proves it a promising mechanism to use these methods for the current scenario of the COVID-19 pandemic. The results prove that the ES performs best among all the used models followed by LR and LASSO which performs well in forecasting the new confirmed cases, death rate as well as recovery rate, while SVM performs poorly in all the prediction scenarios given the available dataset.",2020,26,240,13,True,Computer Science,1430656665,Furqan Rustam,9341675.0,A. Reshi,1403306506.0,A. Mehmood,,48621790.0,S. Ullah,1791452.0,Byung-Won On,48001308.0,W. Aslam,32016133.0,G. Choi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4ec47080fcb2967cbedf2b9d821d7b458aff8799,https://www.semanticscholar.org/paper/4ec47080fcb2967cbedf2b9d821d7b458aff8799,Bayesian Network Refinement Via Machine Learning Approach,"An approach to refining Bayesian network structures from new data is developed. Most previous work has only considered the refinement of the network's conditional probability parameters and has not addressed the issue of refining the network's structure. We tackle this problem by a machine learning approach based on a formalism known as the minimum description length (MDL) principle. The MDL principle is well suited to this task since it can perform tradeoffs between the accuracy, simplicity, and closeness to the existent structure. Another salient feature of this refinement approach is the capability of refining a network structure using partially specified data. Moreover, a localization scheme is developed for efficient computation of the description lengths since direct evaluation involves exponential time resources.",1998,25,59,2,False,Computer Science,144594306,Wai Lam,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b01a7ec32097a1f57fb80ef4073bc8a487d241fb,https://www.semanticscholar.org/paper/b01a7ec32097a1f57fb80ef4073bc8a487d241fb,Using corpora in machine-learning chatbot systems,"A chatbot is a machine conversation system which interacts with human users via natural conversational language. Software to machine-learn conversational patterns from a transcribed dialogue corpus has been used to generate a range of chatbots speaking various languages and sublanguages including varieties of English, as well as French, Arabic and Afrikaans. This paper presents a program to learn from spoken transcripts of the Dialogue Diversity Corpus of English, the Minnesota French Corpus, the Corpus of Spoken Afrikaans, the Qur’an Arabic-English parallel corpus, and the British National Corpus of English; we discuss the problems which arose during learning and testing. Two main goals were achieved from the automation process. One was the ability to generate different versions of the chatbot in different languages, bringing chatbot technology to languages with few if any NLP resources: the corpus-based learning techniques transferred straightforwardly to develop chatbots for Afrikaans and Qur’anic Arabic. The second achievement was the ability to learn a very large number of categories within a short time, saving effort and errors in doing such work manually: we generated more than one million AIML categories or conversation-rules from the BNC corpus, 20 times the size of existing AIML rule-sets, and probably the biggest AI Knowledge-Base ever.",2005,42,136,1,False,Computer Science,1697090,B. A. Shawar,144214753.0,E. Atwell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2ae0ab5303cb374e79193da4846c193c666acc67,https://www.semanticscholar.org/paper/2ae0ab5303cb374e79193da4846c193c666acc67,Machine Learning a General-Purpose Interatomic Potential for Silicon,"The success of first principles electronic structure calculation for predictive modeling in chemistry, solid state physics, and materials science is constrained by the limitations on simulated length and time scales due to computational cost and its scaling. Techniques based on machine learning ideas for interpolating the Born-Oppenheimer potential energy surface without explicitly describing electrons have recently shown great promise, but accurately and efficiently fitting the physically relevant space of configurations has remained a challenging goal. Here we present a Gaussian Approximation Potential for silicon that achieves this milestone, accurately reproducing density functional theory reference results for a wide range of observable properties, including crystal, liquid, and amorphous bulk phases, as well as point, line, and plane defects. We demonstrate that this new potential enables calculations that would be extremely expensive with a first principles electronic structure method, such as finite temperature phase boundary lines, self-diffusivity in the liquid, formation of the amorphous by slow quench, and dynamic brittle fracture. We show that the uncertainty quantification inherent to the Gaussian process regression framework gives a qualitative estimate of the potential's accuracy for a given atomic configuration. The success of this model shows that it is indeed possible to create a useful machine-learning-based interatomic potential that comprehensively describes a material, and serves as a template for the development of such models in the future.",2018,218,218,7,True,Physics,3938091,A. Bartók,11724553.0,J. Kermode,2105796.0,N. Bernstein,Materials Science,2559761.0,Gábor Csányi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c6a83c4fcc99ba6753109301949c5b7cfa978079,https://www.semanticscholar.org/paper/c6a83c4fcc99ba6753109301949c5b7cfa978079,The Alignment Template Approach to Statistical Machine Translation,"A phrase-based statistical machine translation approach the alignment template approach is described. This translation approach allows for general many-to-many relations between words. Thereby, the context of words is taken into account in the translation model, and local changes in word order from source to target language can be learned explicitly. The model is described using a log-linear modeling approach, which is a generalization of the often used source-channel approach. Thereby, the model is easier to extend than classical statistical machine translation systems. We describe in detail the process for learning phrasal translations, the feature functions used, and the search algorithm. The evaluation of this approach is performed on three different tasks. For the German-English speech Verbmobil task, we analyze the effect of various system components. On the French-English Canadian Hansards task, the alignment template system obtains significantly better results than a single-word-based translation model. In the Chinese-English 2002 National Institute of Standards and Technology (NIST) machine translation evaluation it yields statistically significantly better NIST scores than all competing research and commercial translation systems.",2004,50,1053,78,True,Computer Science,2002316,F. Och,145322333.0,H. Ney,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
463ec74665c9476069591aa8e19c7c2fb93e4681,https://www.semanticscholar.org/paper/463ec74665c9476069591aa8e19c7c2fb93e4681,An Explicit Description of the Reproducing Kernel Hilbert Spaces of Gaussian RBF Kernels,"Although Gaussian radial basis function (RBF) kernels are one of the most often used kernels in modern machine learning methods such as support vector machines (SVMs), little is known about the structure of their reproducing kernel Hilbert spaces (RKHSs). In this work, two distinct explicit descriptions of the RKHSs corresponding to Gaussian RBF kernels are given and some consequences are discussed. Furthermore, an orthonormal basis for these spaces is presented. Finally, it is discussed how the results can be used for analyzing the learning performance of SVMs",2006,30,233,23,False,Mathematics,1782193,Ingo Steinwart,1754328.0,D. Hush,143790221.0,C. Scovel,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6dce0d4635c1b84d000c586a635a46d3d4566e4d,https://www.semanticscholar.org/paper/6dce0d4635c1b84d000c586a635a46d3d4566e4d,Enabling Cognitive Smart Cities Using Big Data and Machine Learning: Approaches and Challenges,"The development of smart cities and their fast-paced deployment is resulting in the generation of large quantities of data at unprecedented rates. Unfortunately, most of the generated data is wasted without extracting potentially useful information and knowledge because of the lack of established mechanisms and standards that benefit from the availability of such data. Moreover, the highly dynamic nature of smart cities calls for a new generation of machine learning approaches that are flexible and adaptable to cope with the dynamicity of data to perform analytics and learn from real-time data. In this article, we shed light on the challenge of underutilizing the big data generated by smart cities from a machine learning perspective. In particular, we present the phenomenon of wasting unlabeled data. We argue that semi-supervision is a must for smart cities to address this challenge. We also propose a three-level learning framework for smart cities that matches the hierarchical nature of big data generated by smart cities with a goal of providing different levels of knowledge abstraction. The proposed framework is scalable to meet the needs of smart city services. Fundamentally, the framework benefits from semi-supervised deep reinforcement learning where a small amount of data that has users' feedback serves as labeled data, while a larger amount without such users' feedback serves as unlabeled data. The framework utilizes a mix of labeled and unlabeled data to converge toward better control policies instead of wasting the unlabeled data. This article also explores how deep reinforcement learning and its shift toward semi-supervision can handle the cognitive side of smart city services and improve their performance by providing several use cases spanning the different domains of smart cities. We also highlight several challenges as well as promising future research directions for incorporating machine learning and high-level intelligence into smart city services.",2018,15,215,11,True,Computer Science,2151683198,M. Mohammadi,1389945327.0,Ala Al-Fuqaha,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7864c8cd08ff4da9acc37de2576e9cdbabe03107,https://www.semanticscholar.org/paper/7864c8cd08ff4da9acc37de2576e9cdbabe03107,Neural Architecture Search with Bayesian Optimisation and Optimal Transport,"Bayesian Optimisation (BO) refers to a class of methods for global optimisation of a function $f$ which is only accessible via point evaluations. It is typically used in settings where $f$ is expensive to evaluate. A common use case for BO in machine learning is model selection, where it is not possible to analytically model the generalisation performance of a statistical model, and we resort to noisy and expensive training and validation procedures to choose the best model. Conventional BO methods have focused on Euclidean and categorical domains, which, in the context of model selection, only permits tuning scalar hyper-parameters of machine learning algorithms. However, with the surge of interest in deep learning, there is an increasing demand to tune neural network \emph{architectures}. In this work, we develop NASBOT, a Gaussian process based BO framework for neural architecture search. To accomplish this, we develop a distance metric in the space of neural network architectures which can be computed efficiently via an optimal transport program. This distance might be of independent interest to the deep learning community as it may find applications outside of BO. We demonstrate that NASBOT outperforms other alternatives for architecture search in several cross validation based model selection tasks on multi-layer perceptrons and convolutional neural networks.",2018,60,411,35,False,Mathematics,1887808,Kirthevasan Kandasamy,2934259.0,W. Neiswanger,1753432.0,J. Schneider,Computer Science,1719347.0,B. Póczos,143977260.0,E. Xing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
248f27f0b53255e8958afb4bf1a5c20c3e236a4b,https://www.semanticscholar.org/paper/248f27f0b53255e8958afb4bf1a5c20c3e236a4b,Predictive analytics in health care using machine learning tools and techniques,"When we have a huge data set on which we would like to perform predictive analysis or pattern recognition, machine learning is the way to go. Machine Learning (ML) is the fastest rising arena in computer science, and health informatics is of extreme challenge. The aim of Machine Learning is to develop algorithms which can learn and progress over time and can be used for predictions. Machine Learning practices are widely used in various fields and primarily health care industry has been benefitted a lot through machine learning prediction techniques. It offers a variety of alerting and risk management decision support tools, targeted at improving patients' safety and healthcare quality. With the need to reduce healthcare costs and the movement towards personalized healthcare, the healthcare industry faces challenges in the essential areas like, electronic record management, data integration, and computer aided diagnoses and disease predictions. Machine Learning offers a wide range of tools, techniques, and frameworks to address these challenges. This paper depicts the study on various prediction techniques and tools for Machine Learning in practice. A glimpse on the applications of Machine Learning in various domains are also discussed here by highlighting on its prominence role in health care industry.",2017,25,74,2,False,Computer Science,144692718,B. Nithya,2757904.0,V. Ilango,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46d19644912b36942c5193d3e239849281dd0319,https://www.semanticscholar.org/paper/46d19644912b36942c5193d3e239849281dd0319,Exponential Machines,"Modeling interactions between features improves the performance of machine learning solutions in many domains (e.g. recommender systems or sentiment analysis). In this paper, we introduce Exponential Machines (ExM), a predictor that models all interactions of every order. The key idea is to represent an exponentially large tensor of parameters in a factorized format called Tensor Train (TT). The Tensor Train format regularizes the model and lets you control the number of underlying parameters. To train the model, we develop a stochastic Riemannian optimization procedure, which allows us to fit tensors with 2^160 entries. We show that the model achieves state-of-the-art performance on synthetic data with high-order interactions and that it works on par with high-order factorization machines on a recommender system dataset MovieLens 100K.",2017,35,76,6,False,Computer Science,2050212830,Alexander Novikov,103810919.0,Mikhail Trofimov,1738205.0,I. Oseledets,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94358f789c1d7fa01127c4b2f06b20cd7a453ff8,https://www.semanticscholar.org/paper/94358f789c1d7fa01127c4b2f06b20cd7a453ff8,Learning to Evade Static PE Machine Learning Malware Models via Reinforcement Learning,"Machine learning is a popular approach to signatureless malware detection because it can generalize to never-before-seen malware families and polymorphic strains. This has resulted in its practical use for either primary detection engines or for supplementary heuristic detection by anti-malware vendors. Recent work in adversarial machine learning has shown that deep learning models are susceptible to gradient-based attacks, whereas non-differentiable models that report a score can be attacked by genetic algorithms that aim to systematically reduce the score. We propose a more general framework based on reinforcement learning (RL) for attacking static portable executable (PE) anti-malware engines. The general framework does not require a differentiable model nor does it require the engine to produce a score. Instead, an RL agent is equipped with a set of functionality-preserving operations that it may perform on the PE file. Through a series of games played against the anti-malware engine, it learns which sequences of operations are likely to result in evading the detector for any given malware sample. This enables completely black-box attacks against static PE anti-malware, and produces functional evasive malware samples as a direct result. We show in experiments that our method can attack a gradient-boosted machine learning model with evasion rates that are substantial and appear to be strongly dependent on the dataset. We demonstrate that attacks against this model appear to also evade components of publicly hosted antivirus engines. Adversarial training results are also presented: by retraining the model on evasive ransomware samples, a subsequent attack is 33% less effective. However, there are overfitting dangers when adversarial training, which we note. We release code to allow researchers to reproduce and improve this approach.",2018,37,131,14,False,Computer Science,2639880,H. Anderson,35665260.0,Anant Kharkar,7888676.0,Bobby Filar,,145685504.0,David Evans,153379407.0,P. Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1b7c02e4f07477a5ae2d1aa52db8ac6ddb55f53c,https://www.semanticscholar.org/paper/1b7c02e4f07477a5ae2d1aa52db8ac6ddb55f53c,Using Emoticons to Reduce Dependency in Machine Learning Techniques for Sentiment Classification,"Sentiment Classification seeks to identify a piece of text according to its author's general feeling toward their subject, be it positive or negative. Traditional machine learning techniques have been applied to this problem with reasonable success, but they have been shown to work well only when there is a good match between the training and test data with respect to topic. This paper demonstrates that match with respect to domain and time is also important, and presents preliminary experiments with training data labeled with emoticons, which has the potential of being independent of domain, topic and time.",2005,9,629,31,True,Computer Science,39784208,J. Read,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c1a95197e15fa99f55cd0cb2ee14d2f02699a919,https://www.semanticscholar.org/paper/c1a95197e15fa99f55cd0cb2ee14d2f02699a919,Balancing Training Data for Automated Annotation of Keywords: a Case Study,"There has been an increasing interest in tools for automating the annotation of databases. Machine learning techniques are promising candidates to help curators to, at least, guide the process of annotation which is mostly done manually. Following previous works on automated annotation using symbolic machine learning techniques, the present work deals with a common problem in machine learning: that classes usually have skewed class prior probabilities, i.e., there is a large number of examples of one class compared with just few examples of the other class. This happens due to the fact that a large number of proteins is not annotated for every feature. Thus, we analyze and employ some techniques aiming at balancing the training data. Our experiments show that the classifiers induced from balanced data sampled with our method are more accurate than those induced from the original data.",2003,17,184,30,False,Computer Science,145666101,Gustavo E. A. P. A. Batista,1707374.0,A. Bazzan,1737677.0,M. C. Monard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
828d61fd204bebf70a506ecc0720e4287bec4fd0,https://www.semanticscholar.org/paper/828d61fd204bebf70a506ecc0720e4287bec4fd0,Prediction of Heart Disease Using Machine Learning,"with the rampant increase in the heart stroke rates at juvenile ages, we need to put a system in place to be able to detect the symptoms of a heart stroke at an early stage and thus prevent it. It is impractical for a common man to frequently undergo costly tests like the ECG and thus there needs to be a system in place which is handy and at the same time reliable, in predicting the chances of a heart disease. Thus we propose to develop an application which can predict the vulnerability of a heart disease given basic symptoms like age, sex, pulse rate etc. The machine learning algorithm neural networks has proven to be the most accurate and reliable algorithm and hence used in the proposed system.",2018,5,122,4,False,Computer Science,19260977,A. Gavhane,19307299.0,Gouthami Kokkula,32222567.0,Isha Pandya,,51441416.0,P. K. Devadkar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1b09809b79a7b053391bdd414d4233132747f6ec,https://www.semanticscholar.org/paper/1b09809b79a7b053391bdd414d4233132747f6ec,Effective End-User Interaction with Machine Learning,"End-user interactive machine learning is a promising tool for enhancing human productivity and capabilities with large unstructured data sets. Recent work has shown that we can create end-user interactive machine learning systems for specific applications. However, we still lack a generalized understanding of how to design effective end-user interaction with interactive machine learning systems. This work presents three explorations in designing for effective end-user interaction with machine learning in CueFlik, a system developed to support Web image search. These explorations demonstrate that interactions designed to balance the needs of end-users and machine learning algorithms can significantly improve the effectiveness of end-user interactive machine learning.",2011,9,59,3,True,Computer Science,1719124,Saleema Amershi,145504534.0,J. Fogarty,2189118.0,Ashish Kapoor,,1719056.0,Desney S. Tan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4e84dd37e9898d9655b55d99678da12eeda06615,https://www.semanticscholar.org/paper/4e84dd37e9898d9655b55d99678da12eeda06615,Map-reduce-merge: simplified relational data processing on large clusters,"Map-Reduce is a programming model that enables easy development of scalable parallel applications to process a vast amount of data on large clusters of commodity machines. Through a simple interface with two functions, map and reduce, this model facilitates parallel implementation of many real-world tasks such as data processing jobs for search engines and machine learning.However,this model does not directly support processing multiple related heterogeneous datasets. While processing relational data is a common need, this limitation causes difficulties and/or inefficiency when Map-Reduce is applied on relational operations like joins.We improve Map-Reduce into a new model called Map-Reduce-Merge. It adds to Map-Reduce a Merge phase that can efficiently merge data already partitioned and sorted (or hashed) by map and reduce modules. We also demonstrate that this new model can express relational algebra operators as well as implement several join algorithms.",2007,17,868,36,False,Computer Science,2124616415,Hung-chih Yang,1678670.0,A. Dasdan,34753868.0,R. Hsiao,,1694803.0,D. S. Parker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a44b5cfc5223e88977667b07e68ce3371f50033d,https://www.semanticscholar.org/paper/a44b5cfc5223e88977667b07e68ce3371f50033d,Machine Learning in Orthopedics: A Literature Review,"In this paper we present the findings of a systematic literature review covering the articles published in the last two decades in which the authors described the application of a machine learning technique and method to an orthopedic problem or purpose. By searching both in the Scopus and Medline databases, we retrieved, screened and analyzed the content of 70 journal articles, and coded these resources following an iterative method within a Grounded Theory approach. We report the survey findings by outlining the articles' content in terms of the main machine learning techniques mentioned therein, the orthopedic application domains, the source data and the quality of their predictive performance.",2018,118,112,1,True,Computer Science,3037324,F. Cabitza,1756869.0,A. Locoro,145244821.0,G. Banfi,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
823e9af68ff51fd0d4cc4db596f4aa112ed6bf9c,https://www.semanticscholar.org/paper/823e9af68ff51fd0d4cc4db596f4aa112ed6bf9c,Machine Learning: Neural Networks,"This post is a continuation of the Machine Learning series, which began with the basics and might eventually have more articles. This post assumes an understanding of gradient descent and basic idea of supervised learning, so if those aren’t completely clear, read the previous post as well! In the last post, I talked about machine learning, supervised learning algorithms, and explained how you could use data to create a linear model and learn the parameters of this model via gradient descent. It turns out that we can do the exact same thing with more complex models, which can let us represent much more complex relationships and use highly non-linear and irregular data. One such model is the feed-forward neural network. (There are other types of neural networks, but the feed-forward neural network is the simplest one, so it’s what we’ll be looking at.)",1994,0,66,3,False,Computer Science,1750050,H. Adeli,1752340.0,S. Hung,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8563b0765bcc0b3ae02298d3722bff10bbb15cdb,https://www.semanticscholar.org/paper/8563b0765bcc0b3ae02298d3722bff10bbb15cdb,Detecting P2P botnets through network behavior analysis and machine learning,"Botnets have become one of the major threats on the Internet for serving as a vector for carrying attacks against organizations and committing cybercrimes. They are used to generate spam, carry out DDOS attacks and click-fraud, and steal sensitive information. In this paper, we propose a new approach for characterizing and detecting botnets using network traffic behaviors. Our approach focuses on detecting the bots before they launch their attack. We focus in this paper on detecting P2P bots, which represent the newest and most challenging types of botnets currently available. We study the ability of five different commonly used machine learning techniques to meet online botnet detection requirements, namely adaptability, novelty detection, and early detection. The results of our experimental evaluation based on existing datasets show that it is possible to detect effectively botnets during the botnet Command-and- Control (C&C) phase and before they launch their attacks using traffic behaviors only. However, none of the studied techniques can address all the above requirements at once.",2011,18,244,32,False,Computer Science,12906109,Sherif Saad,143812950.0,I. Traoré,1698268.0,A. Ghorbani,,36733654.0,B. Sayed,2110819522.0,David Zhao,2153424526.0,Wei Lu,2064761645.0,J. Felix,49184511.0,Payman Hakimian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6a5e6ce558edaec2078c3d5a65327fc7aecc3507,https://www.semanticscholar.org/paper/6a5e6ce558edaec2078c3d5a65327fc7aecc3507,OpenNMT: Neural Machine Translation Toolkit,"OpenNMT is an open-source toolkit for neural machine translation (NMT). The system prioritizes efficiency, modularity, and extensibility with the goal of supporting NMT research into model architectures, feature representations, and source modalities, while maintaining competitive performance and reasonable training requirements. The toolkit consists of modeling and translation support, as well as detailed pedagogical documentation about the underlying techniques. OpenNMT has been used in several production MT systems, modified for numerous research papers, and is implemented across several deep learning frameworks.",2018,36,89,9,False,Computer Science,39861444,Guillaume Klein,38367242.0,Yoon Kim,2505751.0,Yuntian Deng,,94051097.0,Vincent Nguyen,3053934.0,Jean Senellart,2531268.0,Alexander M. Rush,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1c6c0d39d377a465834ed608ae23f48a79ab8eac,https://www.semanticscholar.org/paper/1c6c0d39d377a465834ed608ae23f48a79ab8eac,A Very Brief Introduction to Machine Learning With Applications to Communication Systems,"Given the unprecedented availability of data and computing resources, there is widespread renewed interest in applying data-driven machine learning methods to problems for which the development of conventional engineering solutions is challenged by modeling or algorithmic deficiencies. This tutorial-style paper starts by addressing the questions of why and when such techniques can be useful. It then provides a high-level introduction to the basics of supervised and unsupervised learning. For both supervised and unsupervised learning, exemplifying applications to communication networks are discussed by distinguishing tasks carried out at the edge and at the cloud segments of the network at different layers of the protocol stack, with an emphasis on the physical layer.",2018,82,285,16,True,Computer Science,1705869,O. Simeone,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8a3d0bdb9f3b7ec2ce8ede1307cc246150e4ad48,https://www.semanticscholar.org/paper/8a3d0bdb9f3b7ec2ce8ede1307cc246150e4ad48,Statistical Machine Learning Makes Automatic Control Practical for Internet Datacenters,"Horizontally-scalable Internet services on clusters of commodity computers appear to be a great fit for automatic control: there is a target output (service-level agreement), observed output (actual latency), and gain controller (adjusting the number of servers). Yet few datacenters are automated this way in practice, due in part to well-founded skepticism about whether the simple models often used in the research literature can capture complex real-life workload/performance relationships and keep up with changing conditions that might invalidate the models. We argue that these shortcomings can be fixed by importing modeling, control, and analysis techniques from statistics and machine learning. In particular, we apply rich statistical models of the application's performance, simulation-based methods for finding an optimal control policy, and change-point methods to find abrupt changes in performance. Preliminary results running aWeb 2.0 benchmark application driven by real workload traces on Amazon's EC2 cloud show that our method can effectively control the number of servers, even in the face of performance anomalies.",2009,12,235,9,False,Computer Science,1775084,P. Bodík,50331526.0,R. Griffith,37210858.0,Charles Sutton,,143608596.0,A. Fox,1694621.0,Michael I. Jordan,1701130.0,D. Patterson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1f6b9766374d14d81c225c2ced5bb02fe0bccd43,https://www.semanticscholar.org/paper/1f6b9766374d14d81c225c2ced5bb02fe0bccd43,The What-If Tool: Interactive Probing of Machine Learning Models,"A key challenge in developing and deploying Machine Learning (ML) systems is understanding their performance across a wide range of inputs. To address this challenge, we created the What-If Tool, an open-source application that allows practitioners to probe, visualize, and analyze ML systems, with minimal coding. The What-If Tool lets practitioners test performance in hypothetical situations, analyze the importance of different data features, and visualize model behavior across multiple models and subsets of input data. It also lets practitioners measure systems according to multiple ML fairness metrics. We describe the design of the tool, and report on real-life usage at different organizations.",2019,30,225,14,True,Medicine,49556437,James Wexler,51478016.0,Mahima Pushkarna,2843215.0,Tolga Bolukbasi,Computer Science,145233583.0,M. Wattenberg,1765169.0,F. Viégas,2109357255.0,Jimbo Wilson,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68c4749d9d3f1724aa01778d69a3774c732ca44c,https://www.semanticscholar.org/paper/68c4749d9d3f1724aa01778d69a3774c732ca44c,Support Vector Machines: Training and Applications,"The Support Vector Machine (SVM) is a new and very promising classification technique developed by Vapnik and his group at AT\&T Bell Labs. This new learning algorithm can be seen as an alternative training technique for Polynomial, Radial Basis Function and Multi-Layer Perceptron classifiers. An interesting property of this approach is that it is an approximate implementation of the Structural Risk Minimization (SRM) induction principle. The derivation of Support Vector Machines, its relationship with SRM, and its geometrical insight, are discussed in this paper. Training a SVM is equivalent to solve a quadratic programming problem with linear and box constraints in a number of variables equal to the number of data points. When the number of data points exceeds few thousands the problem is very challenging, because the quadratic form is completely dense, so the memory needed to store the problem grows with the square of the number of data points. Therefore, training problems arising in some real applications with large data sets are impossible to load into memory, and cannot be solved using standard non-linear constrained optimization algorithms. We present a decomposition algorithm that can be used to train SVM''s over large data sets. The main idea behind the decomposition is the iterative solution of sub-problems and the evaluation of, and also establish the stopping criteria for the algorithm. We present previous approaches, as well as results and important details of our implementation of the algorithm using a second-order variant of the Reduced Gradient Method as the solver of the sub-problems. As an application of SVM''s, we present preliminary results we obtained applying SVM to the problem of detecting frontal human faces in real images.",1997,25,852,68,False,Computer Science,1781874,E. Osuna,1771659.0,R. Freund,1804489.0,F. Girosi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aa78234335188b27bf7369ae18dfac453359af9e,https://www.semanticscholar.org/paper/aa78234335188b27bf7369ae18dfac453359af9e,Applying the Waek Learning Framework to Understand and Improve C4.5,"There has long been a chasm between theoretical models of machine learning and practical machine learning algorithms. For instance, empirically successful algorithms such as C4:5 and backpropagation have not met the criteria of the PAC model and its variants. Conversely, the algorithms suggested by computational learning theory are usually too limited in various ways to nd wide application. The theoretical status of decision tree learning algorithms is a case in point: while it has been proven that C4:5 (and all reasonable variants of it) fails to meet the PAC model criteria [2], other recently proposed decision tree algorithms that do have non-trivial performance guarantees unfortunately require membership queries [6, 13]. Two recent developments have narrowed this gap between theory and practice|not for the PAC model, but for the related model known as weak learning or boosting . First, an algorithm called Adaboost was proposed that meets the formal criteria of the boosting model and is also competitive in practice [10]. Second, the basic algorithms underlying the popular C4:5 and CART programs have also very recently been shown to meet the formal criteria of the boosting model [12]. Thus, it seems plausible that the weak learning framework may provide a setting for interaction between formal analysis and machine learning practice that is lacking in other theoretical models. Our aim in this paper is to push this interaction further in light of these recent developments. In particular, we perform experiments suggested by the formal results for Adaboost and C4:5 within the weak learning framework. We concentrate on two particularly intriguing issues. First, the theoretical boosting results for top-down decision tree algorithms such as C4:5 [12] suggest that a new splitting criterion may result in trees that are smaller and more accurate than those obtained using the usual information gain. We con rm this suggestion experimentally. Second, a super cial interpretation of the theoretical results suggests that Adaboost should vastly outperform C4:5. This is not the case in practice, and we argue through experimental results that the theory must be understood in terms of a measure of a boosting algorithm's behavior called its advantage sequence. We compare the advantage sequences for C4:5 and Adaboost in a number of experiments. We nd that these sequences have qualitatively different behavior that explains in large part the discrepancies between empirical performance and the theoretical results. Brie y, we nd that although C4:5 and Adaboost are both boosting algorithms, Adaboost creates successively \harder"" ltered distributions, while C4:5 creates successively \easier"" ones, in a sense that will be made precise.",1996,19,114,3,False,Computer Science,144299726,Thomas G. Dietterich,2056642528.0,M. Kearns,144830983.0,Y. Mansour,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aae4d93d5d356b858418e360a9d72257f2bb35a5,https://www.semanticscholar.org/paper/aae4d93d5d356b858418e360a9d72257f2bb35a5,Monotonic Calibrated Interpolated Look-Up Tables,"Real-world machine learning applications may have requirements beyond accuracy, such as fast evaluation times and interpretability. In particular, guaranteed monotonicity of the learned function with respect to some of the inputs can be critical for user confidence. We propose meeting these goals for low-dimensional machine learning problems by learning flexible, monotonic functions using calibrated interpolated look-up tables. We extend the structural risk minimization framework of lattice regression to monotonic functions by adding linear inequality constraints. In addition, we propose jointly learning interpretable calibrations of each feature to normalize continuous features and handle categorical or missing data, at the cost of making the objective non-convex. We address large-scale learning through parallelization, mini-batching, and random sampling of additive regularizer terms. Case studies on real-world problems with up to sixteen features and up to hundreds of millions of training samples demonstrate the proposed monotonic functions can achieve state-of-the-art accuracy in practice while providing greater transparency to users.",2015,78,101,3,False,Computer Science,2109834931,Maya R. Gupta,145658292.0,Andrew Cotter,5479080.0,Jan Pfeifer,Mathematics,2963586.0,Konstantin Voevodski,2963430.0,K. Canini,1388838667.0,Alexander Mangylov,1388838647.0,Wojtek Moczydlowski,2529823.0,A. V. Esbroeck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b51d606db06e178c5dff1e9d8c1460352bdb85db,https://www.semanticscholar.org/paper/b51d606db06e178c5dff1e9d8c1460352bdb85db,Recovering 3D human pose from monocular images,"We describe a learning-based method for recovering 3D human body pose from single images and monocular image sequences. Our approach requires neither an explicit body model nor prior labeling of body parts in the image. Instead, it recovers pose by direct nonlinear regression against shape descriptor vectors extracted automatically from image silhouettes. For robustness against local silhouette segmentation errors, silhouette shape is encoded by histogram-of-shape-contexts descriptors. We evaluate several different regression methods: ridge regression, relevance vector machine (RVM) regression, and support vector machine (SVM) regression over both linear and kernel bases. The RVMs provide much sparser regressors without compromising performance, and kernel bases give a small but worthwhile improvement in performance. The loss of depth and limb labeling information often makes the recovery of 3D pose from single silhouettes ambiguous. To handle this, the method is embedded in a novel regressive tracking framework, using dynamics from the previous state estimate together with a learned regression value to disambiguate the pose. We show that the resulting system tracks long sequences stably. For realism and good generalization over a wide range of viewpoints, we train the regressors on images resynthesized from real human motion capture data. The method is demonstrated for several representations of full body pose, both quantitatively on independent but similar test data and qualitatively on real image sequences. Mean angular errors of 4-6/spl deg/ are obtained for a variety of walking motions.",2006,41,843,89,True,Medicine,145984136,A. Agarwal,1756114.0,B. Triggs,,,Computer Science,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b5b98051b65da6b1b3b579862b0407d48c5bef48,https://www.semanticscholar.org/paper/b5b98051b65da6b1b3b579862b0407d48c5bef48,Principles and Practice of Explainable Machine Learning,"Artificial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and finance. However, such a highly positive impact is coupled with a significant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus specifically on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-specific biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the field of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-specific or model-agnostic post-hoc explainability approaches. We also briefly reflect on deep learning models, and conclude with a discussion about future research directions.",2020,120,124,15,True,Medicine,144893617,Vaishak Belle,40911590.0,I. Papantonis,,,Computer Science,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ca20f8146adf21294f048121f234c449299ef67e,https://www.semanticscholar.org/paper/ca20f8146adf21294f048121f234c449299ef67e,Combining Multiple Knowledge Sources for Discourse Segmentation,"We predict discourse segment boundaries from linguistic features of utterances, using a corpus of spoken narratives as data. We present two methods for developing segmentation algorithms from training data: hand tuning and machine learning. When multiple types of features are used, results approach human performance on an independent test set (both methods), and using cross-validation (machine learning).",1995,59,137,4,True,Computer Science,1737616,D. Litman,1703046.0,R. Passonneau,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
814b9ca695a861dea036ae62a56d2d31dcbcb57b,https://www.semanticscholar.org/paper/814b9ca695a861dea036ae62a56d2d31dcbcb57b,ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies,"The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.",2018,13,34,4,False,Computer Science,3489323,G. Publio,145538480.0,Diego Esteves,1975411.0,Agnieszka Lawrynowicz,Mathematics,145066785.0,P. Panov,3284305.0,L. Soldatova,1869895.0,Tommaso Soru,1717534.0,J. Vanschoren,46195484.0,Hamid Zafar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c8687ca5543bf32a9718627df5cd0fcabaacc61c,https://www.semanticscholar.org/paper/c8687ca5543bf32a9718627df5cd0fcabaacc61c,The stages of event extraction,"Event detection and recognition is a complex task consisting of multiple sub-tasks of varying difficulty. In this paper, we present a simple, modular approach to event extraction that allows us to experiment with a variety of machine learning methods for these sub-tasks, as well as to evaluate the impact on performance these sub-tasks have on the overall task.",2006,11,456,30,True,Computer Science,145079003,David Ahn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8feebb6e160539e3d114ce0b1c851b6f938aa4a9,https://www.semanticscholar.org/paper/8feebb6e160539e3d114ce0b1c851b6f938aa4a9,Dynamically Adapting Kernels in Support Vector Machines,"The kernel-parameter is one of the few tunable parameters in Support Vector machines, controlling the complexity of the resulting hypothesis. Its choice amounts to model selection and its value is usually found by means of a validation set. We present an algorithm which can automatically perform model selection with little additional computational cost and with no need of a validation set. In this procedure model selection and learning are not separate, but kernels are dynamically adjusted during the learning process to find the kernel parameter which provides the best possible upper bound on the generalisation error. Theoretical results motivating the approach and experimental results confirming its validity are presented.",1998,12,187,11,False,Computer Science,1685083,N. Cristianini,145990261.0,C. Campbell,1404459229.0,J. Shawe-Taylor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dc133144d431fc3b75c8de27f6bb21da6eb5bc1b,https://www.semanticscholar.org/paper/dc133144d431fc3b75c8de27f6bb21da6eb5bc1b,Knowledge-based recommender systems,"1. Introduction Recommender systems provide advice to users about items they might wish to purchase or examine. Recommendations made by such systems can help users navigate through large information spaces of product descriptions, news articles or other items. As on-line information and e-commerce burgeon, recommender systems are an increasingly important tool. A recent survey of recommender systems is found in The most well known type of recommender system is the collaborative-or social-filtering type. These systems aggregate data about customers' purchasing habits or preferences, and make recommendations to other users based on similarity in overall purchasing patterns. For example, in the Ringo music recommender system (Shardanand & Maes, 1995), users express their musical preferences by rating various artists and albums, and get suggestions of groups and recordings that others with similar preferences also liked. Content-based recommender systems are classifier systems derived from machine learning research. For example, the NewsDude news filtering system is a recommender system that suggests news stories the user might like to read (Billsus & Pazzani, 1999). These systems use supervised machine learning to induce a classifier that can discriminate between items likely to be of interest to the user and those likely to be uninteresting. A third type of recommender system is one that uses knowledge about users and products to pursue a knowledge-based approach to generating a recommendation, reasoning about what products meet the user's requirements. The PersonalLogic recom-mender system offers a dialog that effectively walks the user down a discrimination tree of product features.",2000,28,884,58,False,Computer Science,1747150,R. Burke,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5259755f9c100e220ffaa7e08439c5d34be7757a,https://www.semanticscholar.org/paper/5259755f9c100e220ffaa7e08439c5d34be7757a,Reinforcement Learning Neural Turing Machines - Revised,"The Neural Turing Machine (NTM) is more expressive than all previously considered models because of its external memory. It can be viewed as a broader effort to use abstract external Interfaces and to learn a parametric model that interacts with them. The capabilities of a model can be extended by providing it with proper Interfaces that interact with the world. These external Interfaces include memory, a database, a search engine, or a piece of software such as a theorem verifier. Some of these Interfaces are provided by the developers of the model. However, many important existing Interfaces, such as databases and search engines, are discrete. We examine feasibility of learning models to interact with discrete Interfaces. We investigate the following discrete Interfaces: a memory Tape, an input Tape, and an output Tape. We use a Reinforcement Learning algorithm to train a neural network that interacts with such Interfaces to solve simple algorithmic tasks. Our Interfaces are expressive enough to make our model Turing complete.",2015,25,153,6,False,Computer Science,2563432,Wojciech Zaremba,1701686.0,Ilya Sutskever,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5308b875bc34cd1c22a0df401dcfe38bd819eca2,https://www.semanticscholar.org/paper/5308b875bc34cd1c22a0df401dcfe38bd819eca2,Machine Learning for Outcome Prediction of Acute Ischemic Stroke Post Intra-Arterial Therapy,"Introduction Stroke is a major cause of death and disability. Accurately predicting stroke outcome from a set of predictive variables may identify high-risk patients and guide treatment approaches, leading to decreased morbidity. Logistic regression models allow for the identification and validation of predictive variables. However, advanced machine learning algorithms offer an alternative, in particular, for large-scale multi-institutional data, with the advantage of easily incorporating newly available data to improve prediction performance. Our aim was to design and compare different machine learning methods, capable of predicting the outcome of endovascular intervention in acute anterior circulation ischaemic stroke. Method We conducted a retrospective study of a prospectively collected database of acute ischaemic stroke treated by endovascular intervention. Using SPSS®, MATLAB®, and Rapidminer®, classical statistics as well as artificial neural network and support vector algorithms were applied to design a supervised machine capable of classifying these predictors into potential good and poor outcomes. These algorithms were trained, validated and tested using randomly divided data. Results We included 107 consecutive acute anterior circulation ischaemic stroke patients treated by endovascular technique. Sixty-six were male and the mean age of 65.3. All the available demographic, procedural and clinical factors were included into the models. The final confusion matrix of the neural network, demonstrated an overall congruency of ∼80% between the target and output classes, with favourable receiving operative characteristics. However, after optimisation, the support vector machine had a relatively better performance, with a root mean squared error of 2.064 (SD: ±0.408). Discussion We showed promising accuracy of outcome prediction, using supervised machine learning algorithms, with potential for incorporation of larger multicenter datasets, likely further improving prediction. Finally, we propose that a robust machine learning system can potentially optimise the selection process for endovascular versus medical treatment in the management of acute stroke.",2014,83,154,5,True,Medicine,145625751,H. Asadi,49990937.0,R. Dowling,143673762.0,B. Yan,,34880338.0,P. Mitchell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11ce07e200882977f8e27bbda7842d7925ed6f48,https://www.semanticscholar.org/paper/11ce07e200882977f8e27bbda7842d7925ed6f48,Preliminary Study on Wilcoxon Learning Machines,"As is well known in statistics, the resulting linear regressors by using the rank-based Wilcoxon approach to linear regression problems are usually robust against (or insensitive to) outliers. This motivates us to introduce in this paper the Wilcoxon approach to the area of machine learning. Specifically, we investigate four new learning machines, namely Wilcoxon neural network (WNN), Wilcoxon generalized radial basis function network (WGRBFN), Wilcoxon fuzzy neural network (WFNN), and kernel-based Wilcoxon regressor (KWR). These provide alternative learning machines when faced with general nonlinear learning problems. Simple weights updating rules based on gradient descent will be derived. Some numerical examples will be provided to compare the robustness against outliers for various learning machines. Simulation results show that the Wilcoxon learning machines proposed in this paper have good robustness against outliers. We firmly believe that the Wilcoxon approach will provide a promising methodology for many machine learning problems.",2008,29,73,4,False,Mathematics,2290180,J. Hsieh,34441450.0,Yih-Lon Lin,3328556.0,J. Jeng,Medicine,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d318c093cb450233dddef5e52833c9371860dc29,https://www.semanticscholar.org/paper/d318c093cb450233dddef5e52833c9371860dc29,Locally Weighted Naive Bayes,"Despite its simplicity, the naive Bayes classifier has surprised machine learning researchers by exhibiting good performance on a variety of learning problems. Encouraged by these results, researchers have looked to overcome naive Bayes' primary weakness-attribute independence-and improve the performance of the algorithm. This paper presents a locally weighted version of naive Bayes that relaxes the independence assumption by learning local models at prediction time. Experimental results show that locally weighted naive Bayes rarely degrades accuracy compared to standard naive Bayes and, in many cases, improves accuracy dramatically. The main advantage of this method compared to other techniques for enhancing naive Bayes is its conceptual and computational simplicity.",2002,20,351,32,False,Computer Science,143713826,Eibe Frank,118860642.0,M. Hall,1737420.0,B. Pfahringer,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
470966e6967c1a0932fa388c7ff7e7b07875aacd,https://www.semanticscholar.org/paper/470966e6967c1a0932fa388c7ff7e7b07875aacd,"Machine Learning for Information Retrieval: Neural Networks, Symbolic Learning, and Genetic Algorithms","Information retrieval using probabilistic techniques has attracted significant attention on the part of researchers in information and computer science over the past few decades. In the 1980s, knowledge-based techniques also made an impressive contribution to “intelligent” information retrieval and indexing. More recently, information science researchers have turned to other newer artificial-intelligence-based inductive learning techniques including neural networks, symbolic learning, and genetic algorithms. These newer techniques, which are grounded on diverse paradigms, have provided great opportunities for researchers to enhance the information processing and retrieval capabilities of current information storage and retrieval systems. In this article, we first provide an overview of these newer techniques and their use in information science research. To familiarize readers with these techniques, we present three popular methods: the connectionist Hopfield network; the symbolic ID3/ID5R; and evolution-based genetic algorithms. We discuss their knowledge representations and algorithms in the context of information retrieval. Sample implementation and testing results from our own research are also provided for each technique. We believe these techniques are promising in their ability to analyze user queries, identify users' information needs, and suggest alternatives for search. With proper user-system interactions, these methods can greatly complement the prevailing full-text, keyword-based, probabilistic, and knowledge-based techniques. © 1995 John Wiley & Sons, Inc.",1995,112,306,20,True,Computer Science,47666658,Hsinchun Chen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
878783964ab23c97052ea82685368099d85c500d,https://www.semanticscholar.org/paper/878783964ab23c97052ea82685368099d85c500d,A Comparison of Algorithms for Maximum Entropy Parameter Estimation,"Conditional maximum entropy (ME) models provide a general purpose machine learning technique which has been successfully applied to fields as diverse as computer vision and econometrics, and which is used for a wide variety of classification problems in natural language processing. However, the flexibility of ME models is not without cost. While parameter estimation for ME models is conceptually straightforward, in practice ME models for typical natural language tasks are very large, and may well contain many thousands of free parameters. In this paper, we consider a number of algorithms for estimating the parameters of ME models, including iterative scaling, gradient ascent, conjugate gradient, and variable metric methods. Sur-prisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, a limited-memory variable metric algorithm outperformed the other choices.",2002,39,759,50,True,Computer Science,145804005,Robert Malouf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7f002c2059f0714b5423f084913e54a50fe1ac58,https://www.semanticscholar.org/paper/7f002c2059f0714b5423f084913e54a50fe1ac58,Deep learning for electroencephalogram (EEG) classification tasks: a review,"Objective. Electroencephalography (EEG) analysis has been an important tool in neuroscience with applications in neuroscience, neural engineering (e.g. Brain–computer interfaces, BCI’s), and even commercial applications. Many of the analytical tools used in EEG studies have used machine learning to uncover relevant information for neural classification and neuroimaging. Recently, the availability of large EEG data sets and advances in machine learning have both led to the deployment of deep learning architectures, especially in the analysis of EEG signals and in understanding the information it may contain for brain functionality. The robust automatic classification of these signals is an important step towards making the use of EEG more practical in many applications and less reliant on trained professionals. Towards this goal, a systematic review of the literature on deep learning applications to EEG classification was performed to address the following critical questions: (1) Which EEG classification tasks have been explored with deep learning? (2) What input formulations have been used for training the deep networks? (3) Are there specific deep learning network structures suitable for specific types of tasks? Approach. A systematic literature review of EEG classification using deep learning was performed on Web of Science and PubMed databases, resulting in 90 identified studies. Those studies were analyzed based on type of task, EEG preprocessing methods, input type, and deep learning architecture. Main results. For EEG classification tasks, convolutional neural networks, recurrent neural networks, deep belief networks outperform stacked auto-encoders and multi-layer perceptron neural networks in classification accuracy. The tasks that used deep learning fell into five general groups: emotion recognition, motor imagery, mental workload, seizure detection, event related potential detection, and sleep scoring. For each type of task, we describe the specific input formulation, major characteristics, and end classifier recommendations found through this review. Significance. This review summarizes the current practices and performance outcomes in the use of deep learning for EEG classification. Practical suggestions on the selection of many hyperparameters are provided in the hope that they will promote or guide the deployment of deep learning to EEG datasets in future research.",2019,187,527,30,False,Physics,1411706241,Alexander Craik,2517432.0,Yongtian He,1398582662.0,J. Contreras-Vidal,Medicine,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,
adc61e21eafecfbf6ebecc570f9f913659a2bfb2,https://www.semanticscholar.org/paper/adc61e21eafecfbf6ebecc570f9f913659a2bfb2,Deep Learning Based Text Classification: A Comprehensive Review,"Deep learning basedmodels have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions. Additional",2021,226,297,15,False,,2164604,Shervin Minaee,49943757.0,E. Cambria,48441311.0,Jianfeng Gao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cfd4259d305a00f13d5f08841230389f61322422,https://www.semanticscholar.org/paper/cfd4259d305a00f13d5f08841230389f61322422,Optimizing search engines using clickthrough data,"This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.",2002,31,4391,688,False,Computer Science,1680188,T. Joachims,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2698bdb4673caa10e0f5eece28ae80393c5ff94f,https://www.semanticscholar.org/paper/2698bdb4673caa10e0f5eece28ae80393c5ff94f,Collaborative Writing Support Tools on the Cloud,"Academic writing, individual or collaborative, is an essential skill for today's graduates. Unfortunately, managing writing activities and providing feedback to students is very labor intensive and academics often opt out of including such learning experiences in their teaching. We describe the architecture for a new collaborative writing support environment used to embed such collaborative learning activities in engineering courses. iWrite provides tools for managing collaborative and individual writing assignments in large cohorts. It outsources the writing tools and the storage of student content to third party cloud-computing vendors (i.e., Google). We further describe how using machine learning and NLP techniques, the architecture provides automated feedback, automatic question generation, and process analysis features.",2011,46,128,3,False,Computer Science,144792845,R. Calvo,2073202565.0,Stephen T. O'Rourke,145869583.0,Janet Jones,,1763220.0,K. Yacef,20779579.0,P. Reimann,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7f0d3991feb75f6f2fd50d0f2f80d820f20054cc,https://www.semanticscholar.org/paper/7f0d3991feb75f6f2fd50d0f2f80d820f20054cc,"ZipML: Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning","Recently there has been significant interest in training machine-learning models at low precision: by reducing precision, one can reduce computation and communication by one order of magnitude. We examine training at reduced precision, both from a theoretical and practical perspective, and ask: is it possible to train models at end-to-end low precision with provable guarantees? Can this lead to consistent order-ofmagnitude speedups? We mainly focus on linear models, and the answer is yes for linear models. We develop a simple framework called ZipML based on one simple but novel strategy called double sampling. Our ZipML framework is able to execute training at low precision with no bias, guaranteeing convergence, whereas naive quantization would introduce significant bias. We validate our framework across a range of applications, and show that it enables an FPGA prototype that is up to 6.5× faster than an implementation using full 32-bit precision. We further develop a variance-optimal stochastic quantization strategy and show that it can make a significant difference in a variety of settings. When applied to linear models together with double sampling, we save up to another 1.7× in data movement compared with uniform quantization. When training deep networks with quantized models, we achieve higher accuracy than the state-of-theart XNOR-Net. ETH Zurich, Switzerland Massachusetts Institute of Technology, USA IST Austria, Austria University of Rochester, USA. Correspondence to: Hantian Zhang <hantian.zhang@inf.ethz.ch>, Ce Zhang <ce.zhang@inf.ethz.ch>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). (a) Linear Regression (c) 3D Reconstruction 32Bit 12Bit (b) FPGA Speed Up (d) Deep Learning Machine Learning Models Data Movement Channels Speed up because of our techniques Gradient Input Samples Model Linear Models De Sa et la., Alistarh et al., ... 1. Double Sampling 2. Data-Optimal Encoding Stochastic Rounding Very Significant Speed up (Up to 10x) Deep Learning Courbariaux et al., Rastegari et al., ... Data-Optimal Encoding Significant Speed up 0 25 50 75 100 32-bit Full Precision Double Sampling 4-bit #Epochs Tr ai ni ng L os s #Epochs (a) Linear Regression (b) LS-SVM 0 25 50 75 100 .3",2017,24,154,10,False,Computer Science,2016429687,Hantian Zhang,2800851.0,Jerry Li,34680313.0,Kaan Kara,,3311387.0,Dan Alistarh,40478933.0,Ji Liu,1776014.0,Ce Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c7baa5d9d6e244586eb90929526fa7d4589d8ed2,https://www.semanticscholar.org/paper/c7baa5d9d6e244586eb90929526fa7d4589d8ed2,Probabilistic Graphical Models: Principles and Techniques - Adaptive Computation and Machine Learning,"Most tasks require a person or an automated system to reasonto reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss empirical cases related to the approach described in the text, including applications in computer vision, robotics, natural language understanding, and computational biology; and concept boxes, which present significant concepts drawn from the material in the chapter. Instructors (and readers) can group chapters in various combinations, from core topics to more technically advanced material, to suit their particular needs. Adaptive Computation and Machine Learning series",2009,0,624,73,False,Computer Science,1736370,D. Koller,50785579.0,N. Friedman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8fb1b96dcc133b170e7e5b340f93c5f230d495ee,https://www.semanticscholar.org/paper/8fb1b96dcc133b170e7e5b340f93c5f230d495ee,A streaming ensemble algorithm (SEA) for large-scale classification,"Ensemble methods have recently garnered a great deal of attention in the machine learning community. Techniques such as Boosting and Bagging have proven to be highly effective but require repeated resampling of the training data, making them inappropriate in a data mining context. The methods presented in this paper take advantage of plentiful data, building separate classifiers on sequential chunks of training points. These classifiers are combined into a fixed-size ensemble using a heuristic replacement strategy. The result is a fast algorithm for large-scale or streaming data that classifies as well as a single decision tree built on all the data, requires approximately constant memory, and adjusts quickly to concept drift.",2001,21,1184,166,False,Computer Science,2562282,W. N. Street,2117912702.0,YongSeog Kim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dd20272cba91c5a47bfd54a9d716a51acd28195f,https://www.semanticscholar.org/paper/dd20272cba91c5a47bfd54a9d716a51acd28195f,Machine Learning at Central Banks,"We introduce machine learning in the context of central banking and policy analyses. Our aim is to give an overview broad enough to allow the reader to place machine learning within the wider range of statistical modelling and computational analyses, and provide an idea of its scope and limitations. We review the underlying technical sources and the nascent literature applying machine learning to economic and policy problems. We present popular modelling approaches, such as artificial neural networks, tree-based models, support vector machines, recommender systems and different clustering techniques. Important concepts like the bias-variance trade-off, optimal model complexity, regularisation and cross-validation are discussed to enrich the econometrics toolbox in their own right. We present three case studies relevant to central bank policy, financial regulation and economic modelling more widely. First, we model the detection of alerts on the balance sheets of financial institutions in the context of banking supervision. Second, we perform a projection exercise for UK CPI inflation on a medium-term horizon of two years. Here, we introduce a simple training-testing framework for time series analyses. Third, we investigate the funding patterns of technology start-ups with the aim to detect potentially disruptive innovators in financial technology. Machine learning models generally outperform traditional modelling approaches in prediction tasks, while open research questions remain with regard to their causal inference properties.",2017,0,80,5,False,Economics,3000889,Chiranjit Chakraborty,47476153.0,Andreas Joseph,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e838ba98e198d2dac047736e77c50c0efa49c2dc,https://www.semanticscholar.org/paper/e838ba98e198d2dac047736e77c50c0efa49c2dc,Data augmentation for improving deep learning in image classification problem,"These days deep learning is the fastest-growing field in the field of Machine Learning (ML) and Deep Neural Networks (DNN). Among many of DNN structures, the Convolutional Neural Networks (CNN) are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is the lack of sufficient amount of the training data or uneven class balance within the datasets. One of the ways of dealing with this problem is so called data augmentation. In the paper we have compared and analyzed multiple methods of data augmentation in the task of image classification, starting from classical image transformations like rotating, cropping, zooming, histogram based methods and finishing at Style Transfer and Generative Adversarial Networks, along with the representative examples. Next, we presented our own method of data augmentation based on image style transfer. The method allows to generate the new images of high perceptual quality that combine the content of a base image with the appearance of another ones. The newly created images can be used to pre-train the given neural network in order to improve the training process efficiency. Proposed method is validated on the three medical case studies: skin melanomas diagnosis, histopathological images and breast magnetic resonance imaging (MRI) scans analysis, utilizing the image classification in order to provide a diagnose. In such kind of problems the data deficiency is one of the most relevant issues. Finally, we discuss the advantages and disadvantages of the methods being analyzed.",2018,45,694,11,False,Computer Science,32920239,Agnieszka Mikołajczyk,31820684.0,M. Grochowski,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f2f0b32444bbb41d198a54e6aeea109c81691f27,https://www.semanticscholar.org/paper/f2f0b32444bbb41d198a54e6aeea109c81691f27,Machine learning - applications in expert systems and information retrieval,"Thank you very much for downloading machine learning applications in expert systems and information retrieval. Maybe you have knowledge that, people have look numerous times for their chosen books like this machine learning applications in expert systems and information retrieval, but end up in malicious downloads. Rather than enjoying a good book with a cup of tea in the afternoon, instead they cope with some malicious bugs inside their computer.",1986,0,123,4,False,Computer Science,25294406,R. Forsyth,1766712.0,R. Rada,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
561c6977d57d33990e4ff840570658d495d37373,https://www.semanticscholar.org/paper/561c6977d57d33990e4ff840570658d495d37373,Seismic facies analysis using machine learning,"Seismic interpretations are, by definition, subjective and often require significant time and expertise from the interpreter. We are convinced that machine-learning techniques can help address these problems by performing seismic facies analyses in a rigorous, repeatable way. For this purpose, we use state-of-the-art 3D broadband seismic reflection data of the northern North Sea. Our workflow includes five basic steps. First, we extract seismic attributes to highlight features in the data. Second, we perform a manual seismic facies classification on 10,000 examples. Third, we use some of these examples to train a range of models to predict seismic facies. Fourth, we analyze the performance of these models on the remaining examples. Fifth, we select the “best” model (i.e., highest accuracy) and apply it to a seismic section. As such, we highlight that machine-learning techniques can increase the efficiency of seismic facies analyses.",2018,68,112,0,False,Geology,46282847,T. Wrona,2316212.0,I. Pan,71764416.0,R. Gawthorpe,,28974766.0,H. Fossen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bcdc102c04fb0e7d4652e8bcc7edd2983bb9576d,https://www.semanticscholar.org/paper/bcdc102c04fb0e7d4652e8bcc7edd2983bb9576d,VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text,"The inherent nature of social media content poses serious challenges to practical applications of sentiment analysis. We present VADER, a simple rule-based model for general sentiment analysis, and compare its effectiveness to eleven typical state-of-practice benchmarks including LIWC, ANEW, the General Inquirer, SentiWordNet, and machine learning oriented techniques relying on Naive Bayes, Maximum Entropy, and Support Vector Machine (SVM) algorithms. Using a combination of qualitative and quantitative methods, we first construct and empirically validate a gold-standard list of lexical features (along with their associated sentiment intensity measures) which are specifically attuned to sentiment in microblog-like contexts. We then combine these lexical features with consideration for five general rules that embody grammatical and syntactical conventions for expressing and emphasizing sentiment intensity. Interestingly, using our parsimonious rule-based model to assess the sentiment of tweets, we find that VADER outperforms individual human raters (F1 Classification Accuracy = 0.96 and 0.84, respectively), and generalizes more favorably across contexts than any of our benchmarks.",2014,39,2646,400,True,Computer Science,40320059,C. Hutto,145280613.0,Eric Gilbert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
872cdc269f3cb59f8a227818f35041415091545f,https://www.semanticscholar.org/paper/872cdc269f3cb59f8a227818f35041415091545f,Learning and Extracting Finite State Automata with Second-Order Recurrent Neural Networks,"We show that a recurrent, second-order neural network using a real-time, forward training algorithm readily learns to infer small regular grammars from positive and negative string training samples. We present simulations that show the effect of initial conditions, training set size and order, and neural network architecture. All simulations were performed with random initial weight strengths and usually converge after approximately a hundred epochs of training. We discuss a quantization algorithm for dynamically extracting finite state automata during and after training. For a well-trained neural net, the extracted automata constitute an equivalence class of state machines that are reducible to the minimal machine of the inferred grammar. We then show through simulations that many of the neural net state machines are dynamically stable, that is, they correctly classify many long unseen strings. In addition, some of these extracted automata actually outperform the trained neural network for classification of unseen strings.",1992,25,491,44,False,Computer Science,145157784,C. Lee Giles,153170210.0,Clifford B. Miller,2158193072.0,Dong Chen,,2115401300.0,Hsing-Hen Chen,34922532.0,Guo-Zheng Sun,2552960.0,Yee-Chun Lee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0bf71f7b1fa5f95b50d27e3583c81ffe7178e58c,https://www.semanticscholar.org/paper/0bf71f7b1fa5f95b50d27e3583c81ffe7178e58c,The Optimality of Naive Bayes,"Naive Bayes is one of the most efficient and effective inductive learning algorithms for machine learning and data mining. Its competitive performance in classification is surprising, because the conditional independence assumption on which it is based, is rarely true in realworld applications. An open question is: what is the true reason for the surprisingly good performance of naive Bayes in classification? In this paper, we propose a novel explanation on the superb classification performance of naive Bayes. We show that, essentially, the dependence distribution; i.e., how the local dependence of a node distributes in each class, evenly or unevenly, and how the local dependencies of all nodes work together, consistently (supporting a certain classification) or inconsistently (canceling each other out), plays a crucial role. Therefore, no matter how strong the dependences among attributes are, naive Bayes can still be optimal if the dependences distribute evenly in classes, or if the dependences cancel each other out. We propose and prove a sufficient and necessary conditions for the optimality of naive Bayes. Further, we investigate the optimality of naive Bayes under the Gaussian distribution. We present and prove a sufficient condition for the optimality of naive Bayes, in which the dependence between attributes do exist. This provides evidence that dependence among attributes may cancel out each other. In addition, we explore when naive Bayes works well. Naive Bayes and Augmented Naive Bayes Classification is a fundamental issue in machine learning and data mining. In classification, the goal of a learning algorithm is to construct a classifier given a set of training examples with class labels. Typically, an example E is represented by a tuple of attribute values (x1, x2, , · · · , xn), where xi is the value of attribute Xi. Let C represent the classification variable, and let c be the value of C. In this paper, we assume that there are only two classes: + (the positive class) or − (the negative class). A classifier is a function that assigns a class label to an example. From the probability perspective, according to Bayes Copyright c © 2004, American Association for Artificial Intelligence (www.aaai.org). All rights reserved. Rule, the probability of an example E = (x1, x2, · · · , xn) being class c is p(c|E) = p(E|c)p(c) p(E) . E is classified as the class C = + if and only if fb(E) = p(C = +|E) p(C = −|E) ≥ 1, (1) where fb(E) is called a Bayesian classifier. Assume that all attributes are independent given the value of the class variable; that is, p(E|c) = p(x1, x2, · · · , xn|c) = n ∏",2004,15,1606,97,False,Computer Science,2108544384,Harry Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
acd6de3ac2a3d9449aae51b87fbb03f6f0020954,https://www.semanticscholar.org/paper/acd6de3ac2a3d9449aae51b87fbb03f6f0020954,The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning,"The nascent field of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last several years, three formal definitions of fairness have gained prominence: (1) anti-classification, meaning that protected attributes---like race, gender, and their proxies---are not explicitly used to make decisions; (2) classification parity, meaning that common measures of predictive performance (e.g., false positive and false negative rates) are equal across groups defined by the protected attributes; and (3) calibration, meaning that conditional on risk estimates, outcomes are independent of protected attributes. Here we show that all three of these fairness definitions suffer from significant statistical limitations. Requiring anti-classification or classification parity can, perversely, harm the very groups they were designed to protect; and calibration, though generally desirable, provides little guarantee that decisions are equitable. In contrast to these formal fairness criteria, we argue that it is often preferable to treat similarly risky people similarly, based on the most statistically accurate estimates of risk that one can produce. Such a strategy, while not universally applicable, often aligns well with policy objectives; notably, this strategy will typically violate both anti-classification and classification parity. In practice, it requires significant effort to construct suitable risk estimates. One must carefully define and measure the targets of prediction to avoid retrenching biases in the data. But, importantly, one cannot generally address these difficulties by requiring that algorithms satisfy popular mathematical formalizations of fairness. By highlighting these challenges in the foundation of fair machine learning, we hope to help researchers and practitioners productively advance the area.",2018,88,614,55,False,Computer Science,1403746185,S. Corbett-Davies,143802734.0,Sharad Goel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4b733a188198dbff57cb8bd1ec996044fe272ce5,https://www.semanticscholar.org/paper/4b733a188198dbff57cb8bd1ec996044fe272ce5,Machine Learning in Genomic Medicine: A Review of Computational Problems and Data Sets,"In this paper, we provide an introduction to machine learning tasks that address important problems in genomic medicine. One of the goals of genomic medicine is to determine how variations in the DNA of individuals can affect the risk of different diseases, and to find causal explanations so that targeted therapies can be designed. Here we focus on how machine learning can help to model the relationship between DNA and the quantities of key molecules in the cell, with the premise that these quantities, which we refer to as cell variables, may be associated with disease risks. Modern biology allows high-throughput measurement of many such cell variables, including gene expression, splicing, and proteins binding to nucleic acids, which can all be treated as training targets for predictive models. With the growing availability of large-scale data sets and advanced computational techniques such as deep learning, researchers can help to usher in a new era of effective genomic medicine.",2016,246,192,6,False,Biology,2952761,M. Leung,3203657.0,Andrew Delong,48401711.0,B. Alipanahi,Computer Science,1749650.0,B. Frey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bfdad8066d2b8dff3e9bae43715724813ad5dbc3,https://www.semanticscholar.org/paper/bfdad8066d2b8dff3e9bae43715724813ad5dbc3,Machine Learning in IoT Security: Current Solutions and Future Challenges,"The future Internet of Things (IoT) will have a deep economical, commercial and social impact on our lives. The participating nodes in IoT networks are usually resource-constrained, which makes them luring targets for cyber attacks. In this regard, extensive efforts have been made to address the security and privacy issues in IoT networks primarily through traditional cryptographic approaches. However, the unique characteristics of IoT nodes render the existing solutions insufficient to encompass the entire security spectrum of the IoT networks. Machine Learning (ML) and Deep Learning (DL) techniques, which are able to provide embedded intelligence in the IoT devices and networks, can be leveraged to cope with different security problems. In this paper, we systematically review the security requirements, attack vectors, and the current security solutions for the IoT networks. We then shed light on the gaps in these security solutions that call for ML and DL approaches. Finally, we discuss in detail the existing ML and DL solutions for addressing different security problems in IoT networks. We also discuss several future research directions for ML- and DL-based IoT security.",2019,225,223,10,True,Computer Science,73882549,Fatima Hussain,2225364.0,R. Hussain,1682336.0,Syed Ali Hassan,Mathematics,144158811.0,E. Hossain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ae617017e3c5c962c844c665b2dd6b2dda5ea4b3,https://www.semanticscholar.org/paper/ae617017e3c5c962c844c665b2dd6b2dda5ea4b3,Dimension Reduction With Extreme Learning Machine,"Data may often contain noise or irrelevant information, which negatively affect the generalization capability of machine learning algorithms. The objective of dimension reduction algorithms, such as principal component analysis (PCA), non-negative matrix factorization (NMF), random projection (RP), and auto-encoder (AE), is to reduce the noise or irrelevant information of the data. The features of PCA (eigenvectors) and linear AE are not able to represent data as parts (e.g. nose in a face image). On the other hand, NMF and non-linear AE are maimed by slow learning speed and RP only represents a subspace of original data. This paper introduces a dimension reduction framework which to some extend represents data as parts, has fast learning speed, and learns the between-class scatter subspace. To this end, this paper investigates a linear and non-linear dimension reduction framework referred to as extreme learning machine AE (ELM-AE) and sparse ELM-AE (SELM-AE). In contrast to tied weight AE, the hidden neurons in ELM-AE and SELM-AE need not be tuned, and their parameters (e.g, input weights in additive neurons) are initialized using orthogonal and sparse random weights, respectively. Experimental results on USPS handwritten digit recognition data set, CIFAR-10 object recognition, and NORB object recognition data set show the efficacy of linear and non-linear ELM-AE and SELM-AE in terms of discriminative capability, sparsity, training time, and normalized mean square error.",2016,60,137,12,False,Mathematics,2996971,L. L. C. Kasun,2108850466.0,Yan Yang,145678691.0,G. Huang,Medicine,2148905797.0,Zhengyou Zhang,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2dc36b8d0c08613fb213ad419973d379a2264765,https://www.semanticscholar.org/paper/2dc36b8d0c08613fb213ad419973d379a2264765,Training algorithms for linear text classifiers,"Systems for text retrieval, routing, categorization and other IR tasks rely heavily on linear classifiers. We propose that two machine learning algorithms, the Widrow-Hoff and EG algorithms, be used in training linear text classifiers. In contrast to most IR methods, theoretical analysis provides performance guarantees and guidance on parameter settings for these algorithms. Experimental data is presented showing Widrow-Hoff and EG to be more effective than the widely used Rocchio algorithm on several categorization and routing tasks.",1996,57,632,34,True,Computer Science,35153517,D. Lewis,1716301.0,R. Schapire,144987107.0,Jamie Callan,,47394834.0,R. Papka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b3acf1e4f2e2e5e34f8828fc57e48cb3cb625e4e,https://www.semanticscholar.org/paper/b3acf1e4f2e2e5e34f8828fc57e48cb3cb625e4e,Human Activity Recognition Process Using 3-D Posture Data,"In this paper, we present a method for recognizing human activities using information sensed by an RGB-D camera, namely the Microsoft Kinect. Our approach is based on the estimation of some relevant joints of the human body by means of the Kinect; three different machine learning techniques, i.e., K-means clustering, support vector machines, and hidden Markov models, are combined to detect the postures involved while performing an activity, to classify them, and to model each activity as a spatiotemporal evolution of known postures. Experiments were performed on Kinect Activity Recognition Dataset, a new dataset, and on CAD-60, a public dataset. Experimental results show that our solution outperforms four relevant works based on RGB-D image fusion, hierarchical Maximum Entropy Markov Model, Markov Random Fields, and Eigenjoints, respectively. The performance we achieved, i.e., precision/recall of 77.3% and 76.7%, and the ability to recognize the activities in real time show promise for applied use.",2015,42,260,36,False,Computer Science,50311449,S. Gaglio,40131930.0,G. Re,1735372.0,M. Morana,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
09d479e266b76da83deb5e044034d9880fc5c211,https://www.semanticscholar.org/paper/09d479e266b76da83deb5e044034d9880fc5c211,A stable multi-scale kernel for topological machine learning,"Topological data analysis offers a rich source of valuable information to study vision problems. Yet, so far we lack a theoretically sound connection to popular kernel-based learning techniques, such as kernel SVMs or kernel PCA. In this work, we establish such a connection by designing a multi-scale kernel for persistence diagrams, a stable summary representation of topological features in data. We show that this kernel is positive definite and prove its stability with respect to the 1-Wasserstein distance. Experiments on two benchmark datasets for 3D shape classification/retrieval and texture recognition show considerable performance gains of the proposed method compared to an alternative approach that is based on the recently introduced persistence landscapes.",2014,37,280,29,True,Computer Science,2663536,Jan Reininghaus,47326739.0,S. Huber,37119171.0,U. Bauer,Mathematics,2132917.0,R. Kwitt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16691c78b5948b5dd6b4efe42870f47460662c02,https://www.semanticscholar.org/paper/16691c78b5948b5dd6b4efe42870f47460662c02,Ten Challenges in Advancing Machine Learning Technologies toward 6G,"As the 5G standard is being completed, academia and industry have begun to consider a more developed cellular communication technique, 6G, which is expected to achieve high data rates up to 1 Tb/s and broad frequency bands of 100 GHz to 3 THz. Besides the significant upgrade of the key communication metrics, Artificial Intelligence (AI) has been envisioned by many researchers as the most important feature of 6G, since the state-of-the-art machine learning technique has been adopted as the top solution in many extremely complex scenarios. Network intelligentization will be the new trend to address the challenges of exponentially increasing number of connected heterogeneous devices. However, compared with the application of machine learning in other fields, such as computer games, current research on intelligent networking still has a long way to go to realize the automatically- configured cellular communication systems. Various problems in terms of communication system, machine learning architectures, and computation efficiency should be addressed for the full use of this technique in 6G. In this paper, we analyze machine learning techniques and introduce 10 most critical challenges in advancing the intelligent 6G system.",2020,13,143,2,False,Computer Science,145842185,N. Kato,152877793.0,Bomin Mao,19282835.0,Fengxiao Tang,,3246156.0,Y. Kawamoto,48211895.0,Jiajia Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18b626df44f1dfc6513fcbe743fe555f6109aeba,https://www.semanticscholar.org/paper/18b626df44f1dfc6513fcbe743fe555f6109aeba,A New Approach to the Study of Translationese: Machine-learning the Difference between Original and Translated Text,"In this article we describe an approach to the identification of 'translationese' based on monolingual comparable corpora and machine learning techniques for text categorization. The article reports on experiments in which support vector machines (SVMs) are employed to recognize translated text in a corpus of Italian articles from the geopolitical domain. An ensemble of SVMs reaches 86.7% accuracy with 89.3% precision and 83.3% recall on this task. A preliminary analysis of the features used by the SVMs suggests that the distribution of function words and morphosyntactic categories in general, and personal pronouns and adverbs in particular, are among the cues used by the SVMs to perform the discrimination task. A follow-up experiment shows that the performance attained by SVMs is well above the average performance of ten human subjects, including five professional translators, on the same task. Our results offer solid evidence supporting the translationese hypothesis, and our method seems to have promising applications in translation studies and in quantitative style analysis in general. Implications for the machine learning/text categorization community are equally important, both because this is a novel application and especially because we provide explicit evidence that a relatively knowledge-poor machine learning algorithm can outperform human beings in a text classification task.",2005,42,188,14,False,Computer Science,145283199,Marco Baroni,46715576.0,Silvia Bernardini,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e7924a71ff89f37f66298a6b42bcd26fa7c0f33b,https://www.semanticscholar.org/paper/e7924a71ff89f37f66298a6b42bcd26fa7c0f33b,River: machine learning for streaming data in Python,"River is a machine learning library for dynamic data streams and continual learning. It provides multiple state-of-the-art learning methods, data generators/transformers, performance metrics and evaluators for different stream learning problems. It is the result from the merger of the two most popular packages for stream learning in Python: Creme and scikit-multiflow. River introduces a revamped architecture based on the lessons learnt from the seminal packages. River's ambition is to be the go-to library for doing machine learning on streaming data. Additionally, this open source package brings under the same umbrella a large community of practitioners and researchers. The source code is available at https://github.com/online-ml/river.",2020,49,45,5,False,Computer Science,35479220,Jacob Montiel,104920778.0,Max Halford,31757587.0,S. M. Mastelini,,2034015026.0,Geoffrey Bolmier,2034015684.0,Raphael Sourty,2034016270.0,Robin Vaysse,103370422.0,Adil Zouitine,13645563.0,Heitor Murilo Gomes,,1383995365.0,Jesse Read,2831624.0,T. Abdessalem,1762931.0,A. Bifet,,,,,,,,,,,,,,,,,,,,,,
05351b3abcca9e535c534c3b4bff0865ba96b3ac,https://www.semanticscholar.org/paper/05351b3abcca9e535c534c3b4bff0865ba96b3ac,Confidence-based active learning,"This paper proposes a new active learning approach, confidence-based active learning, for training a wide range of classifiers. This approach is based on identifying and annotating uncertain samples. The uncertainty value of each sample is measured by its conditional error. The approach takes advantage of current classifiers' probability preserving and ordering properties. It calibrates the output scores of classifiers to conditional error. Thus, it can estimate the uncertainty value for each input sample according to its output score from a classifier and select only samples with uncertainty value above a user-defined threshold. Even though we cannot guarantee the optimality of the proposed approach, we find it to provide good performance. Compared with existing methods, this approach is robust without additional computational effort. A new active learning method for support vector machines (SVMs) is implemented following this approach. A dynamic bin width allocation method is proposed to accurately estimate sample conditional error and this method adapts to the underlying probabilities. The effectiveness of the proposed approach is demonstrated using synthetic and real data sets and its performance is compared with the widely used least certain active learning method",2006,44,223,13,False,Computer Science,49140921,Mingkun Li,1702517.0,I. Sethi,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
edb189b3d0f777525837b3136e109aa0ba01a99a,https://www.semanticscholar.org/paper/edb189b3d0f777525837b3136e109aa0ba01a99a,Multicategory Classification Using An Extreme Learning Machine for Microarray Gene Expression Cancer Diagnosis,"In this paper, the recently developed Extreme Learning Machine (ELM) is used for directing multicategory classification problems in the cancer diagnosis area. ELM avoids problems like local minima, improper learning rate and overfitting commonly faced by iterative learning methods and completes the training very fast. We have evaluated the multicategory classification performance of ELM on three benchmark microarray data sets for cancer diagnosis, namely, the GCM data set, the Lung data set, and the Lymphoma data set. The results indicate that ELM produces comparable or better classification accuracies with reduced training time and implementation complexity compared to artificial neural networks methods like conventional back-propagation ANN, Linder's SANN, and Support Vector Machine methods like SVM-OVO and Ramaswamy's SVM-OVA. ELM also achieves better accuracies for classification of individual categories.",2007,21,246,4,False,Computer Science,2190082425,Runxuan Zhang,145678691.0,G. Huang,145411276.0,N. Sundararajan,Medicine,1800678.0,P. Saratchandran,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4b5eb40e45110dffac9ad7be68a294ecedaec1d4,https://www.semanticscholar.org/paper/4b5eb40e45110dffac9ad7be68a294ecedaec1d4,A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop.,"Imaging research laboratories are rapidly creating machine learning systems that achieve expert human performance using open-source methods and tools. These artificial intelligence systems are being developed to improve medical image reconstruction, noise reduction, quality assurance, triage, segmentation, computer-aided detection, computer-aided classification, and radiogenomics. In August 2018, a meeting was held in Bethesda, Maryland, at the National Institutes of Health to discuss the current state of the art and knowledge gaps and to develop a roadmap for future research initiatives. Key research priorities include: 1, new image reconstruction methods that efficiently produce images suitable for human interpretation from source data; 2, automated image labeling and annotation methods, including information extraction from the imaging report, electronic phenotyping, and prospective structured image reporting; 3, new machine learning methods for clinical imaging data, such as tailored, pretrained model architectures, and federated machine learning methods; 4, machine learning methods that can explain the advice they provide to human users (so-called explainable artificial intelligence); and 5, validated methods for image de-identification and data sharing to facilitate wide availability of clinical imaging data sets. This research roadmap is intended to identify and prioritize these needs for academic research laboratories, funding agencies, professional societies, and industry.",2019,97,190,0,True,Medicine,2356307,C. Langlotz,40221223.0,Bibb Allen,144917634.0,B. Erickson,,1401724111.0,Jayashree Kalpathy-Cramer,49265987.0,K. Bigelow,2066982812.0,T. Cook,1864663.0,A. Flanders,4204731.0,M. Lungren,,2064211562.0,D. Mendelson,2670463.0,J. Rudie,2108296864.0,Ge Wang,10234379.0,K. Kandarpa,,,,,,,,,,,,,,,,,,,,
