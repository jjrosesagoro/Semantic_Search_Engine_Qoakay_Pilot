{"total": 5120627, "offset": 3900, "next": 4000, "data": [{"paperId": "6d0c03d8b3bffd0eec216297bc3762d5ea5da00f", "url": "https://www.semanticscholar.org/paper/6d0c03d8b3bffd0eec216297bc3762d5ea5da00f", "title": "Combining Generative and Discriminative Representation Learning for Lung CT Analysis With Convolutional Restricted Boltzmann Machines", "abstract": "The choice of features greatly influences the performance of a tissue classification system. Despite this, many systems are built with standard, predefined filter banks that are not optimized for that particular application. Representation learning methods such as restricted Boltzmann machines may outperform these standard filter banks because they learn a feature description directly from the training data. Like many other representation learning methods, restricted Boltzmann machines are unsupervised and are trained with a generative learning objective; this allows them to learn representations from unlabeled data, but does not necessarily produce features that are optimal for classification. In this paper we propose the convolutional classification restricted Boltzmann machine, which combines a generative and a discriminative learning objective. This allows it to learn filters that are good both for describing the training data and for classification. We present experiments with feature learning for lung texture classification and airway detection in CT images. In both applications, a combination of learning objectives outperformed purely discriminative or generative learning, increasing, for instance, the lung tissue classification accuracy by 1 to 8 percentage points. This shows that discriminative learning can help an otherwise unsupervised feature learner to learn filters that are optimized for classification.", "year": 2016, "referenceCount": 47, "citationCount": 97, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "51256193", "name": "Gijs van Tulder"}, {"authorId": "32895376", "name": "Marleen de Bruijne"}]}, {"paperId": "bc69383a7d46cbaf80b5b5ef902a3dccf23df696", "url": "https://www.semanticscholar.org/paper/bc69383a7d46cbaf80b5b5ef902a3dccf23df696", "title": "TF.Learn: TensorFlow's High-level Module for Distributed Machine Learning", "abstract": "TF.Learn is a high-level Python module for distributed machine learning inside TensorFlow. It provides an easy-to-use Scikit-learn style interface to simplify the process of creating, configuring, training, evaluating, and experimenting a machine learning model. TF.Learn integrates a wide range of state-of-art machine learning algorithms built on top of TensorFlow's low level APIs for small to large-scale supervised and unsupervised problems. This module focuses on bringing machine learning to non-specialists using a general-purpose high-level language as well as researchers who want to implement, benchmark, and compare their new methods in a structured environment. Emphasis is put on ease of use, performance, documentation, and API consistency.", "year": 2016, "referenceCount": 14, "citationCount": 59, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46556630", "name": "Yuan Tang"}]}, {"paperId": "0b5165a43493b5c20ce9af599b2e8304b7faf26a", "url": "https://www.semanticscholar.org/paper/0b5165a43493b5c20ce9af599b2e8304b7faf26a", "title": "Survey on supervised machine learning techniques for automatic text classification", "abstract": null, "year": 2019, "referenceCount": 87, "citationCount": 117, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9233630", "name": "Ammar Ismael Kadhim"}]}, {"paperId": "ffab12aeb2717c251a4ce1df118d6741fb06617f", "url": "https://www.semanticscholar.org/paper/ffab12aeb2717c251a4ce1df118d6741fb06617f", "title": "A Primer on the Signature Method in Machine Learning", "abstract": "In these notes, we wish to provide an introduction to the signature method, focusing on its basic theoretical properties and recent numerical applications. \nThe notes are split into two parts. The first part focuses on the definition and fundamental properties of the signature of a path, or the path signature. We have aimed for a minimalistic approach, assuming only familiarity with classical real analysis and integration theory, and supplementing theory with straightforward examples. We have chosen to focus in detail on the principle properties of the signature which we believe are fundamental to understanding its role in applications. We also present an informal discussion on some of its deeper properties and briefly mention the role of the signature in rough paths theory, which we hope could serve as a light introduction to rough paths for the interested reader. \nThe second part of these notes discusses practical applications of the path signature to the area of machine learning. The signature approach represents a non-parametric way for extraction of characteristic features from data. The data are converted into a multi-dimensional path by means of various embedding algorithms and then processed for computation of individual terms of the signature which summarise certain information contained in the data. The signature thus transforms raw data into a set of features which are used in machine learning tasks. We will review current progress in applications of signatures to machine learning problems.", "year": 2016, "referenceCount": 29, "citationCount": 121, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "3029003", "name": "I. Chevyrev"}, {"authorId": "3362051", "name": "A. Kormilitzin"}]}, {"paperId": "508db892b1f34149f5a5931d74449d87552bf3a3", "url": "https://www.semanticscholar.org/paper/508db892b1f34149f5a5931d74449d87552bf3a3", "title": "Semiparametric Support Vector and Linear Programming Machines", "abstract": "Semiparametric models are useful tools in the case where domain knowledge exists about the function to be estimated or emphasis is put onto understandability of the model. We extend two learning algorithms - Support Vector machines and Linear Programming machines to this case and give experimental results for SV machines.", "year": 1998, "referenceCount": 13, "citationCount": 104, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "34999823", "name": "T. Frie\u00df"}, {"authorId": "1707625", "name": "B. Sch\u00f6lkopf"}]}, {"paperId": "83ea40bf80e7a8c476510c316d8e5861e1394616", "url": "https://www.semanticscholar.org/paper/83ea40bf80e7a8c476510c316d8e5861e1394616", "title": "Efficient covariance matrix update for variable metric evolution strategies", "abstract": null, "year": 2009, "referenceCount": 93, "citationCount": 112, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1840799", "name": "T. Suttorp"}, {"authorId": "144539890", "name": "N. Hansen"}, {"authorId": "1748824", "name": "C. Igel"}]}, {"paperId": "1904d633fca15140e35d893637232803b6dde6d9", "url": "https://www.semanticscholar.org/paper/1904d633fca15140e35d893637232803b6dde6d9", "title": "Learning under Concept Drift: A Review", "abstract": "Concept drift describes unforeseeable changes in the underlying distribution of streaming data over time. Concept drift research involves the development of methodologies and techniques for drift detection, understanding, and adaptation. Data analysis has revealed that machine learning in a concept drift environment will result in poor learning results if the drift is not addressed. To help researchers identify which research topics are significant and how to apply related techniques in data analysis tasks, it is necessary that a high quality, instructive review of current research developments and trends in the concept drift field is conducted. In addition, due to the rapid development of concept drift in recent years, the methodologies of learning under concept drift have become noticeably systematic, unveiling a framework which has not been mentioned in literature. This paper reviews over 130 high quality publications in concept drift related research areas, analyzes up-to-date developments in methodologies and techniques, and establishes a framework of learning under concept drift including three main components: concept drift detection, concept drift understanding, and concept drift adaptation. This paper lists and discusses 10 popular synthetic datasets and 14 publicly available benchmark datasets used for evaluating the performance of learning algorithms aiming at handling concept drift. Also, concept drift related research directions are covered and discussed. By providing state-of-the-art knowledge, this survey will directly support researchers in their understanding of research developments in the field of learning under concept drift.", "year": 2019, "referenceCount": 148, "citationCount": 401, "influentialCitationCount": 36, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144864069", "name": "Jie Lu"}, {"authorId": "1471737704", "name": "Anjin Liu"}, {"authorId": "46279367", "name": "Fan Dong"}, {"authorId": "2056183624", "name": "Feng Gu"}, {"authorId": "143931014", "name": "Jo\u00e3o Gama"}, {"authorId": "46266495", "name": "Guangquan Zhang"}]}, {"paperId": "f24fa8f9bb1d28019bec34e09f8618f002ca4af9", "url": "https://www.semanticscholar.org/paper/f24fa8f9bb1d28019bec34e09f8618f002ca4af9", "title": "On the Pitfalls of Using Arbiter-PUFs as Building Blocks", "abstract": "Physical unclonable functions (PUFs) have emerged as a promising solution for securing resource-constrained embedded devices such as RFID tokens. PUFs use the inherent physical differences of every chip to either securely authenticate the chip or generate cryptographic keys without the need of nonvolatile memory. However, PUFs have shown to be vulnerable to model building attacks if the attacker has access to challenge and response pairs. In these model building attacks, machine learning is used to determine the internal parameters of the PUF to build an accurate software model. Nevertheless, PUFs are still a promising building block and several protocols and designs have been proposed that are believed to be resistant against machine learning attacks. In this paper, we take a closer look at two such protocols, one based on reverse fuzzy extractors and one based on pattern matching. We show that it is possible to attack these protocols using machine learning despite the fact that an attacker does not have access to direct challenge and response pairs. The introduced attacks demonstrate that even highly obfuscated responses can be used to attack PUF protocols. Hence, this paper shows that even protocols in which it would be computationally infeasible to compute enough challenge and response pairs for a direct machine learning attack can be attacked using machine learning.", "year": 2015, "referenceCount": 22, "citationCount": 84, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "4277384", "name": "G. Becker"}]}, {"paperId": "25e60172a650b3e7482732d65a1f1cc179dfca65", "url": "https://www.semanticscholar.org/paper/25e60172a650b3e7482732d65a1f1cc179dfca65", "title": "Iteration complexity of feasible descent methods for convex optimization", "abstract": "In many machine learning problems such as the dual form of SVM, the objective function to be minimized is convex but not strongly convex. This fact causes difficulties in obtaining the complexity of some commonly used optimization algorithms. In this paper, we proved the global linear convergence on a wide range of algorithms when they are applied to some non-strongly convex problems. In particular, we are the first to prove O(log(1/e)) time complexity of cyclic coordinate descent methods on dual problems of support vector classification and regression.", "year": 2014, "referenceCount": 37, "citationCount": 132, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "145980559", "name": "Po-Wei Wang"}, {"authorId": "1711460", "name": "Chih-Jen Lin"}]}, {"paperId": "c7e9f331e99cefdf9d692f716f5e9d5316d4f4e4", "url": "https://www.semanticscholar.org/paper/c7e9f331e99cefdf9d692f716f5e9d5316d4f4e4", "title": "Crowdfunding support tools: predicting success & failure", "abstract": "Creative individuals increasingly rely on online crowdfunding platforms to crowdsource funding for new ventures. For novice crowdfunding project creators, however, there are few resources to turn to for assistance in the planning of crowdfunding projects. We are building a tool for novice project creators to get feedback on their project designs. One component of this tool is a comparison to existing projects. As such, we have applied a variety of machine learning classifiers to learn the concept of a successful online crowdfunding project at the time of project launch. Currently our classifier can predict with roughly 68% accuracy, whether a project will be successful or not. The classification results will eventually power a prediction segment of the proposed feedback tool. Future work involves turning the results of the machine learning algorithms into human-readable content and integrating this content into the feedback tool.", "year": 2013, "referenceCount": 13, "citationCount": 200, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "94378170", "name": "M. Greenberg"}, {"authorId": "144893701", "name": "B. Pardo"}, {"authorId": "2066148405", "name": "K. Hariharan"}, {"authorId": "145003123", "name": "E. Gerber"}]}, {"paperId": "742432ccfa877d29ec30b19f0b7a3f5d4422681c", "url": "https://www.semanticscholar.org/paper/742432ccfa877d29ec30b19f0b7a3f5d4422681c", "title": "Variational Message Passing", "abstract": "Bayesian inference is now widely established as one of the principal foundations for machine learning. In practice, exact inference is rarely possible, and so a variety of approximation techniques have been developed, one of the most widely used being a deterministic framework called variational inference. In this paper we introduce Variational Message Passing (VMP), a general purpose algorithm for applying variational inference to Bayesian Networks. Like belief propagation, VMP proceeds by sending messages between nodes in the network and updating posterior beliefs using local operations at each node. Each such update increases a lower bound on the log evidence (unless already at a local maximum). In contrast to belief propagation, VMP can be applied to a very general class of conjugate-exponential models because it uses a factorised variational approximation. Furthermore, by introducing additional variational parameters, VMP can be applied to models containing non-conjugate distributions. The VMP framework also allows the lower bound to be evaluated, and this can be used both for model comparison and for detection of convergence. Variational message passing has been implemented in the form of a general purpose inference engine called VIBES ('Variational Inference for BayEsian networkS') which allows models to be specified graphically and then solved variationally without recourse to coding.", "year": 2005, "referenceCount": 22, "citationCount": 698, "influentialCitationCount": 85, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "33652486", "name": "J. Winn"}, {"authorId": "1792884", "name": "Charles M. Bishop"}]}, {"paperId": "d67de704fb67171a4a8647e352b8bd46d091eea0", "url": "https://www.semanticscholar.org/paper/d67de704fb67171a4a8647e352b8bd46d091eea0", "title": "FDML: A Collaborative Machine Learning Framework for Distributed Features", "abstract": "Most current distributed machine learning systems try to scale up model training by using a data-parallel architecture that divides the computation for different samples among workers. We study distributed machine learning from a different motivation, where the information about the same samples, e.g., users and objects, are owned by several parities that wish to collaborate but do not want to share raw data with each other. We propose an asynchronous stochastic gradient descent (SGD) algorithm for such a feature distributed machine learning (FDML) problem, to jointly learn from distributed features, with theoretical convergence guarantees under bounded asynchrony. Our algorithm does not require sharing the original features or even local model parameters between parties, thus preserving the data locality. The system can also easily incorporate differential privacy mechanisms to preserve a higher level of privacy. We implement the FDML system in a parameter server architecture and compare our system with fully centralized learning (which violates data locality) and learning based on only local features, through extensive experiments performed on both a public data set a9a, and a large dataset of 5,000,000 records and 8700 decentralized features from three collaborating apps at Tencent including Tencent MyApp, Tecent QQ Browser and Tencent Mobile Safeguard. Experimental results have demonstrated that the proposed FDML system can be used to significantly enhance app recommendation in Tencent MyApp by leveraging user and item features from other apps, while preserving the locality and privacy of features in each individual app to a high degree.", "year": 2019, "referenceCount": 32, "citationCount": 87, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2911895", "name": "Yaochen Hu"}, {"authorId": "1714907", "name": "Di Niu"}, {"authorId": "2109749450", "name": "Jianming Yang"}, {"authorId": "1387846432", "name": "Shengping Zhou"}]}, {"paperId": "00358a3f17821476d93461192b9229fe7d92bb3f", "url": "https://www.semanticscholar.org/paper/00358a3f17821476d93461192b9229fe7d92bb3f", "title": "GNNExplainer: Generating Explanations for Graph Neural Networks", "abstract": "Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GnnExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GnnExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GnnExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GnnExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0% in explanation accuracy. GnnExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.", "year": 2019, "referenceCount": 62, "citationCount": 447, "influentialCitationCount": 123, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science", "Mathematics"], "authors": [{"authorId": "83539859", "name": "Rex Ying"}, {"authorId": "40974349", "name": "Dylan Bourgeois"}, {"authorId": "145829303", "name": "Jiaxuan You"}, {"authorId": "2095762", "name": "M. Zitnik"}, {"authorId": "1702139", "name": "J. Leskovec"}]}, {"paperId": "1bdb80f106c41bbb036133d6ddcaf3114461d626", "url": "https://www.semanticscholar.org/paper/1bdb80f106c41bbb036133d6ddcaf3114461d626", "title": "Side channel attack: an approach based on machine learning", "abstract": "In cryptography, a side channel attack is any attack based on the analysis of measurements related to the physical implementa- tion of a cryptosystem. Nowadays, the possibility of collecting a large amount of observations paves the way to the adoption of machine learn- ing techniques, i.e. techniques able to extract information and patterns from large datasets. The use of statistical techniques for side channel at- tacks is not new. Techniques like Template Based DPA have shown their eectiveness in recent years. However these techniques rely on paramet- ric assumptions and are often limited to small dimensionality setting, which limits their range of application. This paper explores the use of machine learning techniques to relax such assumption and to deal with high dimensional feature vectors. For this purpose, we first formalize the problem of studying the relation between power consumption and encryption key as a supervised learning task. Then we compare and assess several classifiers and dimensionality reduction techniques in a real experimental setting. Our promising re- sults regarding the 3DES encryption scheme confirms the importance of adopting machine learning approaches in cryptanalysis.", "year": 2011, "referenceCount": 19, "citationCount": 118, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "1802747", "name": "O. Markowitch"}, {"authorId": "39319437", "name": "Liran Lerman"}, {"authorId": "1772497", "name": "Gianluca Bontempi"}]}, {"paperId": "57580f0d04716b6c585cf59435d83e60a819313a", "url": "https://www.semanticscholar.org/paper/57580f0d04716b6c585cf59435d83e60a819313a", "title": "Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate", "abstract": "Many modern machine learning models are trained to achieve zero or near-zero training error in order to obtain near-optimal (but non-zero) test error. This phenomenon of strong generalization performance for \"overfitted\" / interpolated classifiers appears to be ubiquitous in high-dimensional data, having been observed in deep networks, kernel machines, boosting and random forests. Their performance is consistently robust even when the data contain large amounts of label noise. \nVery little theory is available to explain these observations. The vast majority of theoretical analyses of generalization allows for interpolation only when there is little or no label noise. This paper takes a step toward a theoretical foundation for interpolated classifiers by analyzing local interpolating schemes, including geometric simplicial interpolation algorithm and singularly weighted $k$-nearest neighbor schemes. Consistency or near-consistency is proved for these schemes in classification and regression problems. Moreover, the nearest neighbor schemes exhibit optimal rates under some standard statistical assumptions. \nFinally, this paper suggests a way to explain the phenomenon of adversarial examples, which are seemingly ubiquitous in modern machine learning, and also discusses some connections to kernel machines and random forests in the interpolated regime.", "year": 2018, "referenceCount": 56, "citationCount": 198, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics", "Physics"], "authors": [{"authorId": "145520115", "name": "Mikhail Belkin"}, {"authorId": "143724861", "name": "Daniel J. Hsu"}, {"authorId": "48850725", "name": "P. Mitra"}]}, {"paperId": "771c14df5fbe14ace4b7f68c2fdc5d3526e4b4ca", "url": "https://www.semanticscholar.org/paper/771c14df5fbe14ace4b7f68c2fdc5d3526e4b4ca", "title": "Memristive Boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning", "abstract": "The Boltzmann machine is a massively parallel computational model capable of solving a broad class of combinatorial optimization problems. In recent years, it has been successfully applied to training deep machine learning models on massive datasets. High performance implementations of the Boltzmann machine using GPUs, MPI-based HPC clusters, and FPGAs have been proposed in the literature. Regrettably, the required all-to-all communication among the processing units limits the performance of these efforts. This paper examines a new class of hardware accelerators for large-scale combinatorial optimization and deep learning based on memristive Boltzmann machines. A massively parallel, memory-centric hardware accelerator is proposed based on recently developed resistive RAM (RRAM) technology. The proposed accelerator exploits the electrical properties of RRAm to realize in situ, fine-grained parallel computation within memory arrays, thereby eliminating the need for exchanging data between the memory cells and the computational units. Two classical optimization problems, graph partitioning and boolean satisfiability, and a deep belief network application are mapped onto the proposed hardware. As compared to a multicore system, the proposed accelerator achieves 57x higher performance and 25x lower energy with virtually no loss in the quality of the solution to the optimization problems. The memristive accelerator is also compared against an RRAM based processing-in-memory (PIM) system, with respective performance and energy improvements of 6.89x and 5.2x.", "year": 2016, "referenceCount": 92, "citationCount": 171, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1797114", "name": "M. N. Bojnordi"}, {"authorId": "1787439", "name": "Engin Ipek"}]}, {"paperId": "2004356cf836faf746f713c6fb888c506c9c8a91", "url": "https://www.semanticscholar.org/paper/2004356cf836faf746f713c6fb888c506c9c8a91", "title": "Neural Networks and Related Methods for Classification", "abstract": "Feed-forward neural networks are now widely used in classification problems, whereas nonlinear methods of discrimination developed in the statistical field are much less widely known. A general framework for classification is set up within which methods from statistics, neural networks, pattern recognition and machine learning can be compared. Neural networks emerge as one of a class of flexible non-linear regression methods which can be used to classify via regression. Many interesting issues remain, including parameter estimation, the assessment of the classifiers and in algorithm development.", "year": 1994, "referenceCount": 120, "citationCount": 577, "influentialCitationCount": 23, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2122942", "name": "B. Ripley"}]}, {"paperId": "876820b005477aa1c0f852515ef6ad77679452a9", "url": "https://www.semanticscholar.org/paper/876820b005477aa1c0f852515ef6ad77679452a9", "title": "Overview of textual anti-spam filtering techniques", "abstract": "Elecronic mail (E-mail) is an essential communication tool that has been greatly abused by spammers to disseminate unwanted information (messages) and spread malicious contents to Internet users. Current Internet technologies further accelerated the distribution of spam. Effective controls need to be deployed to countermeasure the ever growing spam problem. Machine learning provides better protective mechanisms that are able to control spam. This paper summarizes most common techniques used for anti-spam filtering by analyzing the e-mail content and also looks into machine learning algorithms such as Naive Bayesian, support vector machine and neural network that have been adopted to detect and control spam. Each machine learning has its own strengths and limitations as such appropriate preprocessing need to be carefully considered to increase the effectiveness of any given machine learning. \n \n \u00a0 \n \n Key words:\u00a0Anti-spam filters, text categorization, electronic mail (E-mail), machine learning.", "year": 2010, "referenceCount": 75, "citationCount": 57, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144268957", "name": "T. Subramaniam"}, {"authorId": "2656031", "name": "H. Jalab"}, {"authorId": "9308940", "name": "A. Taqa"}]}, {"paperId": "c55e27e9018f61f105453f3bcee1113e03fc93bf", "url": "https://www.semanticscholar.org/paper/c55e27e9018f61f105453f3bcee1113e03fc93bf", "title": "Part-of-Speech Tagging for English-Spanish Code-Switched Text", "abstract": "Code-switching is an interesting linguistic phenomenon commonly observed in highly bilingual communities. It consists of mixing languages in the same conversational event. This paper presents results on Part-of-Speech tagging Spanish-English code-switched discourse. We explore different approaches to exploit existing resources for both languages that range from simple heuristics, to language identification, to machine learning. The best results are achieved by training a machine learning algorithm with features that combine the output of an English and a Spanish Part-of-Speech tagger.", "year": 2008, "referenceCount": 59, "citationCount": 127, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1794626", "name": "T. Solorio"}, {"authorId": "1614038854", "name": "Yang Liu"}]}, {"paperId": "86bf4e4eb3087fff0dcaf9d0c0bc00c36fd2d11b", "url": "https://www.semanticscholar.org/paper/86bf4e4eb3087fff0dcaf9d0c0bc00c36fd2d11b", "title": "Towards human-guided machine learning", "abstract": "Automated Machine Learning (AutoML) systems are emerging that automatically search for possible solutions from a large space of possible kinds of models. Although fully automated machine learning is appropriate for many applications, users often have knowledge that supplements and constraints the available data and solutions. This paper proposes human-guided machine learning (HGML) as a hybrid approach where a user interacts with an AutoML system and tasks it to explore different problem settings that reflect the user's knowledge about the data available. We present: 1) a task analysis of HGML that shows the tasks that a user would want to carry out, 2) a characterization of two scientific publications, one in neuroscience and one in political science, in terms of how the authors would search for solutions using an AutoML system, 3) requirements for HGML based on those characterizations, and 4) an assessment of existing AutoML systems in terms of those requirements.", "year": 2019, "referenceCount": 44, "citationCount": 50, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145526918", "name": "Y. Gil"}, {"authorId": "143755437", "name": "James Honaker"}, {"authorId": "2118928002", "name": "Shikhar Gupta"}, {"authorId": "2146277142", "name": "Yibo Ma"}, {"authorId": "1405498945", "name": "Vito D'Orazio"}, {"authorId": "1398926410", "name": "D. Garijo"}, {"authorId": "2066310557", "name": "Shruti Gadewar"}, {"authorId": "50513690", "name": "Qifan Yang"}, {"authorId": "1721831", "name": "N. Jahanshad"}]}, {"paperId": "7e8a5e0a87fab337d71ce04ba02b7a5ded392421", "url": "https://www.semanticscholar.org/paper/7e8a5e0a87fab337d71ce04ba02b7a5ded392421", "title": "Detecting and Tracking Political Abuse in Social Media", "abstract": "\n \n We study astroturf political campaigns on microblogging platforms: politically-motivated individuals and organizations that use multiple centrally-controlled accounts to create the appearance of widespread support for a candidate or opinion. We describe a machine learning framework that combines topological, content-based and crowdsourced features of information diffusion networks on Twitter to detect the early stages of viral spreading of political misinformation. \u00a0We present promising preliminary results with better than 96% accuracy in the detection of astroturf content in the run-up to the 2010 U.S. midterm elections.\n \n", "year": 2011, "referenceCount": 36, "citationCount": 568, "influentialCitationCount": 39, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2951268", "name": "Jacob Ratkiewicz"}, {"authorId": "49479696", "name": "Michael D. Conover"}, {"authorId": "2552228", "name": "Mark R. Meiss"}, {"authorId": "2054864984", "name": "B. Gon\u00e7alves"}, {"authorId": "1769960", "name": "A. Flammini"}, {"authorId": "143653472", "name": "F. Menczer"}]}, {"paperId": "8c6fd0282720800be845163d88a1722c198ece63", "url": "https://www.semanticscholar.org/paper/8c6fd0282720800be845163d88a1722c198ece63", "title": "Deep Learning for Consumer Devices and Services: Pushing the limits for machine learning, artificial intelligence, and computer vision.", "abstract": "In the last few years, we have witnessed an exponential growth in research activity into the advanced training of convolutional neural networks (CNNs), a field that has become known as deep learning. This has been triggered by a combination of the availability of significantly larger data sets, thanks in part to a corresponding growth in big data, and the arrival of new graphics-processing-unit (GPU)-based hardware that enables these large data sets to be processed in reasonable timescales. Suddenly, a wide variety of long-standing problems in machine learning, artificial intelligence, and computer vision have seen significant improvements, often sufficient to break through long-standing performance barriers. Across multiple fields, these achievements have inspired the development of improved tools and methodologies leading to even broader applicability of deep learning. The new generation of smart assistants, such as Alexa, Hello Google, and others, have their roots and learning algorithms tied to deep learning. In this article, we review the current state of deep learning, explain what it is, why it has managed to improve on the long-standing techniques of conventional neural networks, and, most importantly, how you can get started with adopting deep learning into your own research activities to solve both new and old problems and build better, smarter consumer devices and services.", "year": 2017, "referenceCount": 11, "citationCount": 166, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9770023", "name": "Joseph Lemley"}, {"authorId": "7172940", "name": "S. Bazrafkan"}, {"authorId": "1734172", "name": "P. Corcoran"}]}, {"paperId": "17239b49bb2c3649f7c220cf5f0a0fced0756942", "url": "https://www.semanticscholar.org/paper/17239b49bb2c3649f7c220cf5f0a0fced0756942", "title": "Active Learning and Crowd-Sourcing for Machine Translation", "abstract": "Large scale parallel data generation for new language pairs requires intensive human effort and availability of experts. It becomes immensely difficult and costly to provide Statistical Machine Translation (SMT) systems for most languages due to the paucity of expert translators to provide parallel data. Even if experts are present, it appears infeasible due to the impending costs. In this paper we propose Active Crowd Translation (ACT), a new paradigm where active learning and crowd-sourcing come together to enable automatic translation for low-resource language pairs. Active learning aims at reducing cost of label acquisition by prioritizing the most informative data for annotation, while crowd-sourcing reduces cost by using the power of the crowds to make do for the lack of expensive language experts. We experiment and compare our active learning strategies with strong baselines and see significant improvements in translation quality. Similarly, our experiments with crowd-sourcing on Mechanical Turk have shown that it is possible to create parallel corpora using non-experts and with sufficient quality assurance, a translation system that is trained using this corpus approaches expert quality.", "year": 2010, "referenceCount": 20, "citationCount": 158, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2582114", "name": "V. Ambati"}, {"authorId": "145247319", "name": "S. Vogel"}, {"authorId": "143712374", "name": "J. Carbonell"}]}, {"paperId": "7ec7cd97ce51f73afa25ef4daddfc4c1df8025cc", "url": "https://www.semanticscholar.org/paper/7ec7cd97ce51f73afa25ef4daddfc4c1df8025cc", "title": "An Efficient Intrusion Detection Model Based on Fast Inductive Learning", "abstract": "In recent years, intelligent intrusion detection techniques based on machine learning have been the research spots in the field of intrusion detection. Whereas, as network traffic and network scale increase continually, some current machine learning algorithms can't meet the requirement of the network intrusion detection models for efficiency and accuracy, which restricts the application of machine learning into intrusion detection. In order to enhance the availability and practicality of intelligent intrusion detection system based on machine learning in high-speed network, an improved fast inductive learning method for intrusion detection (FILMID) is designed and implemented. Accordingly, an efficient intrusion detection model based on FILMID algorithm is presented. The experiment results on the standard testing dataset validate the effectiveness of the FILMID based intrusion detection model.", "year": 2007, "referenceCount": 9, "citationCount": 29, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1390531397", "name": "Wu Yang"}, {"authorId": "2072512978", "name": "Wei Wan"}, {"authorId": "2110670698", "name": "Lin Guo"}, {"authorId": "2108781628", "name": "Lejun Zhang"}]}, {"paperId": "f9e86e353eea55d8db10dc2a478071781ac43a7f", "url": "https://www.semanticscholar.org/paper/f9e86e353eea55d8db10dc2a478071781ac43a7f", "title": "The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World", "abstract": "\"Wonderfully erudite, humorous, and easy to read.\" --KDNuggets In the world's top research labs and universities, the race is on to invent the ultimate learning algorithm: one capable of discovering any knowledge from data, and doing anything we want, before we even ask. In The Master Algorithm, Pedro Domingos lifts the veil to give us a peek inside the learning machines that power Google, Amazon, and your smartphone. He assembles a blueprint for the future universal learner--the Master Algorithm--and discusses what it will mean for business, science, and society. If data-ism is today's philosophy, this book is its bible.", "year": 2015, "referenceCount": 0, "citationCount": 223, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "1740213", "name": "Pedro M. Domingos"}]}, {"paperId": "1f2bc5d57ccbf5a04e7fea87f1f4db464f533ca8", "url": "https://www.semanticscholar.org/paper/1f2bc5d57ccbf5a04e7fea87f1f4db464f533ca8", "title": "Deep Learning for Video Game Playing", "abstract": "In this paper, we review recent deep learning advances in the context of how they have been applied to play different types of video games such as first-person shooters, arcade games, and real-time strategy games. We analyze the unique requirements that different game genres pose to a deep learning system and highlight important open challenges in the context of applying these machine learning methods to video games, such as general game playing, dealing with extremely large decision spaces and sparse rewards.", "year": 2017, "referenceCount": 181, "citationCount": 141, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2775866", "name": "Niels Justesen"}, {"authorId": "14171685", "name": "Philip Bontrager"}, {"authorId": "1810053", "name": "J. Togelius"}, {"authorId": "1745664", "name": "S. Risi"}]}, {"paperId": "c8c84e086f9df905879682c456eb3865e956bf7e", "url": "https://www.semanticscholar.org/paper/c8c84e086f9df905879682c456eb3865e956bf7e", "title": "Attention in Psychology, Neuroscience, and Machine Learning", "abstract": "Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.", "year": 2020, "referenceCount": 185, "citationCount": 69, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science", "Psychology"], "authors": [{"authorId": "32911505", "name": "Grace W. Lindsay"}]}, {"paperId": "0664e0a00a3cdeb4fd518d00b84abb5ccc3a1c57", "url": "https://www.semanticscholar.org/paper/0664e0a00a3cdeb4fd518d00b84abb5ccc3a1c57", "title": "A Survey of Deep Learning Methods for Cyber Security", "abstract": "This survey paper describes a literature review of deep learning (DL) methods for cyber security applications. A short tutorial-style description of each DL method is provided, including deep autoencoders, restricted Boltzmann machines, recurrent neural networks, generative adversarial networks, and several others. Then we discuss how each of the DL methods is used for security applications. We cover a broad array of attack types including malware, spam, insider threats, network intrusions, false data injection, and malicious domain names used by botnets.", "year": 2019, "referenceCount": 171, "citationCount": 264, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2069999925", "name": "Daniel S. Berman"}, {"authorId": "2343019", "name": "A. Buczak"}, {"authorId": "3376925", "name": "Jeffrey S. Chavis"}, {"authorId": "2382727", "name": "C. Corbett"}]}, {"paperId": "2f7cfe8aba54585a58af703099fe66aebcd129c9", "url": "https://www.semanticscholar.org/paper/2f7cfe8aba54585a58af703099fe66aebcd129c9", "title": "Large margin distribution machine", "abstract": "Support vector machine (SVM) has been one of the most popular learning algorithms, with the central idea of maximizing the minimum margin, i.e., the smallest distance from the instances to the classification boundary. Recent theoretical results, however, disclosed that maximizing the minimum margin does not necessarily lead to better generalization performances, and instead, the margin distribution has been proven to be more crucial. In this paper, we propose the Large margin Distribution Machine (LDM), which tries to achieve a better generalization performance by optimizing the margin distribution. We characterize the margin distribution by the first- and second-order statistics, i.e., the margin mean and variance. The LDM is a general learning approach which can be used in any place where SVM can be applied, and its superiority is verified both theoretically and empirically in this paper.", "year": 2013, "referenceCount": 32, "citationCount": 87, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144427929", "name": "Teng Zhang"}, {"authorId": "145624000", "name": "Zhi-Hua Zhou"}]}, {"paperId": "951d6492b8173c774ddf24bcbb409664f2bad495", "url": "https://www.semanticscholar.org/paper/951d6492b8173c774ddf24bcbb409664f2bad495", "title": "Development and Validation of a Learning Analytics Framework: Two Case Studies Using Support Vector Machines", "abstract": null, "year": 2014, "referenceCount": 59, "citationCount": 151, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2965730", "name": "Dirk Ifenthaler"}, {"authorId": "3282664", "name": "Chathuranga Widanapathirana"}]}, {"paperId": "23e5aa293415a500c1ae730f6aa857c802ba0504", "url": "https://www.semanticscholar.org/paper/23e5aa293415a500c1ae730f6aa857c802ba0504", "title": "Fuzzy Automata and Languages: Theory and Applications", "abstract": "INTRODUCTION Sets Relations Functions Fuzzy Subsets Semigroups Finite-State Machines Finite State Automata Languages and Grammars Nondeterministic Finite-State Automata Relationships Between Languages and Automata Pushdown Automata MAX-MIN AUTOMATA Max-Min Automata General Formulation of Automata Classes of Automata Behavior of Max-Min Automata Equivalences and Homomorphisms of Max-Min Automata Reduction of Max-Min Automata Definite Max-Min Automata Reduction of Max-Min Machines Equivalences Irreducibility and Minimality Nondeterministic and Deterministic Case FUZZY MACHINES, LANGUAGES, AND GRAMMARS Max-Product Machines Equivalences Irreducibility and Minimality Max-Product Grammars and Languages Weak Regular Max-Product Grammars Weak Regular Max-Product Languages Properties of GBP Exercises FUZZY LANGUAGES AND GRAMMARS Fuzzy Languages Types of Grammars Fuzzy Context-Free Grammars Context-Free Max-Product Grammars Context-Free Fuzzy Languages On the Description of the Fuzzy Meaning of Context-Free Languages Trees and Pseudoterms Fuzzy Dendrolanguage Generating Systems Normal Form of F-CFDS Sets of Derivation Trees of Fuzzy Context-Free Grammars Fuzzy Tree Automaton Fuzzy Tree Transducer Fuzzy Meaning of Context-Free Languages PROBABILISTIC AUTOMATA AND GRAMMARS Probabilistic Automata and their Approximation e-Approximating by Nonprobability Devices e-Approximating by Finite Automata Applications The Pe Relation Fuzzy Stars Acceptors and Probabilistic Acceptors Characterizations and the Re -Relation Probabilistic and Weighted Grammars Probabilistic and Weighted Grammars of Type 3 Interrelations with Programmed and Time-variant Grammars Probabilistic Grammars and Automata Probabilistic Grammars Weakly Regular Grammars and Asynchronous Automata Type-0 Probabilistic Grammars and Probabilistic Turing Machines Context-Free Probabilistic Grammars and Pushdown Automata Realization of Fuzzy Languages by Various Automata Properties of Lk, k - 1,2,3 Further Properties of L3 ALGEBRAIC FUZZY AUTOMATA THEORY Fuzzy Finite State Machines Semigroups of Fuzzy Finite State Machines Homomorphisms Admissible Relation Fuzzy Transformation Semigroups Products of Fuzzy Finite State Machines Submachines of a Fuzzy Finite State Machine Retrievability, Separability, and Connectivity Decomposition of Fuzzy Finite State Machines Subsystems of a Fuzzy Finite State Machine Strong Subsystems Cartesian Composition of Fuzzy Finite State Machines Cartesian Composition Admissible Partitions Coverings of Products of Fuzzy Finite State Machines Associative Properties of Products Covering Properties of Products Fuzzy Semiautomaton over a Finite Group MORE ON FUZZY LANGUAGES Fuzzy Regular Languages On Fuzzy Recognizers Minimal Fuzzy Recognizers Fuzzy Recognizers and Recognizable Sets Operation on (Fuzzy) Subsets Construction of Recognizers and Recognizable Sets Accessible and Coaccessible Recognizers Complete Fuzzy Machines Fuzzy Languages on a Free Monoid Algebraic Character and Properties of Fuzzy Regular Languages Deterministic Acceptors of Regular Fuzzy Languages MINIMIZATION OF FUZZY AUTOMATA Equivalence, Reduction, and Minimization of Finite Fuzzy Automata Equivalence of Fuzzy Automata: An Algebraic Approach Reduction and Minimization of Fuzzy Automata Minimal Fuzzy Finite State Automata Behavior, Reduction, and Minimization of Finite L-Automata Matrices over a Bounded Chain Systems of Linear Equivalences over a Bounded Chain Finite L-Automata-Behavior Matrix e-Equivalence e-Irreducibility Minimization L-FUZZY AUTOMATA, GRAMMARS, AND LANGUAGES Fuzzy Recognition of Fuzzy Languages Fuzzy Languages Fuzzy Recognition by Machines Cutpoint Languages Fuzzy Languages not Fuzzy Recognized by Machines in DT2 Rational Probabilistic Events Recursive Fuzzy Languages Closure Properties Fuzzy Grammars and Recursively Enumerable Fuzzy Languages Recursively Enumerable L-Subsets Various Kind of Automata with Weights APPLICATIONS A Formulation of Fuzzy Automata and its Application as a Model of Learning Systems Formulation of Fuzzy Automata Special Cases of Fuzzy Automata Fuzzy Automata as Models of Learning Systems Applications and Simulation Results Properties of Fuzzy Automata Fractionally Fuzzy Grammars with Application to Pattern Recognition Fractionally Fuzzy Grammars A Pattern Recognition Experiment General Fuzzy Acceptors for Syntactic Pattern Recognition e-Equivalence by Inputs Fuzzy-State Automata: Their Stability and Fault Tolerance Relational Description of Automata Fuzzy-State Automata Stable and Almost Stable Behavior of Fuzzy-State Automata Fault Tolerance of Fuzzy-State Automata Clinical Monitoring with Fuzzy Automata Fuzzy Systems REFERENCES INDEX Each chapter also includes a section of exercises", "year": 2002, "referenceCount": 0, "citationCount": 315, "influentialCitationCount": 28, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1797145", "name": "J. Mordeson"}, {"authorId": "2576671", "name": "D. Malik"}]}, {"paperId": "f031df138fdea7a8fcb5d6d599fa8294269a953c", "url": "https://www.semanticscholar.org/paper/f031df138fdea7a8fcb5d6d599fa8294269a953c", "title": "Implementation of Breiman's Random Forest Machine Learning Algorithm", "abstract": "This research provides tools for exploring Breiman\u2019s Random Forest algorithm. This paper will focus on the development, the verification, and the significance of variable importance. Introduction A classical machine learner is developed by collecting samples of data to represent the entire population. This data set is usually subdivided into two or more dataset. Part of the dataset set is commonly use for developing the machine learner, and the remaining data is use for evaluation. Often this data set is imbalanced; the data consists of only a very small minority of the data. Imbalanced machine learners tend to perform poorly with the classification of fraud detection, network intrusion, rare disease diagnosing, etc [1, 2]. This is due to imbalanced sampling during developing the machine learner. During the testing phase these rare cases are unseen during the training phase and are usually misclassified. Leo Breiman, a statistician from University of California at Berkeley, developed a machine learning algorithm to improve classification of diverse data using random sampling and attributes selection. This project involved the implementation of Breiman\u2019s random forest algorithm into Weka. Weka is a data mining software in development by The University of Waikato. Many features of the random forest algorithm have yet to be implemented into this software.", "year": 2005, "referenceCount": 4, "citationCount": 93, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "47457355", "name": "F. Livingston"}]}, {"paperId": "f38b1c390eedc55cbbd5716e03b15b67ff7e942b", "url": "https://www.semanticscholar.org/paper/f38b1c390eedc55cbbd5716e03b15b67ff7e942b", "title": "Quantum convolutional neural networks", "abstract": null, "year": 2018, "referenceCount": 61, "citationCount": 432, "influentialCitationCount": 39, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "30467296", "name": "Iris Cong"}, {"authorId": "12478116", "name": "Soonwon Choi"}, {"authorId": "145572474", "name": "M. Lukin"}]}, {"paperId": "c52876bb6e421896d36e2909ade078b3b4a99230", "url": "https://www.semanticscholar.org/paper/c52876bb6e421896d36e2909ade078b3b4a99230", "title": "Fuzzy learning enhanced speed control of an indirect field-oriented induction machine drive", "abstract": "Indirect field orientation (IFO) induction machine drives are increasingly employed in industrial drive systems, but the drive performance often degrades due to machine parameter variations. In this paper, a fuzzy model reference learning control technique is applied to an IFO induction machine drive, such that the machine can follow a reference model (an ideal field oriented machine) to achieve the desired speed performance. Experimental results are presented to verify the effectiveness of the proposed control scheme.", "year": 2000, "referenceCount": 10, "citationCount": 96, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "143713307", "name": "L. Zhen"}, {"authorId": "2109290322", "name": "Longya Xu"}]}, {"paperId": "9895fffe30eed4bd8dc8fbf1a46a71a1bc1ffd9d", "url": "https://www.semanticscholar.org/paper/9895fffe30eed4bd8dc8fbf1a46a71a1bc1ffd9d", "title": "Medical subdomain classification of clinical notes using a machine learning-based natural language processing approach", "abstract": null, "year": 2017, "referenceCount": 60, "citationCount": 108, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "2088565", "name": "W. Weng"}, {"authorId": "2727465", "name": "K. Wagholikar"}, {"authorId": "1780229", "name": "A. McCray"}, {"authorId": "1679873", "name": "Peter Szolovits"}, {"authorId": "3000692", "name": "H. Chueh"}]}, {"paperId": "7c83f0c67fb9dd27e6ea57989ff5d02e61e6ace0", "url": "https://www.semanticscholar.org/paper/7c83f0c67fb9dd27e6ea57989ff5d02e61e6ace0", "title": "Introduction to Statistical Machine Learning", "abstract": null, "year": 2013, "referenceCount": 0, "citationCount": 66, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1799035", "name": "Erik B. Sudderth"}]}, {"paperId": "e360cac5d1af72375dddc02e1dede047c9217fab", "url": "https://www.semanticscholar.org/paper/e360cac5d1af72375dddc02e1dede047c9217fab", "title": "Systematic learning of gene functional classes from DNA array expression data by using multilayer perceptrons.", "abstract": "Recent advances in microarray technology have opened new ways for functional annotation of previously uncharacterised genes on a genomic scale. This has been demonstrated by unsupervised clustering of co-expressed genes and, more importantly, by supervised learning algorithms. Using prior knowledge, these algorithms can assign functional annotations based on more complex expression signatures found in existing functional classes. Previously, support vector machines (SVMs) and other machine-learning methods have been applied to a limited number of functional classes for this purpose. Here we present, for the first time, the comprehensive application of supervised neural networks (SNNs) for functional annotation. Our study is novel in that we report systematic results for ~100 classes in the Munich Information Center for Protein Sequences (MIPS) functional catalog. We found that only ~10% of these are learnable (based on the rate of false negatives). A closer analysis reveals that false positives (and negatives) in a machine-learning context are not necessarily \"false\" in a biological sense. We show that the high degree of interconnections among functional classes confounds the signatures that ought to be learned for a unique class. We term this the \"Borges effect\" and introduce two new numerical indices for its quantification. Our analysis indicates that classification systems with a lower Borges effect are better suitable for machine learning. Furthermore, we introduce a learning procedure for combining false positives with the original class. We show that in a few iterations this process converges to a gene set that is learnable with considerably low rates of false positives and negatives and contains genes that are biologically related to the original class, allowing for a coarse reconstruction of the interactions between associated biological pathways. We exemplify this methodology using the well-studied tricarboxylic acid cycle.", "year": 2002, "referenceCount": 36, "citationCount": 134, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "121570730", "name": "\u00c1. Mateos"}, {"authorId": "145909087", "name": "J. Dopazo"}, {"authorId": "144322209", "name": "R. Jansen"}, {"authorId": "145817287", "name": "Y. Tu"}, {"authorId": "1717018", "name": "M. Gerstein"}, {"authorId": "2003079", "name": "G. Stolovitzky"}]}, {"paperId": "3da055661bbeef5a69570d0cfb2c195d90e4a309", "url": "https://www.semanticscholar.org/paper/3da055661bbeef5a69570d0cfb2c195d90e4a309", "title": "Applications of Supervised Machine Learning in Autism Spectrum Disorder Research: a Review", "abstract": null, "year": 2019, "referenceCount": 96, "citationCount": 83, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "145898346", "name": "Kayleigh Hyde"}, {"authorId": "7788825", "name": "M. Novack"}, {"authorId": "89667275", "name": "Nicholas LaHaye"}, {"authorId": "1410383043", "name": "Chelsea Parlett-Pelleriti"}, {"authorId": "1410399830", "name": "Raymond Anden"}, {"authorId": "33392486", "name": "D. Dixon"}, {"authorId": "3186827", "name": "E. Linstead"}]}, {"paperId": "c08db078d5dd093134383352f650968846de5b17", "url": "https://www.semanticscholar.org/paper/c08db078d5dd093134383352f650968846de5b17", "title": "Detecting Stealthy False Data Injection Using Machine Learning in Smart Grid", "abstract": "Aging power industries, together with the increase in demand from industrial and residential customers, are the main incentive for policy makers to define a road map to the next-generation power system called the smart grid. In the smart grid, the overall monitoring costs will be decreased, but at the same time, the risk of cyber attacks might be increased. Recently, a new type of attacks (called the stealth attack) has been introduced, which cannot be detected by the traditional bad data detection using state estimation. In this paper, we show how normal operations of power networks can be statistically distinguished from the case under stealthy attacks. We propose two machine-learning-based techniques for stealthy attack detection. The first method utilizes supervised learning over labeled data and trains a distributed support vector machine (SVM). The design of the distributed SVM is based on the alternating direction method of multipliers, which offers provable optimality and convergence rate. The second method requires no training data and detects the deviation in measurements. In both methods, principal component analysis is used to reduce the dimensionality of the data to be processed, which leads to lower computation complexities. The results of the proposed detection methods on IEEE standard test systems demonstrate the effectiveness of both schemes.", "year": 2013, "referenceCount": 44, "citationCount": 312, "influentialCitationCount": 21, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Engineering"], "authors": [{"authorId": "1684409", "name": "Mohammad Esmalifalak"}, {"authorId": "2116204721", "name": "Lanchao Liu"}, {"authorId": "1845448", "name": "N. Nguyen"}, {"authorId": "2027592", "name": "Rong Zheng"}, {"authorId": "145169163", "name": "Zhu Han"}]}, {"paperId": "6f8c23bc954b6ec5f7ce2d3b8b5ff73be2545c1d", "url": "https://www.semanticscholar.org/paper/6f8c23bc954b6ec5f7ce2d3b8b5ff73be2545c1d", "title": "Reinforcement learning using quantum Boltzmann machines", "abstract": "We investigate whether quantum annealers with select chip layouts can outperform classical computers in reinforcement learning tasks. We associate a transverse field Ising spin Hamiltonian with a layout of qubits similar to that of a deep Boltzmann machine (DBM) and use simulated quantum annealing (SQA) to numerically simulate quantum sampling from this system. We design a reinforcement learning algorithm in which the set of visible nodes representing the states and actions of an optimal policy are the first and last layers of the deep network. In absence of a transverse field, our simulations show that DBMs are trained more effectively than restricted Boltzmann machines (RBM) with the same number of nodes. We then develop a framework for training the network as a quantum Boltzmann machine (QBM) in the presence of a significant transverse field for reinforcement learning. This method also outperforms the reinforcement learning method that uses RBMs.", "year": 2016, "referenceCount": 67, "citationCount": 77, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics", "Physics"], "authors": [{"authorId": "145980819", "name": "Daniel Crawford"}, {"authorId": "40300826", "name": "A. Levit"}, {"authorId": "3132329", "name": "Navid Ghadermarzy"}, {"authorId": "7285568", "name": "J. S. Oberoi"}, {"authorId": "2789901", "name": "Pooya Ronagh"}]}, {"paperId": "bd2cb4546fc01074d55a183a68ce0a0f7be43a43", "url": "https://www.semanticscholar.org/paper/bd2cb4546fc01074d55a183a68ce0a0f7be43a43", "title": "Communication Complexity of Distributed Convex Learning and Optimization", "abstract": "We study the fundamental limits to communication-efficient distributed methods for convex learning and optimization, under different assumptions on the information available to individual machines, and the types of functions considered. We identify cases where existing algorithms are already worst-case optimal, as well as cases where room for further improvement is still possible. Among other things, our results indicate that without similarity between the local objective functions (due to statistical data similarity or otherwise) many communication rounds may be required, even if the machines have unbounded computational power.", "year": 2015, "referenceCount": 28, "citationCount": 168, "influentialCitationCount": 31, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2864002", "name": "Yossi Arjevani"}, {"authorId": "1768909", "name": "O. Shamir"}]}, {"paperId": "00884757c8c6e823200bb71741aaa132a84badec", "url": "https://www.semanticscholar.org/paper/00884757c8c6e823200bb71741aaa132a84badec", "title": "A Formalism for Relevance and Its Application in Feature Subset Selection", "abstract": null, "year": 2000, "referenceCount": 44, "citationCount": 243, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "145931269", "name": "D. Bell"}, {"authorId": "49527646", "name": "Hui Wang"}]}, {"paperId": "b9fd2932b6a27ed86c06f6fa4b050a3aad4a37d2", "url": "https://www.semanticscholar.org/paper/b9fd2932b6a27ed86c06f6fa4b050a3aad4a37d2", "title": "Building Machine Learning Systems with Python", "abstract": null, "year": 2013, "referenceCount": 19, "citationCount": 95, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1755926", "name": "Luis Pedro Coelho"}, {"authorId": "1940085", "name": "W. Richert"}]}, {"paperId": "e9540a9611fd85d556308deec5e3c3def017667e", "url": "https://www.semanticscholar.org/paper/e9540a9611fd85d556308deec5e3c3def017667e", "title": "Causal inference and counterfactual prediction in machine learning for actionable healthcare", "abstract": null, "year": 2020, "referenceCount": 102, "citationCount": 97, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144270737", "name": "M. Prosperi"}, {"authorId": "46791561", "name": "Yi Guo"}, {"authorId": "2715187", "name": "M. Sperrin"}, {"authorId": "39721843", "name": "J. Koopman"}, {"authorId": "145545650", "name": "Jae Min"}, {"authorId": "153003061", "name": "Xing He"}, {"authorId": "144075547", "name": "S. Rich"}, {"authorId": "2109019099", "name": "Mo Wang"}, {"authorId": "39525949", "name": "I. Buchan"}, {"authorId": "152441499", "name": "J. Bian"}]}, {"paperId": "0132b27e3681ce910ae74643e33a53b74bd5f5c7", "url": "https://www.semanticscholar.org/paper/0132b27e3681ce910ae74643e33a53b74bd5f5c7", "title": "Learning Steady-States of Iterative Algorithms over Graphs", "abstract": "Many graph analytics problems can be solved via iterative algorithms where the solutions are often characterized by a set of steady-state conditions. Different algorithms respect to different set of fixed point constraints, so instead of using these traditional algorithms, can we learn an algorithm which can obtain the same steady-state solutions automatically from examples, in an effective and scalable way? How to represent the meta learner for such algorithm and how to carry out the learning? In this paper, we propose an embedding representation for iterative algorithms over graphs, and design a learning method which alternates between updating the embeddings and projecting them onto the steadystate constraints. We demonstrate the effectiveness of our framework using a few commonly used graph algorithms, and show that in some cases, the learned algorithm can handle graphs with more than 100,000,000 nodes in a single machine.", "year": 2018, "referenceCount": 25, "citationCount": 122, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2791430", "name": "H. Dai"}, {"authorId": "1714932", "name": "Zornitsa Kozareva"}, {"authorId": "144445933", "name": "Bo Dai"}, {"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "1779453", "name": "Le Song"}]}, {"paperId": "e9253bf2ff09858a0dc07293071225e9a1d1d534", "url": "https://www.semanticscholar.org/paper/e9253bf2ff09858a0dc07293071225e9a1d1d534", "title": "Deep architectures for modulation recognition", "abstract": "We survey the latest advances in machine learning with deep neural networks by applying them to the task of radio modulation recognition. Results show that ratio modulation recognition is not limited by network depth and further work should focus on improving learned synchronization and equalization. Advances in these areas will likely come from novel architectures designed for these tasks or through novel training methods.", "year": 2017, "referenceCount": 27, "citationCount": 241, "influentialCitationCount": 33, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145028728", "name": "Nathan E. West"}, {"authorId": "1388350203", "name": "Tim O'Shea"}]}, {"paperId": "a10e79e21be020daab308d0fb5aafe3b3efa5adf", "url": "https://www.semanticscholar.org/paper/a10e79e21be020daab308d0fb5aafe3b3efa5adf", "title": "COMPARISON OF MACHINE LEARNING ALGORITHMS RANDOM FOREST, ARTIFICIAL NEURAL NETWORK AND SUPPORT VECTOR MACHINE TO MAXIMUM LIKELIHOOD FOR SUPERVISED CROP TYPE CLASSIFICATION", "abstract": "The classification and recognition of agricultural crop types is an important application of remote sensing. New machine learning algorithms have emerged in the last years, but so far, few studies only have compared their performance and usability. Therefore, we compared three different state-of-the-art machine learning classifiers, namely Support Vector Machine (SVM), Artificial Neural Network (ANN) and Random Forest (RF) as well as the traditional classification method Maximum Likelihood (ML) among each other. For this purpose we classified a dataset of more than 500 crop fields located in the Canadian Prairies with a stratified randomized sampling approach. Up to four multi-spectral RapidEye images from the 2009 growing season were used. We compared the mean overall classification accuracies as well as standard deviations. Furthermore, the classification accuracy of single crops was analysed. Support Vector Machine classifiers using radial basis function or polynomial kernels exhibited superior results to ANN and RF in terms of overall accuracy and robustness, while ML exhibited inferior accuracies and higher variability. Grassland exhibited the best results for early-season mono-temporal analysis. With a multi-temporal approach, the highest accuracies were achieved for Rapeseed and Field Peas. Other crops, such as Wheat, Flax and Lentils were also successfully classified. The user\u2019s and producer\u2019s accuracies were higher than 85 %.", "year": 2012, "referenceCount": 17, "citationCount": 152, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "3172845", "name": "I. Nitze"}, {"authorId": "86904928", "name": "U. Schulthess"}, {"authorId": "3295834", "name": "H. Asche"}]}, {"paperId": "96b7e0ba9b7d13f0dde49d42ab94b58aac3a8e3e", "url": "https://www.semanticscholar.org/paper/96b7e0ba9b7d13f0dde49d42ab94b58aac3a8e3e", "title": "Read the fine print", "abstract": null, "year": 2015, "referenceCount": 9, "citationCount": 160, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "20996436", "name": "S. Aaronson"}]}, {"paperId": "4e7bad15b12e1ecd07ed7541c80bcf5e6ff89f0e", "url": "https://www.semanticscholar.org/paper/4e7bad15b12e1ecd07ed7541c80bcf5e6ff89f0e", "title": "Mapping of hyperspectral AVIRIS data using machine-learning algorithms", "abstract": "Hyperspectral imaging provides detailed spectral and spatial information from the land cover that enables a precise differentiation between various surface materials. On the other hand, the performance of traditional and widely used statistical classification methods is often limited in this context, and thus alternative methods are required. In the study presented here, the performance of two machine-learning techniques, namely support vector machines (SVMs) and random forests (RFs), is investigated and the classification results are compared with those from well-known methods (i.e., maximum likelihood classifier and spectral angle mapper). The classifiers are applied to an Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) dataset that was acquired near the Hekla volcano in Iceland. The results clearly show the advantages of the two proposed classifier algorithms in terms of accuracy. They significantly outperform the other methods and achieve overall accuracies of approximately 90%. Although SVM and RF show some diversity in the classification results, the global performance of the two classifiers is very similar. Thus, both methods can be considered attractive for the classification of hyperspectral data.", "year": 2009, "referenceCount": 46, "citationCount": 130, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Geography"], "authors": [{"authorId": "2642030", "name": "B. Waske"}, {"authorId": "1682001", "name": "J. Benediktsson"}, {"authorId": "40354497", "name": "K. \u00c1rnason"}, {"authorId": "1728860", "name": "J. Sveinsson"}]}, {"paperId": "1c1ea4eaf2c5ec2fb55debcbfa2bc8c07a821435", "url": "https://www.semanticscholar.org/paper/1c1ea4eaf2c5ec2fb55debcbfa2bc8c07a821435", "title": "Convexity, Classification, and Risk Bounds", "abstract": "Many of the classification algorithms developed in the machine learning literature, including the support vector machine and boosting, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0\u20131 loss function. The convexity makes these algorithms computationally efficient. The use of a surrogate, however, has statistical consequences that must be balanced against the computational virtues of convexity. To study these issues, we provide a general quantitative relationship between the risk as assessed using the 0\u20131 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial upper bounds on excess risk under the weakest possible condition on the loss function\u2014that it satisfies a pointwise form of Fisher consistency for classification. The relationship is based on a simple variational transformation of the loss function that is easy to compute in many applications. We also present a refined version of this result in the case of low noise, and show that in this case, strictly convex loss functions lead to faster rates of convergence of the risk than would be implied by standard uniform convergence arguments. Finally, we present applications of our results to the estimation of convergence rates in function classes that are scaled convex hulls of a finite-dimensional base class, with a variety of commonly used loss functions.", "year": 2006, "referenceCount": 81, "citationCount": 1245, "influentialCitationCount": 184, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1745169", "name": "P. Bartlett"}, {"authorId": "1694621", "name": "Michael I. Jordan"}, {"authorId": "40411909", "name": "Jon D. McAuliffe"}]}, {"paperId": "c01a881f50341a688d5677e77a17963f9e80ffde", "url": "https://www.semanticscholar.org/paper/c01a881f50341a688d5677e77a17963f9e80ffde", "title": "Practical Solutions for Machine Learning Safety in Autonomous Vehicles", "abstract": "Autonomous vehicles rely on machine learning to solve challenging tasks in perception and motion planning. However, automotive software safety standards have not fully evolved to address the challenges of machine learning safety such as interpretability, verification, and performance limitations. In this paper, we review and organize practical machine learning safety techniques that can complement engineering safety for machine learning based software in autonomous vehicles. Our organization maps safety strategies to state-of-the-art machine learning techniques in order to enhance dependability and safety of machine learning algorithms. We also discuss security limitations and user experience aspects of machine learning components in autonomous vehicles.", "year": 2019, "referenceCount": 55, "citationCount": 35, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3228458", "name": "Sina Mohseni"}, {"authorId": "118527696", "name": "Mandar Pitale"}, {"authorId": "39155463", "name": "Vasu Singh"}, {"authorId": "2969311", "name": "Zhangyang Wang"}]}, {"paperId": "d50460e89233c502b70b1e7dcf3fad9da5697f03", "url": "https://www.semanticscholar.org/paper/d50460e89233c502b70b1e7dcf3fad9da5697f03", "title": "Applications of Machine Learning in Cyber Security", "abstract": "With the exponential rise in technological awareness in the recent decades, technology has taken over our lives for good, but with the application of computer-aided technological systems in various domains of our day-to-day lives, the potential risks and threats have also come to the fore, aiming at the various security features that include confidentiality, integrity, authentication, authorization, and so on. Computer scientists the world over have tried to come up, time and again, with solutions to these impending problems. With time, attackers have played out complicated attacks on systems that are hard to comprehend and even harder to mitigate. The very fact that a huge amount of data is processed each second in organizations gave birth to the concept of Big Data, thereby making the systems more adept and intelligent in dealing with unprecedented attacks on a real-time basis. This chapter presents a study about applications of machine learning algorithms in cyber security.", "year": 2020, "referenceCount": 27, "citationCount": 33, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9374721", "name": "Charu Virmani"}, {"authorId": "148187183", "name": "Tanu Choudhary"}, {"authorId": "9355020", "name": "Anuradha Pillai"}, {"authorId": "2056086037", "name": "M. Rani"}]}, {"paperId": "ce10676634b0c8299a27c3303049c60d6ecbf87d", "url": "https://www.semanticscholar.org/paper/ce10676634b0c8299a27c3303049c60d6ecbf87d", "title": "Interpretability of deep learning models: A survey of results", "abstract": "Deep neural networks have achieved near-human accuracy levels in various types of classification and prediction tasks including images, text, speech, and video data. However, the networks continue to be treated mostly as black-box function approximators, mapping a given input to a classification output. The next step in this human-machine evolutionary process \u2014 incorporating these networks into mission critical processes such as medical diagnosis, planning and control \u2014 requires a level of trust association with the machine output. Typically, statistical metrics are used to quantify the uncertainty of an output. However, the notion of trust also depends on the visibility that a human has into the working of the machine. In other words, the neural network should provide human-understandable justifications for its output leading to insights about the inner workings. We call such models as interpretable deep networks. Interpretability is not a monolithic notion. In fact, the subjectivity of an interpretation, due to different levels of human understanding, implies that there must be a multitude of dimensions that together constitute interpretability. In addition, the interpretation itself can be provided either in terms of the low-level network parameters, or in terms of input features used by the model. In this paper, we outline some of the dimensions that are useful for model interpretability, and categorize prior work along those dimensions. In the process, we perform a gap analysis of what needs to be done to improve model interpretability.", "year": 2017, "referenceCount": 47, "citationCount": 241, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144387904", "name": "Supriyo Chakraborty"}, {"authorId": "50998197", "name": "Richard J. Tomsett"}, {"authorId": "34164013", "name": "R. Raghavendra"}, {"authorId": "51021483", "name": "Daniel Harborne"}, {"authorId": "3030212", "name": "M. Alzantot"}, {"authorId": "1721540", "name": "F. Cerutti"}, {"authorId": "1702254", "name": "M. Srivastava"}, {"authorId": "1762890", "name": "A. Preece"}, {"authorId": "1751475", "name": "S. Julier"}, {"authorId": "145507684", "name": "R. Rao"}, {"authorId": "2331780", "name": "T. Kelley"}, {"authorId": "2215679", "name": "Dave Braines"}, {"authorId": "1715430", "name": "M. Sensoy"}, {"authorId": "51295510", "name": "C. Willis"}, {"authorId": "1804334", "name": "Prudhvi K. Gurram"}]}, {"paperId": "c7538affc2aa9f7c3127583a42a636eb7f27818f", "url": "https://www.semanticscholar.org/paper/c7538affc2aa9f7c3127583a42a636eb7f27818f", "title": "Applications of Machine Learning Methods to Genomic Selection in Breeding Wheat for Rust Resistance", "abstract": "Genomic\u2010enabled prediction Machine learning Wheat breeding Rust resistance", "year": 2018, "referenceCount": 82, "citationCount": 76, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "1401765575", "name": "J. M. GONZ\u00c1LEZ-CAMACHO"}, {"authorId": "50209055", "name": "L. Ornella"}, {"authorId": "1399269445", "name": "P. P\u00e9rez-Rodr\u00edguez"}, {"authorId": "5460852", "name": "D. Gianola"}, {"authorId": "8047697", "name": "S. Dreisigacker"}, {"authorId": "40572013", "name": "J. Crossa"}]}, {"paperId": "84e32cdb2a9e2fba5794f25fdd6f30cf33cdc2c2", "url": "https://www.semanticscholar.org/paper/84e32cdb2a9e2fba5794f25fdd6f30cf33cdc2c2", "title": "Machine learning and computer vision approaches for phenotypic profiling", "abstract": "Grys et al. review computer vision and machine-learning methods that have been applied to phenotypic profiling of image-based data. Descriptions are provided for segmentation, feature extraction, selection, and dimensionality reduction, as well as clustering, outlier detection, and classification of data.", "year": 2017, "referenceCount": 80, "citationCount": 117, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "10331061", "name": "Ben T Grys"}, {"authorId": "6055019", "name": "Dara S Lo"}, {"authorId": "144920147", "name": "Nil Sahin"}, {"authorId": "40031925", "name": "Oren Z. Kraus"}, {"authorId": "1731810", "name": "Q. Morris"}, {"authorId": "145538763", "name": "Charles Boone"}, {"authorId": "1710778", "name": "B. Andrews"}]}, {"paperId": "5b18fda1f3e067e897089c4d439603844a71a1a3", "url": "https://www.semanticscholar.org/paper/5b18fda1f3e067e897089c4d439603844a71a1a3", "title": "An integrated machine learning approach to stroke prediction", "abstract": "Stroke is the third leading cause of death and the principal cause of serious long-term disability in the United States. Accurate prediction of stroke is highly valuable for early intervention and treatment. In this study, we compare the Cox proportional hazards model with a machine learning approach for stroke prediction on the Cardiovascular Health Study (CHS) dataset. Specifically, we consider the common problems of data imputation, feature selection, and prediction in medical datasets. We propose a novel automatic feature selection algorithm that selects robust features based on our proposed heuristic: conservative mean. Combined with Support Vector Machines (SVMs), our proposed feature selection algorithm achieves a greater area under the ROC curve (AUC) as compared to the Cox proportional hazards model and L1 regularized Cox feature selection algorithm. Furthermore, we present a margin-based censored regression algorithm that combines the concept of margin-based classifiers with censored regression to achieve a better concordance index than the Cox model. Overall, our approach outperforms the current state-of-the-art in both metrics of AUC and concordance index. In addition, our work has also identified potential risk factors that have not been discovered by traditional approaches. Our method can be applied to clinical prediction of other diseases, where missing data are common and risk factors are not well understood.", "year": 2010, "referenceCount": 45, "citationCount": 126, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2556428", "name": "A. Khosla"}, {"authorId": "144149886", "name": "Yu Cao"}, {"authorId": "2585821", "name": "Cliff Chiung-Yu Lin"}, {"authorId": "3306760", "name": "Hsu-kuang Chiu"}, {"authorId": "2117230730", "name": "Junling Hu"}, {"authorId": "1697141", "name": "Honglak Lee"}]}, {"paperId": "f7a81ee4f293f1b6cedf90535af51a3e770cd8eb", "url": "https://www.semanticscholar.org/paper/f7a81ee4f293f1b6cedf90535af51a3e770cd8eb", "title": "Medical Dataset Classification: A Machine Learning Paradigm Integrating Particle Swarm Optimization with Extreme Learning Machine Classifier", "abstract": "Medical data classification is a prime data mining problem being discussed about for a decade that has attracted several researchers around the world. Most classifiers are designed so as to learn from the data itself using a training process, because complete expert knowledge to determine classifier parameters is impracticable. This paper proposes a hybrid methodology based on machine learning paradigm. This paradigm integrates the successful exploration mechanism called self-regulated learning capability of the particle swarm optimization (PSO) algorithm with the extreme learning machine (ELM) classifier. As a recent off-line learning method, ELM is a single-hidden layer feedforward neural network (FFNN), proved to be an excellent classifier with large number of hidden layer neurons. In this research, PSO is used to determine the optimum set of parameters for the ELM, thus reducing the number of hidden layer neurons, and it further improves the network generalization performance. The proposed method is experimented on five benchmarked datasets of the UCI Machine Learning Repository for handling medical dataset classification. Simulation results show that the proposed approach is able to achieve good generalization performance, compared to the results of other classifiers.", "year": 2015, "referenceCount": 38, "citationCount": 59, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "33719529", "name": "C. Subbulakshmi"}, {"authorId": "143939682", "name": "S. Deepa"}]}, {"paperId": "573d42695ea8311c39487e0b9ba21c6f3320bead", "url": "https://www.semanticscholar.org/paper/573d42695ea8311c39487e0b9ba21c6f3320bead", "title": "CAIM discretization algorithm", "abstract": "The task of extracting knowledge from databases is quite often performed by machine learning algorithms. The majority of these algorithms can be applied only to data described by discrete numerical or nominal attributes (features). In the case of continuous attributes, there is a need for a discretization algorithm that transforms continuous attributes into discrete ones. We describe such an algorithm, called CAIM (class-attribute interdependence maximization), which is designed to work with supervised data. The goal of the CAIM algorithm is to maximize the class-attribute interdependence and to generate a (possibly) minimal number of discrete intervals. The algorithm does not require the user to predefine the number of intervals, as opposed to some other discretization algorithms. The tests performed using CAIM and six other state-of-the-art discretization algorithms show that discrete attributes generated by the CAIM algorithm almost always have the lowest number of intervals and the highest class-attribute interdependency. Two machine learning algorithms, the CLIP4 rule algorithm and the decision tree algorithm, are used to generate classification rules from data discretized by CAIM. For both the CLIP4 and decision tree algorithms, the accuracy of the generated rules is higher and the number of the rules is lower for data discretized using the CAIM algorithm when compared to data discretized using six other discretization algorithms. The highest classification accuracy was achieved for data sets discretized with the CAIM algorithm, as compared with the other six algorithms.", "year": 2004, "referenceCount": 32, "citationCount": 435, "influentialCitationCount": 42, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1721347", "name": "Lukasz Kurgan"}, {"authorId": "2810659", "name": "K. Cios"}]}, {"paperId": "5eca51c7d165860758a29334e7d64225c8f0788b", "url": "https://www.semanticscholar.org/paper/5eca51c7d165860758a29334e7d64225c8f0788b", "title": "Machine learning for crystal identification and discovery", "abstract": "As computers get faster, researchers -- not hardware or algorithms -- become the bottleneck in scientific discovery. Computational study of colloidal self-assembly is one area that is keenly affected: even after computers generate massive amounts of raw data, performing an exhaustive search to determine what (if any) ordered structures occur in a large parameter space of many simulations can be excruciating. We demonstrate how machine learning can be applied to discover interesting areas of parameter space in colloidal self assembly. We create numerical fingerprints -- inspired by bond orientational order diagrams -- of structures found in self-assembly studies and use these descriptors to both find interesting regions in a phase diagram and identify characteristic local environments in simulations in an automated manner for simple and complex crystal structures. Utilizing these methods allows analysis methods to keep up with the data generation ability of modern high-throughput computing environments.", "year": 2017, "referenceCount": 44, "citationCount": 76, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Materials Science"], "authors": [{"authorId": "143601761", "name": "Matthew Spellings"}, {"authorId": "145205400", "name": "S. Glotzer"}]}, {"paperId": "33051bfb4bbf12431b8ab6bc8e33396d09a5448c", "url": "https://www.semanticscholar.org/paper/33051bfb4bbf12431b8ab6bc8e33396d09a5448c", "title": "A new concept using LSTM Neural Networks for dynamic system identification", "abstract": "Recently, Recurrent Neural Network becomes a very popular research topic in machine learning field. Many new ideas and RNN structures have been generated by different authors, including long short term memory (LSTM) RNN and Gated Recurrent United (GRU) RNN ([1],[2]), a number of applications have also been developed among various research labs or industrial companies ([3]-[5]). Most of these schemes, however, are only applicable to machine learning problems, or static systems in control field. In this paper, a new concept of applying one of the most popular RNN approach - LSTM to identify and control dynamic system is to be investigated. Both identification (or learning) dynamic system and design of controller based on identification are going to be discussed. Also, a new concept of using a convex-based LSTM networks for fast learning purpose will be explained in detail. Simulation studies will be presented to demonstrated the new LSTM structure performs much better than conventional RNN and even single LSTM network.", "year": 2017, "referenceCount": 28, "citationCount": 117, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "119918316", "name": "Yu Wang"}]}, {"paperId": "fd5b57c083ac298330d9109373b2347720379b5d", "url": "https://www.semanticscholar.org/paper/fd5b57c083ac298330d9109373b2347720379b5d", "title": "Towards Machine Learning on the Semantic Web", "abstract": null, "year": 2008, "referenceCount": 138, "citationCount": 54, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1700754", "name": "Volker Tresp"}, {"authorId": "2168590", "name": "Markus Bundschus"}, {"authorId": "1748257", "name": "Achim Rettinger"}, {"authorId": "145905495", "name": "Yi Huang"}]}, {"paperId": "00baed147e80e1fd38816f09f0e9eda4981286d3", "url": "https://www.semanticscholar.org/paper/00baed147e80e1fd38816f09f0e9eda4981286d3", "title": "Khiops: A Statistical Discretization Method of Continuous Attributes", "abstract": null, "year": 2004, "referenceCount": 22, "citationCount": 124, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1714638", "name": "M. Boull\u00e9"}]}, {"paperId": "9fddc0f3e54bbc2dd08a2d4b660f88add5212ff5", "url": "https://www.semanticscholar.org/paper/9fddc0f3e54bbc2dd08a2d4b660f88add5212ff5", "title": "Evaluation of Classification Models in Machine Learning", "abstract": "We study the problem of evaluation of di\ufb00erent classification models that are used in machine learning. The reason of the model evaluation is to find the optimal solution from various classification models generated in an iterated and complex model building process. Depending on the method of observing, there are di\ufb00erent measures for evaluation the performance of the model. To evaluate classification models the most direct criterion that can be measured quantitatively is the classification accuracy. The main disadvantages of accuracy as a measure for evaluation are as follows: neglects the di\ufb00erences between the types of errors and it dependent on the distribution of class in the dataset. In this paper we discussed selection of the most appropriate measures depends on the characteristics of the problem and the various ways it can be implemented.", "year": 2017, "referenceCount": 8, "citationCount": 75, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "144204205", "name": "J. Novakovic"}, {"authorId": "2136372", "name": "A. Veljovic"}, {"authorId": "2066663317", "name": "S. Ili\u0107"}, {"authorId": "103496406", "name": "\u017d. Papic"}, {"authorId": "104412188", "name": "Tomovi\u0107 Milica"}]}, {"paperId": "660ff427b97bda39a007687b777a3e1fae56be9d", "url": "https://www.semanticscholar.org/paper/660ff427b97bda39a007687b777a3e1fae56be9d", "title": "The production of prediction: What does machine learning want?", "abstract": "Retail, media, finance, science, industry, security and government increasingly depend on predictions produced through techniques such as machine learning. How is it that machine learning can promise to predict with great specificity what differences matter or what people want in many different settings? We need, I suggest, an account of its generalization if we are to understand the contemporary production of prediction. This article maps the principal forms of material action, narrative and problematization that run across algorithmic modelling techniques such as logistic regression, decision trees and Naive Bayes classifiers. It highlights several interlinked modes of generalization that engender increasingly vast data infrastructures and platforms, and intensified mathematical and statistical treatments of differences. Such an account also points to some key sites of instability or problematization inherent to the process of generalization. If movement through data is becoming a principal intersection of power relations, economic value and valid knowledge, an account of the production of prediction might also help us begin to ask how its generalization potentially gives rise to new forms of agency, experience or individuations.", "year": 2015, "referenceCount": 34, "citationCount": 122, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39822261", "name": "A. Mackenzie"}]}, {"paperId": "114ef99286c961337ad780a9e3451c63555e383b", "url": "https://www.semanticscholar.org/paper/114ef99286c961337ad780a9e3451c63555e383b", "title": "Teaching Machine Learning to Design Students", "abstract": null, "year": 2008, "referenceCount": 24, "citationCount": 22, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2214521", "name": "B. Vlist"}, {"authorId": "2821526", "name": "R. V. D. Westelaken"}, {"authorId": "1728894", "name": "C. Bartneck"}, {"authorId": "40705707", "name": "Jun Hu"}, {"authorId": "34704856", "name": "R. Ahn"}, {"authorId": "145741020", "name": "E. Barakova"}, {"authorId": "2819150", "name": "F. Delbressine"}, {"authorId": "144939886", "name": "L. Feijs"}]}, {"paperId": "4925f0256f2de9157a5a382002061d00ad4eb735", "url": "https://www.semanticscholar.org/paper/4925f0256f2de9157a5a382002061d00ad4eb735", "title": "Machine Learning and Data Mining in Pattern Recognition", "abstract": null, "year": 2000, "referenceCount": 22, "citationCount": 114, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144877016", "name": "M. Petrou"}, {"authorId": "2833363", "name": "P. Perner"}]}, {"paperId": "520ec00dc35475e0554dbb72f27bd2eeb6f4191d", "url": "https://www.semanticscholar.org/paper/520ec00dc35475e0554dbb72f27bd2eeb6f4191d", "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks", "abstract": "This paper describes a testing methodology for quantitatively assessing the risk that rare or unique training-data sequences are unintentionally memorized by generative sequence models---a common type of machine-learning model. Because such models are sometimes trained on sensitive data (e.g., the text of users' private messages), this methodology can benefit privacy by allowing deep-learning practitioners to select means of training that minimize such memorization. \nIn experiments, we show that unintended memorization is a persistent, hard-to-avoid issue that can have serious consequences. Specifically, for models trained without consideration of memorization, we describe new, efficient procedures that can extract unique, secret sequences, such as credit card numbers. We show that our testing strategy is a practical and easy-to-use first line of defense, e.g., by describing its application to quantitatively limit data exposure in Google's Smart Compose, a commercial text-completion neural network trained on millions of users' email messages.", "year": 2018, "referenceCount": 69, "citationCount": 487, "influentialCitationCount": 46, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2483738", "name": "Nicholas Carlini"}, {"authorId": "2118484320", "name": "Chang Liu"}, {"authorId": "1758110", "name": "\u00da. Erlingsson"}, {"authorId": "36426383", "name": "Jernej Kos"}, {"authorId": "143711382", "name": "D. Song"}]}, {"paperId": "e04a31bd8213aea7a11e1b16e90e114d5d28a7a8", "url": "https://www.semanticscholar.org/paper/e04a31bd8213aea7a11e1b16e90e114d5d28a7a8", "title": "Accelerated discovery of stable lead-free hybrid organic-inorganic perovskites via machine learning", "abstract": null, "year": 2018, "referenceCount": 90, "citationCount": 300, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Materials Science"], "authors": [{"authorId": "51218556", "name": "Shuaihua Lu"}, {"authorId": "9559823", "name": "Qionghua Zhou"}, {"authorId": "8879095", "name": "Y. Ouyang"}, {"authorId": "51212988", "name": "Yilv Guo"}, {"authorId": "2146262094", "name": "Qiang Li"}, {"authorId": "97773567", "name": "Jinlan Wang"}]}, {"paperId": "a88f71c0f63c3c0d791926179716985d65f2a87a", "url": "https://www.semanticscholar.org/paper/a88f71c0f63c3c0d791926179716985d65f2a87a", "title": "ECG Signal Preprocessing and SVM Classifier-Based Abnormality Detection in Remote Healthcare Applications", "abstract": "Medical expert systems are part of the portable and smart healthcare monitoring devices used in day-to-day life. Arrhythmic beat classification is mainly used in electrocardiogram (ECG) abnormality detection for identifying heart related problems. In this paper, ECG signal preprocessing and support vector machine-based arrhythmic beat classification are performed to categorize into normal and abnormal subjects. In ECG signal preprocessing, a delayed error normalized LMS adaptive filter is used to achieve high speed and low latency design with less computational elements. Since the signal processing technique is developed for remote healthcare systems, white noise removal is mainly focused. Discrete wavelet transform is applied on the preprocessed signal for HRV feature extraction and machine learning techniques are used for performing arrhythmic beat classification. In this paper, SVM classifier and other popular classifiers have been used on noise removed feature extracted signal for beat classification. Results indicate that the performance of SVM classifier is better than other machine learning-based classifiers.", "year": 2018, "referenceCount": 27, "citationCount": 136, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144901002", "name": "C. Venkatesan"}, {"authorId": "2307252", "name": "P. Karthigaikumar"}, {"authorId": "1940632", "name": "Anand Paul"}, {"authorId": "29426813", "name": "S. Satheeskumaran"}, {"authorId": "2149048321", "name": "R. Kumar"}]}, {"paperId": "bb38c180777326ed103ad0aa31545c8754da959f", "url": "https://www.semanticscholar.org/paper/bb38c180777326ed103ad0aa31545c8754da959f", "title": "Machine Learning Approaches to Bioinformatics", "abstract": "This book covers a wide range of subjects in applying machine learning approaches for bioinformatics projects. The book succeeds on two key unique features. First, it introduces the most widely used machine learning approaches in bioinformatics and discusses, with evaluations from real case studies, how they are used in individual bioinformatics projects. Second, it introduces state-of-the-art bioinformatics research methods. The theoretical parts and the practical parts are well integrated for readers to follow the existing procedures in individual research. Unlike most of the bioinformatics books on the market, the content coverage is not limited to just one subject. A broad spectrum of relevant topics in bioinformatics including systematic data mining and computational systems biology researches are brought together in this book, thereby offering an efficient and convenient platform for teaching purposes. An essential reference for both final year undergraduates and graduate students in universities, as well as a comprehensive handbook for new researchers, this book will also serve as a practical guide for software development in relevant bioinformatics projects.", "year": 2010, "referenceCount": 481, "citationCount": 52, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31272605", "name": "Z. Yang"}]}, {"paperId": "4e7a77326bc8fcf64943aab06c658c27ec28ec55", "url": "https://www.semanticscholar.org/paper/4e7a77326bc8fcf64943aab06c658c27ec28ec55", "title": "A Quasi-Newton Approach to Nonsmooth Convex Optimization Problems in Machine Learning", "abstract": "We extend the well-known BFGS quasi-Newton method and its memory-limited variant LBFGS to the optimization of nonsmooth convex objectives. This is done in a rigorous fashion by generalizing three components of BFGS to subdifferentials: the local quadratic model, the identification of a descent direction, and the Wolfe line search conditions. We prove that under some technical conditions, the resulting subBFGS algorithm is globally convergent in objective function value. We apply its memory-limited variant (subLBFGS) to L2-regularized risk minimization with the binary hinge loss. To extend our algorithm to the multiclass and multilabel settings, we develop a new, efficient, exact line search algorithm. We prove its worst-case time complexity bounds, and show that our line search can also be used to extend a recently developed bundle method to the multiclass and multilabel settings. We also apply the direction-finding component of our algorithm to L1-regularized risk minimization with logistic loss. In all these contexts our methods perform comparable to or better than specialized state-of-the-art solvers on a number of publicly available data sets. An open source implementation of our algorithms is freely available.", "year": 2008, "referenceCount": 49, "citationCount": 110, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "40565216", "name": "Jin Yu"}, {"authorId": "145713876", "name": "S. Vishwanathan"}, {"authorId": "2105506680", "name": "Simon G\u00fcnter"}, {"authorId": "1739396", "name": "N. Schraudolph"}]}, {"paperId": "3eae3a2fe22117e640f00661f1daaee341653882", "url": "https://www.semanticscholar.org/paper/3eae3a2fe22117e640f00661f1daaee341653882", "title": "Sentiment Classification using Machine Learning Techniques", "abstract": "Large amount of information are available online on web.The discussion forum, review sites, blogs are some of the opinion rich resources where review or posted articles is their sentiment, or overall opinion towards the subject matter. The opinions obtained from those can be classified in to positive or negative which can be used by customer to make product choice and by businessmen for finding customer satisfaction .This paper studies online movie reviews using sentiment analysis approaches. In this study, sentiment classification techniques were applied to movie reviews. Specifically, we compared two supervised machine learning approaches SVM, Navie Bayes for Sentiment Classification of Reviews. Results states that Na\u00efve Bayes approach outperformed the svm. If the training dataset had a large number of reviews, Naive bayes approach reached high accuracies as compare to other.", "year": 2016, "referenceCount": 8, "citationCount": 75, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2102642255", "name": "Suchita V Wawre"}, {"authorId": "35255645", "name": "S. Deshmukh"}]}, {"paperId": "53c8dccd276876b0c030f59dedea382c90af00da", "url": "https://www.semanticscholar.org/paper/53c8dccd276876b0c030f59dedea382c90af00da", "title": "DNA methylation-based classification of central nervous system tumours", "abstract": null, "year": 2018, "referenceCount": 51, "citationCount": 1317, "influentialCitationCount": 45, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "150964707", "name": "D. Capper"}, {"authorId": "145513781", "name": "David T. W. Jones"}, {"authorId": "11508752", "name": "M. Sill"}, {"authorId": "6300116", "name": "V. Hovestadt"}, {"authorId": "7450979", "name": "D. Schrimpf"}, {"authorId": "1754320", "name": "D. Sturm"}, {"authorId": "6430963", "name": "C. Koelsche"}, {"authorId": "5125548", "name": "F. Sahm"}, {"authorId": "144045561", "name": "L. Chavez"}, {"authorId": "3197783", "name": "D. Reuss"}, {"authorId": "32141757", "name": "A. Kratz"}, {"authorId": "5076736", "name": "A. Wefers"}, {"authorId": "6703701", "name": "K. Huang"}, {"authorId": "5629795", "name": "K. Pajtler"}, {"authorId": "1813549", "name": "L. Schweizer"}, {"authorId": "4610419", "name": "D. Stichel"}, {"authorId": "3805956", "name": "A. Olar"}, {"authorId": "8629734", "name": "Nils W. Engel"}, {"authorId": "153341912", "name": "K. Lindenberg"}, {"authorId": "36933618", "name": "P. Harter"}, {"authorId": "4328654", "name": "Anne K. Braczynski"}, {"authorId": "4226732", "name": "K. Plate"}, {"authorId": "2604069", "name": "H. Dohmen"}, {"authorId": "3772997", "name": "B. Garvalov"}, {"authorId": "5676334", "name": "R. Coras"}, {"authorId": "6835204", "name": "A. H\u00f6lsken"}, {"authorId": "3771241", "name": "E. Hewer"}, {"authorId": "1397986885", "name": "M. Bewerunge-Hudler"}, {"authorId": "50350089", "name": "M. Schick"}, {"authorId": "46901168", "name": "R. Fischer"}, {"authorId": "2421697", "name": "R. Beschorner"}, {"authorId": "4567626", "name": "J. Schittenhelm"}, {"authorId": "4826299", "name": "O. Staszewski"}, {"authorId": "7201089", "name": "K. Wani"}, {"authorId": "4985728", "name": "P. Varlet"}, {"authorId": "38782018", "name": "M. Pages"}, {"authorId": "3871296", "name": "P. Temming"}, {"authorId": "49706261", "name": "D. Lohmann"}, {"authorId": "5034596", "name": "F. Selt"}, {"authorId": "46977555", "name": "H. Witt"}, {"authorId": "48681633", "name": "T. Milde"}, {"authorId": "3287653", "name": "O. Witt"}, {"authorId": "2369251", "name": "E. Aronica"}, {"authorId": "3918072", "name": "F. Giangaspero"}, {"authorId": "4147674", "name": "E. Rushing"}, {"authorId": "48339362", "name": "W. Scheurlen"}, {"authorId": "3661976", "name": "C. Geisenberger"}, {"authorId": "144893518", "name": "F. Rodriguez"}, {"authorId": "40650735", "name": "A. Becker"}, {"authorId": "144646703", "name": "M. Preusser"}, {"authorId": "4885069", "name": "C. Haberler"}, {"authorId": "5396878", "name": "R. Bjerkvig"}, {"authorId": "5724085", "name": "J. Cryan"}, {"authorId": "143841590", "name": "M. Farrell"}, {"authorId": "3562286", "name": "M. Deckert"}, {"authorId": "2831885", "name": "J. Hench"}, {"authorId": "1784029", "name": "S. Frank"}, {"authorId": "49939652", "name": "J. Serrano"}, {"authorId": "49813122", "name": "Kasthuri Kannan"}, {"authorId": "2669575", "name": "A. Tsirigos"}, {"authorId": "2665083", "name": "W. Br\u00fcck"}, {"authorId": "31951653", "name": "S. Hofer"}, {"authorId": "3088038", "name": "S. Brehmer"}, {"authorId": "1390177203", "name": "M. Seiz-Rosenhagen"}, {"authorId": "3788823", "name": "D. H\u00e4nggi"}, {"authorId": "144027971", "name": "V. Hans"}, {"authorId": "7362538", "name": "S. Rozsnoki"}, {"authorId": "6555485", "name": "J. Hansford"}, {"authorId": "8071420", "name": "P. Kohlhof"}, {"authorId": "2884845", "name": "B. Kristensen"}, {"authorId": "40168732", "name": "M. Lechner"}, {"authorId": "133711375", "name": "Beatriz Lopes"}, {"authorId": "5221334", "name": "C. Mawrin"}, {"authorId": "5404699", "name": "R. Ketter"}, {"authorId": "3917770", "name": "A. Kulozik"}, {"authorId": "69523137", "name": "Z. Khatib"}, {"authorId": "3568640", "name": "F. Heppner"}, {"authorId": "113308083", "name": "A. Koch"}, {"authorId": "4166413", "name": "A. Jouvet"}, {"authorId": "3176589", "name": "C. Keohane"}, {"authorId": "32425312", "name": "H. M\u00fchleisen"}, {"authorId": "2066546374", "name": "W. M\u00fcller"}, {"authorId": "46929437", "name": "U. Pohl"}, {"authorId": "2406999", "name": "M. Prinz"}, {"authorId": "2836909", "name": "A. Benner"}, {"authorId": "2290088", "name": "M. Zapatka"}, {"authorId": "5041694", "name": "N. Gottardo"}, {"authorId": "6145431", "name": "P. H. Driever"}, {"authorId": "4012604", "name": "C. Kramm"}, {"authorId": "2151194298", "name": "H. M\u00fcller"}, {"authorId": "145578932", "name": "S. Rutkowski"}, {"authorId": "6944131", "name": "K. Hoff"}, {"authorId": "4292917", "name": "M. Fr\u00fchwald"}, {"authorId": "4223778", "name": "A. Gnekow"}, {"authorId": "5238371", "name": "G. Fleischhack"}, {"authorId": "3717627", "name": "S. Tippelt"}, {"authorId": "3889115", "name": "G. Calaminus"}, {"authorId": "153554607", "name": "C. Monoranu"}, {"authorId": "144144978", "name": "A. Perry"}, {"authorId": "49037136", "name": "Chris Jones"}, {"authorId": "4682456", "name": "T. Jacques"}, {"authorId": "10271830", "name": "B. Radlwimmer"}, {"authorId": "3990616", "name": "M. Gessi"}, {"authorId": "144208043", "name": "T. Pietsch"}, {"authorId": "145237467", "name": "J. Schramm"}, {"authorId": "2672469", "name": "G. Schackert"}, {"authorId": "144140243", "name": "M. Westphal"}, {"authorId": "4995271", "name": "G. Reifenberger"}, {"authorId": "3053722", "name": "P. Wesseling"}, {"authorId": "145115639", "name": "M. Weller"}, {"authorId": "3241447", "name": "V. P. Collins"}, {"authorId": "2750453", "name": "I. Bl\u00fcmcke"}, {"authorId": "2685024", "name": "M. Bendszus"}, {"authorId": "144161333", "name": "J. Debus"}, {"authorId": "13020147", "name": "A. Huang"}, {"authorId": "3732933", "name": "N. Jabado"}, {"authorId": "5309415", "name": "P. Northcott"}, {"authorId": "144869687", "name": "W. Paulus"}, {"authorId": "3732235", "name": "A. Gajjar"}, {"authorId": "1770903", "name": "G. Robinson"}, {"authorId": "150235843", "name": "Michael D. Taylor"}, {"authorId": "3788181", "name": "Z. Jaunmuktane"}, {"authorId": "32102893", "name": "M. Ryzhova"}, {"authorId": "2141376259", "name": "M. Platten"}, {"authorId": "3290065", "name": "A. Unterberg"}, {"authorId": "2707080", "name": "W. Wick"}, {"authorId": "6487782", "name": "M. Karajannis"}, {"authorId": "143674804", "name": "M. Mittelbronn"}, {"authorId": "1896568", "name": "T. Acker"}, {"authorId": "144691766", "name": "C. Hartmann"}, {"authorId": "50138848", "name": "K. Aldape"}, {"authorId": "145723359", "name": "U. Sch\u00fcller"}, {"authorId": "144766329", "name": "R. Buslei"}, {"authorId": "2638155", "name": "P. Lichter"}, {"authorId": "4168100", "name": "M. Kool"}, {"authorId": "1389233110", "name": "C. Herold\u2010Mende"}, {"authorId": "145839173", "name": "D. Ellison"}, {"authorId": "4629270", "name": "M. Hasselblatt"}, {"authorId": "3579975", "name": "M. Snuderl"}, {"authorId": "2462761", "name": "S. Brandner"}, {"authorId": "145083277", "name": "A. Korshunov"}, {"authorId": "7536198", "name": "A. Deimling"}, {"authorId": "145320843", "name": "S. Pfister"}]}, {"paperId": "784b018c87c7dcbbe772374e45d5191bae9938ee", "url": "https://www.semanticscholar.org/paper/784b018c87c7dcbbe772374e45d5191bae9938ee", "title": "Hyperbolic Graph Neural Networks", "abstract": "Learning from graph-structured data is an important task in machine learning and artificial intelligence, for which Graph Neural Networks (GNNs) have shown great promise. Motivated by recent advances in geometric representation learning, we propose a novel GNN architecture for learning representations on Riemannian manifolds with differentiable exponential and logarithmic maps. We develop a scalable algorithm for modeling the structural properties of graphs, comparing Euclidean and hyperbolic geometry. In our experiments, we show that hyperbolic GNNs can lead to substantial improvements on various benchmark datasets.", "year": 2019, "referenceCount": 52, "citationCount": 156, "influentialCitationCount": 20, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2144831836", "name": "Qi Liu"}, {"authorId": "1729762", "name": "Maximilian Nickel"}, {"authorId": "1743722", "name": "Douwe Kiela"}]}, {"paperId": "92f20a1e21a20ab24ce7e335b6f1844b92515864", "url": "https://www.semanticscholar.org/paper/92f20a1e21a20ab24ce7e335b6f1844b92515864", "title": "Introduction to Machine Learning with Python: A Guide for Data Scientists", "abstract": " ", "year": 2016, "referenceCount": 0, "citationCount": 442, "influentialCitationCount": 43, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2113786044", "name": "Andreas M\u00fcller"}, {"authorId": "2094280216", "name": "Sarah Guido"}]}, {"paperId": "a5081733ffda51d1418a7317ac17543525ef61c3", "url": "https://www.semanticscholar.org/paper/a5081733ffda51d1418a7317ac17543525ef61c3", "title": "Renew", "abstract": "Massive multiple-input multiple-output (mMIMO) technology uses a very large number of antennas at base stations to significantly increase efficient use of the wireless spectrum. Thus, mMIMO is considered an essential part of 5G and beyond. However, developing a scalable and reliable mMIMO system is an extremely challenging task, significantly hampering the ability of the research community to research nextgeneration networks. This \"research bottleneck\" motivated us to develop a deployable experimental mMIMO platform to enable research across many areas. We also envision that this platform could unleash novel collaborations between communications, computing, and machine learning researchers to completely rethink next-generation networks.", "year": 2022, "referenceCount": 6, "citationCount": 559, "influentialCitationCount": 24, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1405698997", "name": "Rahman Doost-Mohammady"}, {"authorId": "2112683608", "name": "Lin Zhong"}, {"authorId": "2064337919", "name": "Ashutosh Sabharwal"}]}, {"paperId": "a7389bf99e4201a3f9230117df594bddc8ed5bcf", "url": "https://www.semanticscholar.org/paper/a7389bf99e4201a3f9230117df594bddc8ed5bcf", "title": "Chemoinformatics and Advanced Machine Learning Perspectives: Complex Computational Methods and Collaborative Techniques", "abstract": "Chemoinformatics is a scientific area that endeavours to study and solve complex chemical problems using computational techniques and methods. Chemoinformatics and Advanced Machine Learning Perspectives: Complex Computational Methods and Collaborative Techniques provides an overview of current research in machine learning and applications to chemoinformatics tasks. As a timely compendium of research, this book offers perspectives on key elements that are crucial for complex study and investigation.", "year": 2010, "referenceCount": 0, "citationCount": 79, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1727076", "name": "H. Lodhi"}, {"authorId": "34724293", "name": "Yoshihiro Yamanishi"}]}, {"paperId": "f6881f51393704cda399733078d571d964e909cd", "url": "https://www.semanticscholar.org/paper/f6881f51393704cda399733078d571d964e909cd", "title": "A Re-examination of Machine Learning Approaches for Sentence-Level MT Evaluation", "abstract": "Recent studies suggest that machine learning can be applied to develop good automatic evaluation metrics for machine translated sentences. This paper further analyzes aspects of learning that impact performance. We argue that previously proposed approaches of training a HumanLikeness classifier is not as well correlated with human judgments of translation quality, but that regression-based learning produces more reliable metrics. We demonstrate the feasibility of regression-based metrics through empirical analysis of learning curves and generalization studies and show that they can achieve higher correlations with human judgments than standard automatic metrics.", "year": 2007, "referenceCount": 25, "citationCount": 72, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144803472", "name": "Joshua Albrecht"}, {"authorId": "1726601", "name": "R. Hwa"}]}, {"paperId": "41d642b022f5af9cd49481ed2ea3f801d8818806", "url": "https://www.semanticscholar.org/paper/41d642b022f5af9cd49481ed2ea3f801d8818806", "title": "Learning with limited minority class data", "abstract": "A practical problem in data mining and machine learning is the limited availability of data. For example, in a binary classification problem it is often the case that examples of one class are abundant, while examples of the other class are in short supply. Examples from one class, typically the positive class, can be limited due to the financial cost or time required to collect these examples. This work presents a comprehensive empirical study of learning when examples from one class are extremely rare, but examples of the other class(es) are plentiful. Specifically, we address the issue of how many examples from the abundant class should be used when training a classifier on data where one class is very rare. Nearly one million classifiers were built and evaluated to generate the results presented in this work. Our results demonstrate that the often used 'even distribution' is not optimal when dealing with such rare events.", "year": 2007, "referenceCount": 21, "citationCount": 94, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1725285", "name": "T. Khoshgoftaar"}, {"authorId": "2541661", "name": "C. Seiffert"}, {"authorId": "3328057", "name": "J. V. Hulse"}, {"authorId": "1690347", "name": "A. Napolitano"}, {"authorId": "2154647", "name": "A. Folleco"}]}, {"paperId": "e516c11de1838ad9d79a36177defd50e35610f74", "url": "https://www.semanticscholar.org/paper/e516c11de1838ad9d79a36177defd50e35610f74", "title": "Semi-Supervised Semantic Segmentation With High- and Low-Level Consistency", "abstract": "The ability to understand visual information from limited labeled data is an important aspect of machine learning. While image-level classification has been extensively studied in a semi-supervised setting, dense pixel-level classification with limited data has only drawn attention recently. In this work, we propose an approach for semi-supervised semantic segmentation that learns from limited pixel-wise annotated samples while exploiting additional annotation-free images. The proposed approach relies on adversarial training with a feature matching loss to learn from unlabeled images. It uses two network branches that link semi-supervised classification with semi-supervised segmentation including self-training. The dual-branch approach reduces both the low-level and the high-level artifacts typical when training with few labels. The approach attains significant improvement over existing methods, especially when trained with very few labeled samples. On several standard benchmarks\u2014PASCAL VOC 2012, PASCAL-Context, and Cityscapes\u2014the approach achieves new state-of-the-art in semi-supervised learning.", "year": 2019, "referenceCount": 42, "citationCount": 158, "influentialCitationCount": 22, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "9452482", "name": "Sudhanshu Mittal"}, {"authorId": "3332944", "name": "Maxim Tatarchenko"}, {"authorId": "1710872", "name": "T. Brox"}]}, {"paperId": "e2a35c1f0d859ea7f3745b8afc8ae4940414cfb5", "url": "https://www.semanticscholar.org/paper/e2a35c1f0d859ea7f3745b8afc8ae4940414cfb5", "title": "Automatic microseismic event picking via unsupervised machine learning", "abstract": "\n Effective and efficient arrival picking plays an important role in microseismic and earthquake data processing and imaging. Widely used short-term-average long-term-average ratio (STA/LTA) based arrival picking algorithms suffer from the sensitivity to moderate-to-strong random ambient noise. To make the state-of-the-art arrival picking approaches effective, microseismic data need to be first pre-processed, for example, removing sufficient amount of noise, and second analysed by arrival pickers. To conquer the noise issue in arrival picking for weak microseismic or earthquake event, I leverage the machine learning techniques to help recognizing seismic waveforms in microseismic or earthquake data. Because of the dependency of supervised machine learning algorithm on large volume of well-designed training data, I utilize an unsupervised machine learning algorithm to help cluster the time samples into two groups, that is, waveform points and non-waveform points. The fuzzy clustering algorithm has been demonstrated to be effective for such purpose. A group of synthetic, real microseismic and earthquake data sets with different levels of complexity show that the proposed method is much more robust than the state-of-the-art STA/LTA method in picking microseismic events, even in the case of moderately strong background noise.", "year": 2020, "referenceCount": 81, "citationCount": 117, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2860323", "name": "Yangkang Zhang"}]}, {"paperId": "d1f37d9cab68eb8cda669cc949394732f33264b4", "url": "https://www.semanticscholar.org/paper/d1f37d9cab68eb8cda669cc949394732f33264b4", "title": "Inducing Crosslingual Distributed Representations of Words", "abstract": "Distributed representations of words have proven extremely useful in numerous natural language processing tasks. Their appeal is that they can help alleviate data sparsity problems common to supervised learning. Methods for inducing these representations require only unlabeled language data, which are plentiful for many natural languages. In this work, we induce distributed representations for a pair of languages jointly. We treat it as a multitask learning problem where each task corresponds to a single word, and task relatedness is derived from co-occurrence statistics in bilingual parallel data. These representations can be used for a number of crosslingual learning tasks, where a learner can be trained on annotations present in one language and applied to test data in another. We show that our representations are informative by using them for crosslingual document classification, where classifiers trained on these representations substantially outperform strong baselines (e.g. machine translation) when applied to a new language.", "year": 2012, "referenceCount": 31, "citationCount": 361, "influentialCitationCount": 56, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2393075", "name": "A. Klementiev"}, {"authorId": "144889265", "name": "Ivan Titov"}, {"authorId": "48467774", "name": "Binod Bhattarai"}]}, {"paperId": "4d02cc73bf0f0e9e63642543d6a1c1df53e75688", "url": "https://www.semanticscholar.org/paper/4d02cc73bf0f0e9e63642543d6a1c1df53e75688", "title": "Hidden Markov models in biological sequence analysis", "abstract": "The vast increase of data in biology has meant that many aspects of computational science have been drawn into the field. Two areas of crucial importance are large-scale data management and machine learning. The field between computational science and biology is varyingly described as \"computational biology\" or \"bioinformatics.\" This paper reviews machine learning techniques based on the use of hidden Markov models (HMMs) for investigating biomolecular sequences. The approach is illustrated with brief descriptions of gene-prediction HMMs and protein family HMMs.", "year": 2001, "referenceCount": 16, "citationCount": 97, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1702103", "name": "E. Birney"}]}, {"paperId": "38ae42878d6b646b8840464add9f867ff1294600", "url": "https://www.semanticscholar.org/paper/38ae42878d6b646b8840464add9f867ff1294600", "title": "OpenML: A Collaborative Science Platform", "abstract": null, "year": 2013, "referenceCount": 7, "citationCount": 96, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1764155", "name": "J. N. Rijn"}, {"authorId": "1686924", "name": "B. Bischl"}, {"authorId": "66444903", "name": "L. Torgo"}, {"authorId": "2067890963", "name": "Bo Gao"}, {"authorId": "1992025", "name": "Venkatesh Umaashankar"}, {"authorId": "2061646831", "name": "S. Fischer"}, {"authorId": "2053517097", "name": "Patrick Winter"}, {"authorId": "1711128", "name": "Bernd Wiswedel"}, {"authorId": "1683418", "name": "M. Berthold"}, {"authorId": "1717534", "name": "J. Vanschoren"}]}, {"paperId": "8e43311c1ce85411c88a81ff255a9ff8958637a5", "url": "https://www.semanticscholar.org/paper/8e43311c1ce85411c88a81ff255a9ff8958637a5", "title": "Two Machine Learning Approaches for Short-Term Wind Speed Time-Series Prediction", "abstract": "The increasing liberalization of European electricity markets, the growing proportion of intermittent renewable energy being fed into the energy grids, and also new challenges in the patterns of energy consumption (such as electric mobility) require flexible and intelligent power grids capable of providing efficient, reliable, economical, and sustainable energy production and distribution. From the supplier side, particularly, the integration of renewable energy sources (e.g., wind and solar) into the grid imposes an engineering and economic challenge because of the limited ability to control and dispatch these energy sources due to their intermittent characteristics. Time-series prediction of wind speed for wind power production is a particularly important and challenging task, wherein prediction intervals (PIs) are preferable results of the prediction, rather than point estimates, because they provide information on the confidence in the prediction. In this paper, two different machine learning approaches to assess PIs of time-series predictions are considered and compared: 1) multilayer perceptron neural networks trained with a multiobjective genetic algorithm and 2) extreme learning machines combined with the nearest neighbors approach. The proposed approaches are applied for short-term wind speed prediction from a real data set of hourly wind speed measurements for the region of Regina in Saskatchewan, Canada. Both approaches demonstrate good prediction precision and provide complementary advantages with respect to different evaluation criteria.", "year": 2016, "referenceCount": 57, "citationCount": 106, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "50309003", "name": "R. Ak"}, {"authorId": "2757308", "name": "Olga Fink"}, {"authorId": "144027144", "name": "E. Zio"}]}, {"paperId": "f7bfb74db11faef395da5100ee81fdd6bffd0fe2", "url": "https://www.semanticscholar.org/paper/f7bfb74db11faef395da5100ee81fdd6bffd0fe2", "title": "Combining Symbolic and Neural Learning", "abstract": null, "year": 1994, "referenceCount": 62, "citationCount": 50, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1734317", "name": "J. Shavlik"}]}, {"paperId": "6daf14076a7ad2c4b4f1a8eb28778b9c641777e7", "url": "https://www.semanticscholar.org/paper/6daf14076a7ad2c4b4f1a8eb28778b9c641777e7", "title": "On the effect of data set size on bias and variance in classification learning", "abstract": "With the advent of data mining, machine learning has come of age and is now a critical technology in many businesses. However, machine learning evolved in a different research context to that in which it now finds itself employed. A particularly important problem in the data mining world is working effectively with large data sets. However, most machine learning research has been conducted in the context of learning from very small data sets. To date most approaches to scaling up machine learning to large data sets have attempted to modify existing algorithms to deal with large data sets in a more computationally efficient and effective manner. But is this necessarily the best method? This paper explores the possibility of designing algorithms specifically for large data sets. Specifically, the paper looks at how increasing data set size affects bias and variance error decompositions for classification algorithms. Preliminary results of experiments to determine these effects are presented, showing that, as hypothesised variance can be expected to decrease as training set size increases. No clear effect of training set size on bias was observed. These results have profound implications for data mining from large data sets, indicating that developing effective learning algorithms for large data sets is not simply a matter of finding computationally efficient variants of existing learning algorithms.", "year": 1999, "referenceCount": 14, "citationCount": 83, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144836106", "name": "Damien Brain"}, {"authorId": "1726660", "name": "Geoffrey I. Webb"}]}, {"paperId": "0b1317a42760d4de86d721a867e340db4d6b0810", "url": "https://www.semanticscholar.org/paper/0b1317a42760d4de86d721a867e340db4d6b0810", "title": "Multi-Domain Neural Machine Translation through Unsupervised Adaptation", "abstract": "We investigate the application of Neural Machine Translation (NMT) under the following three conditions posed by realworld application scenarios. First, we operate with an input stream of sentences coming from many different domains and with no predefined order. Second, the sentences are presented without domain information. Third, the input stream should be processed by a single generic NMT model. To tackle the weaknesses of current NMT technology in this unsupervised multi-domain setting, we explore an efficient instance-based adaptation method that, by exploiting the similarity between the training instances and each test sentence, dynamically sets the hyperparameters of the learning algorithm and updates the generic model on-the-fly. The results of our experiments with multi-domain data show that local adaptation outperforms not only the original generic NMT system, but also a strong phrase-based system and even single-domain NMT models specifically optimized on each domain and applicable only by violating two of our aforementioned assumptions.", "year": 2017, "referenceCount": 22, "citationCount": 111, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2252391", "name": "M. Amin Farajian"}, {"authorId": "145862931", "name": "M. Turchi"}, {"authorId": "2138026", "name": "Matteo Negri"}, {"authorId": "102811815", "name": "Marcello Federico"}]}, {"paperId": "96133e6f5d80c89d3ea31673dc9e467f63fd7366", "url": "https://www.semanticscholar.org/paper/96133e6f5d80c89d3ea31673dc9e467f63fd7366", "title": "Ontology Learning from Text: An Overview", "abstract": "This volume brings together a collection of extended versions of selected papers from two workshops on ontology learning, knowledge acquisition and related topics that were organized in the context of the European Conference on Artificial Intelligence (ECAI) 2004 and the International Conference on Knowledge Engineering and Management (EKAW) 2004. The volume presents current research in ontology learning, addressing three perspectives: methodologies that have been proposed to automatically extract information from texts and to give a structured organization to such knowledge, including approaches based on machine learning techniques; evaluation methods for ontology learning, aiming at defining procedures and metrics for a quantitative evaluation of the ontology learning task; and finally application scenarios that make ontology learning a challenging area in the context of real applications such as bio-informatics. According to the three perspectives mentioned above, the book is divided into three sections, each including a selection of papers addressing respectively the methods, the applications and the evaluation of ontology learning approaches. However, all selected papers pay considerably attention to the evaluation perspective, as this was a central topic of the ECAI 2004 workshop out of which most of the papers in this volume originate.", "year": 2005, "referenceCount": 48, "citationCount": 334, "influentialCitationCount": 23, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3338131", "name": "P. Buitelaar"}, {"authorId": "1748977", "name": "P. Cimiano"}, {"authorId": "1712352", "name": "B. Magnini"}]}, {"paperId": "1882f194cb43828852cc052887671e55a80f945a", "url": "https://www.semanticscholar.org/paper/1882f194cb43828852cc052887671e55a80f945a", "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding", "abstract": "Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-fire approach for better model quality, there are challenges on the path such as the computation cost, ease of programming, and efficient implementation on parallel devices. GShard is a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler. It provides an elegant way to express a wide range of parallel computation patterns with minimal changes to the existing model code. GShard enabled us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts beyond 600 billion parameters using automatic sharding. We demonstrate that such a giant model can efficiently be trained on 2048 TPU v3 accelerators in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.", "year": 2020, "referenceCount": 86, "citationCount": 310, "influentialCitationCount": 62, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "150077954", "name": "Dmitry Lepikhin"}, {"authorId": "34946720", "name": "HyoukJoong Lee"}, {"authorId": "2145139570", "name": "Yuanzhong Xu"}, {"authorId": "7167328", "name": "Dehao Chen"}, {"authorId": "2345617", "name": "Orhan Firat"}, {"authorId": "2145438541", "name": "Yanping Huang"}, {"authorId": "2048712", "name": "M. Krikun"}, {"authorId": "1846258", "name": "Noam M. Shazeer"}, {"authorId": "2545358", "name": "Z. Chen"}]}, {"paperId": "3190181e9e0e8011e9eb176823e0715ec6fd7226", "url": "https://www.semanticscholar.org/paper/3190181e9e0e8011e9eb176823e0715ec6fd7226", "title": "Learning Comprehensible Descriptions of Multivariate Time Series", "abstract": "Supervised classiication is one of the most active areas of machine learning research. Most work has focused on classiication in static domains, where an instantaneous snapshot of attributes is meaningful. In many domains, attributes are not static; in fact, it is the way they vary temporally that can make classiication possible. Examples of such domains include speech recognition, gesture recognition and electrocardiograph clas-siication. While it is possible to use ad hoc, domain-speciic techniques for \\\\atten-ing\" the time series to a learner-friendly representation , this fails to take into account both the special problems and special heuris-tics applicable to temporal data and often results in unreadable concept descriptions. Though traditional time series techniques can sometimes produce accurate classiiers, few can provide comprehensible descriptions. We propose a general architecture for classiica-tion and description of multivariate time series. It employs event primitives to analyse the training data and extract events. These events are clustered, creating proto-typical events which are used as the basis for creating more accurate and comprehensi-ble classiiers. A minimal implementation of this architecture, called TClass, is applied to two domains, one real and one artiicial and compared against a na ve approach. TClass shows great promise, particularly in compre-hensibility, but also in accuracy.", "year": 1999, "referenceCount": 23, "citationCount": 125, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1793159", "name": "M. W. Kadous"}]}, {"paperId": "8644f6f449d7d93ddcb3786e93c5ad40988da500", "url": "https://www.semanticscholar.org/paper/8644f6f449d7d93ddcb3786e93c5ad40988da500", "title": "Prediction and validation of foliage projective cover from Landsat-5 TM and Landsat-7 ETM+ imagery", "abstract": "The detection of long term trends in woody vegetation in Queensland, Australia, from the Landsat-5 TM and Landsat-7 ETM+ sensors requires the automated prediction of overstorey foliage projective cover (FPC) from a large volume of Landsat imagery. This paper presents a comparison of parametric (Multiple Linear Regression, Generalized Linear Models) and machine learning (Random Forests, Support Vector Machines) regression models for predicting overstorey FPC from Landsat-5 TM and Landsat-7 ETM+ imagery. Estimates of overstorey FPC were derived from field measured stand basal area (RMSE 7.26%) for calibration of the regression models. Independent estimates of overstorey FPC were derived from field and airborne LiDAR (RMSE 5.34%) surveys for validation of model predictions. The airborne LiDAR-derived estimates of overstorey FPC enabled the bias and variance of model predictions to be quantified in regional areas. The results showed all the parametric and machine learning models had similar prediction errors (RMSE < 10%), but the machine learning models had less bias than the parametric models at greater than ~60% overstorey FPC. All models showed greater than 10% bias in plant communities with high herbaceous or understorey FPC. The results of this work indicate that use of overstorey FPC products derived from Landsat-5 TM or Landsat-7 ETM+ data in Queensland using any of the regression models requires the assumption of senescent or absent herbaceous foliage at the time of image acquisition.", "year": 2009, "referenceCount": 75, "citationCount": 136, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Engineering"], "authors": [{"authorId": "88709668", "name": "J. Armston"}, {"authorId": "144779661", "name": "R. Denham"}, {"authorId": "2239468", "name": "T. Danaher"}, {"authorId": "2695582", "name": "P. Scarth"}, {"authorId": "6682465", "name": "T. Moffiet"}]}, {"paperId": "dd02246d76d9dfe9d40b5d7974f0c6eb1b3485ce", "url": "https://www.semanticscholar.org/paper/dd02246d76d9dfe9d40b5d7974f0c6eb1b3485ce", "title": "FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare", "abstract": "With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.", "year": 2019, "referenceCount": 62, "citationCount": 251, "influentialCitationCount": 22, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109360525", "name": "Yiqiang Chen"}, {"authorId": "1519290245", "name": "Jindong Wang"}, {"authorId": "1786336", "name": "Chaohui Yu"}, {"authorId": "101001846", "name": "Wen Gao"}, {"authorId": "2106593912", "name": "Xin Qin"}]}, {"paperId": "92173ee9731aa45be5d3295e69c00d3387abb3b0", "url": "https://www.semanticscholar.org/paper/92173ee9731aa45be5d3295e69c00d3387abb3b0", "title": "Embedded Methods", "abstract": null, "year": 2006, "referenceCount": 50, "citationCount": 198, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2312432", "name": "T. N. Lal"}, {"authorId": "1730609", "name": "O. Chapelle"}, {"authorId": "145183709", "name": "J. Weston"}, {"authorId": "1766703", "name": "A. Elisseeff"}]}, {"paperId": "16d3d35d313e8cdcd204f83d2b68e86673b36360", "url": "https://www.semanticscholar.org/paper/16d3d35d313e8cdcd204f83d2b68e86673b36360", "title": "Performance Evaluation of Supervised Machine Learning Algorithms for Intrusion Detection", "abstract": null, "year": 2016, "referenceCount": 23, "citationCount": 171, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31392219", "name": "Manjula C. Belavagi"}, {"authorId": "9101453", "name": "Balachandra Muniyal"}]}, {"paperId": "1609d25c07421e6f7aecef1db474dc8fef9a8853", "url": "https://www.semanticscholar.org/paper/1609d25c07421e6f7aecef1db474dc8fef9a8853", "title": "Machine Learning for Soft Robotic Sensing and Control", "abstract": "Herein, the progress of machine learning methods in the field of soft robotics, specifically in the applications of sensing and control, is outlined. Data\u2010driven methods such as machine learning are especially suited to systems with governing functions that are unknown, impractical or impossible to represent analytically, or computationally intractable to integrate into real\u2010world solutions. Function approximation with careful formulation of the machine learning architecture enables the encoding of dynamic behavior and nonlinearities, with the added potential to address hysteresis and nonstationary behavior. Supervised learning and reinforcement learning in simulation and on a wide variety of physical robotic systems have shown promising results for the use of empirical data\u2010driven methods as a solution to contemporary soft robotics problems.", "year": 2020, "referenceCount": 57, "citationCount": 62, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1572889093", "name": "Keene Chin"}, {"authorId": "2576308", "name": "T. Hellebrekers"}, {"authorId": "2292027", "name": "C. Majidi"}]}, {"paperId": "0fc9f651e6a1e01ac6dfdc41fa118dbe49ae26b6", "url": "https://www.semanticscholar.org/paper/0fc9f651e6a1e01ac6dfdc41fa118dbe49ae26b6", "title": "Research Paper: Text Categorization Models for High-Quality Article Retrieval in Internal Medicine", "abstract": "OBJECTIVE Finding the best scientific evidence that applies to a patient problem is becoming exceedingly difficult due to the exponential growth of medical publications. The objective of this study was to apply machine learning techniques to automatically identify high-quality, content-specific articles for one time period in internal medicine and compare their performance with previous Boolean-based PubMed clinical query filters of Haynes et al. DESIGN The selection criteria of the ACP Journal Club for articles in internal medicine were the basis for identifying high-quality articles in the areas of etiology, prognosis, diagnosis, and treatment. Naive Bayes, a specialized AdaBoost algorithm, and linear and polynomial support vector machines were applied to identify these articles. MEASUREMENTS The machine learning models were compared in each category with each other and with the clinical query filters using area under the receiver operating characteristic curves, 11-point average recall precision, and a sensitivity/specificity match method. RESULTS In most categories, the data-induced models have better or comparable sensitivity, specificity, and precision than the clinical query filters. The polynomial support vector machine models perform the best among all learning methods in ranking the articles as evaluated by area under the receiver operating curve and 11-point average recall precision. CONCLUSION This research shows that, using machine learning methods, it is possible to automatically build models for retrieving high-quality, content-specific articles using inclusion or citation by the ACP Journal Club as a gold standard in a given time period in internal medicine that perform better than the 1994 PubMed clinical query filters.", "year": 2004, "referenceCount": 42, "citationCount": 131, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "8340776", "name": "Yindalon Aphinyanagphongs"}, {"authorId": "3032369", "name": "I. Tsamardinos"}, {"authorId": "1702228", "name": "A. Statnikov"}, {"authorId": "47762372", "name": "D. Hardin"}, {"authorId": "1803212", "name": "C. Aliferis"}]}, {"paperId": "69212cb4c6ea3e770152a82e60b7b52997278787", "url": "https://www.semanticscholar.org/paper/69212cb4c6ea3e770152a82e60b7b52997278787", "title": "Soft Architecture Machines", "abstract": "This book is an offspring of Negroponte's \"The Architecture Machine, \" published by The MIT Press in 1970. As is usually the case where computer systems are involved, the new generation is several orders of magnitude more powerful than even its remarkably mind-extending parent. The last few years have represented a \"passing from an idiom to a reality, following (not necessarily consciously) notions set down in \"The Architecture Machine\" with an uncanny precision. The prognostications of hardware enumerated in wanton fantasy have been achieved and even superseded in the actual Architecture Machine of 1972.\"The general assumption of this new book is that the architect is an unnecessary and even detrimental middleman between individual, continuously changing needs and the continuous incorporation of those needs into the built environment. The book proposes a new kind of architecture without architects, and even without surrogate architects.The first chapter sets forth generally what is involved in learning to understand both the makings of intelligence and the making of architecture. It reveals polarities in attitudes toward thinking about thinking, and it appraises techniques--real and potential--that lead to meaningful thought about the process.A more direct analysis of architectural design activities is presented in the second chapter. Its goal is to achieve a closer coupling between man and machine, and it proposes sidestepping the traditional division of labor in which man and machine are assigned tasks that they are supposed to be respectively better at. Instead, a joint venture model is suggested: man and machine are treated as equal partners, even as candid good friends.The third chapter moves beyond the architect--beyond the need for an outside designer's intervention between our needs and their fulfillment. It asserts that each individual can be the best architect for his own needs and does not require a paternalistic human or mechanical architect to dictate his final decisions.The last chapter--furthest out of all--looks toward a distant future not only beyond the architect but beyond architecture as we know it. Here architecture machines are not simply used as aids in the design of buildings--they serve as buildings in themselves. Man will live in living, intelligent machines or cognitive physical environments that can immediately respond to his needs or wishes or whims. The possibilities are unlimited and a challenge to any imagination.", "year": 1976, "referenceCount": 0, "citationCount": 292, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "2687459", "name": "N. Negroponte"}]}, {"paperId": "0b60515ded1c56d6caa6e159896453312707297e", "url": "https://www.semanticscholar.org/paper/0b60515ded1c56d6caa6e159896453312707297e", "title": "Photonic tensor cores for machine learning", "abstract": "With an ongoing trend in computing hardware towards increased heterogeneity, domain-specific co-processors are emerging as alternatives to centralized paradigms. The tensor core unit (TPU) has shown to outperform graphic process units by almost 3-orders of magnitude enabled by higher signal throughout and energy efficiency. In this context, photons bear a number of synergistic physical properties while phase-change materials allow for local nonvolatile mnemonic functionality in these emerging distributed non van-Neumann architectures. While several photonic neural network designs have been explored, a photonic TPU to perform matrix vector multiplication and summation is yet outstanding. Here we introduced an integrated photonics-based TPU by strategically utilizing a) photonic parallelism via wavelength division multiplexing, b) high 2 Peta-operations-per second throughputs enabled by 10s of picosecond-short delays from optoelectronics and compact photonic integrated circuitry, and c) zero power-consuming novel photonic multi-state memories based on phase-change materials featuring vanishing losses in the amorphous state. Combining these physical synergies of material, function, and system, we show that the performance of this 8-bit photonic TPU can be 2-3 orders higher compared to an electrical TPU whilst featuring similar chip areas. This work shows that photonic specialized processors have the potential to augment electronic systems and may perform exceptionally well in network-edge devices in the looming 5G networks and beyond.", "year": 2020, "referenceCount": 45, "citationCount": 90, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Engineering"], "authors": [{"authorId": "50533784", "name": "M. Miscuglio"}, {"authorId": "1995822", "name": "V. Sorger"}]}, {"paperId": "1ed3e20bbcf12c60e766189987074ac2935d7140", "url": "https://www.semanticscholar.org/paper/1ed3e20bbcf12c60e766189987074ac2935d7140", "title": "Machine Recognition of Auslan Signs Using PowerGloves: Towards Large-Lexicon Recognition of Sign Lan", "abstract": "Instrumented gloves use a variety of sensors to provide information about the user's hand. They can be used for recognition of gestures; especially well-deened gesture sets such as sign languages. However, recognising gestures is a diicult task, due to intrapersonal and inter-personal variations in performing them. One approach to solving this problem is to use machine learning. In this case, samples of 95 discrete Australian Sign Language (Auslan) signs were collected using a Power-Glove. Two machine learning techniques were applied { instance-based learning (IBL) and decision-tree learning { to the data after some simple features were extracted. Accuracy of approximately 80 per cent was achieved using IBL, despite the severe limitations of the glove.", "year": 1996, "referenceCount": 18, "citationCount": 112, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1793159", "name": "M. W. Kadous"}]}]}