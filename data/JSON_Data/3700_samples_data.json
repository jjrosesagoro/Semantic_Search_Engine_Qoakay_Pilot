{"total": 5120627, "offset": 3600, "next": 3700, "data": [{"paperId": "3c316f48f1c4c7bcc5d0e2540b7614d962849082", "url": "https://www.semanticscholar.org/paper/3c316f48f1c4c7bcc5d0e2540b7614d962849082", "title": "Machine Learning Methods", "abstract": "Mn/DOT uses meteorological information obtained from Road Weather Information System (RWIS) sensors for the maintenance of roads and to ensure safe driving conditions. It is important that these sensors report accurate data in order to make accurate forecasts, as these forecasts are used extensively by Mn/DOT. Real time detection of sensor malfunctions can reduce the expense incurred in performing routine maintenance checks and re-calibrations of the sensors, while guaranteeing accurate data. In this work we predict RWIS sensor values using weather information from nearby RWIS sensors and other sensors from the AWOS network. Significant and/or systemic deviations from the predicted values are used to identify malfunctions. Based on historical data collected from the sensor and its nearby locations, we construct statistical models that can be used to predict current values. We use machine learning (ML) methods to build these models. We employ three types of ML models: classification algorithms, regression algorithms and Hidden Markov Models (HMMs). We use classification algorithms such as J48 decision trees, Naive Bayes and Bayesian Networks, regression algorithms such as Linear Regression, Least Median Square (LMS), M5P regression trees, MultiLayer Perceptron, RBF Networks and Conjunctive Rule, and HMMs to predict the variables temperature, precipitation type and visibility. We selected a representative sample of the RWIS sites in Minnesota. We employed different representations of the data to try improve the model efficiency. To use temperature in regression algorithms and HMMs, we developed a method to discretize temperature. The Viterbi algorithm used in HMM was modified to obtain the symbol observed along the most probable path. From the results, we observed that LMS and M5P are highly accurate in predicting temperature and visibility. Predicting precipitation works well with J48 decision trees and", "year": 2012, "referenceCount": 32, "citationCount": 49, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2192265840", "name": "Ashok Srivastava"}]}, {"paperId": "cb2bdd57842ca4144d120f5cb357069e8d5e63bd", "url": "https://www.semanticscholar.org/paper/cb2bdd57842ca4144d120f5cb357069e8d5e63bd", "title": "Machine Learning and Integrative Analysis of Biomedical Big Data", "abstract": "Recent developments in high-throughput technologies have accelerated the accumulation of massive amounts of omics data from multiple sources: genome, epigenome, transcriptome, proteome, metabolome, etc. Traditionally, data from each source (e.g., genome) is analyzed in isolation using statistical and machine learning (ML) methods. Integrative analysis of multi-omics and clinical data is key to new biomedical discoveries and advancements in precision medicine. However, data integration poses new computational challenges as well as exacerbates the ones associated with single-omics studies. Specialized computational approaches are required to effectively and efficiently perform integrative analysis of biomedical data acquired from diverse modalities. In this review, we discuss state-of-the-art ML-based approaches for tackling five specific computational challenges associated with integrative analysis: curse of dimensionality, data heterogeneity, missing data, class imbalance and scalability issues.", "year": 2019, "referenceCount": 257, "citationCount": 139, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "1740506815", "name": "Bilal Mirza"}, {"authorId": "2158624987", "name": "Wei Wang"}, {"authorId": "2146043765", "name": "Jie Wang"}, {"authorId": "47741794", "name": "H. Choi"}, {"authorId": "3219565", "name": "N. C. Chung"}, {"authorId": "3023770", "name": "P. Ping"}]}, {"paperId": "903a45a02e51ea74a68f0aa459a8a9fbd8cd5a7a", "url": "https://www.semanticscholar.org/paper/903a45a02e51ea74a68f0aa459a8a9fbd8cd5a7a", "title": "Emotion Classification Using Web Blog Corpora", "abstract": "In this paper, we investigate the emotion classification of web blog corpora using support vector machine (SVM) and conditional random field (CRF) machine learning techniques. The emotion classifiers are trained at the sentence level and applied to the document level. Our methods also determine an emotion category by taking the context of a sentence into account. Experiments show that CRF classifiers outperform SVM classifiers. When applying emotion classification to a blog at the document level, the emotion of the last sentence in a document plays an important role in determining the overall emotion.", "year": 2007, "referenceCount": 14, "citationCount": 255, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1782222", "name": "Changhua Yang"}, {"authorId": "29828959", "name": "K. Lin"}, {"authorId": "153924342", "name": "Hsin-Hsi Chen"}]}, {"paperId": "7e7d471cb29c18d34fc9f4be82e7d1de01e6a832", "url": "https://www.semanticscholar.org/paper/7e7d471cb29c18d34fc9f4be82e7d1de01e6a832", "title": "Human Active Learning", "abstract": "We investigate a topic at the interface of machine learning and cognitive science. Human active learning, where learners can actively query the world for information, is contrasted with passive learning from random examples. Furthermore, we compare human active learning performance with predictions from statistical learning theory. We conduct a series of human category learning experiments inspired by a machine learning task for which active and passive learning error bounds are well understood, and dramatically distinct. Our results indicate that humans are capable of actively selecting informative queries, and in doing so learn better and faster than if they are given random training data, as predicted by learning theory. However, the improvement over passive learning is not as dramatic as that achieved by machine active learning algorithms. To the best of our knowledge, this is the first quantitative study comparing human category learning in active versus passive settings.", "year": 2008, "referenceCount": 24, "citationCount": 68, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143683066", "name": "R. Castro"}, {"authorId": "2347339", "name": "C. Kalish"}, {"authorId": "50033772", "name": "R. Nowak"}, {"authorId": "49031498", "name": "Ruichen Qian"}, {"authorId": "2647414", "name": "T. Rogers"}, {"authorId": "1832364", "name": "Xiaojin Zhu"}]}, {"paperId": "1409df3208e6e05f4f788037355bb5bf7c151c5e", "url": "https://www.semanticscholar.org/paper/1409df3208e6e05f4f788037355bb5bf7c151c5e", "title": "Machine learning and data mining", "abstract": null, "year": 2007, "referenceCount": 5, "citationCount": 73, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143986204", "name": "I. Kononenko"}, {"authorId": "1719813", "name": "M. Kukar"}]}, {"paperId": "80ab54c73fdd518310a0d52cf3632b3b5a668ad8", "url": "https://www.semanticscholar.org/paper/80ab54c73fdd518310a0d52cf3632b3b5a668ad8", "title": "Rethinking statistical learning theory: learning using statistical invariants", "abstract": null, "year": 2018, "referenceCount": 10, "citationCount": 38, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "50560492", "name": "V. Vapnik"}, {"authorId": "143719748", "name": "R. Izmailov"}]}, {"paperId": "c3cdd505ac569baf21e736aa4ca59b99174b15a2", "url": "https://www.semanticscholar.org/paper/c3cdd505ac569baf21e736aa4ca59b99174b15a2", "title": "Scaling Factorization Machines to Relational Data", "abstract": "The most common approach in predictive modeling is to describe cases with feature vectors (aka design matrix). Many machine learning methods such as linear regression or support vector machines rely on this representation. However, when the underlying data has strong relational patterns, especially relations with high cardinality, the design matrix can get very large which can make learning and prediction slow or even infeasible. \n \nThis work solves this issue by making use of repeating patterns in the design matrix which stem from the underlying relational structure of the data. It is shown how coordinate descent learning and Bayesian Markov Chain Monte Carlo inference can be scaled for linear regression and factorization machine models. Empirically, it is shown on two large scale and very competitive datasets (Netflix prize, KDDCup 2012), that (1) standard learning algorithms based on the design matrix representation cannot scale to relational predictor variables, (2) the proposed new algorithms scale and (3) the predictive quality of the proposed generic feature-based approach is as good as the best specialized models that have been tailored to the respective tasks.", "year": 2013, "referenceCount": 24, "citationCount": 101, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2843982", "name": "Steffen Rendle"}]}, {"paperId": "62ad80eb69a687a58abd88f500ef83d7a9ec1224", "url": "https://www.semanticscholar.org/paper/62ad80eb69a687a58abd88f500ef83d7a9ec1224", "title": "The need to approximate the use-case in clinical machine learning", "abstract": "Abstract The availability of smartphone and wearable sensor technology is leading to a rapid accumulation of human subject data, and machine learning is emerging as a technique to map those data into clinical predictions. As machine learning algorithms are increasingly used to support clinical decision making, it is vital to reliably quantify their prediction accuracy. Cross-validation (CV) is the standard approach where the accuracy of such algorithms is evaluated on part of the data the algorithm has not seen during training. However, for this procedure to be meaningful, the relationship between the training and the validation set should mimic the relationship between the training set and the dataset expected for the clinical use. Here we compared two popular CV methods: record-wise and subject-wise. While the subject-wise method mirrors the clinically relevant use-case scenario of diagnosis in newly recruited subjects, the record-wise strategy has no such interpretation. Using both a publicly available dataset and a simulation, we found that record-wise CV often massively overestimates the prediction accuracy of the algorithms. We also conducted a systematic review of the relevant literature, and found that this overly optimistic method was used by almost half of the retrieved studies that used accelerometers, wearable sensors, or smartphones to predict clinical outcomes. As we move towards an era of machine learning-based diagnosis and treatment, using proper methods to evaluate their accuracy is crucial, as inaccurate results can mislead both clinicians and data scientists.", "year": 2017, "referenceCount": 41, "citationCount": 145, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "3059087", "name": "Sohrab Saeb"}, {"authorId": "3146304", "name": "L. Lonini"}, {"authorId": "2226306", "name": "A. Jayaraman"}, {"authorId": "50228835", "name": "D. Mohr"}, {"authorId": "3282030", "name": "Konrad Paul Kording"}]}, {"paperId": "f87c036dd73c7755caab2fd0f1ff8f2f5feb7169", "url": "https://www.semanticscholar.org/paper/f87c036dd73c7755caab2fd0f1ff8f2f5feb7169", "title": "Evaluation of machine learning algorithms for intrusion detection system", "abstract": "Intrusion detection system (IDS) is one of the implemented solutions against harmful attacks. Furthermore, attackers always keep changing their tools and techniques. However, implementing an accepted IDS system is also a challenging task. In this paper, several experiments have been performed and evaluated to assess various machine learning classifiers based on KDD intrusion dataset. It succeeded to compute several performance metrics in order to evaluate the selected classifiers. The focus was on false negative and false positive performance metrics in order to enhance the detection rate of the intrusion detection system. The implemented experiments demonstrated that the decision table classifier achieved the lowest value of false negative while the random forest classifier has achieved the highest average accuracy rate.", "year": 2017, "referenceCount": 23, "citationCount": 139, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "26965709", "name": "Mohammad Almseidin"}, {"authorId": "37046177", "name": "Maen Alzubi"}, {"authorId": "144434899", "name": "S. Kov\u00e1cs"}, {"authorId": "2767899", "name": "M. Alkasassbeh"}]}, {"paperId": "df976ef18596067c4f06b714edd3e3a70b1a0fd7", "url": "https://www.semanticscholar.org/paper/df976ef18596067c4f06b714edd3e3a70b1a0fd7", "title": "Proceedings of the 22nd international conference on Machine learning", "abstract": "This volume, which is also available online from http://www.machinelearning.org, contains the papers accepted for presentation at ICML-2005, the 22nd lnternational Conference on Machine Learning, which was held at the University of Bonn in Germany from August 7 to August 11, 2005. ICML is the annual conference of the lnternational Machine Learning Society (IMLS), and forms an international forum for the discussion and presentation of the latest results in the field of machine learning. This year, ICML was co-located with the 15th lnternational Conference on Inductive Logic Programming (ILP-2005), the proceedings of which are published by Springer Verlag in a separate volume. \n \nThe papers in this volume were selected on the basis of a thorough review process. In the first round of reviewing, three program committee members produced individual reviews for a paper. Authors then had the opportunity to view those reviews and submit an author's reply to the reviewers. Led by the responsible area chair, the reviewers then engaged in a discussion about the paper, ultimately leading to the decision by the program chairs. In sum, of the 491 papers that were initially submitted, 62 were accepted immediately, and a further 81 were conditionally accepted and reconsidered after resubmission in a second round of reviewing. Of those 81 conditionally accepted papers, 72 were finally accepted, leading to a total of 134 accepted papers, which translates into an acceptance rate of 27.3 %. The author reply was a new feature of ICML this year, while the option of working with conditional accepts has already become a tradition. \n \nIn addition to the presentations of the accepted papers, the ICML program included several other features. On the first and last day of the conference, 11 workshops and 6 tutorials on current topics of machine learning were held. For many of these, proceedings and/or presentation materials are available online from the ICML website. The other days of the conference each featured an invited talk by a prominent researcher as a program highlight. We were delighted that Johannes Gehrke of Cornell University, Michael Jordan of the University of California at Berkeley, and Gerhard Widmer of the University of Linz in Austria, agreed to deliver an invited talk. The abstracts of their talks are also published as part of these proceedings. \n \nContinuing a long standing tradition at ICML, all papers presented in a talk at the conference were also exhibited at evening poster sessions, giving everyone ample time to discuss the results in depth. In order to emphasize the co-location with ILP-2005, the program contained joint elements in both invited speakers, paper sessions, poster sessions, and tutorials. As usual, the scientific program was complemented by a social program, this time featuring an excursion to the scenic surroundings of the city of Bonn. \n \nDuring the conference best paper and best student paper awards were presented, the former being sponsored by NICTA, the later by the Machine Learning Journal.", "year": 2005, "referenceCount": 0, "citationCount": 129, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Sociology"], "authors": [{"authorId": "1693549", "name": "S. D\u017eeroski"}, {"authorId": "1740042", "name": "L. D. Raedt"}, {"authorId": "145057418", "name": "S. Wrobel"}]}, {"paperId": "10f2f3f589888c455a6571c380b075bcd4ce004b", "url": "https://www.semanticscholar.org/paper/10f2f3f589888c455a6571c380b075bcd4ce004b", "title": "A Parallel Multiclassification Algorithm for Big Data Using an Extreme Learning Machine", "abstract": "As data sets become larger and more complicated, an extreme learning machine (ELM) that runs in a traditional serial environment cannot realize its ability to be fast and effective. Although a parallel ELM (PELM) based on MapReduce to process large-scale data shows more efficient learning speed than identical ELM algorithms in a serial environment, some operations, such as intermediate results stored on disks and multiple copies for each task, are indispensable, and these operations create a large amount of extra overhead and degrade the learning speed and efficiency of the PELMs. In this paper, an efficient ELM based on the Spark framework (SELM), which includes three parallel subalgorithms, is proposed for big data classification. By partitioning the corresponding data sets reasonably, the hidden layer output matrix calculation algorithm, matrix <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbf {\\hat {U}}$ </tex-math></inline-formula> decomposition algorithm, and matrix <inline-formula> <tex-math notation=\"LaTeX\">$\\mathbf {V}$ </tex-math></inline-formula> decomposition algorithm perform most of the computations locally. At the same time, they retain the intermediate results in distributed memory and cache the diagonal matrix as broadcast variables instead of several copies for each task to reduce a large amount of the costs, and these actions strengthen the learning ability of the SELM. Finally, we implement our SELM algorithm to classify large data sets. Extensive experiments have been conducted to validate the effectiveness of the proposed algorithms. As shown, our SELM achieves an <inline-formula> <tex-math notation=\"LaTeX\">$8.71\\times$ </tex-math></inline-formula> speedup on a cluster with ten nodes, and reaches a <inline-formula> <tex-math notation=\"LaTeX\">$13.79\\times$ </tex-math></inline-formula> speedup with 15 nodes, an <inline-formula> <tex-math notation=\"LaTeX\">$18.74\\times$ </tex-math></inline-formula> speedup with 20 nodes, a <inline-formula> <tex-math notation=\"LaTeX\">$23.79\\times$ </tex-math></inline-formula> speedup with 25 nodes, a <inline-formula> <tex-math notation=\"LaTeX\">$28.89\\times$ </tex-math></inline-formula> speedup with 30 nodes, and a <inline-formula> <tex-math notation=\"LaTeX\">$33.81\\times$ </tex-math></inline-formula> speedup with 35 nodes.", "year": 2018, "referenceCount": 35, "citationCount": 104, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "48664471", "name": "Mingxing Duan"}, {"authorId": "145730774", "name": "Kenli Li"}, {"authorId": "144078016", "name": "Xiangke Liao"}, {"authorId": "2181606", "name": "Keqin Li"}]}, {"paperId": "e3c9a2b515f90e233d1474cf6666111fd9a2e735", "url": "https://www.semanticscholar.org/paper/e3c9a2b515f90e233d1474cf6666111fd9a2e735", "title": "Non-Convex Min-Max Optimization: Provable Algorithms and Applications in Machine Learning", "abstract": "Min-max saddle-point problems have broad applications in many tasks in machine learning, e.g., distributionally robust learning, learning with non-decomposable loss, or learning with uncertain data. Although convex-concave saddle-point problems have been broadly studied with efficient algorithms and solid theories available, it remains a challenge to design provably efficient algorithms for non-convex saddle-point problems, especially when the objective function involves an expectation or a large-scale finite sum. Motivated by recent literature on non-convex non-smooth minimization, this paper studies a family of non-convex min-max problems where the minimization component is non-convex (weakly convex) and the maximization component is concave. We propose a proximally guided stochastic subgradient method and a proximally guided stochastic variance-reduced method for expected and finite-sum saddle-point problems, respectively. We establish the computation complexities of both methods for finding a nearly stationary point of the corresponding minimization problem.", "year": 2018, "referenceCount": 47, "citationCount": 148, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "34165881", "name": "Hassan Rafique"}, {"authorId": "14697929", "name": "Mingrui Liu"}, {"authorId": "39436683", "name": "Qihang Lin"}, {"authorId": "40381920", "name": "Tianbao Yang"}]}, {"paperId": "2236b261240afcc560a0475b81ae0c9c98867708", "url": "https://www.semanticscholar.org/paper/2236b261240afcc560a0475b81ae0c9c98867708", "title": "Advances in Minimum Description Length: Theory and Applications", "abstract": "The process of inductive inference -- to infer general laws and principles from particular instances -- is the basis of statistical modeling, pattern recognition, and machine learning. The Minimum Descriptive Length (MDL) principle, a powerful method of inductive inference, holds that the best explanation, given a limited set of observed data, is the one that permits the greatest compression of the data -- that the more we are able to compress the data, the more we learn about the regularities underlying the data. Advances in Minimum Description Length is a sourcebook that will introduce the scientific community to the foundations of MDL, recent theoretical advances, and practical applications.The book begins with an extensive tutorial on MDL, covering its theoretical underpinnings, practical implications as well as its various interpretations, and its underlying philosophy. The tutorial includes a brief history of MDL -- from its roots in the notion of Kolmogorov complexity to the beginning of MDL proper. The book then presents recent theoretical advances, introducing modern MDL methods in a way that is accessible to readers from many different scientific fields. The book concludes with examples of how to apply MDL in research settings that range from bioinformatics and machine learning to psychology.", "year": 2005, "referenceCount": 51, "citationCount": 481, "influentialCitationCount": 32, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144729640", "name": "P. Gr\u00fcnwald"}, {"authorId": "2968127", "name": "I. J. Myung"}, {"authorId": "2356583", "name": "M. Pitt"}]}, {"paperId": "37c23886aff83995d074baeefed3ad66fd3901c2", "url": "https://www.semanticscholar.org/paper/37c23886aff83995d074baeefed3ad66fd3901c2", "title": "A Case Study on the Critical Role of Geometric Regularity in Machine Learning", "abstract": "An important feature of many problem domains in machine learning is their geometry. For example, adjacency relationships, symmetries, and Cartesian coordinates are essential to any complete description of board games, visual recognition, or vehicle control. Yet many approaches to learning ignore such information in their representations, instead inputting flat parameter vectors with no indication of how those parameters are situated geometrically. This paper argues that such geometric information is critical to the ability of any machine learning approach to effectively generalize; even a small shift in the configuration of the task in space from what was experienced in training can go wholly unrecognized unless the algorithm is able to learn the regularities in decision-making across the problem geometry. To demonstrate the importance of learning from geometry, three variants of the same evolutionary learning algorithm (NeuroEvolution of Augmenting Topologies), whose representations vary in their capacity to encode geometry, are compared in checkers. The result is that the variant that can learn geometric regularities produces a significantly more general solution. The conclusion is that it is important to enable machine learning to detect and thereby learn from the geometry of its problems.", "year": 2008, "referenceCount": 22, "citationCount": 97, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3351507", "name": "J. Gauci"}, {"authorId": "1846883", "name": "Kenneth O. Stanley"}]}, {"paperId": "336241edd63791cc92e00774cee4de48bc92c75f", "url": "https://www.semanticscholar.org/paper/336241edd63791cc92e00774cee4de48bc92c75f", "title": "Machine Learning Approach to RF Transmitter Identification", "abstract": "With the increasing domain and widespread use of wireless devices in recent years (mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has become extremely crowded. To counter security threats posed by rogue or unknown transmitters, we must identify RF transmitters not only by the data content of the transmissions but also based on the intrinsic physical characteristics of the transmitters. RF waveforms represent a particular challenge because of the extremely high data rates involved and the potentially large number of transmitters sharing a channel in a given location. These factors outline the need for rapid fingerprinting and identification methods that go beyond the traditional hand-engineered approaches. In this paper, we investigate the use of machine learning strategies to the classification and identification problem. We evaluate four different strategies: conventional deep neural nets, convolutional neural nets, support vector machines, and deep neural nets with multi-stage training. The latter was by far the most accurate, achieving 100% classification accuracy of 12 transmitters, and showing remarkable potential for scalability to large transmitter populations.", "year": 2017, "referenceCount": 68, "citationCount": 82, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Engineering", "Mathematics"], "authors": [{"authorId": "47226368", "name": "K. Youssef"}, {"authorId": "46798560", "name": "Louis-S. Bouchard"}, {"authorId": "145296351", "name": "K. Haigh"}, {"authorId": "3330139", "name": "J. Silovsk\u00fd"}, {"authorId": "34830793", "name": "B. Thapa"}, {"authorId": "116019827", "name": "Chris Vander Valk"}]}, {"paperId": "81a01f6984a5581f5b89718d011d4f386fec8a20", "url": "https://www.semanticscholar.org/paper/81a01f6984a5581f5b89718d011d4f386fec8a20", "title": "Artificial Intelligence", "abstract": null, "year": 1999, "referenceCount": 9, "citationCount": 110, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "145107462", "name": "Stuart J. Russell"}, {"authorId": "2784519", "name": "Peter Norvig"}]}, {"paperId": "407fe62032a0d69cf77a13fb86645858f46ee9c8", "url": "https://www.semanticscholar.org/paper/407fe62032a0d69cf77a13fb86645858f46ee9c8", "title": "Wireless Networks Design in the Era of Deep Learning: Model-Based, AI-Based, or Both?", "abstract": "This paper deals with the use of emerging deep learning techniques in future wireless communication networks. It will be shown that the data-driven approaches should not replace, but rather complement, traditional design techniques based on mathematical models. Extensive motivation is given for why deep learning based on artificial neural networks will be an indispensable tool for the design and operation of future wireless communication networks, and our vision of how artificial neural networks should be integrated into the architecture of future wireless communication networks is presented. A thorough description of deep learning methodologies is provided, starting with the general machine learning paradigm, followed by a more in-depth discussion about deep learning and artificial neural networks, covering the most widely used artificial neural network architectures and their training methods. Deep learning will also be connected to other major learning frameworks, such as reinforcement learning and transfer learning. A thorough survey of the literature on deep learning for wireless communication networks is provided, followed by a detailed description of several novel case studies wherein the use of deep learning proves extremely useful for network design. For each case study, it will be shown how the use of (even approximate) mathematical models can significantly reduce the amount of live data that needs to be acquired/measured to implement the data-driven approaches. Finally, concluding remarks describe those that, in our opinion, are the major directions for future research in this field.", "year": 2019, "referenceCount": 222, "citationCount": 293, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Engineering", "Mathematics"], "authors": [{"authorId": "1750646", "name": "A. Zappone"}, {"authorId": "121644245", "name": "M. Di Renzo"}, {"authorId": "145118318", "name": "M. Debbah"}]}, {"paperId": "b6b883a7559c3195ba220c5921cdd601d00719c5", "url": "https://www.semanticscholar.org/paper/b6b883a7559c3195ba220c5921cdd601d00719c5", "title": "Learning of Ontologies from the Web: the Analysis of Existent Approaches", "abstract": "The next generation of the Web, called Semantic Web, has to improve the Web with semantic (ontological) page annotations to enable knowledge-level querying and searches. Manual construction of these ontologies will require tremendous efforts that force future integration of machine learning with knowledge acquisition to enable highly automated ontology learning. In the paper we present the state of the-art in the field of ontology learning from the Web to see how it can contribute to the task of semantic Web querying. We consider three components of the query processing system: natural language ontologies, domain ontologies and ontology instances. We discuss the requirements for machine learning algorithms to be applied for the learning of the ontologies of each type from the Web documents, and survey the existent ontology learning and other closely related approaches.", "year": 2001, "referenceCount": 24, "citationCount": 108, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1833643", "name": "B. Omelayenko"}]}, {"paperId": "354fb2f2607040fb461095cf3b2c90fbc66bd852", "url": "https://www.semanticscholar.org/paper/354fb2f2607040fb461095cf3b2c90fbc66bd852", "title": "Learning the Structure of Generative Models without Labeled Data", "abstract": "Curating labeled training data has become the primary bottleneck in machine learning. Recent frameworks address this bottleneck with generative models to synthesize labels at scale from weak supervision sources. The generative model's dependency structure directly affects the quality of the estimated labels, but selecting a structure automatically without any labeled data is a distinct challenge. We propose a structure estimation method that maximizes the \u2113 1-regularized marginal pseudolikelihood of the observed data. Our analysis shows that the amount of unlabeled data required to identify the true structure scales sublinearly in the number of possible dependencies for a broad class of models. Simulations show that our method is 100\u00d7 faster than a maximum likelihood approach and selects 1/4 as many extraneous dependencies. We also show that our method provides an average of 1.5 F1 points of improvement over existing, user-developed information extraction applications on real-world data such as PubMed journal abstracts.", "year": 2017, "referenceCount": 39, "citationCount": 122, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "authors": [{"authorId": "2870504", "name": "Stephen H. Bach"}, {"authorId": "17303636", "name": "Bryan D. He"}, {"authorId": "143711421", "name": "Alexander J. Ratner"}, {"authorId": "2114485554", "name": "C. R\u00e9"}]}, {"paperId": "fa0fe8f97a20e2f82f466506ebb29d9c27eb6869", "url": "https://www.semanticscholar.org/paper/fa0fe8f97a20e2f82f466506ebb29d9c27eb6869", "title": "Nonparametric Divergence Estimation with Applications to Machine Learning on Distributions", "abstract": "Low-dimensional embedding, manifold learning, clustering, classification, and anomaly detection are among the most important problems in machine learning. The existing methods usually consider the case when each instance has a fixed, finite-dimensional feature representation. Here we consider a different setting. We assume that each instance corresponds to a continuous probability distribution. These distributions are unknown, but we are given some i.i.d. samples from each distribution. Our goal is to estimate the distances between these distributions and use these distances to perform low-dimensional embedding, clustering/classification, or anomaly detection for the distributions. We present estimation algorithms, describe how to apply them for machine learning tasks on distributions, and show empirical results on synthetic data, real word images, and astronomical data sets.", "year": 2011, "referenceCount": 41, "citationCount": 105, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1719347", "name": "B. P\u00f3czos"}, {"authorId": "2068236719", "name": "L. Xiong"}, {"authorId": "1753432", "name": "J. Schneider"}]}, {"paperId": "cbc2547ad8940160d2d62826c0ff48c6c390725e", "url": "https://www.semanticscholar.org/paper/cbc2547ad8940160d2d62826c0ff48c6c390725e", "title": "A high-bias, low-variance introduction to Machine Learning for physicists", "abstract": null, "year": 2018, "referenceCount": 369, "citationCount": 525, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Medicine", "Computer Science", "Mathematics"], "authors": [{"authorId": "143788219", "name": "Pankaj Mehta"}, {"authorId": "12679312", "name": "M. Bukov"}, {"authorId": "21659195", "name": "Ching-Hao Wang"}, {"authorId": "144087089", "name": "A. G. Day"}, {"authorId": "40809840", "name": "C. Richardson"}, {"authorId": "2814205", "name": "Charles K. Fisher"}, {"authorId": "40111234", "name": "D. Schwab"}]}, {"paperId": "711c7d1b80719c34b6b97f5ba572f7872e4c4902", "url": "https://www.semanticscholar.org/paper/711c7d1b80719c34b6b97f5ba572f7872e4c4902", "title": "Machine Learning-Assisted Discovery of Solid Li-Ion Conducting Materials", "abstract": "We discover many new crystalline solid materials with fast single crystal Li ion conductivity at room temperature, discovered through density functional theory simulations guided by machine learning-based methods. The discovery of new solid Li superionic conductors is of critical importance to the development of safe all-solid-state Li-ion batteries. With a predictive universal structure\u2013property relationship for fast ion conduction not well understood, the search for new solid Li ion conductors has relied largely on trial-and-error computational and experimental searches over the last several decades. In this work, we perform a guided search of materials space with a machine learning (ML)-based prediction model for material selection and density functional theory molecular dynamics (DFT-MD) simulations for calculating ionic conductivity. These materials are screened from over 12\u202f000 experimentally synthesized and characterized candidates with very diverse structures and compositions. When compared to a r...", "year": 2018, "referenceCount": 30, "citationCount": 132, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Materials Science"], "authors": [{"authorId": "3797152", "name": "Austin D. Sendek"}, {"authorId": "8132903", "name": "E. D. Cubuk"}, {"authorId": "51958630", "name": "Evan R. Antoniuk"}, {"authorId": "15464038", "name": "Gowoon Cheon"}, {"authorId": "144241783", "name": "Yi Cui"}, {"authorId": "145908744", "name": "E. Reed"}]}, {"paperId": "cfddbf2e58ec39bd8573a28e718041c79006b8e0", "url": "https://www.semanticscholar.org/paper/cfddbf2e58ec39bd8573a28e718041c79006b8e0", "title": "Machine translation using deep learning: An overview", "abstract": "This Paper reveals the information about Deep Neural Network (DNN) and concept of deep learning in field of natural language processing i.e. machine translation. Now day's DNN is playing major role in machine leaning technics. Recursive recurrent neural network (R2NN) is a best technic for machine learning. It is the combination of recurrent neural network and recursive neural network (such as Recursive auto encoder). This paper presents how to train the recurrent neural network for reordering for source to target language by using Semi-supervised learning methods. Word2vec tool is required to generate word vectors of source language and Auto encoder helps us in reconstruction of the vectors for target language in tree structure. Results of word2vec play an important role in word alignment of the input vectors. RNN structure is very complicated and to train the large data file on word2vec is also a time-consuming task. Hence, a powerful hardware support (GPU) is required. GPU improves the system performance by decreasing training time period.", "year": 2017, "referenceCount": 14, "citationCount": 88, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2108407081", "name": "S. Singh"}, {"authorId": "2109186487", "name": "Ajai Kumar"}, {"authorId": "2992038", "name": "H. Darbari"}, {"authorId": "39259906", "name": "Lenali Singh"}, {"authorId": "31158157", "name": "Anshika Rastogi"}, {"authorId": "49837642", "name": "Shikha Jain"}]}, {"paperId": "08bd705920792314e3ef806c28d0a7f40505634f", "url": "https://www.semanticscholar.org/paper/08bd705920792314e3ef806c28d0a7f40505634f", "title": "Clustered Federated Learning: Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints", "abstract": "Federated learning (FL) is currently the most widely adopted framework for collaborative training of (deep) machine learning models under privacy constraints. Albeit its popularity, it has been observed that FL yields suboptimal results if the local clients\u2019 data distributions diverge. To address this issue, we present clustered FL (CFL), a novel federated multitask learning (FMTL) framework, which exploits geometric properties of the FL loss surface to group the client population into clusters with jointly trainable data distributions. In contrast to existing FMTL approaches, CFL does not require any modifications to the FL communication protocol to be made, is applicable to general nonconvex objectives (in particular, deep neural networks), does not require the number of clusters to be known a priori, and comes with strong mathematical guarantees on the clustering quality. CFL is flexible enough to handle client populations that vary over time and can be implemented in a privacy-preserving way. As clustering is only performed after FL has converged to a stationary point, CFL can be viewed as a postprocessing method that will always achieve greater or equal performance than conventional FL by allowing clients to arrive at more specialized models. We verify our theoretical analysis in experiments with deep convolutional and recurrent neural networks on commonly used FL data sets.", "year": 2019, "referenceCount": 43, "citationCount": 267, "influentialCitationCount": 42, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine", "Mathematics"], "authors": [{"authorId": "46223357", "name": "Felix Sattler"}, {"authorId": "145034054", "name": "K. M\u00fcller"}, {"authorId": "1699054", "name": "W. Samek"}]}, {"paperId": "13d8d4b8515717fba3b7dbe6cbafa64511140230", "url": "https://www.semanticscholar.org/paper/13d8d4b8515717fba3b7dbe6cbafa64511140230", "title": "Multisubject Learning for Common Spatial Patterns in Motor-Imagery BCI", "abstract": "Motor-imagery-based brain-computer interfaces (BCIs) commonly use the common spatial pattern filter (CSP) as preprocessing step before feature extraction and classification. The CSP method is a supervised algorithm and therefore needs subject-specific training data for calibration, which is very time consuming to collect. In order to reduce the amount of calibration data that is needed for a new subject, one can apply multitask (from now on called multisubject) machine learning techniques to the preprocessing phase. Here, the goal of multisubject learning is to learn a spatial filter for a new subject based on its own data and that of other subjects. This paper outlines the details of the multitask CSP algorithm and shows results on two data sets. In certain subjects a clear improvement can be seen, especially when the number of training trials is relatively low.", "year": 2011, "referenceCount": 18, "citationCount": 507, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2585222", "name": "D. Devlaminck"}, {"authorId": "1775487", "name": "B. Wyns"}, {"authorId": "1399050539", "name": "M. Grosse-Wentrup"}, {"authorId": "33985443", "name": "G. Otte"}, {"authorId": "1920462", "name": "P. Santens"}]}, {"paperId": "9884d18f265f9178ff9862d53cacbbc9957ddc4c", "url": "https://www.semanticscholar.org/paper/9884d18f265f9178ff9862d53cacbbc9957ddc4c", "title": "Advances in Variational Inference", "abstract": "Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully applied to various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.", "year": 2017, "referenceCount": 266, "citationCount": 391, "influentialCitationCount": 37, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "authors": [{"authorId": "37588498", "name": "C. Zhang"}, {"authorId": "2784486", "name": "Judith B\u00fctepage"}, {"authorId": "1704879", "name": "H. Kjellstr\u00f6m"}, {"authorId": "1783468", "name": "S. Mandt"}]}, {"paperId": "1ff60a51c94eebafdaacc6d0d3848e39b470b609", "url": "https://www.semanticscholar.org/paper/1ff60a51c94eebafdaacc6d0d3848e39b470b609", "title": "Deep Learning of Semisupervised Process Data With Hierarchical Extreme Learning Machine and Soft Sensor Application", "abstract": "Data-driven soft sensors have been widely utilized in industrial processes to estimate the critical quality variables which are intractable to directly measure online through physical devices. Due to the low sampling rate of quality variables, most of the soft sensors are developed on small number of labeled samples and the large number of unlabeled process data is discarded. The loss of information greatly limits the improvement of quality prediction accuracy. One of the main issues of data-driven soft sensor is to furthest exploit the information contained in all available process data. This paper proposes a semisupervised deep learning model for soft sensor development based on the hierarchical extreme learning machine (HELM). First, the deep network structure of autoencoders is implemented for unsupervised feature extraction with all the process samples. Then, extreme learning machine is utilized for regression through appending the quality variable. Meanwhile, the manifold regularization method is introduced for semisupervised model training. The new method can not only deeply extract the information that the data contains, but learn more from the extra unlabeled samples as well. The proposed semisupervised HELM method is applied in a high\u2013low transformer to estimate the carbon monoxide content, which shows a significant improvement of the prediction accuracy, compared to traditional methods.", "year": 2018, "referenceCount": 26, "citationCount": 173, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "48028582", "name": "Le Yao"}, {"authorId": "145619185", "name": "Zhiqiang Ge"}]}, {"paperId": "552d3cf6e713c7c98f6c1e3bdfcae748f91e4384", "url": "https://www.semanticscholar.org/paper/552d3cf6e713c7c98f6c1e3bdfcae748f91e4384", "title": "SVM Light: Support Vector Machine", "abstract": "Overview SVM light is an implementation of Support Vector Machines (SVMs) in C. The main features of the program are the following: fast optimization algorithm working set selection based on steepest feasible descent \"shrinking\" heuristic caching of kernel evaluations use of folding in the linear case solves classification and regression problems. For multivariate and structured outputs use SVM struct. solves ranking problems (e. g. learning retrieval functions in STRIVER search engine). computes XiAlpha-estimates of the error rate, the precision, and the recall efficiently computes Leave-One-Out estimates of the error rate, the precision, and the recall includes algorithm for approximately training large transductive SVMs (TSVMs) (see also Spectral Graph Transducer) can train SVMs with cost models and example dependent costs allows restarts from specified vector of dual variables handles many thousands of support vectors handles several hundred-thousands of training examples supports standard kernel functions and lets you define your own uses sparse vector representation SVM struct : SVM learning for multivariate and structured outputs like trees, sequences, and sets (available here).", "year": 2002, "referenceCount": 13, "citationCount": 147, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1680188", "name": "T. Joachims"}]}, {"paperId": "1b310cd2322cb14faa7d99038717c313a9441539", "url": "https://www.semanticscholar.org/paper/1b310cd2322cb14faa7d99038717c313a9441539", "title": "Kernel methods in system identification, machine learning and function estimation: A survey", "abstract": null, "year": 2014, "referenceCount": 194, "citationCount": 552, "influentialCitationCount": 35, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1719301", "name": "G. Pillonetto"}, {"authorId": "3125402", "name": "Francesco Dinuzzo"}, {"authorId": "7934735", "name": "Tianshi Chen"}, {"authorId": "7648294", "name": "G. Nicolao"}, {"authorId": "1699388", "name": "L. Ljung"}]}, {"paperId": "29b72183b618c6a87b583fa0d03f3279900fbf25", "url": "https://www.semanticscholar.org/paper/29b72183b618c6a87b583fa0d03f3279900fbf25", "title": "An Introduction to Nonlinear Dimensionality Reduction by Maximum Variance Unfolding", "abstract": "Many problems in AI are simplified by clever representations of sensory or symbolic input. How to discover such representations automatically, from large amounts of unlabeled data, remains a fundamental challenge. The goal of statistical methods for dimensionality reduction is to detect and discover low dimensional structure in high dimensional data. In this paper, we review a recently proposed algorithm-- maximum, variance unfolding--for learning faithful low dimensional representations of high dimensional data. The algorithm relies on modem tools in convex optimization that are proving increasingly useful in many areas of machine learning.", "year": 2006, "referenceCount": 12, "citationCount": 288, "influentialCitationCount": 21, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "7446832", "name": "Kilian Q. Weinberger"}, {"authorId": "1796044", "name": "L. Saul"}]}, {"paperId": "013c142c242b3239f5f19e41381b2175c7f3c1cd", "url": "https://www.semanticscholar.org/paper/013c142c242b3239f5f19e41381b2175c7f3c1cd", "title": "Searching molecular structure databases with tandem mass spectra using CSI:FingerID", "abstract": "Significance Untargeted metabolomics experiments usually rely on tandem MS (MS/MS) to identify the thousands of compounds in a biological sample. Today, the vast majority of metabolites remain unknown. Recently, several computational approaches were presented for searching molecular structure databases using MS/MS data. Here, we present CSI:FingerID, which combines fragmentation tree computation and machine learning. An in-depth evaluation on two large-scale datasets shows that our method can find 150% more correct identifications than the second-best search method. In comparison with the two runner-up methods, CSI:FingerID reaches 5.4-fold more unique identifications. We also present evaluations indicating that the performance of our method will further improve when more training data become available. CSI:FingerID is publicly available at www.csi-fingerid.org. Metabolites provide a direct functional signature of cellular state. Untargeted metabolomics experiments usually rely on tandem MS to identify the thousands of compounds in a biological sample. Today, the vast majority of metabolites remain unknown. We present a method for searching molecular structure databases using tandem MS data of small molecules. Our method computes a fragmentation tree that best explains the fragmentation spectrum of an unknown molecule. We use the fragmentation tree to predict the molecular structure fingerprint of the unknown compound using machine learning. This fingerprint is then used to search a molecular structure database such as PubChem. Our method is shown to improve on the competing methods for computational metabolite identification by a considerable margin.", "year": 2015, "referenceCount": 57, "citationCount": 483, "influentialCitationCount": 29, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Chemistry"], "authors": [{"authorId": "2178853", "name": "Kai D\u00fchrkop"}, {"authorId": "36230745", "name": "Huibin Shen"}, {"authorId": "47102593", "name": "Marvin Meusel"}, {"authorId": "2768655", "name": "Juho Rousu"}, {"authorId": "1715474", "name": "S. B\u00f6cker"}]}, {"paperId": "e1d7e18915bd8991373404ea157c3599e493122f", "url": "https://www.semanticscholar.org/paper/e1d7e18915bd8991373404ea157c3599e493122f", "title": "A Survey on Compiler Autotuning using Machine Learning", "abstract": "Since the mid-1990s, researchers have been trying to use machine-learning-based approaches to solve a number of different compiler optimization problems. These techniques primarily enhance the quality of the obtained results and, more importantly, make it feasible to tackle two main compiler optimization problems: optimization selection (choosing which optimizations to apply) and phase-ordering (choosing the order of applying optimizations). The compiler optimization space continues to grow due to the advancement of applications, increasing number of compiler optimizations, and new target architectures. Generic optimization passes in compilers cannot fully leverage newly introduced optimizations and, therefore, cannot keep up with the pace of increasing options. This survey summarizes and classifies the recent advances in using machine learning for the compiler optimization field, particularly on the two major problems of (1) selecting the best optimizations, and (2) the phase-ordering of optimizations. The survey highlights the approaches taken so far, the obtained results, the fine-grain classification among different approaches, and finally, the influential papers of the field.", "year": 2018, "referenceCount": 308, "citationCount": 131, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2206135", "name": "Amir H. Ashouri"}, {"authorId": "46315768", "name": "W. Killian"}, {"authorId": "1874233", "name": "J. Cavazos"}, {"authorId": "144570312", "name": "G. Palermo"}, {"authorId": "1784619", "name": "C. Silvano"}]}, {"paperId": "ad33d1fa8628cb55c32fb52feb537f65184c3b29", "url": "https://www.semanticscholar.org/paper/ad33d1fa8628cb55c32fb52feb537f65184c3b29", "title": "Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure", "abstract": "We show how to pretrain and fine-tune a multilayer neural network to learn a nonlinear transformation from the input space to a lowdimensional feature space in which K-nearest neighbour classification performs well. We also show how the non-linear transformation can be improved using unlabeled data. Our method achieves a much lower error rate than Support Vector Machines or standard backpropagation on a widely used version of the MNIST handwritten digit recognition task. If some of the dimensions of the low-dimensional feature space are not used for nearest neighbor classification, our method uses these dimensions to explicitly represent transformations of the digits that do not affect their identity.", "year": 2007, "referenceCount": 21, "citationCount": 496, "influentialCitationCount": 43, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov"}, {"authorId": "1695689", "name": "Geoffrey E. Hinton"}]}, {"paperId": "c950a3da3aa755e3cc25a304e9bf25cc2b56fea1", "url": "https://www.semanticscholar.org/paper/c950a3da3aa755e3cc25a304e9bf25cc2b56fea1", "title": "Combinatorial Approaches to Finding Subtle Signals in DNA Sequences", "abstract": "Signal finding (pattern discovery in unaligned DNA sequences) is a fundamental problem in both computer science and molecular biology with important applications in locating regulatory sites and drug target identification. Despite many studies, this problem is far from being resolved: most signals in DNA sequences are so complicated that we don't yet have good models or reliable algorithms for their recognition. We complement existing statistical and machine learning approaches to this problem by a combinatorial approach that proved to be successful in identifying very subtle signals.", "year": 2000, "referenceCount": 40, "citationCount": 628, "influentialCitationCount": 115, "isOpenAccess": false, "fieldsOfStudy": ["Biology", "Computer Science", "Medicine"], "authors": [{"authorId": "1779993", "name": "P. Pevzner"}, {"authorId": "144262905", "name": "S. Sze"}]}, {"paperId": "d38e8631bba0720becdaf7b89f79d9f9dca45d82", "url": "https://www.semanticscholar.org/paper/d38e8631bba0720becdaf7b89f79d9f9dca45d82", "title": "Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets", "abstract": "Despite the recent achievements in machine learning, we are still very far from achieving real artificial intelligence. In this paper, we discuss the limitations of standard deep learning approaches and show that some of these limitations can be overcome by learning how to grow the complexity of a model in a structured way. Specifically, we study the simplest sequence prediction problems that are beyond the scope of what is learnable with standard recurrent networks, algorithmically generated sequences which can only be learned by models which have the capacity to count and to memorize sequences. We show that some basic algorithms can be learned from sequential data using a recurrent network associated with a trainable memory.", "year": 2015, "referenceCount": 43, "citationCount": 360, "influentialCitationCount": 36, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2319608", "name": "Armand Joulin"}, {"authorId": "2047446108", "name": "Tomas Mikolov"}]}, {"paperId": "8d7f6dc8b0b9101580cc96f1f303d1eba3d590af", "url": "https://www.semanticscholar.org/paper/8d7f6dc8b0b9101580cc96f1f303d1eba3d590af", "title": "A Survey of Text Summarization Techniques", "abstract": null, "year": 2012, "referenceCount": 106, "citationCount": 495, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3115414", "name": "A. Nenkova"}, {"authorId": "145590324", "name": "K. McKeown"}]}, {"paperId": "31ac550caf8ca1ac779c5213510c85dc6c3d2227", "url": "https://www.semanticscholar.org/paper/31ac550caf8ca1ac779c5213510c85dc6c3d2227", "title": "The linear separability problem: some testing methods", "abstract": "The notion of linear separability is used widely in machine learning research. Learning algorithms that use this concept to learn include neural networks (single layer perceptron and recursive deterministic perceptron), and kernel machines (support vector machines). This paper presents an overview of several of the methods for testing linear separability between two classes. The methods are divided into four groups: Those based on linear programming, those based on computational geometry, one based on neural networks, and one based on quadratic programming. The Fisher linear discriminant method is also presented. A section on the quantification of the complexity of classification problems is included.", "year": 2006, "referenceCount": 36, "citationCount": 105, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Medicine", "Computer Science"], "authors": [{"authorId": "143845181", "name": "D. Elizondo"}]}, {"paperId": "ab561713a71da567d315c09da693060e32ee3470", "url": "https://www.semanticscholar.org/paper/ab561713a71da567d315c09da693060e32ee3470", "title": "Learning to Teach with Dynamic Loss Functions", "abstract": "Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as \"learning to teach with dynamic loss functions\" (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.", "year": 2018, "referenceCount": 62, "citationCount": 76, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "47767550", "name": "Lijun Wu"}, {"authorId": "143853336", "name": "Fei Tian"}, {"authorId": "2794096", "name": "Yingce Xia"}, {"authorId": "144566102", "name": "Yang Fan"}, {"authorId": "143826491", "name": "Tao Qin"}, {"authorId": "66117656", "name": "J. Lai"}, {"authorId": "2110264337", "name": "Tie-Yan Liu"}]}, {"paperId": "3d13d6f847e8f4c76c5a8d6f99fa49dbabe473c0", "url": "https://www.semanticscholar.org/paper/3d13d6f847e8f4c76c5a8d6f99fa49dbabe473c0", "title": "Automatic classification of MR scans in Alzheimer's disease.", "abstract": "To be diagnostically useful, structural MRI must reliably distinguish Alzheimer's disease (AD) from normal aging in individual scans. Recent advances in statistical learning theory have led to the application of support vector machines to MRI for detection of a variety of disease states. The aims of this study were to assess how successfully support vector machines assigned individual diagnoses and to determine whether data-sets combined from multiple scanners and different centres could be used to obtain effective classification of scans. We used linear support vector machines to classify the grey matter segment of T1-weighted MR scans from pathologically proven AD patients and cognitively normal elderly individuals obtained from two centres with different scanning equipment. Because the clinical diagnosis of mild AD is difficult we also tested the ability of support vector machines to differentiate control scans from patients without post-mortem confirmation. Finally we sought to use these methods to differentiate scans between patients suffering from AD from those with frontotemporal lobar degeneration. Up to 96% of pathologically verified AD patients were correctly classified using whole brain images. Data from different centres were successfully combined achieving comparable results from the separate analyses. Importantly, data from one centre could be used to train a support vector machine to accurately differentiate AD and normal ageing scans obtained from another centre with different subjects and different scanner equipment. Patients with mild, clinically probable AD and age/sex matched controls were correctly separated in 89% of cases which is compatible with published diagnosis rates in the best clinical centres. This method correctly assigned 89% of patients with post-mortem confirmed diagnosis of either AD or frontotemporal lobar degeneration to their respective group. Our study leads to three conclusions: Firstly, support vector machines successfully separate patients with AD from healthy aging subjects. Secondly, they perform well in the differential diagnosis of two different forms of dementia. Thirdly, the method is robust and can be generalized across different centres. This suggests an important role for computer based diagnostic image analysis for clinical practice.", "year": 2008, "referenceCount": 54, "citationCount": 1087, "influentialCitationCount": 87, "isOpenAccess": true, "fieldsOfStudy": ["Psychology", "Medicine"], "authors": [{"authorId": "144225920", "name": "S. Kl\u00f6ppel"}, {"authorId": "2609123", "name": "C. Stonnington"}, {"authorId": "145606181", "name": "C. Chu"}, {"authorId": "7447906", "name": "Bogdan Draganski"}, {"authorId": "116292660", "name": "R. Scahill"}, {"authorId": "1772842", "name": "J. Rohrer"}, {"authorId": "1764768", "name": "Nick C Fox"}, {"authorId": "144402064", "name": "C. Jack"}, {"authorId": "3985221", "name": "J. Ashburner"}, {"authorId": "52216909", "name": "Richard S. J. Frackowiak"}]}, {"paperId": "719e65379c5959141180a45f540f707d583b8ce2", "url": "https://www.semanticscholar.org/paper/719e65379c5959141180a45f540f707d583b8ce2", "title": "Accurate quantitative estimation of energy performance of residential buildings using statistical machine learning tools", "abstract": null, "year": 2012, "referenceCount": 28, "citationCount": 540, "influentialCitationCount": 45, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "2151583", "name": "A. Tsanas"}, {"authorId": "98132248", "name": "Angeliki Xifara"}]}, {"paperId": "aa2fbcf28b58ba3dd6e871d37331cb0ffe4cc390", "url": "https://www.semanticscholar.org/paper/aa2fbcf28b58ba3dd6e871d37331cb0ffe4cc390", "title": "A learning approach to improving sentence-level MT evaluation", "abstract": "The problem of evaluating machine translation (MT) systems is more challenging than it may first appear, as diverse translations can often be considered equally correct. The task is even more difficult when practical circumstances require that evaluation be done automatically over short texts, for instance, during incremental system development and error analysis. While several automatic metrics, such as BLEU, have been proposed and adopted for largescale MT system discrimination, they all fail to achieve satisfactory levels of correlation with human judgments at the sentence level. Here, a new class of metrics based on machine learning is introduced. A novel method involving classifying translations as machine or humanproduced rather than directly predicting numerical human judgments eliminates the need for labor-intensive user studies as a source of training data. The resulting metric, based on support vector machines, is shown to significantly improve upon current automatic metrics, increasing correlation with human judgments at the sentence level halfway toward that achieved by an independent human evaluator.", "year": 2004, "referenceCount": 14, "citationCount": 113, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145500336", "name": "Alex Kulesza"}, {"authorId": "1692491", "name": "S. Shieber"}]}, {"paperId": "c15b34f6cbf13643033f5d1152966911b7591eeb", "url": "https://www.semanticscholar.org/paper/c15b34f6cbf13643033f5d1152966911b7591eeb", "title": "Misleading Learners: Co-opting Your Spam Filter", "abstract": null, "year": 2009, "referenceCount": 22, "citationCount": 104, "influentialCitationCount": 8, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39743720", "name": "Blaine Nelson"}, {"authorId": "145140480", "name": "M. Barreno"}, {"authorId": "1852911", "name": "F. J. Chi"}, {"authorId": "1687701", "name": "A. Joseph"}, {"authorId": "1868067", "name": "Benjamin I. P. Rubinstein"}, {"authorId": "39708572", "name": "Udam Saini"}, {"authorId": "37210858", "name": "Charles Sutton"}, {"authorId": "1787610", "name": "J. Tygar"}, {"authorId": "2065015702", "name": "Kai Xia"}]}, {"paperId": "a74e08de91a756b067f2aac0533ec0ef30b0b127", "url": "https://www.semanticscholar.org/paper/a74e08de91a756b067f2aac0533ec0ef30b0b127", "title": "Machine Learning and Bias Correction of MODIS Aerosol Optical Depth", "abstract": "Machine-learning approaches (neural networks and support vector machines) are used to explore the reasons for a persistent bias between aerosol optical depth (AOD) retrieved from the MODerate resolution Imaging Spectroradiometer (MODIS) and the accurate ground-based Aerosol Robotic Network. While this bias falls within the expected uncertainty of the MODIS algorithms, there is room for algorithm improvement. The results of the machine-learning approaches suggest a link between the MODIS AOD biases and surface type. MODIS-derived AOD may be showing dependence on the surface type either because of the link between surface type and surface reflectance or because of the covariance between aerosol properties and surface type.", "year": 2009, "referenceCount": 21, "citationCount": 79, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Environmental Science", "Computer Science"], "authors": [{"authorId": "46965265", "name": "David John Lary"}, {"authorId": "96605497", "name": "L. Remer"}, {"authorId": "47734278", "name": "D. MacNeill"}, {"authorId": "3417950", "name": "B. Roscoe"}, {"authorId": "1732223", "name": "S. Paradise"}]}, {"paperId": "025917fd73695c87b2b35d8059b2961f433ae048", "url": "https://www.semanticscholar.org/paper/025917fd73695c87b2b35d8059b2961f433ae048", "title": "Big data machine learning using apache spark MLlib", "abstract": "Artificial intelligence, and particularly machine learning, has been used in many ways by the research community to turn a variety of diverse and even heterogeneous data sources into high quality facts and knowledge, providing premier capabilities to accurate pattern discovery. However, applying machine learning strategies on big and complex datasets is computationally expensive, and it consumes a very large amount of logical and physical resources, such as data file space, CPU, and memory. A sophisticated platform for efficient big data analytics is becoming more important these days as the data amount generated in a daily basis exceeds over quintillion bytes. Apache Spark MLlib is one of the most prominent platforms for big data analysis which offers a set of excellent functionalities for different machine learning tasks ranging from regression, classification, and dimension reduction to clustering and rule extraction. In this contribution, we explore, from the computational perspective, the expanding body of the Apache Spark MLlib 2.0 as an open-source, distributed, scalable, and platform independent machine learning library. Specifically, we perform several real world machine learning experiments to examine the qualitative and quantitative attributes of the platform. Furthermore, we highlight current trends in big data machine learning research and provide insights for future work.", "year": 2017, "referenceCount": 68, "citationCount": 59, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3023549", "name": "Mehdi Assefi"}, {"authorId": "8618149", "name": "Ehsun Behravesh"}, {"authorId": "2091591", "name": "Guangchi Liu"}, {"authorId": "31838600", "name": "A. Tafti"}]}, {"paperId": "9906692b7590a724f0ab3ae6831567efe69586c6", "url": "https://www.semanticscholar.org/paper/9906692b7590a724f0ab3ae6831567efe69586c6", "title": "Pixel-Based Machine Learning in Medical Imaging", "abstract": "Machine learning (ML) plays an important role in the medical imaging field, including medical image analysis and computer-aided diagnosis, because objects such as lesions and organs may not be represented accurately by a simple equation; thus, medical pattern recognition essentially require \u201clearning from examples.\u201d One of the most popular uses of ML is classification of objects such as lesions into certain classes (e.g., abnormal or normal, or lesions or nonlesions) based on input features (e.g., contrast and circularity) obtained from segmented object candidates. Recently, pixel/voxel-based ML (PML) emerged in medical image processing/analysis, which use pixel/voxel values in images directly instead of features calculated from segmented objects as input information; thus, feature calculation or segmentation is not required. Because the PML can avoid errors caused by inaccurate feature calculation and segmentation which often occur for subtle or complex objects, the performance of the PML can potentially be higher for such objects than that of common classifiers (i.e., feature-based MLs). In this paper, PMLs are surveyed to make clear (a) classes of PMLs, (b) similarities and differences within (among) different PMLs and those between PMLs and feature-based MLs, (c) advantages and limitations of PMLs, and (d) their applications in medical imaging.", "year": 2012, "referenceCount": 119, "citationCount": 82, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2118855751", "name": "Kenji Suzuki"}]}, {"paperId": "f720a3a92c666681413f835c36f6aba5456db9aa", "url": "https://www.semanticscholar.org/paper/f720a3a92c666681413f835c36f6aba5456db9aa", "title": "Automatically explaining machine learning prediction results: a demonstration on type 2 diabetes risk prediction", "abstract": null, "year": 2016, "referenceCount": 35, "citationCount": 74, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "authors": [{"authorId": "144050855", "name": "Gang Luo"}]}, {"paperId": "e494ef4e285520ba8daaeffa1626616f1e135baf", "url": "https://www.semanticscholar.org/paper/e494ef4e285520ba8daaeffa1626616f1e135baf", "title": "Model-based fault diagnosis in electric drives using machine learning", "abstract": "Electric motor and power electronics-based inverter are the major components in industrial and automotive electric drives. In this paper, we present a model-based fault diagnostics system developed using a machine learning technology for detecting and locating multiple classes of faults in an electric drive. Power electronics inverter can be considered to be the weakest link in such a system from hardware failure point of view; hence, this work is focused on detecting faults and finding which switches in the inverter cause the faults. A simulation model has been developed based on the theoretical foundations of electric drives to simulate the normal condition, all single-switch and post-short-circuit faults. A machine learning algorithm has been developed to automatically select a set of representative operating points in the (torque, speed) domain, which in turn is sent to the simulated electric drive model to generate signals for the training of a diagnostic neural network, fault diagnostic neural network (FDNN). We validated the capability of the FDNN on data generated by an experimental bench setup. Our research demonstrates that with a robust machine learning approach, a diagnostic system can be trained based on a simulated electric drive model, which can lead to a correct classification of faults over a wide operating domain.", "year": 2006, "referenceCount": 45, "citationCount": 126, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "31304755", "name": "Yi Lu Murphey"}, {"authorId": "144347027", "name": "M. Masrur"}, {"authorId": "31358642", "name": "ZhiHang Chen"}, {"authorId": "30834562", "name": "Baifang Zhang"}]}, {"paperId": "cfe7643e4f54cd2ce5b9a9478cf0a55dafb65d46", "url": "https://www.semanticscholar.org/paper/cfe7643e4f54cd2ce5b9a9478cf0a55dafb65d46", "title": "Machine Learning in High Energy Physics Community White Paper", "abstract": "Machine learning is an important applied research area in particle physics, beginning with applications to high-level physics analysis in the 1990s and 2000s, followed by an explosion of applications in particle and event identification and reconstruction in the 2010s. In this document we discuss promising future research and development areas in machine learning in particle physics with a roadmap for their implementation, software and hardware resource requirements, collaborative initiatives with the data science community, academia and industry, and training the particle physics community in data science. The main objective of the document is to connect and motivate these areas of research and development with the physics drivers of the High-Luminosity Large Hadron Collider and future neutrino experiments and identify the resource needs for their implementation. Additionally we identify areas where collaboration with external communities will be of great benefit.", "year": 2018, "referenceCount": 70, "citationCount": 130, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Physics", "Mathematics"], "authors": [{"authorId": "2555574", "name": "K. Albertsson"}, {"authorId": "2076048438", "name": "Piero Altoe"}, {"authorId": "145839220", "name": "D. Anderson"}, {"authorId": "46422123", "name": "M. Andrews"}, {"authorId": "26856321", "name": "Juan Pedro Araque Espinosa"}, {"authorId": "145435602", "name": "A. Aurisano"}, {"authorId": "4194523", "name": "L. Basara"}, {"authorId": "95703949", "name": "A. Bevan"}, {"authorId": "73991716", "name": "W. Bhimji"}, {"authorId": "2434951", "name": "D. Bonacorsi"}, {"authorId": "2177162564", "name": "P. Calafiura"}, {"authorId": "16253351", "name": "M. Campanelli"}, {"authorId": "32012717", "name": "Louis Capps"}, {"authorId": "30092039", "name": "F. Carminati"}, {"authorId": "2674972", "name": "S. Carrazza"}, {"authorId": "33024340", "name": "T. Childers"}, {"authorId": "3913447", "name": "E. Coniavitis"}, {"authorId": "11638962", "name": "K. Cranmer"}, {"authorId": "88976857", "name": "C. David"}, {"authorId": "2083433937", "name": "D. Davis"}, {"authorId": "1389378372", "name": "Javier Mauricio Duarte"}, {"authorId": "39024091", "name": "M. Erdmann"}, {"authorId": "51131571", "name": "J. Eschle"}, {"authorId": "6266455", "name": "A. Farbin"}, {"authorId": "51112700", "name": "M. Feickert"}, {"authorId": "145847058", "name": "N. Castro"}, {"authorId": "46268700", "name": "C. Fitzpatrick"}, {"authorId": "152233126", "name": "M. Floris"}, {"authorId": "152344273", "name": "A. Forti"}, {"authorId": "1389704694", "name": "J. Garra-Tico"}, {"authorId": "51110034", "name": "J. Gemmler"}, {"authorId": "102421475", "name": "M. Girone"}, {"authorId": "40955844", "name": "P. Glaysher"}, {"authorId": "14794022", "name": "S. Gleyzer"}, {"authorId": "145135665", "name": "V. Gligorov"}, {"authorId": "5778473", "name": "T. Golling"}, {"authorId": "51122440", "name": "Jonas Graw"}, {"authorId": "121643590", "name": "L. Gray"}, {"authorId": "144172679", "name": "D. Greenwood"}, {"authorId": "2058993880", "name": "T. Hacker"}, {"authorId": "144660463", "name": "J. Harvey"}, {"authorId": "94071841", "name": "B. Hegner"}, {"authorId": "24060472", "name": "L. Heinrich"}, {"authorId": "5043628", "name": "B. Hooberman"}, {"authorId": "46823312", "name": "J. Junggeburth"}, {"authorId": "11413078", "name": "M. Kagan"}, {"authorId": "144036260", "name": "M. Kane"}, {"authorId": "137998986", "name": "K. Kanishchev"}, {"authorId": "26936798", "name": "P. Karpinski"}, {"authorId": "4956058", "name": "Z. Kassabov"}, {"authorId": "40237549", "name": "Gaurav Kaul"}, {"authorId": "2956298", "name": "D. Kcira"}, {"authorId": "143926707", "name": "T. Keck"}, {"authorId": "144021890", "name": "A. Klimentov"}, {"authorId": "2080118", "name": "J. Kowalkowski"}, {"authorId": "31228673", "name": "Luke Kreczko"}, {"authorId": "152460087", "name": "A. Kurepin"}, {"authorId": "50874586", "name": "R. Kutschke"}, {"authorId": "2037763389", "name": "V. Kuznetsov"}, {"authorId": "51126328", "name": "Nicolas K\u00f6hler"}, {"authorId": "145830397", "name": "I. Lakomov"}, {"authorId": "1716753", "name": "K. Lannon"}, {"authorId": "32169062", "name": "M. Lassnig"}, {"authorId": "5241012", "name": "A. Limosani"}, {"authorId": "1881041", "name": "Gilles Louppe"}, {"authorId": "51122292", "name": "A. Mangu"}, {"authorId": "152172681", "name": "P. Mato"}, {"authorId": "51116386", "name": "N. Meenakshi"}, {"authorId": "46269977", "name": "H. Meinhard"}, {"authorId": "51050611", "name": "D. Menasce"}, {"authorId": "49778710", "name": "L. Moneta"}, {"authorId": "4494046", "name": "S. Moortgat"}, {"authorId": "48339925", "name": "M. Neubauer"}, {"authorId": "93596685", "name": "H. Newman"}, {"authorId": "1820941511", "name": "Hans Pabst"}, {"authorId": "35550664", "name": "Michela Paganini"}, {"authorId": "102306732", "name": "M. Paulini"}, {"authorId": "51116496", "name": "G. Perdue"}, {"authorId": "2095496051", "name": "Uzziel Perez"}, {"authorId": "51052756", "name": "A. Picazio"}, {"authorId": "3379619", "name": "J. Pivarski"}, {"authorId": "104308394", "name": "H. Prosper"}, {"authorId": "3393638", "name": "F. Psihas"}, {"authorId": "40189320", "name": "A. Radovic"}, {"authorId": "51129171", "name": "R. Reece"}, {"authorId": "51051191", "name": "Aurelius Rinkevicius"}, {"authorId": "2065078099", "name": "Eduardo Rodrigues"}, {"authorId": "14509605", "name": "J. Rorie"}, {"authorId": "3200334", "name": "D. Rousseau"}, {"authorId": "51127504", "name": "A. Sauers"}, {"authorId": "145245769", "name": "S. Schramm"}, {"authorId": "69907043", "name": "A. Schwartzman"}, {"authorId": "2259410", "name": "H. Severini"}, {"authorId": "4765849", "name": "P. Seyfert"}, {"authorId": "51133662", "name": "Filip Siroky"}, {"authorId": "1404979544", "name": "Konstantin Skazytkin"}, {"authorId": "2556099", "name": "M. Sokoloff"}, {"authorId": "34481035", "name": "G. Stewart"}, {"authorId": "25571773", "name": "B. Stienen"}, {"authorId": "40947541", "name": "I. Stockdale"}, {"authorId": "51119692", "name": "G. Strong"}, {"authorId": "51050561", "name": "S. Thais"}, {"authorId": "8865907", "name": "K. Tomko"}, {"authorId": "1735099", "name": "E. Upfal"}, {"authorId": "145191410", "name": "E. Usai"}, {"authorId": "1763161", "name": "A. Ustyuzhanin"}, {"authorId": "1387650493", "name": "M. Vala"}, {"authorId": "3425469", "name": "S. Vallecorsa"}, {"authorId": "51052911", "name": "M. Verzetti"}, {"authorId": "1382790348", "name": "X. Vilas\u00eds-Cardona"}, {"authorId": "52630992", "name": "J. Vlimant"}, {"authorId": "8426071", "name": "I. Vukotic"}, {"authorId": "2116230104", "name": "Sean Wang"}, {"authorId": "1815031", "name": "G. Watts"}, {"authorId": "2116400713", "name": "Michael Williams"}, {"authorId": "2143794603", "name": "Wenjing Wu"}, {"authorId": "1388409121", "name": "S. Wunsch"}, {"authorId": "2069219352", "name": "O. Zapata"}]}, {"paperId": "9ac088c00d5b279e057dc7beeb241ebe383d5af5", "url": "https://www.semanticscholar.org/paper/9ac088c00d5b279e057dc7beeb241ebe383d5af5", "title": "{AUC} maximizing support vector learning", "abstract": "The area under the ROC curve (AUC) is a natural performance measure when the goal is to find a discriminative decision function. We present a rigorous derivation of an AUC maximizing Support Vector Machine; its optimization criterion is composed of a convex bound on the AUC and a margin term. The number of constraints in the optimization problem grows quadratically in the number of examples. We discuss an approximation for large data sets that clusters the constraints. Our experiments show that the AUC maximizing Support Vector Machine does in fact lead to higher AUC values.", "year": 2005, "referenceCount": 23, "citationCount": 134, "influentialCitationCount": 20, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1765114", "name": "Ulf Brefeld"}, {"authorId": "1751348", "name": "T. Scheffer"}]}, {"paperId": "079932bf6ff8b99c899172ba60071818f6b5dfcb", "url": "https://www.semanticscholar.org/paper/079932bf6ff8b99c899172ba60071818f6b5dfcb", "title": "Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters", "abstract": "Deep learning models can take weeks to train on a single GPU-equipped machine, necessitating scaling out DL training to a GPU-cluster. However, current distributed DL implementations can scale poorly due to substantial parameter synchronization over the network, because the high throughput of GPUs allows more data batches to be processed per unit time than CPUs, leading to more frequent network synchronization. We present Poseidon, an efficient communication architecture for distributed DL on GPUs. Poseidon exploits the layered model structures in DL programs to overlap communication and computation, reducing bursty network communication. Moreover, Poseidon uses a hybrid communication scheme that optimizes the number of bytes required to synchronize each layer, according to layer properties and the number of machines. We show that Poseidon is applicable to different DL frameworks by plugging Poseidon into Caffe and TensorFlow. We show that Poseidon enables Caffe and TensorFlow to achieve 15.5x speed-up on 16 single-GPU machines, even with limited bandwidth (10GbE) and the challenging VGG19-22K network for image classification. Moreover, Poseidon-enabled TensorFlow achieves 31.5x speed-up with 32 single-GPU machines on Inception-V3, a 50% improvement over the open-source TensorFlow (20x speed-up).", "year": 2017, "referenceCount": 37, "citationCount": 253, "influentialCitationCount": 29, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1682058", "name": "H. Zhang"}, {"authorId": "2109692193", "name": "Zeyu Zheng"}, {"authorId": "1704538", "name": "Shizhen Xu"}, {"authorId": "143716171", "name": "Wei Dai"}, {"authorId": "1707357", "name": "Qirong Ho"}, {"authorId": "40250403", "name": "Xiaodan Liang"}, {"authorId": "2749311", "name": "Zhiting Hu"}, {"authorId": "1766143", "name": "Jinliang Wei"}, {"authorId": "40526720", "name": "P. Xie"}, {"authorId": "143977260", "name": "E. Xing"}]}, {"paperId": "9d7bbf669ce96e022379bc99f8b9aa6083400829", "url": "https://www.semanticscholar.org/paper/9d7bbf669ce96e022379bc99f8b9aa6083400829", "title": "One-Level Storage System", "abstract": "After a brief survey of the basic Atlas machine, the paper describes an automatic system which in principle can be applied to any combination of two storage systems so that the combination can be regarded by the machine user as a single level. The actual system described relates to a fast core store-drum combination. The effect of the system on instruction times is illustrated, and the tape transfer system is also introduced since it fits basically in through the same hardware. The scheme incorporates a ``learning'' program, a technique which can be of greater importance in future computers.", "year": 1962, "referenceCount": 7, "citationCount": 293, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Business"], "authors": [{"authorId": "34704748", "name": "T. Kilburn"}, {"authorId": "29334852", "name": "D. Edwards"}, {"authorId": "97926494", "name": "M. Lanigan"}, {"authorId": "24348125", "name": "F. Sumner"}]}, {"paperId": "660ff427b97bda39a007687b777a3e1fae56be9d", "url": "https://www.semanticscholar.org/paper/660ff427b97bda39a007687b777a3e1fae56be9d", "title": "The production of prediction: What does machine learning want?", "abstract": "Retail, media, finance, science, industry, security and government increasingly depend on predictions produced through techniques such as machine learning. How is it that machine learning can promise to predict with great specificity what differences matter or what people want in many different settings? We need, I suggest, an account of its generalization if we are to understand the contemporary production of prediction. This article maps the principal forms of material action, narrative and problematization that run across algorithmic modelling techniques such as logistic regression, decision trees and Naive Bayes classifiers. It highlights several interlinked modes of generalization that engender increasingly vast data infrastructures and platforms, and intensified mathematical and statistical treatments of differences. Such an account also points to some key sites of instability or problematization inherent to the process of generalization. If movement through data is becoming a principal intersection of power relations, economic value and valid knowledge, an account of the production of prediction might also help us begin to ask how its generalization potentially gives rise to new forms of agency, experience or individuations.", "year": 2015, "referenceCount": 34, "citationCount": 122, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39822261", "name": "A. Mackenzie"}]}, {"paperId": "c3af641a9a7fcb73924a211f97421d2b43c4599f", "url": "https://www.semanticscholar.org/paper/c3af641a9a7fcb73924a211f97421d2b43c4599f", "title": "Machine Learning", "abstract": null, "year": 2021, "referenceCount": 0, "citationCount": 44, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1439122425", "name": "Ethem Alpayd\u0131n"}]}, {"paperId": "cef206029e2a925e0754d23651ab228d5904d481", "url": "https://www.semanticscholar.org/paper/cef206029e2a925e0754d23651ab228d5904d481", "title": "A tutorial on -support vector machines", "abstract": "We briefly describe the main ideas of statistical learning theory, support vector machines (SVMs), and kernel feature spaces. We place particular emphasis on a description of the so-called -SVM, in...", "year": 2005, "referenceCount": 38, "citationCount": 125, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Economics"], "authors": [{"authorId": "1897534699", "name": "ChenPai-Hsuen"}, {"authorId": "1643819532", "name": "LinChih-Jen"}, {"authorId": "1643791277", "name": "Sch\u00f6lkopfBernhard"}]}, {"paperId": "70f1b279f96a9ba8e15f599635ba0e3ec449ef5f", "url": "https://www.semanticscholar.org/paper/70f1b279f96a9ba8e15f599635ba0e3ec449ef5f", "title": "Personalized Federated Learning with Moreau Envelopes", "abstract": "Federated learning (FL) is a decentralized and privacy-preserving machine learning technique in which a group of clients collaborate with a server to learn a global model without sharing clients' data. One challenge associated with FL is statistical diversity among clients, which restricts the global model from delivering good performance on each client's task. To address this, we propose an algorithm for personalized FL (pFedMe) using Moreau envelopes as clients' regularized loss functions, which help decouple personalized model optimization from the global model learning in a bi-level problem stylized for personalized FL. Theoretically, we show that pFedMe's convergence rate is state-of-the-art: achieving quadratic speedup for strongly convex and sublinear speedup of order 2/3 for smooth nonconvex objectives. Experimentally, we verify that pFedMe excels at empirical performance compared with the vanilla FedAvg and Per-FedAvg, a meta-learning based personalized FL algorithm.", "year": 2020, "referenceCount": 57, "citationCount": 276, "influentialCitationCount": 45, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "35784038", "name": "Canh T. Dinh"}, {"authorId": "145359941", "name": "Nguyen H. Tran"}, {"authorId": "2116225572", "name": "Tuan Dung Nguyen"}]}, {"paperId": "ff09de520ce7a40fb2e274cd91dac8fbce8adfc9", "url": "https://www.semanticscholar.org/paper/ff09de520ce7a40fb2e274cd91dac8fbce8adfc9", "title": "Machine Learning Techniques for Multimedia: Case Studies on Organization and Retrieval", "abstract": "to Learning Principles for Multimedia Data.- to Bayesian Methods and Decision Theory.- Supervised Learning.- Unsupervised Learning and Clustering.- Dimension Reduction.- Multimedia Applications.- Online Content-Based Image Retrieval Using Active Learning.- Conservative Learning for Object Detectors.- Machine Learning Techniques for Face Analysis.- Mental Search in Image Databases: Implicit Versus Explicit Content Query.- Combining Textual and Visual Information for Semantic Labeling of Images and Videos.- Machine Learning for Semi-structured Multimedia Documents: Application to Pornographic Filtering and Thematic Categorization.- Classification and Clustering of Music for Novel Music Access Applications.", "year": 2009, "referenceCount": 0, "citationCount": 64, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "51021910", "name": "M. Cord"}, {"authorId": "143709732", "name": "P. Cunningham"}, {"authorId": "5113463", "name": "D. Joshi"}]}, {"paperId": "83ef0b469a994b998d412d523e58256e7a151601", "url": "https://www.semanticscholar.org/paper/83ef0b469a994b998d412d523e58256e7a151601", "title": "Using recurrent neural network models for early detection of heart failure onset", "abstract": "Objective: We explored whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would improve model performance in predicting initial diagnosis of heart failure (HF) compared to conventional methods that ignore temporality. Materials and Methods: Data were from a health system\u2019s EHR on 3884 incident HF cases and 28\u2009903 controls, identified as primary care patients, between May 16, 2000, and May 23, 2013. Recurrent neural network (RNN) models using gated recurrent units (GRUs) were adapted to detect relations among time-stamped events (eg, disease diagnosis, medication orders, procedure orders, etc.) with a 12- to 18-month observation window of cases and controls. Model performance metrics were compared to regularized logistic regression, neural network, support vector machine, and K-nearest neighbor classifier approaches. Results: Using a 12-month observation window, the area under the curve (AUC) for the RNN model was 0.777, compared to AUCs for logistic regression (0.747), multilayer perceptron (MLP) with 1 hidden layer (0.765), support vector machine (SVM) (0.743), and K-nearest neighbor (KNN) (0.730). When using an 18-month observation window, the AUC for the RNN model increased to 0.883 and was significantly higher than the 0.834 AUC for the best of the baseline methods (MLP). Conclusion: Deep learning models adapted to leverage temporal relations appear to improve performance of models for detection of incident heart failure with a short observation window of 12\u201318 months.", "year": 2016, "referenceCount": 63, "citationCount": 568, "influentialCitationCount": 23, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "3242613", "name": "E. Choi"}, {"authorId": "20079790", "name": "A. Schuetz"}, {"authorId": "49523072", "name": "W. Stewart"}, {"authorId": "1738536", "name": "Jimeng Sun"}]}, {"paperId": "8725c167e385aeae93f90aceefb69819f84238c4", "url": "https://www.semanticscholar.org/paper/8725c167e385aeae93f90aceefb69819f84238c4", "title": "Survey of Machine Learning Accelerators", "abstract": "New machine learning accelerators are being announced and released each month for a variety of applications from speech recognition, video object detection, assisted driving, and many data center applications. This paper updates the survey of of AI accelerators and processors from last year's IEEE-HPEC paper. This paper collects and summarizes the current accelerators that have been publicly announced with performance and power consumption numbers. The performance and power values are plotted on a scatter graph and a number of dimensions and observations from the trends on this plot are discussed and analyzed. For instance, there are interesting trends in the plot regarding power consumption, numerical precision, and inference versus training. This year, there are many more announced accelerators that are implemented with many more architectures and technologies from vector engines, dataflow engines, neuromorphic designs, flash-based analog memory processing, and photonic-based processing.", "year": 2020, "referenceCount": 129, "citationCount": 58, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2097629", "name": "A. Reuther"}, {"authorId": "1684116", "name": "P. Michaleas"}, {"authorId": "2111328084", "name": "Michael Jones"}, {"authorId": "74882299", "name": "V. Gadepally"}, {"authorId": "2331418", "name": "S. Samsi"}, {"authorId": "3257323", "name": "J. Kepner"}]}, {"paperId": "2cebf0212380f83b7171fb5660f842c8d7043f60", "url": "https://www.semanticscholar.org/paper/2cebf0212380f83b7171fb5660f842c8d7043f60", "title": "Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge", "abstract": "Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumoris a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses thestate-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross tota lresection. Finally, we investigate the challenge of identifying the best ML algorithms for each of these tasks, considering that apart from being diverse on each instance of the challenge, the multi-institutional mpMRI BraTS dataset has also been a continuously evolving/growing dataset.", "year": 2018, "referenceCount": 109, "citationCount": 904, "influentialCitationCount": 52, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3199900", "name": "S. Bakas"}, {"authorId": "21119833", "name": "M. Reyes"}, {"authorId": "153194548", "name": "A. Jakab"}, {"authorId": "2067693441", "name": "S. Bauer"}, {"authorId": "2736816", "name": "M. Rempfler"}, {"authorId": "1842515", "name": "A. Crimi"}, {"authorId": "2099904817", "name": "R. Shinohara"}, {"authorId": "2018562628", "name": "Christoph Berger"}, {"authorId": "47286636", "name": "S. Ha"}, {"authorId": "3363368", "name": "Martin Rozycki"}, {"authorId": "1774950", "name": "M. Prastawa"}, {"authorId": "46822867", "name": "E. Alberts"}, {"authorId": "1959705", "name": "Jana Lipkov\u00e1"}, {"authorId": "37845261", "name": "J. Freymann"}, {"authorId": "40078837", "name": "J. Kirby"}, {"authorId": "1981194", "name": "M. Bilello"}, {"authorId": "1398249653", "name": "H. Fathallah-Shaykh"}, {"authorId": "1800611", "name": "R. Wiest"}, {"authorId": "38095391", "name": "J. Kirschke"}, {"authorId": "2364183", "name": "B. Wiestler"}, {"authorId": "2153726", "name": "R. Colen"}, {"authorId": "6287014", "name": "Aikaterini Kotrotsou"}, {"authorId": "50398915", "name": "Pamela J. LaMontagne"}, {"authorId": "145454295", "name": "D. Marcus"}, {"authorId": "49574776", "name": "Mikhail Milchenko"}, {"authorId": "117346498", "name": "Arash Nazeri"}, {"authorId": "2034063990", "name": "M. Weber"}, {"authorId": "4883630", "name": "A. Mahajan"}, {"authorId": "1455206803", "name": "Ujjwal Baid"}, {"authorId": "2082471952", "name": "Dongjin Kwon"}, {"authorId": "2938767", "name": "M. Agarwal"}, {"authorId": "2109936179", "name": "M. Alam"}, {"authorId": "1803435", "name": "A. Albiol"}, {"authorId": "35658720", "name": "A. Albiol"}, {"authorId": "34319048", "name": "Alex Varghese"}, {"authorId": "143723820", "name": "T. A. Tuan"}, {"authorId": "1699104", "name": "T. Arbel"}, {"authorId": "40585581", "name": "Aaron Avery"}, {"authorId": "51936673", "name": "B. Pranjal"}, {"authorId": "51007396", "name": "Subhashis Banerjee"}, {"authorId": "1411393839", "name": "Thomas Batchelder"}, {"authorId": "1902312", "name": "N. Batmanghelich"}, {"authorId": "40799943", "name": "E. Battistella"}, {"authorId": "2685024", "name": "M. Bendszus"}, {"authorId": "48512882", "name": "E. Benson"}, {"authorId": "40076935", "name": "J. Bernal"}, {"authorId": "2395747", "name": "G. Biros"}, {"authorId": "144511905", "name": "M. Cabezas"}, {"authorId": "40340011", "name": "Siddhartha Chandra"}, {"authorId": "2048602248", "name": "Yi-Ju Chang"}, {"authorId": "2053413480", "name": "et al."}]}, {"paperId": "302a251058006493ef50cc966c78cdc88c80a2c7", "url": "https://www.semanticscholar.org/paper/302a251058006493ef50cc966c78cdc88c80a2c7", "title": "Predictive Analytics with Microsoft Azure Machine Learning", "abstract": null, "year": 2015, "referenceCount": 1, "citationCount": 55, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1692499", "name": "R. Barga"}, {"authorId": "3369615", "name": "Valentine Fontama"}, {"authorId": "2242121", "name": "W. Tok"}]}, {"paperId": "30e3dee9e345260d25d79f3dd051eca836fec8ca", "url": "https://www.semanticscholar.org/paper/30e3dee9e345260d25d79f3dd051eca836fec8ca", "title": "From Real\u2010World Patient Data to Individualized Treatment Effects Using Machine Learning: Current and Future Methods to Address Underlying Challenges", "abstract": "Clinical decision making needs to be supported by evidence that treatments are beneficial to individual patients. Although randomized control trials (RCTs) are the gold standard for testing and introducing new drugs, due to the focus on specific questions with respect to establishing efficacy and safety vs. standard treatment, they do not provide a full characterization of the heterogeneity in the final intended treatment population. Conversely, real\u2010world observational data, such as electronic health records (EHRs), contain large amounts of clinical information about heterogeneous patients and their response to treatments. In this paper, we introduce the main opportunities and challenges in using observational data for training machine learning methods to estimate individualized treatment effects and make treatment recommendations. We describe the modeling choices of the state\u2010of\u2010the\u2010art machine learning methods for causal inference, developed for estimating treatment effects both in the cross\u2010section and longitudinal settings. Additionally, we highlight future research directions that could lead to achieving the full potential of leveraging EHRs and machine learning for making individualized treatment recommendations. We also discuss how experimental data from RCTs and Pharmacometric and Quantitative Systems Pharmacology approaches can be used to not only improve machine learning methods, but also provide ways for validating them. These future research directions will require us to collaborate across the scientific disciplines to incorporate models based on RCTs and known disease processes, physiology, and pharmacology into these machine learning models based on EHRs to fully optimize the opportunity these data present.", "year": 2020, "referenceCount": 117, "citationCount": 75, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1751623812", "name": "I. Bica"}, {"authorId": "145629795", "name": "A. Alaa"}, {"authorId": "2061832125", "name": "Craig Lambert"}, {"authorId": "1729969", "name": "M. Schaar"}]}, {"paperId": "fd0e6fb052b9be4d706dedd6b1b9eb89a677fa67", "url": "https://www.semanticscholar.org/paper/fd0e6fb052b9be4d706dedd6b1b9eb89a677fa67", "title": "Comparative Experiments on Sentiment Classification for Online Product Reviews", "abstract": "Evaluating text fragments for positive and negative subjective expressions and their strength can be important in applications such as single- or multi- document summarization, document ranking, data mining, etc. This paper looks at a simplified version of the problem: classifying online product reviews into positive and negative classes. We discuss a series of experiments with different machine learning algorithms in order to experimentally evaluate various trade-offs, using approximately 100K product reviews from the web.", "year": 2006, "referenceCount": 17, "citationCount": 366, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3129614", "name": "H. Cui"}, {"authorId": "1751139", "name": "Vibhu Mittal"}, {"authorId": "145112445", "name": "Mayur Datar"}]}, {"paperId": "8dd974f35a6a2adf0d0508c43ade01c801e30297", "url": "https://www.semanticscholar.org/paper/8dd974f35a6a2adf0d0508c43ade01c801e30297", "title": "Machine-Learning Prediction of CO Adsorption in Thiolated, Ag-Alloyed Au Nanoclusters.", "abstract": "We propose a machine-learning model, based on the random-forest method, to predict CO adsorption in thiolate protected nanoclusters. Two phases of feature selection and training, based initially on the Au25 nanocluster, are utilized in our model. One advantage to a machine-learning approach is that correlations in defined features disentangle relationships among the various structural parameters. For example, in Au25, we find that features based on the distribution of Ag atoms relative to the CO adsorption site are the most important in predicting adsorption energies. Our machine-learning model is easily extended to other Au-based nanoclusters, and we demonstrate predictions about CO adsorption on Ag-alloyed Au36 and Au133 nanoclusters.", "year": 2018, "referenceCount": 41, "citationCount": 67, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Chemistry"], "authors": [{"authorId": "15333658", "name": "G. Panapitiya"}, {"authorId": "1410616897", "name": "Guillermo Avenda\u00f1o-Franco"}, {"authorId": "47388017", "name": "Pengju Ren"}, {"authorId": "50653958", "name": "X. Wen"}, {"authorId": "2111166654", "name": "Yongwang Li"}, {"authorId": "2109240404", "name": "James P. Lewis"}]}, {"paperId": "b4299baa815ca5a815a70fba94a9f6f2b42fff19", "url": "https://www.semanticscholar.org/paper/b4299baa815ca5a815a70fba94a9f6f2b42fff19", "title": "A High-Performance Semi-Supervised Learning Method for Text Chunking", "abstract": "In machine learning, whether one can build a more accurate classifier by using unlabeled data (semi-supervised learning) is an important issue. Although a number of semi-supervised methods have been proposed, their effectiveness on NLP tasks is not always clear. This paper presents a novel semi-supervised method that employs a learning paradigm which we call structural learning. The idea is to find \"what good classifiers are like\" by learning from thousands of automatically generated auxiliary classification problems on unlabeled data. By doing so, the common predictive structure shared by the multiple classification problems can be discovered, which can then be used to improve performance on the target problem. The method produces performance higher than the previous best results on CoNLL'00 syntactic chunking and CoNLL'03 named entity chunking (English and German).", "year": 2005, "referenceCount": 21, "citationCount": 240, "influentialCitationCount": 23, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "38070424", "name": "R. Ando"}, {"authorId": "2117881943", "name": "Tong Zhang"}]}, {"paperId": "335dfbd8f4c60e44ade648280bddb4407a7c90c8", "url": "https://www.semanticscholar.org/paper/335dfbd8f4c60e44ade648280bddb4407a7c90c8", "title": "Combining metaheuristics with mathematical programming, constraint programming and machine learning", "abstract": null, "year": 2016, "referenceCount": 162, "citationCount": 84, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "41218226", "name": "E. Talbi"}]}, {"paperId": "39c3073181f2330804696a489f32d9c189febec1", "url": "https://www.semanticscholar.org/paper/39c3073181f2330804696a489f32d9c189febec1", "title": "Arabic Tweets Sentimental Analysis Using Machine Learning", "abstract": null, "year": 2017, "referenceCount": 17, "citationCount": 80, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3430877", "name": "K. Alomari"}, {"authorId": "2879551", "name": "H. M. Elsherif"}, {"authorId": "40241708", "name": "K. Shaalan"}]}, {"paperId": "4160673155915128ae9d28ba34f1192801fb2824", "url": "https://www.semanticscholar.org/paper/4160673155915128ae9d28ba34f1192801fb2824", "title": "Boosting compound-protein interaction prediction by deep learning", "abstract": "The identification of interactions between compounds and proteins plays an important role in network pharmacology and drug discovery. However, experimentally identifying compound-protein interactions (CPIs) is generally expensive and time-consuming, computational approaches are thus introduced. Among these, machine-learning based methods have achieved a considerable success. However, due to the nonlinear and imbalanced nature of biological data, many machine learning approaches have their own limitations. Recently, deep learning techniques show advantages over many state-of-the-art machine learning methods in many applications. In this study, we aim at improving the performance of CPI prediction based on deep learning, and propose a method called DL-CPI (the abbreviation of Deep Learning for Compound-Protein Interactions prediction), which employs deep neural network (DNN) to effectively learn the representations of compound-protein pairs. Extensive experiments show that DL-CPI can learn useful features of compound-protein pairs by a layerwise abstraction, and thus achieves better prediction performance than existing methods on both balanced and imbalanced datasets.", "year": 2015, "referenceCount": 39, "citationCount": 118, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "2065130003", "name": "Kai Tian"}, {"authorId": "1471282712", "name": "Mingyu Shao"}, {"authorId": "50730331", "name": "Shuigeng Zhou"}, {"authorId": "1707899", "name": "J. Guan"}]}, {"paperId": "08296665aa24d7d20b1f0997756750a5f1f49e7f", "url": "https://www.semanticscholar.org/paper/08296665aa24d7d20b1f0997756750a5f1f49e7f", "title": "Statistical Learning Theory and Support Vector Machines", "abstract": "It has been more than 30 years that statistical learning theory (SLT) has been introduced in the field of machine learning. Its objective is to provide a framework for studying the problem of inference that is of gaining knowledge, making predictions, making decisions or constructing models from a set of data. Support Vector Machine, a method based on SLT, then emerged and becoming a widely accepted method for solving real-world problems. This paper overviews the pattern recognition techniques and describes the state of art in SVM in the field of pattern recognition.", "year": 2010, "referenceCount": 62, "citationCount": 84, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2677048", "name": "D. Nasien"}, {"authorId": "2285634", "name": "S. Yuhaniz"}, {"authorId": "2208192", "name": "H. Haron"}]}, {"paperId": "23cd2de2d754f53f6e0527d117b227b683387b4b", "url": "https://www.semanticscholar.org/paper/23cd2de2d754f53f6e0527d117b227b683387b4b", "title": "A Performance Evaluation of Machine Learning-Based Streaming Spam Tweets Detection", "abstract": "The popularity of Twitter attracts more and more spammers. Spammers send unwanted tweets to Twitter users to promote websites or services, which are harmful to normal users. In order to stop spammers, researchers have proposed a number of mechanisms. The focus of recent works is on the application of machine learning techniques into Twitter spam detection. However, tweets are retrieved in a streaming way, and Twitter provides the Streaming API for developers and researchers to access public tweets in real time. There lacks a performance evaluation of existing machine learning-based streaming spam detection methods. In this paper, we bridged the gap by carrying out a performance evaluation, which was from three different aspects of data, feature, and model. A big ground-truth of over 600 million public tweets was created by using a commercial URL-based security tool. For real-time spam detection, we further extracted 12 lightweight features for tweet representation. Spam detection was then transformed to a binary classification problem in the feature space and can be solved by conventional machine learning algorithms. We evaluated the impact of different factors to the spam detection performance, which included spam to nonspam ratio, feature discretization, training data size, data sampling, time-related data, and machine learning algorithms. The results show the streaming spam tweet detection is still a big challenge and a robust detection technique should take into account the three aspects of data, feature, and model.", "year": 2015, "referenceCount": 41, "citationCount": 95, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2145763295", "name": "Chao Chen"}, {"authorId": "37269546", "name": "Jun Zhang"}, {"authorId": "144802684", "name": "Yi Xie"}, {"authorId": "98232756", "name": "Yang Xiang"}, {"authorId": "1745566", "name": "Wanlei Zhou"}, {"authorId": "1745717", "name": "M. Hassan"}, {"authorId": "2682134", "name": "Abdulhameed Alelaiwi"}, {"authorId": "1994425", "name": "Majed Alrubaian"}]}, {"paperId": "cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d", "url": "https://www.semanticscholar.org/paper/cf5ea582bccc7cb21a2ebeb7a0987f79652bde8d", "title": "Knowledge vault: a web-scale approach to probabilistic knowledge fusion", "abstract": "Recent years have witnessed a proliferation of large-scale knowledge bases, including Wikipedia, Freebase, YAGO, Microsoft's Satori, and Google's Knowledge Graph. To increase the scale even further, we need to explore automatic methods for constructing knowledge bases. Previous approaches have primarily focused on text-based extraction, which can be very noisy. Here we introduce Knowledge Vault, a Web-scale probabilistic knowledge base that combines extractions from Web content (obtained via analysis of text, tabular data, page structure, and human annotations) with prior knowledge derived from existing knowledge repositories. We employ supervised machine learning methods for fusing these distinct information sources. The Knowledge Vault is substantially bigger than any previously published structured knowledge repository, and features a probabilistic inference system that computes calibrated probabilities of fact correctness. We report the results of multiple studies that explore the relative utility of the different information sources and extraction methods.", "year": 2014, "referenceCount": 50, "citationCount": 1487, "influentialCitationCount": 161, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145867172", "name": "Xin Dong"}, {"authorId": "1718798", "name": "E. Gabrilovich"}, {"authorId": "1728179", "name": "G. Heitz"}, {"authorId": "40428294", "name": "Wilko Horn"}, {"authorId": "1914797", "name": "N. Lao"}, {"authorId": "1702318", "name": "K. Murphy"}, {"authorId": "2931575", "name": "Thomas Strohmann"}, {"authorId": "2109375570", "name": "Shaohua Sun"}, {"authorId": null, "name": "Wei Zhang"}]}, {"paperId": "ee3d8fad2ce98f20b5a3cffb2a8deed3cb673479", "url": "https://www.semanticscholar.org/paper/ee3d8fad2ce98f20b5a3cffb2a8deed3cb673479", "title": "Scaling, machine learning, and genetic neural nets", "abstract": null, "year": 1989, "referenceCount": 21, "citationCount": 103, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1705072", "name": "E. Mjolsness"}, {"authorId": "11069815", "name": "D. Sharp"}, {"authorId": "35147437", "name": "B. Alpert"}]}, {"paperId": "808476bcc068a2621ad9f57195670c7c65bc131b", "url": "https://www.semanticscholar.org/paper/808476bcc068a2621ad9f57195670c7c65bc131b", "title": "Learning the quantum algorithm for state overlap", "abstract": "Short-depth algorithms are crucial for reducing computational error on near-term quantum computers, for which decoherence and gate infidelity remain important issues. Here we present a machine-learning approach for discovering such algorithms. We apply our method to a ubiquitous primitive: computing the overlap Tr ( \u03c1 \u03c3 ) between two quantum states \u03c1 and \u03c3. The standard algorithm for this task, known as the Swap Test, is used in many applications such as quantum support vector machines, and, when specialized to \u03c1 = \u03c3, quantifies the Renyi entanglement. Here, we find algorithms that have shorter depths than the Swap Test, including one that has a constant depth (independent of problem size). Furthermore, we apply our approach to the hardware-specific connectivity and gate sets used by Rigetti\u2019s and IBM\u2019s quantum computers and demonstrate that the shorter algorithms that we derive significantly reduce the error\u2014compared to the Swap Test\u2014on these computers.", "year": 2018, "referenceCount": 38, "citationCount": 154, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "49556529", "name": "L. Cincio"}, {"authorId": "102838891", "name": "Y. Suba\u015f\u0131"}, {"authorId": "2110179", "name": "A. Sornborger"}, {"authorId": "50721537", "name": "Patrick J. Coles"}]}, {"paperId": "1617cfa2103e8d5dd33e65401327a3260c28d059", "url": "https://www.semanticscholar.org/paper/1617cfa2103e8d5dd33e65401327a3260c28d059", "title": "Stochastic Alternating Direction Method of Multipliers", "abstract": "The Alternating Direction Method of Multipliers (ADMM) has received lots of attention recently due to the tremendous demand from large-scale and data-distributed machine learning applications. In this paper, we present a stochastic setting for optimization problems with non-smooth composite objective functions. To solve this problem, we propose a stochastic ADMM algorithm. Our algorithm applies to a more general class of convex and nonsmooth objective functions, beyond the smooth and separable least squares loss used in lasso. We also demonstrate the rates of convergence for our algorithm under various structural assumptions of the stochastic function: O(1/\u221at)) for convex functions and O(log t/t) for strongly convex functions. Compared to previous literature, we establish the convergence rate of ADMM for convex problems in terms of both the objective value and the feasibility violation. A novel application named Graph-Guided SVM is proposed to demonstrate the usefulness of our algorithm.", "year": 2013, "referenceCount": 43, "citationCount": 257, "influentialCitationCount": 67, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "34346353", "name": "H. Ouyang"}, {"authorId": "2903347", "name": "Niao He"}, {"authorId": "2055288480", "name": "L. Tran"}, {"authorId": "1703070", "name": "Alexander G. Gray"}]}, {"paperId": "126113d251297812e091c5990064c8300effa684", "url": "https://www.semanticscholar.org/paper/126113d251297812e091c5990064c8300effa684", "title": "Bridged Refinement for Transfer Learning", "abstract": null, "year": 2007, "referenceCount": 20, "citationCount": 77, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "15146619", "name": "Dikan Xing"}, {"authorId": "1752769", "name": "Wenyuan Dai"}, {"authorId": "1701421", "name": "Gui-Rong Xue"}, {"authorId": "1811427", "name": "Yong Yu"}]}, {"paperId": "d0f95a9ae047ca69ca30b0ca88be7387b2074c23", "url": "https://www.semanticscholar.org/paper/d0f95a9ae047ca69ca30b0ca88be7387b2074c23", "title": "A Machine Learning Approach to Software Requirements Prioritization", "abstract": "Deciding which, among a set of requirements, are to be considered first and in which order is a strategic process in software development. This task is commonly referred to as requirements prioritization. This paper describes a requirements prioritization method called Case-Based Ranking (CBRank), which combines project's stakeholders preferences with requirements ordering approximations computed through machine learning techniques, bringing promising advantages. First, the human effort to input preference information can be reduced, while preserving the accuracy of the final ranking estimates. Second, domain knowledge encoded as partial order relations defined over the requirement attributes can be exploited, thus supporting an adaptive elicitation process. The techniques CBRank rests on and the associated prioritization process are detailed. Empirical evaluations of properties of CBRank are performed on simulated data and compared with a state-of-the-art prioritization method, providing evidence of the method ability to support the management of the tradeoff between elicitation effort and ranking accuracy and to exploit domain knowledge. A case study on a real software project complements these experimental measurements. Finally, a positioning of CBRank with respect to state-of-the-art requirements prioritization methods is proposed, together with a discussion of benefits and limits of the method.", "year": 2013, "referenceCount": 43, "citationCount": 138, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144124986", "name": "A. Perini"}, {"authorId": "145030257", "name": "A. Susi"}, {"authorId": "1744234", "name": "P. Avesani"}]}, {"paperId": "f6cb47a3b5f27833cfc3f7b7cebffea1e0dfb91b", "url": "https://www.semanticscholar.org/paper/f6cb47a3b5f27833cfc3f7b7cebffea1e0dfb91b", "title": "Using machine learning to replicate chaotic attractors and calculate Lyapunov exponents from data.", "abstract": "We use recent advances in the machine learning area known as \"reservoir computing\" to formulate a method for model-free estimation from data of the Lyapunov exponents of a chaotic process. The technique uses a limited time series of measurements as input to a high-dimensional dynamical system called a \"reservoir.\" After the reservoir's response to the data is recorded, linear regression is used to learn a large set of parameters, called the \"output weights.\" The learned output weights are then used to form a modified autonomous reservoir designed to be capable of producing an arbitrarily long time series whose ergodic properties approximate those of the input signal. When successful, we say that the autonomous reservoir reproduces the attractor's \"climate.\" Since the reservoir equations and output weights are known, we can compute the derivatives needed to determine the Lyapunov exponents of the autonomous reservoir, which we then use as estimates of the Lyapunov exponents for the original input generating system. We illustrate the effectiveness of our technique with two examples, the Lorenz system and the Kuramoto-Sivashinsky (KS) equation. In the case of the KS equation, we note that the high dimensional nature of the system and the large number of Lyapunov exponents yield a challenging test of our method, which we find the method successfully passes.", "year": 2017, "referenceCount": 25, "citationCount": 341, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Medicine"], "authors": [{"authorId": "35620505", "name": "Jaideep Pathak"}, {"authorId": "34949672", "name": "Zhixin Lu"}, {"authorId": "1868698", "name": "B. Hunt"}, {"authorId": "3269691", "name": "M. Girvan"}, {"authorId": "144596753", "name": "E. Ott"}]}, {"paperId": "6b97bb582249022377fafff51e64b3ec197342f2", "url": "https://www.semanticscholar.org/paper/6b97bb582249022377fafff51e64b3ec197342f2", "title": "Anomaly Detection for Resonant New Physics with Machine Learning.", "abstract": "Despite extensive theoretical motivation for physics beyond the standard model (BSM) of particle physics, searches at the Large Hadron Collider have found no significant evidence for BSM physics. Therefore, it is essential to broaden the sensitivity of the search program to include unexpected scenarios. We present a new model-agnostic anomaly detection technique that naturally benefits from modern machine learning algorithms. The only requirement on the signal for this new procedure is that it is localized in at least one known direction in phase space. Any other directions of phase space that are uncorrelated with the localized one can be used to search for unexpected features. This new method is applied to the dijet resonance search to show that it can turn a modest 2\u03c3 excess into a 7\u03c3 excess for a model with an intermediate BSM particle that is not currently targeted by a dedicated search.", "year": 2018, "referenceCount": 85, "citationCount": 125, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Medicine"], "authors": [{"authorId": "153639309", "name": "J. Collins"}, {"authorId": "28203888", "name": "K. Howe"}, {"authorId": "3085579", "name": "B. Nachman"}]}, {"paperId": "de338882ca81b4ecf486f10b12ca71d4131d09f4", "url": "https://www.semanticscholar.org/paper/de338882ca81b4ecf486f10b12ca71d4131d09f4", "title": "Understanding the Origins of Bias in Word Embeddings", "abstract": "The power of machine learning systems not only promises great technical progress, but risks societal harm. As a recent example, researchers have shown that popular word embedding algorithms exhibit stereotypical biases, such as gender bias. The widespread use of these algorithms in machine learning systems, from automated translation services to curriculum vitae scanners, can amplify stereotypes in important contexts. Although methods have been developed to measure these biases and alter word embeddings to mitigate their biased representations, there is a lack of understanding in how word embedding bias depends on the training data. In this work, we develop a technique for understanding the origins of bias in word embeddings. Given a word embedding trained on a corpus, our method identifies how perturbing the corpus will affect the bias of the resulting embedding. This can be used to trace the origins of word embedding bias back to the original training documents. Using our method, one can investigate trends in the bias of the underlying corpus and identify subsets of documents whose removal would most reduce bias. We demonstrate our techniques on both a New York Times and Wikipedia corpus and find that our influence function-based approximations are very accurate.", "year": 2018, "referenceCount": 25, "citationCount": 116, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "16233775", "name": "Marc-Etienne Brunet"}, {"authorId": "1411418984", "name": "Colleen Alkalay-Houlihan"}, {"authorId": "32071555", "name": "Ashton Anderson"}, {"authorId": "1804104", "name": "R. Zemel"}]}, {"paperId": "83ec245d470a3b75c0861acd5e67db5216e8e049", "url": "https://www.semanticscholar.org/paper/83ec245d470a3b75c0861acd5e67db5216e8e049", "title": "Automating model search for large scale machine learning", "abstract": "The proliferation of massive datasets combined with the development of sophisticated analytical techniques has enabled a wide variety of novel applications such as improved product recommendations, automatic image tagging, and improved speech-driven interfaces. A major obstacle to supporting these predictive applications is the challenging and expensive process of identifying and training an appropriate predictive model. Recent efforts aiming to automate this process have focused on single node implementations and have assumed that model training itself is a black box, limiting their usefulness for applications driven by large-scale datasets. In this work, we build upon these recent efforts and propose an architecture for automatic machine learning at scale comprised of a cost-based cluster resource allocation estimator, advanced hyper-parameter tuning techniques, bandit resource allocation via runtime algorithm introspection, and physical optimization via batching and optimal resource allocation. The result is TuPAQ, a component of the MLbase system that automatically finds and trains models for a user's predictive application with comparable quality to those found using exhaustive strategies, but an order of magnitude more efficiently than the standard baseline approach. TuPAQ scales to models trained on Terabytes of data across hundreds of machines.", "year": 2015, "referenceCount": 58, "citationCount": 139, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144752747", "name": "Evan R. Sparks"}, {"authorId": "145532827", "name": "Ameet S. Talwalkar"}, {"authorId": "30462672", "name": "D. Haas"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "1694621", "name": "Michael I. Jordan"}, {"authorId": "1746961", "name": "Tim Kraska"}]}, {"paperId": "b88aff3b7bb19035ed3e420ff3cbc50bf9fe2df5", "url": "https://www.semanticscholar.org/paper/b88aff3b7bb19035ed3e420ff3cbc50bf9fe2df5", "title": "Tensor Train decomposition on TensorFlow (T3F)", "abstract": "Tensor Train decomposition is used across many branches of machine learning, but until now it lacked an implementation with GPU support, batch processing, automatic differentiation, and versatile functionality for Riemannian optimization framework, which takes in account the underlying manifold structure in order to construct efficient optimization methods. In this work, we propose a library that aims to fix it and makes machine learning papers that rely on Tensor Train decomposition easier to implement. The library includes 92% test coverage, examples, and API reference documentation.", "year": 2018, "referenceCount": 35, "citationCount": 46, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2050212830", "name": "Alexander Novikov"}, {"authorId": "7991830", "name": "Pavel Izmailov"}, {"authorId": "10662951", "name": "Valentin Khrulkov"}, {"authorId": "73776617", "name": "Michael Figurnov"}, {"authorId": "1738205", "name": "I. Oseledets"}]}, {"paperId": "96ac1d61ff5ed5d4fc828f62297e8e007d7b674e", "url": "https://www.semanticscholar.org/paper/96ac1d61ff5ed5d4fc828f62297e8e007d7b674e", "title": "Early Methods for Detecting Adversarial Images", "abstract": "Many machine learning classifiers are vulnerable to adversarial perturbations. An adversarial perturbation modifies an input to change a classifier's prediction without causing the input to seem substantially different to human perception. We deploy three methods to detect adversarial images. Adversaries trying to bypass our detectors must make the adversarial image less pathological or they will fail trying. Our best detection method reveals that adversarial images place abnormal emphasis on the lower-ranked principal components from PCA. Other detectors and a colorful saliency map are in an appendix.", "year": 2016, "referenceCount": 21, "citationCount": 186, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "3422872", "name": "Dan Hendrycks"}, {"authorId": "1700980", "name": "Kevin Gimpel"}]}, {"paperId": "ab35b1d088a15daa6e6b0831e814d1c0aaec5b87", "url": "https://www.semanticscholar.org/paper/ab35b1d088a15daa6e6b0831e814d1c0aaec5b87", "title": "Information Perspective to Probabilistic Modeling: Boltzmann Machines versus Born Machines", "abstract": "We compare and contrast the statistical physics and quantum physics inspired approaches for unsupervised generative modeling of classical data. The two approaches represent probabilities of observed data using energy-based models and quantum states, respectively. Classical and quantum information patterns of the target datasets therefore provide principled guidelines for structural design and learning in these two approaches. Taking the Restricted Boltzmann Machines (RBM) as an example, we analyze the information theoretical bounds of the two approaches. We also estimate the classical mutual information of the standard MNIST datasets and the quantum R\u00e9nyi entropy of corresponding Matrix Product States (MPS) representations. Both information measures are much smaller compared to their theoretical upper bound and exhibit similar patterns, which imply a common inductive bias of low information complexity. By comparing the performance of RBM with various architectures on the standard MNIST datasets, we found that the RBM with local sparse connection exhibit high learning efficiency, which supports the application of tensor network states in machine learning problems.", "year": 2017, "referenceCount": 105, "citationCount": 73, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Mathematics", "Computer Science", "Medicine"], "authors": [{"authorId": "145354942", "name": "Song Cheng"}, {"authorId": "145539430", "name": "J. Chen"}, {"authorId": "2152511181", "name": "Lei Wang"}]}, {"paperId": "0b04f080f56a99c97c9bfbc3fd7317742d161014", "url": "https://www.semanticscholar.org/paper/0b04f080f56a99c97c9bfbc3fd7317742d161014", "title": "Early Detection of Diabetic Retinopathy Using PCA-Firefly Based Deep Learning Model", "abstract": "Diabetic Retinopathy is a major cause of vision loss and blindness affecting millions of people across the globe. Although there are established screening methods - fluorescein angiography and optical coherence tomography for detection of the disease but in majority of the cases, the patients remain ignorant and fail to undertake such tests at an appropriate time. The early detection of the disease plays an extremely important role in preventing vision loss which is the consequence of diabetes mellitus remaining untreated among patients for a prolonged time period. Various machine learning and deep learning approaches have been implemented on diabetic retinopathy dataset for classification and prediction of the disease but majority of them have neglected the aspect of data pre-processing and dimensionality reduction, leading to biased results. The dataset used in the present study is a diabetes retinopathy dataset collected from the UCI machine learning repository. At its inceptions, the raw dataset is normalized using the Standardscalar technique and then Principal Component Analysis (PCA) is used to extract the most significant features in the dataset. Further, Firefly algorithm is implemented for dimensionality reduction. This reduced dataset is fed into a Deep Neural Network Model for classification. The results generated from the model is evaluated against the prevalent machine learning models and the results justify the superiority of the proposed model in terms of Accuracy, Precision, Recall, Sensitivity and Specificity.", "year": 2020, "referenceCount": 42, "citationCount": 151, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "11041265", "name": "T. Gadekallu"}, {"authorId": "2705556", "name": "Neelu Khare"}, {"authorId": "71424255", "name": "S. Bhattacharya"}, {"authorId": "144704227", "name": "Saurabh Singh"}, {"authorId": "29919430", "name": "P. Maddikunta"}, {"authorId": "40123895", "name": "In-ho Ra"}, {"authorId": "2474250", "name": "M. Alazab"}]}, {"paperId": "f2339cab222de05377f40858d549f53cfd34f804", "url": "https://www.semanticscholar.org/paper/f2339cab222de05377f40858d549f53cfd34f804", "title": "Machine learning in radiation oncology : theory and applications", "abstract": "Introduction: What is Machine Learning.- Computational Learning Theory.- Overview of Supervised Learning Methods.- Overview of Unsupervised Learning Methods.- Performance Evaluation.- Variety of Applications in Radiation Oncology.- Machine Learning for Quality Assurance: Quality Assurance as a Learning Problem.- Detection of Radiotherapy Errors Using Unsupervised Learning.- Prediction of Radiotherapy Errors Using Supervised Learning.- Machine Learning for Computer-Aided Detection: Detection of Cancer Lesions from Imaging.- Classification of Malignant and Benign Tumours.- Machine Learning for Treatment Planning and Delivery.- Image-guided Radiotherapy with Machine Learning: IMRT Optimization Using Machine Learning.- Treatment Assessment Tools.- Machine Learning for Motion Management: Prediction of Respiratory Motion.- Motion-Correction Using Learning Methods.- Machine Learning Application in 4D-CT.- Machine Learning Application in Dynamic Delivery.- Machine Learning for Outcomes Modeling: Bioinformatics of Treatment Response.- Modelling of Norma Tissue Complication Probabilities (NTCP).- Modelling of Tumour Control Probability (TCP).", "year": 2015, "referenceCount": 0, "citationCount": 33, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2571273", "name": "I. E. Naqa"}, {"authorId": "1736607", "name": "Ruijiang Li"}, {"authorId": "30436861", "name": "M. Murphy"}]}, {"paperId": "85eb54db4ea19f8ac260e59ce57fd860890492a1", "url": "https://www.semanticscholar.org/paper/85eb54db4ea19f8ac260e59ce57fd860890492a1", "title": "Last Words: Computational Linguistics and Deep Learning", "abstract": "Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences. However, some pundits are predicting that the final damage will be even worse. Accompanying ICML 2015 in Lille, France, there was another, almost as big, event: the 2015 Deep Learning Workshop. The workshop ended with a panel discussion, and at it, Neil Lawrence said, \u201cNLP is kind of like a rabbit in the headlights of the Deep Learning machine, waiting to be flattened.\u201d Now that is a remark that the computational linguistics community has to take seriously! Is it the end of the road for us? Where are these predictions of steamrollering coming from? At the June 2015 opening of the Facebook AI Research Lab in Paris, its director Yann LeCun said: \u201cThe next big step for Deep Learning is natural language understanding, which aims to give machines the power to understand not just individual words but entire sentences and paragraphs.\u201d1 In a November 2014 Reddit AMA (Ask Me Anything), Geoff Hinton said, \u201cI think that the most exciting areas over the next five years will be really understanding text and videos. I will be disappointed if in five years\u2019 time we do not have something that can watch a YouTube video and tell a story about what happened. In a few years time we will put [Deep Learning] on a chip that fits into someone\u2019s ear and have an English-decoding chip that\u2019s just like a real Babel fish.\u201d2 And Yoshua Bengio, the third giant of modern Deep Learning, has also increasingly oriented his group\u2019s research toward language, including recent exciting new developments in neural machine translation systems. It\u2019s not just Deep Learning researchers. When leading machine learning researcher Michael Jordan was asked at a September 2014 AMA, \u201cIf you got a billion dollars to spend on a huge research project that you get to lead, what would you like to do?\u201d, he answered: \u201cI\u2019d use the billion dollars to build a NASA-size program focusing on natural language processing, in all of its glory (semantics, pragmatics, etc.).\u201d He went on: \u201cIntellectually I think that NLP is fascinating, allowing us to focus on highly structured inference problems, on issues that go to the core of \u2018what is thought\u2019 but remain eminently practical, and on a technology", "year": 2015, "referenceCount": 16, "citationCount": 177, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["History", "Computer Science"], "authors": [{"authorId": "144783904", "name": "Christopher D. Manning"}]}, {"paperId": "1ccf8e72c36f36e5327245594cb951adb925b319", "url": "https://www.semanticscholar.org/paper/1ccf8e72c36f36e5327245594cb951adb925b319", "title": "Machine-learning approach for one- and two-body corrections to density functional theory: Applications to molecular and condensed water", "abstract": "We show how machine learning techniques based on Bayesian inference can be used to enhance the computer simulation of molecular materials, focusing here on water. We train our machine-learning algorithm using accurate, correlated quantum chemistry, and predict energies and forces in molecular aggregates ranging from clusters to solid and liquid phases. The widely used electronic-structure methods based on density functional theory (DFT) by themselves give poor accuracy for molecular materials like water, and we show how our techniques can be used to generate systematically improvable one- and two-body corrections to DFT with modest extra resources. The resulting corrected DFT scheme is considerably more accurate than uncorrected DFT for the relative energies of small water clusters and different ice structures and significantly improves the description of the structure and dynamics of liquid water. However, our results for ice structures and the liquid indicate that beyond-two-body DFT errors cannot be ignored, and we suggest how our machine-learning methods can be further developed to correct these errors.", "year": 2013, "referenceCount": 91, "citationCount": 148, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "3938091", "name": "A. Bart\u00f3k"}, {"authorId": "2583100", "name": "M. Gillan"}, {"authorId": "3028215", "name": "F. Manby"}, {"authorId": "2559761", "name": "G\u00e1bor Cs\u00e1nyi"}]}, {"paperId": "301b4af1889fd3845d27886e43c0c1eadf674417", "url": "https://www.semanticscholar.org/paper/301b4af1889fd3845d27886e43c0c1eadf674417", "title": "Comparative study of machine learning techniques in sentimental analysis", "abstract": "Sentimental Analysis is reference to the task of Natural Language Processing to determine whether a text contains subjective information and what information it expresses i.e., whether the attitude behind the text is positive, negative or neutral. This paper focuses on the several machine learning techniques which are used in analyzing the sentiments and in opinion mining. Sentimental analysis with the blend of machine learning could be useful in predicting the product reviews and consumer attitude towards to newly launched product. This paper presents a detail survey of various machine learning techniques and then compared with their accuracy, advantages and limitations of each technique. On comparing we get 85% of accuracy by using supervised machine learning technique which is higher than that of unsupervised learning techniques.", "year": 2017, "referenceCount": 22, "citationCount": 58, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "20927626", "name": "B. Bhavitha"}, {"authorId": "33792727", "name": "Anisha P. Rodrigues"}, {"authorId": "2722512", "name": "N. Chiplunkar"}]}, {"paperId": "0ef957a487251f893670421ae456a2d59e037138", "url": "https://www.semanticscholar.org/paper/0ef957a487251f893670421ae456a2d59e037138", "title": "Black-Box vs. White-Box: Understanding Their Advantages and Weaknesses From a Practical Point of View", "abstract": "Nowadays, in the international scientific community of machine learning, there exists an enormous discussion about the use of black-box models or explainable models; especially in practical problems. On the one hand, a part of the community defends that black-box models are more accurate than explainable models in some contexts, like image preprocessing. On the other hand, there exist another part of the community alleging that explainable models are better than black-box models because they can obtain comparable results and also they can explain these results in a language close to a human expert by using patterns. In this paper, advantages and weaknesses for each approach are shown; taking into account a state-of-the-art review for both approaches, their practical applications, trends, and future challenges. This paper shows that both approaches are suitable for solving practical problems, but experts in machine learning need to understand the input data, the problem to solve, and the best way for showing the output data before applying a machine learning model. Also, we propose some ideas for fusing both, explainable and black-box, approaches to provide better solutions to experts in real-world domains. Additionally, we show one way to measure the effectiveness of the applied machine learning model by using expert opinions jointly with statistical methods. Throughout this paper, we show the impact of using explainable and black-box models on the security and medical applications.", "year": 2019, "referenceCount": 167, "citationCount": 119, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1390024239", "name": "O. Loyola-Gonz\u00e1lez"}]}, {"paperId": "ede0a8039a561905f40777ec2ae66c2010e3f2bc", "url": "https://www.semanticscholar.org/paper/ede0a8039a561905f40777ec2ae66c2010e3f2bc", "title": "Cybersecurity data science: an overview from machine learning perspective", "abstract": null, "year": 2020, "referenceCount": 210, "citationCount": 131, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3456687", "name": "I. Sarker"}, {"authorId": "144366819", "name": "A. Kayes"}, {"authorId": "49696663", "name": "S. Badsha"}, {"authorId": "15597895", "name": "Hamed Alqahtani"}, {"authorId": "1682100", "name": "P. Watters"}, {"authorId": "46201673", "name": "Alex Ng"}]}, {"paperId": "17f70b9d1fcf3b31948ffa578ac89399751fe73d", "url": "https://www.semanticscholar.org/paper/17f70b9d1fcf3b31948ffa578ac89399751fe73d", "title": "Petuum: A New Platform for Distributed Machine Learning on Big Data", "abstract": "What is a systematic way to efficiently apply a wide spectrum of advanced ML programs to industrial scale problems, using Big Models (up to 100 s of billions of parameters) on Big Data (up to terabytes or petabytes)? Modern parallelization strategies employ fine-grained operations and scheduling beyond the classic bulk-synchronous processing paradigm popularized by MapReduce, or even specialized graph-based execution that relies on graph representations of ML programs. The variety of approaches tends to pull systems and algorithms design in different directions, and it remains difficult to find a universal platform applicable to a wide range of ML programs at scale. We propose a general-purpose framework, Petuum, that systematically addresses data- and model-parallel challenges in large-scale ML, by observing that many ML programs are fundamentally optimization-centric and admit error-tolerant, iterative-convergent algorithmic solutions. This presents unique opportunities for an integrative system design, such as bounded-error network synchronization and dynamic scheduling based on ML program structure. We demonstrate the efficacy of these system designs versus well-known implementations of modern ML algorithms, showing that Petuum allows ML programs to run in much less time and at considerably larger model sizes, even on modestly-sized compute clusters.", "year": 2013, "referenceCount": 74, "citationCount": 468, "influentialCitationCount": 48, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143977260", "name": "E. Xing"}, {"authorId": "1707357", "name": "Qirong Ho"}, {"authorId": "143716171", "name": "Wei Dai"}, {"authorId": "2152674455", "name": "Jin Kyu Kim"}, {"authorId": "1766143", "name": "Jinliang Wei"}, {"authorId": "1739906504", "name": "Seunghak Lee"}, {"authorId": "2496226", "name": "Xun Zheng"}, {"authorId": "40526720", "name": "P. Xie"}, {"authorId": "1776255", "name": "Abhimanu Kumar"}, {"authorId": "40508553", "name": "Yaoliang Yu"}]}, {"paperId": "63fb32fd3b99f754ae973a8c2c0b6ab661511ef3", "url": "https://www.semanticscholar.org/paper/63fb32fd3b99f754ae973a8c2c0b6ab661511ef3", "title": "Cognitive Machine-Learning Algorithm for Cardiac Imaging: A Pilot Study for Differentiating Constrictive Pericarditis From Restrictive Cardiomyopathy.", "abstract": "BACKGROUND\nAssociating a patient's profile with the memories of prototypical patients built through previous repeat clinical experience is a key process in clinical judgment. We hypothesized that a similar process using a cognitive computing tool would be well suited for learning and recalling multidimensional attributes of speckle tracking echocardiography data sets derived from patients with known constrictive pericarditis and restrictive cardiomyopathy.\n\n\nMETHODS AND RESULTS\nClinical and echocardiographic data of 50 patients with constrictive pericarditis and 44 with restrictive cardiomyopathy were used for developing an associative memory classifier-based machine-learning algorithm. The speckle tracking echocardiography data were normalized in reference to 47 controls with no structural heart disease, and the diagnostic area under the receiver operating characteristic curve of the associative memory classifier was evaluated for differentiating constrictive pericarditis from restrictive cardiomyopathy. Using only speckle tracking echocardiography variables, associative memory classifier achieved a diagnostic area under the curve of 89.2%, which improved to 96.2% with addition of 4 echocardiographic variables. In comparison, the area under the curve of early diastolic mitral annular velocity and left ventricular longitudinal strain were 82.1% and 63.7%, respectively. Furthermore, the associative memory classifier demonstrated greater accuracy and shorter learning curves than other machine-learning approaches, with accuracy asymptotically approaching 90% after a training fraction of 0.3 and remaining flat at higher training fractions.\n\n\nCONCLUSIONS\nThis study demonstrates feasibility of a cognitive machine-learning approach for learning and recalling patterns observed during echocardiographic evaluations. Incorporation of machine-learning algorithms in cardiac imaging may aid standardized assessments and support the quality of interpretations, particularly for novice readers with limited experience.", "year": 2016, "referenceCount": 42, "citationCount": 96, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "2274738", "name": "P. Sengupta"}, {"authorId": "46844307", "name": "Yen-Min Huang"}, {"authorId": "46745911", "name": "M. Bansal"}, {"authorId": "2063937402", "name": "Ali Ashrafi"}, {"authorId": "2114403569", "name": "Matt Fisher"}, {"authorId": "47189518", "name": "K. Shameer"}, {"authorId": "2091367544", "name": "Walt Gall"}, {"authorId": "13964487", "name": "J. Dudley"}]}, {"paperId": "985ec818b640fa697ecb77d20f9c3d529b303c06", "url": "https://www.semanticscholar.org/paper/985ec818b640fa697ecb77d20f9c3d529b303c06", "title": "A comparative study on content-based music genre classification", "abstract": "Content-based music genre classification is a fundamental component of music information retrieval systems and has been gaining importance and enjoying a growing amount of attention with the emergence of digital music on the Internet. Currently little work has been done on automatic music genre classification, and in addition, the reported classification accuracies are relatively low. This paper proposes a new feature extraction method for music genre classification, DWCHs. DWCHs stands for Daubechies Wavelet Coefficient Histograms. DWCHs capture the local and global information of music signals simultaneously by computing histograms on their Daubechies wavelet coefficients. Effectiveness of this new feature and of previously studied features are compared using various machine learning classification algorithms, including Support Vector Machines and Linear Discriminant Analysis. It is demonstrated that the use of DWCHs significantly improves the accuracy of music genre classification.", "year": 2003, "referenceCount": 36, "citationCount": 457, "influentialCitationCount": 33, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "50289773", "name": "Tao Li"}, {"authorId": "144669577", "name": "M. Ogihara"}, {"authorId": "101489025", "name": "Qi Li"}]}, {"paperId": "fb8f6c5670755a7d282fb9322bc8439492ea052a", "url": "https://www.semanticscholar.org/paper/fb8f6c5670755a7d282fb9322bc8439492ea052a", "title": "Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge", "abstract": "When humans approach the task of text categorization, they interpret the specific wording of the document in the much larger context of their background knowledge and experience. On the other hand, state-of-the-art information retrieval systems are quite brittle--they traditionally represent documents as bags of words, and are restricted to learning from individual word occurrences in the (necessarily limited) training set. For instance, given the sentence \"Wal-Mart supply chain goes real time\", how can a text categorization system know that Wal-Mart manages its stock with RFID technology? And having read that \"Ciprofloxacin belongs to the quinolones group\", how on earth can a machine know that the drug mentioned is an antibiotic produced by Bayer? In this paper we present algorithms that can do just that. We propose to enrich document representation through automatic use of a vast compendium of human knowledge--an encyclopedia. We apply machine learning techniques to Wikipedia, the largest encyclopedia to date, which surpasses in scope many conventional encyclopedias and provides a cornucopia of world knowledge. Each Wikipedia article represents a concept, and documents to be categorized are represented in the rich feature space of words and relevant Wikipedia concepts. Empirical results confirm that this knowledge-intensive representation brings text categorization to a qualitatively new level of performance across a diverse collection of datasets.", "year": 2006, "referenceCount": 34, "citationCount": 500, "influentialCitationCount": 32, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1718798", "name": "E. Gabrilovich"}, {"authorId": "2309269", "name": "Shaul Markovitch"}]}, {"paperId": "3539f67ba7f9025e2695709814aef4864843473b", "url": "https://www.semanticscholar.org/paper/3539f67ba7f9025e2695709814aef4864843473b", "title": "Early diagnosis of Alzheimer's disease with deep learning", "abstract": "The accurate diagnosis of Alzheimer's disease (AD) plays a significant role in patient care, especially at the early stage, because the consciousness of the severity and the progression risks allows the patients to take prevention measures before irreversible brain damages are shaped. Although many studies have applied machine learning methods for computer-aided-diagnosis (CAD) of AD recently, a bottleneck of the diagnosis performance was shown in most of the existing researches, mainly due to the congenital limitations of the chosen learning models. In this study, we design a deep learning architecture, which contains stacked auto-encoders and a softmax output layer, to overcome the bottleneck and aid the diagnosis of AD and its prodromal stage, Mild Cognitive Impairment (MCI). Compared to the previous workflows, our method is capable of analyzing multiple classes in one setting, and requires less labeled training samples and minimal domain prior knowledge. A significant performance gain on classification of all diagnosis groups was achieved in our experiments.", "year": 2014, "referenceCount": 30, "citationCount": 350, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "47130333", "name": "Siqi Liu"}, {"authorId": "1847158", "name": "Sidong Liu"}, {"authorId": "122905659", "name": "Weidong (Tom) Cai"}, {"authorId": "2455284", "name": "Sonia Pujol"}, {"authorId": "48307303", "name": "R. Kikinis"}, {"authorId": "145855523", "name": "D. Feng"}]}, {"paperId": "2666050601ce1a7281a9154fb781ebcb40695863", "url": "https://www.semanticscholar.org/paper/2666050601ce1a7281a9154fb781ebcb40695863", "title": "Identifying children with autism spectrum disorder based on their face processing abnormality: A machine learning framework", "abstract": "The atypical face scanning patterns in individuals with Autism Spectrum Disorder (ASD) has been repeatedly discovered by previous research. The present study examined whether their face scanning patterns could be potentially useful to identify children with ASD by adopting the machine learning algorithm for the classification purpose. Particularly, we applied the machine learning method to analyze an eye movement dataset from a face recognition task [Yi et al., 2016], to classify children with and without ASD. We evaluated the performance of our model in terms of its accuracy, sensitivity, and specificity of classifying ASD. Results indicated promising evidence for applying the machine learning algorithm based on the face scanning patterns to identify children with ASD, with a maximum classification accuracy of 88.51%. Nevertheless, our study is still preliminary with some constraints that may apply in the clinical practice. Future research should shed light on further valuation of our method and contribute to the development of a multitask and multimodel approach to aid the process of early detection and diagnosis of ASD. Autism Res 2016, 9: 888\u2013898. \u00a9 2016 International Society for Autism Research, Wiley Periodicals, Inc.", "year": 2016, "referenceCount": 40, "citationCount": 145, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Psychology", "Medicine"], "authors": [{"authorId": "2109213645", "name": "Wenbo Liu"}, {"authorId": "2150655534", "name": "Ming Li"}, {"authorId": "145951510", "name": "Li Yi"}]}, {"paperId": "2826ac3621fdd599303c97cb9e32f165521967b2", "url": "https://www.semanticscholar.org/paper/2826ac3621fdd599303c97cb9e32f165521967b2", "title": "Direct Uncertainty Prediction for Medical Second Opinions", "abstract": "The issue of disagreements amongst human experts is a ubiquitous one in both machine learning and medicine. In medicine, this often corresponds to doctor disagreements on a patient diagnosis. In this work, we show that machine learning models can be trained to give uncertainty scores to data instances that might result in high expert disagreements. In particular, they can identify patient cases that would benefit most from a medical second opinion. Our central methodological finding is that Direct Uncertainty Prediction (DUP), training a model to predict an uncertainty score directly from the raw patient features, works better than Uncertainty Via Classification, the two-step process of training a classifier and postprocessing the output distribution to give an uncertainty score. We show this both with a theoretical result, and on extensive evaluations on a large scale medical imaging application.", "year": 2018, "referenceCount": 39, "citationCount": 63, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "40297238", "name": "M. Raghu"}, {"authorId": "144484239", "name": "Katy Blumer"}, {"authorId": "144042306", "name": "R. Sayres"}, {"authorId": "3797258", "name": "Z. Obermeyer"}, {"authorId": "2633757", "name": "Robert D. Kleinberg"}, {"authorId": "2062143", "name": "S. Mullainathan"}, {"authorId": "3371403", "name": "J. Kleinberg"}]}, {"paperId": "745d6175061f225f47b91480fc55c52ce855f9c7", "url": "https://www.semanticscholar.org/paper/745d6175061f225f47b91480fc55c52ce855f9c7", "title": "SVD-Based Quality Metric for Image and Video Using Machine Learning", "abstract": "We study the use of machine learning for visual quality evaluation with comprehensive singular value decomposition (SVD)-based visual features. In this paper, the two-stage process and the relevant work in the existing visual quality metrics are first introduced followed by an in-depth analysis of SVD for visual quality assessment. Singular values and vectors form the selected features for visual quality assessment. Machine learning is then used for the feature pooling process and demonstrated to be effective. This is to address the limitations of the existing pooling techniques, like simple summation, averaging, Minkowski summation, etc., which tend to be ad hoc. We advocate machine learning for feature pooling because it is more systematic and data driven. The experiments show that the proposed method outperforms the eight existing relevant schemes. Extensive analysis and cross validation are performed with ten publicly available databases (eight for images with a total of 4042 test images and two for video with a total of 228 videos). We use all publicly accessible software and databases in this study, as well as making our own software public, to facilitate comparison in future research.", "year": 2012, "referenceCount": 72, "citationCount": 140, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1758088", "name": "Manish Narwaria"}, {"authorId": "144968898", "name": "Weisi Lin"}]}, {"paperId": "86c37cd1109ce5b465116695b7705444a45185cf", "url": "https://www.semanticscholar.org/paper/86c37cd1109ce5b465116695b7705444a45185cf", "title": "Censoring Representations with an Adversary", "abstract": "In practice, there are often explicit constraints on what representations or decisions are acceptable in an application of machine learning. For example it may be a legal requirement that a decision must not favour a particular group. Alternatively it can be that that representation of data must not have identifying information. We address these two related issues by learning flexible representations that minimize the capability of an adversarial critic. This adversary is trying to predict the relevant sensitive variable from the representation, and so minimizing the performance of the adversary ensures there is little or no information in the representation about the sensitive variable. We demonstrate this adversarial approach on two problems: making decisions free from discrimination and removing private information from images. We formulate the adversarial model as a minimax problem, and optimize that minimax objective using a stochastic gradient alternate min-max optimizer. We demonstrate the ability to provide discriminant free representations for standard test problems, and compare with previous state of the art methods for fairness, showing statistically significant improvement across most cases. The flexibility of this method is shown via a novel problem: removing annotations from images, from unaligned training examples of annotated and unannotated images, and with no a priori knowledge of the form of annotation provided to the model.", "year": 2015, "referenceCount": 29, "citationCount": 396, "influentialCitationCount": 50, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144632352", "name": "Harrison Edwards"}, {"authorId": "1728216", "name": "A. Storkey"}]}, {"paperId": "117fcfef38aa4641ae33e2605dc35013fc908719", "url": "https://www.semanticscholar.org/paper/117fcfef38aa4641ae33e2605dc35013fc908719", "title": "Learning to Monitor Machine Health with Convolutional Bi-Directional LSTM Networks", "abstract": "In modern manufacturing systems and industries, more and more research efforts have been made in developing effective machine health monitoring systems. Among various machine health monitoring approaches, data-driven methods are gaining in popularity due to the development of advanced sensing and data analytic techniques. However, considering the noise, varying length and irregular sampling behind sensory data, this kind of sequential data cannot be fed into classification and regression models directly. Therefore, previous work focuses on feature extraction/fusion methods requiring expensive human labor and high quality expert knowledge. With the development of deep learning methods in the last few years, which redefine representation learning from raw data, a deep neural network structure named Convolutional Bi-directional Long Short-Term Memory networks (CBLSTM) has been designed here to address raw sensory data. CBLSTM firstly uses CNN to extract local features that are robust and informative from the sequential input. Then, bi-directional LSTM is introduced to encode temporal information. Long Short-Term Memory networks (LSTMs) are able to capture long-term dependencies and model sequential data, and the bi-directional structure enables the capture of past and future contexts. Stacked, fully-connected layers and the linear regression layer are built on top of bi-directional LSTMs to predict the target value. Here, a real-life tool wear test is introduced, and our proposed CBLSTM is able to predict the actual tool wear based on raw sensory data. The experimental results have shown that our model is able to outperform several state-of-the-art baseline methods.", "year": 2017, "referenceCount": 56, "citationCount": 435, "influentialCitationCount": 18, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Engineering", "Medicine"], "authors": [{"authorId": "49832912", "name": "Rui Zhao"}, {"authorId": "35374692", "name": "Ruqiang Yan"}, {"authorId": "49605588", "name": "Jinjiang Wang"}, {"authorId": "144067957", "name": "K. Mao"}]}, {"paperId": "c8ef5694423b05f0c2ac97ff20c483f051e1228a", "url": "https://www.semanticscholar.org/paper/c8ef5694423b05f0c2ac97ff20c483f051e1228a", "title": "Machine Learning Techniques Applied to Wireless Ad-Hoc Networks: Guide and Survey", "abstract": "This work is a survey on the usage of machine learning techniques in wireless sensor networks (WSNs) and mobile ad-hoc networks (MANETs). Its focus lies on approaches for data routing. The goal of the work is two-fold: first, to classify and evaluate the most important existing and on-going research in the area and, second, to provide a guide for researchers wanting to apply machine learning techniques. For this, it also gives short description of the most appropriate algorithms and suggests for which scenarios they can be best used.", "year": 2007, "referenceCount": 30, "citationCount": 107, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1646500881", "name": "A. Forster"}]}]}