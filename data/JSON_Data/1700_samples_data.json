{"total": 5120627, "offset": 1600, "next": 1700, "data": [{"paperId": "51006f395255a3c5bed1f418a1b838b2f24b7b38", "url": "https://www.semanticscholar.org/paper/51006f395255a3c5bed1f418a1b838b2f24b7b38", "title": "Malicious URL Detection using Machine Learning: A Survey", "abstract": "Malicious URL, a.k.a. malicious website, is a common and serious threat to cybersecurity. Malicious URLs host unsolicited content (spam, phishing, drive-by exploits, etc.) and lure unsuspecting users to become victims of scams (monetary loss, theft of private information, and malware installation), and cause losses of billions of dollars every year. It is imperative to detect and act on such threats in a timely manner. Traditionally, this detection is done mostly through the usage of blacklists. However, blacklists cannot be exhaustive, and lack the ability to detect newly generated malicious URLs. To improve the generality of malicious URL detectors, machine learning techniques have been explored with increasing attention in recent years. This article aims to provide a comprehensive survey and a structural understanding of Malicious URL Detection techniques using machine learning. We present the formal formulation of Malicious URL Detection as a machine learning task, and categorize and review the contributions of literature studies that addresses different dimensions of this problem (feature representation, algorithm design, etc.). Further, this article provides a timely and comprehensive survey for a range of different audiences, not only for machine learning researchers and engineers in academia, but also for professionals and practitioners in cybersecurity industry, to help them understand the state of the art and facilitate their own research and practical applications. We also discuss practical issues in system design, open research challenges, and point out some important directions for future research.", "year": 2017, "referenceCount": 209, "citationCount": 196, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "36187119", "name": "Doyen Sahoo"}, {"authorId": "2039481", "name": "Chenghao Liu"}, {"authorId": "1741126", "name": "S. Hoi"}]}, {"paperId": "4e4303ac23684034f0ba7f2aefa75d18fc660e41", "url": "https://www.semanticscholar.org/paper/4e4303ac23684034f0ba7f2aefa75d18fc660e41", "title": "IoT Security Techniques Based on Machine Learning: How Do IoT Devices Use AI to Enhance Security?", "abstract": "The Internet of things (IoT), which integrates a variety of devices into networks to provide advanced and intelligent services, has to protect user privacy and address attacks such as spoofing attacks, denial of service (DoS) attacks, jamming, and eavesdropping. We investigate the attack model for IoT systems and review the IoT security solutions based on machine-learning (ML) techniques including supervised learning, unsupervised learning, and reinforcement learning (RL). ML-based IoT authentication, access control, secure offloading, and malware detection schemes to protect data privacy are the focus of this article. We also discuss the challenges that need to be addressed to implement these ML-based security schemes in practical IoT systems.", "year": 2018, "referenceCount": 30, "citationCount": 283, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "33821409", "name": "Liang Xiao"}, {"authorId": "14423947", "name": "Xiaoyue Wan"}, {"authorId": "47062683", "name": "Xiaozhen Lu"}, {"authorId": "38200671", "name": "Yanyong Zhang"}, {"authorId": "48198096", "name": "Di Wu"}]}, {"paperId": "14befe3574b4133dc7107df529cfb64592647ba5", "url": "https://www.semanticscholar.org/paper/14befe3574b4133dc7107df529cfb64592647ba5", "title": "Machine Learning", "abstract": "In machine learning, a computer first learns to perform a task by studying a training set of examples. The computer then performs the same task with data it hasn't encountered before. This article presents a brief overview of machine-learning technologies, with a concrete case study from code analysis.", "year": 2016, "referenceCount": 5, "citationCount": 62, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "6932577", "name": "P. Louridas"}, {"authorId": "144993235", "name": "C. Ebert"}]}, {"paperId": "d836a8d6a0ec72fe1564c30a5fabce2463e79188", "url": "https://www.semanticscholar.org/paper/d836a8d6a0ec72fe1564c30a5fabce2463e79188", "title": "Machine Learning Methods to Predict Diabetes Complications", "abstract": "One of the areas where Artificial Intelligence is having more impact is machine learning, which develops algorithms able to learn patterns and decision rules from data. Machine learning algorithms have been embedded into data mining pipelines, which can combine them with classical statistical strategies, to extract knowledge from data. Within the EU-funded MOSAIC project, a data mining pipeline has been used to derive a set of predictive models of type 2 diabetes mellitus (T2DM) complications based on electronic health record data of nearly one thousand patients. Such pipeline comprises clinical center profiling, predictive model targeting, predictive model construction and model validation. After having dealt with missing data by means of random forest (RF) and having applied suitable strategies to handle class imbalance, we have used Logistic Regression with stepwise feature selection to predict the onset of retinopathy, neuropathy, or nephropathy, at different time scenarios, at 3, 5, and 7 years from the first visit at the Hospital Center for Diabetes (not from the diagnosis). Considered variables are gender, age, time from diagnosis, body mass index (BMI), glycated hemoglobin (HbA1c), hypertension, and smoking habit. Final models, tailored in accordance with the complications, provided an accuracy up to 0.838. Different variables were selected for each complication and time scenario, leading to specialized models easy to translate to the clinical practice.", "year": 2018, "referenceCount": 28, "citationCount": 162, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2104799", "name": "A. Dagliati"}, {"authorId": "49264013", "name": "Simone Marini"}, {"authorId": "1800686", "name": "L. Sacchi"}, {"authorId": "48626952", "name": "Giulia Cogni"}, {"authorId": "11018474", "name": "Marsida Teliti"}, {"authorId": "3359382", "name": "V. Tibollo"}, {"authorId": "13173994", "name": "P. De Cata"}, {"authorId": "3009240", "name": "L. Chiovato"}, {"authorId": "1781522", "name": "R. Bellazzi"}]}, {"paperId": "9fe0ec4855136007fa73d306f1ff59365002bc58", "url": "https://www.semanticscholar.org/paper/9fe0ec4855136007fa73d306f1ff59365002bc58", "title": "Machine Learning Force Fields: Construction, Validation, and Outlook", "abstract": "Force fields developed with machine learning methods in tandem with quantum mechanics are beginning to find merit, given their (i) low cost, (ii) accuracy, and (iii) versatility. Recently, we proposed one such approach, wherein, the vectorial force on an atom is computed directly from its environment. Here, we discuss the multistep workflow required for their construction, which begins with generating diverse reference atomic environments and force data, choosing a numerical representation for the atomic environments, down selecting a representative training set, and lastly the learning method itself, for the case of Al. The constructed force field is then validated by simulating complex materials phenomena such as surface melting and stress\u2013strain behavior, that truly go beyond the realm of ab initio methods, both in length and time scales. To make such force fields truly versatile an attempt to estimate the uncertainty in force predictions is put forth, allowing one to identify areas of poor performance...", "year": 2016, "referenceCount": 40, "citationCount": 309, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Materials Science", "Physics", "Chemistry"], "authors": [{"authorId": "8352724", "name": "V. Botu"}, {"authorId": "143832304", "name": "R. Batra"}, {"authorId": "2086719652", "name": "James Chapman"}, {"authorId": "4063724", "name": "R. Ramprasad"}]}, {"paperId": "82a5a84528a7ca0409f75e2211a3b33a217e9bac", "url": "https://www.semanticscholar.org/paper/82a5a84528a7ca0409f75e2211a3b33a217e9bac", "title": "Ensuring Fairness in Machine Learning to Advance Health Equity", "abstract": "Machine learning can identify the statistical patterns of data generated by tens of thousands of physicians and billions of patients to train computers to perform specific tasks with sometimes superhuman ability, such as detecting diabetic eye disease better than retinal specialists (1). However, historical data also capture patterns of health care disparities, and machine-learning models trained on these data may perpetuate these inequities. This concern is not just academic. In a model used to predict future crime on the basis of historical arrest records, African American defendants who did not reoffend were classified as high risk at a substantially higher rate than white defendants who did not reoffend (2, 3). Similar biases have been observed in predictive policing (4) and identifying which calls to a child protective services agency required an in-person investigation (5, 6). The implications for health care led the American Medical Association to pass policy recommendations to promote development of thoughtfully designed, high-quality, clinically validated health care AI [artificial or augmented intelligence, such as machine learning] that . . . identifies and takes steps to address bias and avoids introducing or exacerbating health care disparities including when testing or deploying new AI tools on vulnerable populations (7). We argue that health care organizations and policymakers should go beyond the American Medical Association's position of doing no harm and instead proactively design and use machine-learning systems to advance health equity. Whereas much health disparities work has focused on discriminatory decision making and implicit biases by clinicians, policymakers, organizational leaders, and researchers are increasingly focusing on the ill health effects of structural racism and classismhow systems are shaped in ways that harm the health of disempowered, marginalized populations (8). For example, the United States has a shameful history of purposive decisions by government and private businesses to segregate housing. Zoning laws, discrimination in mortgage lending, prejudicial practices by real estate agents, and the ghettoization of public housing all contributed to the concentration of urban African Americans in inferior housing that has led to poor health (9, 10). Even when the goal of decision makers is not outright discrimination against disadvantaged groups, actions may lead to inequities. For example, if the goal of a machine-learning system is to maximize efficiency, that might come at the expense of disadvantaged populations. As a society, we value health equity. For example, the Healthy People 2020 vision statement aims for a society in which all people live long, healthy lives, and one of the mission's goals is to achieve health equity, eliminate disparities, and improve the health of all groups (11). The 4 classic principles of Western clinical medical ethics are justice, autonomy, beneficence, and nonmaleficence. However, health equity will not be attained unless we purposely design our health and social systems, which increasingly will be infused with machine learning (12), to achieve this goal. To ensure fairness in machine learning, we recommend a participatory process that involves key stakeholders, including frequently marginalized populations, and considers distributive justice within specific clinical and organizational contexts. Different technical approaches can configure the mathematical properties of machine-learning models to render predictions that are equitable in various ways. The existence of mathematical levers must be supplemented with criteria for when and why they should be usedeach tool comes with tradeoffs that require ethical reasoning to decide what is best for a given application. We propose incorporating fairness into the design, deployment, and evaluation of machine-learning models. We discuss 2 clinical applications in which machine learning might harm protected groups by being inaccurate, diverting resources, or worsening outcomes, especially if the models are built without consideration for these patients. We then describe the mechanisms by which a model's design, data, and deployment may lead to disparities; explain how different approaches to distributive justice in machine learning can advance health equity; and explore what contexts are more appropriate for different equity approaches in machine learning. Case Study 1: Intensive Care Unit Monitoring A common area of predictive modeling research focuses on creating a monitoring systemfor example, to warn a rapid response team about inpatients at high risk for deterioration (1315), requiring their transfer to an intensive care unit within 6 hours. How might such a system inadvertently result in harm to a protected group? In this thought experiment, we consider African Americans as a protected group. To build the model, our hypothetical researchers collected historical records of patients who had clinical deterioration and those who did not. The model acts like a diagnostic test of risk for intensive care unit transfer. However, if too few African American patients were included in the training datathe data used to construct the modelthe model might be inaccurate for them. For example, it might have a lower sensitivity and miss more patients at risk for deterioration. African American patients might be harmed if clinical teams started relying on alerts to identify at-risk patients without realizing that the prediction system underdetects patients in that group (automation bias) (16). If the model had a lower positive predictive value for African Americans, it might also disproportionately harm them through dismissal biasa generalization of alert fatigue in which clinicians may learn to discount or dismiss alerts for African Americans because they are more likely to be false-positive (17). Case Study 2: Reducing Length of Stay Imagine that a hospital created a model with clinical and social variables to predict which inpatients might be discharged earliest so that it could direct limited case management resources to them to prevent delays. If residence in ZIP codes of socioeconomically depressed or predominantly African American neighborhoods predicted greater lengths of stay (18), this model might disproportionately allocate case management resources to patients from richer, predominantly white neighborhoods and away from African Americans in poorer ones. What Is Machine Learning? Traditionally, computer systems map inputs to outputs according to manually specified ifthen rules. With increasingly complex tasks, such as language translation, manually specifying rules becomes infeasible, and instead the mapping (or model) is learned by the system given only input examples represented through a set of features together with their desired output, referred to as labels. The quality of a model is assessed by computing evaluation metrics on data not used to build the model, such as sensitivity, specificity, or the c-statistic, which measures the ability of a model to distinguish patients with a condition from those without it (19, 20). Once the model's quality is deemed satisfactory, it can be deployed to make predictions on new examples for which the label is unknown when the prediction is made. The quality of the models on retrospective data must be followed with tests of clinical effectiveness, safety, and comparison with current practice, which may require clinical trials (21). Traditionally, statistical models for prediction, such as the pooled-cohort equation (22), have used few variables to predict clinical outcomes, such as cardiovascular risk (23). Modern machine-learning techniques, however, can consider many more features. For example, a recent model to predict hospital readmissions examined hundreds of thousands of pieces of information, including the free text of clinical notes (24). Complex data and models can drive more personalized and accurate predictions but may also make algorithms hard to understand and trust (25). What Can Cause a Machine-Learning System to Be Unfair? The Glossary lists key biases in the design, data, and deployment of a machine-learning model that may perpetuate or exacerbate health care disparities if left unchecked. The Figure reveals how the various biases relate to one another and how the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Biases may arise during the design of a model. For example, if the label is marred by health care disparities, such as predicting the onset of clinical depression in environments where protected groups have been systematically misdiagnosed, then the model will learn to perpetuate this disparity. This represents a generalization of test-referral bias (26) that we refer to as label bias. Moreover, the data on which the model is developed may be biased. Data on patients in the protected group might be distributed differently from those in the nonprotected group because of biological or nonbiological variation (9, 27). For example, the data may not contain enough examples from a group to properly tailor the predictions to them (minority bias) (28), or the data set of the protected group may be less informative because features are missing not at random as a result of more fragmented care (29, 30). Glossary Figure. Conceptual framework of how various biases relate to one another. During model development, differences in the distribution of features used to predict a label between the protected and nonprotected groups may bias a model to be less accurate for protected groups. Moreover, the data used to develop a model may not generalize to the data used during model deployment (trainingserving skew). Biases in model design and data affect patient outcomes through the model's interaction with clinicians and patients. The immediate effect of these differences is that the model may ", "year": 2018, "referenceCount": 52, "citationCount": 296, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "8638650", "name": "A. Rajkomar"}, {"authorId": "40356669", "name": "Michaela Hardt"}, {"authorId": "145310670", "name": "M. Howell"}, {"authorId": "2084098271", "name": "Greg S. Corrado"}, {"authorId": "2186184", "name": "M. Chin"}]}, {"paperId": "923d8dd5d36dd5ab68aadbe2e3eecb57de88d859", "url": "https://www.semanticscholar.org/paper/923d8dd5d36dd5ab68aadbe2e3eecb57de88d859", "title": "Learning Deep Generative Models", "abstract": "Building intelligent systems that are capable of extracting high-level representations from high-dimensional sensory data lies at the core of solving many AI related tasks, including object recognition, speech perception, and language understanding. Theoretical and biological arguments strongly suggest that building such systems requires models with deep architectures that involve many layers of nonlinear processing. \nThe aim of the thesis is to demonstrate that deep generative models that contain many layers of latent variables and millions of parameters can be learned efficiently, and that the learned high-level feature representations can be successfully applied in a wide spectrum of application domains, including visual object recognition, information retrieval, and classification and regression tasks. In addition, similar methods can be used for nonlinear dimensionality reduction. \nThe first part of the thesis focuses on analysis and applications of probabilistic generative models called Deep Belief Networks. We show that these deep hierarchical models can learn useful feature representations from a large supply of unlabeled sensory inputs. The learned high-level representations capture a lot of structure in the input data, which is useful for subsequent problem-specific tasks, such as classification, regression or information retrieval, even though these tasks are unknown when the generative model is being trained. \nIn the second part of the thesis, we introduce a new learning algorithm for a different type of hierarchical probabilistic model, which we call a Deep Boltzmann Machine. Like Deep Belief Networks, Deep Boltzmann Machines have the potential of learning internal representations that become increasingly complex at higher layers, which is a promising way of solving object and speech recognition problems. Unlike Deep Belief Networks and many existing models with deep architectures, the approximate inference procedure, in addition to a fast bottom-up pass, can incorporate top-down feedback. This allows Deep Boltzmann Machines to better propagate uncertainty about ambiguous inputs.", "year": 2009, "referenceCount": 123, "citationCount": 337, "influentialCitationCount": 26, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov"}]}, {"paperId": "0922801f4411760b53827e234df74c178f2f2f72", "url": "https://www.semanticscholar.org/paper/0922801f4411760b53827e234df74c178f2f2f72", "title": "Support Vector Machines Applications", "abstract": null, "year": 2014, "referenceCount": 64, "citationCount": 181, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2363386", "name": "Yunqian Ma"}, {"authorId": "2067614871", "name": "Guodong Guo"}]}, {"paperId": "3a6447361b20c249f5306ae17dee43f645430e31", "url": "https://www.semanticscholar.org/paper/3a6447361b20c249f5306ae17dee43f645430e31", "title": "Neural Logic Machines", "abstract": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks---as function approximators, and logic programming---as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.", "year": 2019, "referenceCount": 81, "citationCount": 145, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "88880715", "name": "Honghua Dong"}, {"authorId": "13589371", "name": "Jiayuan Mao"}, {"authorId": "2143608361", "name": "Tian Lin"}, {"authorId": "2146308808", "name": "Chong Wang"}, {"authorId": "47681372", "name": "Lihong Li"}, {"authorId": "65855107", "name": "Denny Zhou"}]}, {"paperId": "8023b835934e8c2ccfe068d59d6c319bb8a1c293", "url": "https://www.semanticscholar.org/paper/8023b835934e8c2ccfe068d59d6c319bb8a1c293", "title": "Foolbox v0.8.0: A Python toolbox to benchmark the robustness of machine learning models", "abstract": "Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at this https URL . The most up-to-date documentation can be found at this http URL .", "year": 2017, "referenceCount": 18, "citationCount": 275, "influentialCitationCount": 26, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "19237612", "name": "Jonas Rauber"}, {"authorId": "40634590", "name": "Wieland Brendel"}, {"authorId": "1731199", "name": "M. Bethge"}]}, {"paperId": "81518e0c9edf55515c0109047146a24cfccce0ee", "url": "https://www.semanticscholar.org/paper/81518e0c9edf55515c0109047146a24cfccce0ee", "title": "Reproducing kernel Banach spaces for machine learning", "abstract": "Reproducing kernel Hilbert space (RKHS) methods have become powerful tools in machine learning. However, their kernels, which measure similarity of inputs, are required to be symmetric, constraining certain applications in practice. Furthermore, the celebrated representer theorem only applies to regularizers induced by the norm of an RKHS. To remove these limitations, we introduce the notion of reproducing kernel Banach spaces (RKBS) for pairs of reflexive Banach spaces of functions by making use of semi-inner-products and the duality mapping. As applications, we develop the framework of RKBS standard learning schemes including minimal norm interpolation, regularization network, and support vector machines. In particular, existence, uniqueness and representer theorems are established.", "year": 2009, "referenceCount": 57, "citationCount": 154, "influentialCitationCount": 27, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2108659894", "name": "Haizhang Zhang"}, {"authorId": "2110802854", "name": "Yuesheng Xu"}, {"authorId": "145929323", "name": "Jun Zhang"}]}, {"paperId": "f486552980946ee761ecd668e3c73802a0714a03", "url": "https://www.semanticscholar.org/paper/f486552980946ee761ecd668e3c73802a0714a03", "title": "Prediction of Organic Reaction Outcomes Using Machine Learning", "abstract": "Computer assistance in synthesis design has existed for over 40 years, yet retrosynthesis planning software has struggled to achieve widespread adoption. One critical challenge in developing high-quality pathway suggestions is that proposed reaction steps often fail when attempted in the laboratory, despite initially seeming viable. The true measure of success for any synthesis program is whether the predicted outcome matches what is observed experimentally. We report a model framework for anticipating reaction outcomes that combines the traditional use of reaction templates with the flexibility in pattern recognition afforded by neural networks. Using 15\u202f000 experimental reaction records from granted United States patents, a model is trained to select the major (recorded) product by ranking a self-generated list of candidates where one candidate is known to be the major product. Candidate reactions are represented using a unique edit-based representation that emphasizes the fundamental transformation from reactants to products, rather than the constituent molecules\u2019 overall structures. In a 5-fold cross-validation, the trained model assigns the major product rank 1 in 71.8% of cases, rank \u22643 in 86.7% of cases, and rank \u22645 in 90.8% of cases.", "year": 2017, "referenceCount": 32, "citationCount": 402, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "13027820", "name": "Connor W. Coley"}, {"authorId": "1741283", "name": "R. Barzilay"}, {"authorId": "35132120", "name": "T. Jaakkola"}, {"authorId": "143964245", "name": "W. Green"}, {"authorId": "144050039", "name": "K. Jensen"}]}, {"paperId": "6a1e5f1ff1b3106d160cb1e486fb9611252c393d", "url": "https://www.semanticscholar.org/paper/6a1e5f1ff1b3106d160cb1e486fb9611252c393d", "title": "Automated detection and differentiation of drusen, exudates, and cotton-wool spots in digital color fundus photographs for diabetic retinopathy diagnosis.", "abstract": "PURPOSE\nTo describe and evaluate a machine learning-based, automated system to detect exudates and cotton-wool spots in digital color fundus photographs and differentiate them from drusen, for early diagnosis of diabetic retinopathy.\n\n\nMETHODS\nThree hundred retinal images from one eye of 300 patients with diabetes were selected from a diabetic retinopathy telediagnosis database (nonmydriatic camera, two-field photography): 100 with previously diagnosed bright lesions and 200 without. A machine learning computer program was developed that can identify and differentiate among drusen, (hard) exudates, and cotton-wool spots. A human expert standard for the 300 images was obtained by consensus annotation by two retinal specialists. Sensitivities and specificities of the annotations on the 300 images by the automated system and a third retinal specialist were determined.\n\n\nRESULTS\nThe system achieved an area under the receiver operating characteristic (ROC) curve of 0.95 and sensitivity/specificity pairs of 0.95/0.88 for the detection of bright lesions of any type, and 0.95/0.86, 0.70/0.93, and 0.77/0.88 for the detection of exudates, cotton-wool spots, and drusen, respectively. The third retinal specialist achieved pairs of 0.95/0.74 for bright lesions and 0.90/0.98, 0.87/0.98, and 0.92/0.79 per lesion type.\n\n\nCONCLUSIONS\nA machine learning-based, automated system capable of detecting exudates and cotton-wool spots and differentiating them from drusen in color images obtained in community based diabetic patients has been developed and approaches the performance level of retinal experts. If the machine learning can be improved with additional training data sets, it may be useful for detecting clinically important bright lesions, enhancing early diagnosis, and reducing visual loss in patients with diabetes.", "year": 2007, "referenceCount": 29, "citationCount": 400, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "3142710", "name": "M. Niemeijer"}, {"authorId": "123637526", "name": "B. van Ginneken"}, {"authorId": "1985675", "name": "S. Russell"}, {"authorId": "1397807242", "name": "M. Suttorp-Schulten"}, {"authorId": "143650563", "name": "M. Abr\u00e0moff"}]}, {"paperId": "85f94d8098322f8130512b4c6c4627548ce4a6cc", "url": "https://www.semanticscholar.org/paper/85f94d8098322f8130512b4c6c4627548ce4a6cc", "title": "Unsupervised Pretraining for Sequence to Sequence Learning", "abstract": "This work presents a general unsupervised learning method to improve the accuracy of sequence to sequence (seq2seq) models. In our method, the weights of the encoder and decoder of a seq2seq model are initialized with the pretrained weights of two language models and then fine-tuned with labeled data. We apply this method to challenging benchmarks in machine translation and abstractive summarization and find that it significantly improves the subsequent supervised models. Our main result is that pretraining improves the generalization of seq2seq models. We achieve state-of-the-art results on the WMT English\u2192German task, surpassing a range of methods using both phrase-based machine translation and neural machine translation. Our method achieves a significant improvement of 1.3 BLEU from th previous best models on both WMT\u201914 and WMT\u201915 English\u2192German. We also conduct human evaluations on abstractive summarization and find that our method outperforms a purely supervised learning baseline in a statistically significant manner.", "year": 2016, "referenceCount": 66, "citationCount": 261, "influentialCitationCount": 16, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3377142", "name": "Prajit Ramachandran"}, {"authorId": "35025299", "name": "Peter J. Liu"}, {"authorId": "2827616", "name": "Quoc V. Le"}]}, {"paperId": "2f3bc41085ae509ab72ab4f3ca6817b9c3261a19", "url": "https://www.semanticscholar.org/paper/2f3bc41085ae509ab72ab4f3ca6817b9c3261a19", "title": "A Study of Machine Learning in Healthcare", "abstract": "In the past few years, there has been significant developments in how machine learning can be used in various industries and research. This paper discusses the potential of utilizing machine learning technologies in healthcare and outlines various industry initiatives using machine learning initiatives in the healthcare sector.", "year": 2017, "referenceCount": 10, "citationCount": 93, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "24890152", "name": "Rohan Bhardwaj"}, {"authorId": "24732051", "name": "Ankita R. Nambiar"}, {"authorId": "144519383", "name": "Debojyoti Dutta"}]}, {"paperId": "01a88df21603bc53386c0cfc294ef3004c5a4439", "url": "https://www.semanticscholar.org/paper/01a88df21603bc53386c0cfc294ef3004c5a4439", "title": "Machine Learning: ECML 2000", "abstract": null, "year": 2003, "referenceCount": 389, "citationCount": 90, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "41070350", "name": "R. M\u00e1ntaras"}, {"authorId": "145863467", "name": "E. Plaza"}]}, {"paperId": "472b5378c0df643c5507eccbd594980e5895c516", "url": "https://www.semanticscholar.org/paper/472b5378c0df643c5507eccbd594980e5895c516", "title": "The Next Era: Deep Learning in Pharmaceutical Research", "abstract": null, "year": 2016, "referenceCount": 99, "citationCount": 137, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1887610", "name": "S. Ekins"}]}, {"paperId": "c39a7d4c36efd7d08678f6ab6d97e31df91235b5", "url": "https://www.semanticscholar.org/paper/c39a7d4c36efd7d08678f6ab6d97e31df91235b5", "title": "The application of machine learning to structural health monitoring", "abstract": "In broad terms, there are two approaches to damage identification. Model-driven methods establish a high-fidelity physical model of the structure, usually by finite element analysis, and then establish a comparison metric between the model and the measured data from the real structure. If the model is for a system or structure in normal (i.e. undamaged) condition, any departures indicate that the structure has deviated from normal condition and damage is inferred. Data-driven approaches also establish a model, but this is usually a statistical representation of the system, e.g. a probability density function of the normal condition. Departures from normality are then signalled by measured data appearing in regions of very low density. The algorithms that have been developed over the years for data-driven approaches are mainly drawn from the discipline of pattern recognition, or more broadly, machine learning. The object of this paper is to illustrate the utility of the data-driven approach to damage identification by means of a number of case studies.", "year": 2007, "referenceCount": 37, "citationCount": 322, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Medicine"], "authors": [{"authorId": "144789804", "name": "K. Worden"}, {"authorId": "145004158", "name": "G. Manson"}]}, {"paperId": "6c90345f4b020162cc8121be6cc2abcd0ad2b849", "url": "https://www.semanticscholar.org/paper/6c90345f4b020162cc8121be6cc2abcd0ad2b849", "title": "The Hundred-Page Machine Learning Book", "abstract": "Buku ini menjelaskan tentang: \n1. Apa itu pembelajaran mesin \n2. Notasi dan definisi \n3. Algoritma fundamental \n4. Anatomi algorthms pembelajaran \n5. Latihan dasar \n6. Jaringan saraf dan pembelajaran yang mendalam \n7. Masalah dan solusi \n8. Latihan lanjutan \n9. Pembelajaran tanpa pengawasan", "year": 2019, "referenceCount": 0, "citationCount": 203, "influentialCitationCount": 23, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145466078", "name": "A. Burkov"}]}, {"paperId": "4f50385ea413bc602b7da506e218160fa99a504c", "url": "https://www.semanticscholar.org/paper/4f50385ea413bc602b7da506e218160fa99a504c", "title": "Learning Theory: An Approximation Theory Viewpoint", "abstract": "Preface Foreword 1. The framework of learning 2. Basic hypothesis spaces 3. Estimating the sample error 4. Polynomial decay approximation error 5. Estimating covering numbers 6. Logarithmic decay approximation error 7. On the bias-variance problem 8. Regularization 9. Support vector machines for classification 10. General regularized classifiers Bibliography Index.", "year": 2007, "referenceCount": 0, "citationCount": 435, "influentialCitationCount": 56, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1755208", "name": "F. Cucker"}, {"authorId": "1758237", "name": "Ding-Xuan Zhou"}]}, {"paperId": "f57254ac87c6a46c0cb0e582b173fe183b84a389", "url": "https://www.semanticscholar.org/paper/f57254ac87c6a46c0cb0e582b173fe183b84a389", "title": "Explanatory Interactive Machine Learning", "abstract": "Although interactive learning puts the user into the loop, the learner remains mostly a black box for the user. Understanding the reasons behind predictions and queries is important when assessing how the learner works and, in turn, trust. Consequently, we propose the novel framework of explanatory interactive learning where, in each step, the learner explains its query to the user, and the user interacts by both answering the query and correcting the explanation. We demonstrate that this can boost the predictive and explanatory powers of, and the trust into, the learned model, using text (e.g. SVMs) and image classification (e.g. neural networks) experiments as well as a user study.", "year": 2019, "referenceCount": 43, "citationCount": 97, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2580338", "name": "Stefano Teso"}, {"authorId": "1746871", "name": "K. Kersting"}]}, {"paperId": "7bf93d409033b67c349f840b94966a546253b85b", "url": "https://www.semanticscholar.org/paper/7bf93d409033b67c349f840b94966a546253b85b", "title": "Multiscale modeling meets machine learning: What can we learn?", "abstract": null, "year": 2019, "referenceCount": 159, "citationCount": 119, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Computer Science", "Medicine"], "authors": [{"authorId": "48560703", "name": "G. Peng"}, {"authorId": "3490162", "name": "M. Alber"}, {"authorId": "8262551", "name": "A. Buganza Tepole"}, {"authorId": "26989769", "name": "W. R. Cannon"}, {"authorId": "145285175", "name": "S. De"}, {"authorId": "2127635491", "name": "Savador Dura-Bernal"}, {"authorId": "2779870", "name": "K. Garikipati"}, {"authorId": "1720124", "name": "G. Karniadakis"}, {"authorId": "1779102", "name": "W. Lytton"}, {"authorId": "3410970", "name": "P. Perdikaris"}, {"authorId": "21038849", "name": "Linda Petzold"}, {"authorId": "2307122", "name": "E. Kuhl"}]}, {"paperId": "23bae60509630acda34cb1811125de3a0cb86cd7", "url": "https://www.semanticscholar.org/paper/23bae60509630acda34cb1811125de3a0cb86cd7", "title": "Machine Learning and Deep Learning frameworks and libraries for large-scale data mining: a survey", "abstract": null, "year": 2019, "referenceCount": 128, "citationCount": 320, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1697308", "name": "Giang T. Nguyen"}, {"authorId": "2160638", "name": "S. Dlugolinsky"}, {"authorId": "2105227365", "name": "Martin Bob\u00e1k"}, {"authorId": "143824490", "name": "V. Tran"}, {"authorId": "2830481", "name": "\u00c1. Garc\u00eda"}, {"authorId": "145154247", "name": "Ignacio Heredia"}, {"authorId": "2057232086", "name": "Peter Mal\u00edk"}, {"authorId": "1744707", "name": "L. Hluch\u00fd"}]}, {"paperId": "8cec80e8752952188dba7ec407366e0962e3d4a6", "url": "https://www.semanticscholar.org/paper/8cec80e8752952188dba7ec407366e0962e3d4a6", "title": "Co-EM support vector learning", "abstract": "Multi-view algorithms, such as co-training and co-EM, utilize unlabeled data when the available attributes can be split into independent and compatible subsets. Co-EM outperforms co-training for many problems, but it requires the underlying learner to estimate class probabilities, and to learn from probabilistically labeled data. Therefore, co-EM has so far only been studied with naive Bayesian learners. We cast linear classifiers into a probabilistic framework and develop a co-EM version of the Support Vector Machine. We conduct experiments on text classification problems and compare the family of semi-supervised support vector algorithms under different conditions, including violations of the assumptions underlying multi-view learning. For some problems, such as course web page classification, we observe the most accurate results reported so far.", "year": 2004, "referenceCount": 30, "citationCount": 201, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1765114", "name": "Ulf Brefeld"}, {"authorId": "1751348", "name": "T. Scheffer"}]}, {"paperId": "391fbbaf289a8cb8915050c25216a05ea5985d72", "url": "https://www.semanticscholar.org/paper/391fbbaf289a8cb8915050c25216a05ea5985d72", "title": "Introduction to astroML: Machine learning for astrophysics", "abstract": "Astronomy and astrophysics are witnessing dramatic increases in data volume as detectors, telescopes and computers become ever more powerful. During the last decade, sky surveys across the electromagnetic spectrum have collected hundreds of terabytes of astronomical data for hundreds of millions of sources. Over the next decade, the data volume will enter the petabyte domain, and provide accurate measurements for billions of sources. Astronomy and physics students are not traditionally trained to handle such voluminous and complex data sets. In this paper we describe astroML; an initiative, based on python and scikit-learn, to develop a compendium of machine learning tools designed to address the statistical needs of the next generation of students and astronomical surveys. We introduce astroML and present a number of example applications that are enabled by this package.", "year": 2012, "referenceCount": 36, "citationCount": 171, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "2081469", "name": "J. Vanderplas"}, {"authorId": "3232661", "name": "A. Connolly"}, {"authorId": "113343324", "name": "\u017d. Ivezi\u0107"}, {"authorId": "1703070", "name": "Alexander G. Gray"}]}, {"paperId": "8dd5b04e5f89f9bf26d93eef995bbc58e3d1de87", "url": "https://www.semanticscholar.org/paper/8dd5b04e5f89f9bf26d93eef995bbc58e3d1de87", "title": "Machine Learning in Enzyme Engineering", "abstract": "Enzyme engineering plays a central role in developing efficient biocatalysts for biotechnology, biomedicine, and life sciences. Apart from classical rational design and directed evolution approache...", "year": 2020, "referenceCount": 112, "citationCount": 137, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "40550171", "name": "S. Mazurenko"}, {"authorId": "3105282", "name": "Z. Prokop"}, {"authorId": "3069214", "name": "J. Damborsk\u00fd"}]}, {"paperId": "c88634bba44b6c6ccc851820ebafbf51afc29b2c", "url": "https://www.semanticscholar.org/paper/c88634bba44b6c6ccc851820ebafbf51afc29b2c", "title": "Residual Unfairness in Fair Machine Learning from Prejudiced Data", "abstract": "Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairness-adjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-the-art fair machine learning can have a \"bias in, bias out\" property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.", "year": 2018, "referenceCount": 31, "citationCount": 91, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3174388", "name": "Nathan Kallus"}, {"authorId": "47031262", "name": "Angela Zhou"}]}, {"paperId": "b897c744f1fd96632453f7381cce0070d4bf6701", "url": "https://www.semanticscholar.org/paper/b897c744f1fd96632453f7381cce0070d4bf6701", "title": "Drug design by machine learning: the use of inductive logic programming to model the structure-activity relationships of trimethoprim analogues binding to dihydrofolate reductase.", "abstract": "The machine learning program GOLEM from the field of inductive logic programming was applied to the drug design problem of modeling structure-activity relationships. The training data for the program were 44 trimethoprim analogues and their observed inhibition of Escherichia coli dihydrofolate reductase. A further 11 compounds were used as unseen test data. GOLEM obtained rules that were statistically more accurate on the training data and also better on the test data than a Hansch linear regression model. Importantly machine learning yields understandable rules that characterized the chemistry of favored inhibitors in terms of polarity, flexibility, and hydrogen-bonding character. These rules agree with the stereochemistry of the interaction observed crystallographically.", "year": 1992, "referenceCount": 16, "citationCount": 254, "influentialCitationCount": 8, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "65901274", "name": "R. King"}, {"authorId": "145147566", "name": "S. Muggleton"}, {"authorId": "2107671428", "name": "R. A. Lewis"}, {"authorId": "145410834", "name": "M. Sternberg"}]}, {"paperId": "4e13bcc9abc8520e29db1a2064213f297078b370", "url": "https://www.semanticscholar.org/paper/4e13bcc9abc8520e29db1a2064213f297078b370", "title": "Information geometry of Boltzmann machines", "abstract": "A Boltzmann machine is a network of stochastic neurons. The set of all the Boltzmann machines with a fixed topology forms a geometric manifold of high dimension, where modifiable synaptic weights of connections play the role of a coordinate system to specify networks. A learning trajectory, for example, is a curve in this manifold. It is important to study the geometry of the neural manifold, rather than the behavior of a single network, in order to know the capabilities and limitations of neural networks of a fixed topology. Using the new theory of information geometry, a natural invariant Riemannian metric and a dual pair of affine connections on the Boltzmann neural network manifold are established. The meaning of geometrical structures is elucidated from the stochastic and the statistical point of view. This leads to a natural modification of the Boltzmann machine learning rule.", "year": 1992, "referenceCount": 17, "citationCount": 216, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Medicine", "Computer Science"], "authors": [{"authorId": "144362425", "name": "S. Amari"}, {"authorId": "2685825", "name": "K. Kurata"}, {"authorId": "145930529", "name": "H. Nagaoka"}]}, {"paperId": "b8d90e4b3f68044727973d62a17ca8a6dec6e9c5", "url": "https://www.semanticscholar.org/paper/b8d90e4b3f68044727973d62a17ca8a6dec6e9c5", "title": "Mean-field theory of Boltzmann machine learning", "abstract": "I present a mean-field theory for Boltzmann machine learning, derived by employing Thouless-Anderson-Palmer free energy formalism to a full extent. Using the Plefka expansion an extended theory that takes higher-order correction to mean-field free energy formalism into consideration is presented, from which the mean-field approximation of general orders, along with the linear response correction, are derived by truncating the Plefka expansion up to desired orders. A theoretical foundation for an effective trick of using ``diagonal weights,'' introduced by Kappen and Rodr\\'{\\i}guez, is also given. Because of the finite system size and a lack of scaling assumptions on interaction coefficients, the truncated free energy formalism cannot provide an exact description in the case of Boltzmann machines. Accuracies of mean-field approximations of several orders are compared by computer simulations.", "year": 1998, "referenceCount": 10, "citationCount": 149, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "145876882", "name": "Toshiyuki TANAKA"}]}, {"paperId": "38753ed76cca05bcdb95a1ce8bb8743ff3ae52b8", "url": "https://www.semanticscholar.org/paper/38753ed76cca05bcdb95a1ce8bb8743ff3ae52b8", "title": "Review: machine learning techniques applied to cybersecurity", "abstract": null, "year": 2019, "referenceCount": 183, "citationCount": 59, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2116091959", "name": "Javier Martinez"}, {"authorId": "2080843165", "name": "Carla Iglesias Comesa\u00f1a"}, {"authorId": "1402275389", "name": "P. G. Nieto"}]}, {"paperId": "c1609be41d3a5c6e743dabc8a70bb61507a8e871", "url": "https://www.semanticscholar.org/paper/c1609be41d3a5c6e743dabc8a70bb61507a8e871", "title": "On the effectiveness of machine and deep learning for cyber security", "abstract": "Machine learning is adopted in a wide range of domains where it shows its superiority over traditional rule-based algorithms. These methods are being integrated in cyber detection systems with the goal of supporting or even replacing the first level of security analysts. Although the complete automation of detection and analysis is an enticing goal, the efficacy of machine learning in cyber security must be evaluated with the due diligence. We present an analysis, addressed to security specialists, of machine learning techniques applied to the detection of intrusion, malware, and spam. The goal is twofold: to assess the current maturity of these solutions and to identify their main limitations that prevent an immediate adoption of machine learning cyber detection schemes. Our conclusions are based on an extensive review of the literature as well as on experiments performed on real enterprise systems and network traffic.", "year": 2018, "referenceCount": 42, "citationCount": 137, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "119764154", "name": "Giovanni Apruzzese"}, {"authorId": "1754638", "name": "M. Colajanni"}, {"authorId": "8106445", "name": "Luca Ferretti"}, {"authorId": "40489608", "name": "Alessandro Guido"}, {"authorId": "152743829", "name": "Mirco Marchetti"}]}, {"paperId": "47f7631dd7e5d892a7a5e36607ce7b2faf686f2c", "url": "https://www.semanticscholar.org/paper/47f7631dd7e5d892a7a5e36607ce7b2faf686f2c", "title": "Pattern analysis for machine olfaction: a review", "abstract": "Pattern analysis constitutes a critical building block in the development of gas sensor array instruments capable of detecting, identifying, and measuring volatile compounds, a technology that has been proposed as an artificial substitute for the human olfactory system. The successful design of a pattern analysis system for machine olfaction requires a careful consideration of the various issues involved in processing multivariate data: signal-preprocessing, feature extraction, feature selection, classification, regression, clustering, and validation. A considerable number of methods from statistical pattern recognition, neural networks, chemometrics, machine learning, and biological cybernetics have been used to process electronic nose data. The objective of this review paper is to provide a summary and guidelines for using the most widely used pattern analysis techniques, as well as to identify research directions that are at the frontier of sensor-based machine olfaction.", "year": 2002, "referenceCount": 125, "citationCount": 527, "influentialCitationCount": 26, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1389225550", "name": "R. Gutierrez-Osuna"}]}, {"paperId": "e78a35a75dc10f366da57b490679bb38a46da531", "url": "https://www.semanticscholar.org/paper/e78a35a75dc10f366da57b490679bb38a46da531", "title": "Incremental Learning from Noisy Data", "abstract": null, "year": 1986, "referenceCount": 34, "citationCount": 244, "influentialCitationCount": 17, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2620923", "name": "J. C. Schlimmer"}, {"authorId": "144297714", "name": "R. Granger"}]}, {"paperId": "6cad4a36102b6387259f56cc2f09dd7a994ba8fa", "url": "https://www.semanticscholar.org/paper/6cad4a36102b6387259f56cc2f09dd7a994ba8fa", "title": "Gaia: Geo-Distributed Machine Learning Approaching LAN Speeds", "abstract": "Machine learning (ML) is widely used to derive useful information from large-scale data (such as user activities, pictures, and videos) generated at increasingly rapid rates, all over the world. Unfortunately, it is infeasible to move all this globally-generated data to a centralized data center before running an ML algorithm over it--moving large amounts of raw data over wide-area networks (WANs) can be extremely slow, and is also subject to the constraints of privacy and data sovereignty laws. This motivates the need for a geo-distributed ML system spanning multiple data centers. Unfortunately, communicating over WANs can significantly degrade ML system performance (by as much as 53.7\u00d7 in our study) because the communication overwhelms the limited WAN bandwidth. \n \nOur goal in this work is to develop a geo-distributed ML system that (1) employs an intelligent communication mechanism over WANs to efficiently utilize the scarce WAN bandwidth, while retaining the accuracy and correctness guarantees of an ML algorithm; and (2) is generic and flexible enough to run a wide range of ML algorithms, without requiring any changes to the algorithms. \n \nTo this end, we introduce a new, general geo-distributed ML system, Gaia, that decouples the communication within a data center from the communication between data centers, enabling different communication and consistency models for each. We present a new ML synchronization model, Approximate Synchronous Parallel (ASP), whose key idea is to dynamically eliminate insignificant communication between data centers while still guaranteeing the correctness of ML algorithms. Our experiments on our prototypes of Gaia running across 11 Amazon EC2 global regions and on a cluster that emulates EC2 WAN bandwidth show that Gaia provides 1.8-53.5\u00d7 speedup over two state-of-the-art distributed ML systems, and is within 0.94-1.40\u00d7 of the speed of running the same ML algorithm on machines on a local area network (LAN).", "year": 2017, "referenceCount": 86, "citationCount": 286, "influentialCitationCount": 46, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145115422", "name": "Kevin Hsieh"}, {"authorId": "3459901", "name": "A. Harlap"}, {"authorId": "1920997", "name": "N. Vijaykumar"}, {"authorId": "9758493", "name": "Dimitris Konomis"}, {"authorId": "1707164", "name": "G. Ganger"}, {"authorId": "1974678", "name": "Phillip B. Gibbons"}, {"authorId": "145929920", "name": "O. Mutlu"}]}, {"paperId": "729024d584d5833683d28ef416959b679891f393", "url": "https://www.semanticscholar.org/paper/729024d584d5833683d28ef416959b679891f393", "title": "Locally Defined Principal Curves and Surfaces", "abstract": "Principal curves are defined as self-consistent smooth curves passing through the middle of the data, and they have been used in many applications of machine learning as a generalization, dimensionality reduction and a feature extraction tool. We redefine principal curves and surfaces in terms of the gradient and the Hessian of the probability density estimate. This provides a geometric understanding of the principal curves and surfaces, as well as a unifying view for clustering, principal curve fitting and manifold learning by regarding those as principal manifolds of different intrinsic dimensionalities. The theory does not impose any particular density estimation method can be used with any density estimator that gives continuous first and second derivatives. Therefore, we first present our principal curve/surface definition without assuming any particular density estimation method. Afterwards, we develop practical algorithms for the commonly used kernel density estimation (KDE) and Gaussian mixture models (GMM). Results of these algorithms are presented in notional data sets as well as real applications with comparisons to other approaches in the principal curve literature. All in all, we present a novel theoretical understanding of principal curves and surfaces, practical algorithms as general purpose machine learning tools, and applications of these algorithms to several practical problems.", "year": 2011, "referenceCount": 149, "citationCount": 199, "influentialCitationCount": 44, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2730288", "name": "U. Ozertem"}, {"authorId": "1774876", "name": "Deniz Erdo\u011fmu\u015f"}]}, {"paperId": "36be649eeb7fc159d71c43ec575f3b3f9a5cf305", "url": "https://www.semanticscholar.org/paper/36be649eeb7fc159d71c43ec575f3b3f9a5cf305", "title": "Identifying topological order through unsupervised machine learning", "abstract": null, "year": 2018, "referenceCount": 83, "citationCount": 150, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "1398819873", "name": "J. Rodriguez-Nieva"}, {"authorId": "4238038", "name": "M. Scheurer"}]}, {"paperId": "5a05c543d533b9e7dfd7dd10ca59c2f6147b2900", "url": "https://www.semanticscholar.org/paper/5a05c543d533b9e7dfd7dd10ca59c2f6147b2900", "title": "Evaluation of unsupervised semantic mapping of natural language with Leximancer concept mapping", "abstract": null, "year": 2006, "referenceCount": 32, "citationCount": 948, "influentialCitationCount": 76, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "47450615", "name": "Andrew E. Smith"}, {"authorId": "2232163", "name": "M. Humphreys"}]}, {"paperId": "91aafea90a542684183c2c06c99eac082e6deaf8", "url": "https://www.semanticscholar.org/paper/91aafea90a542684183c2c06c99eac082e6deaf8", "title": "FSVM-CIL: Fuzzy Support Vector Machines for Class Imbalance Learning", "abstract": "Support vector machines (SVMs) is a popular machine learning technique, which works effectively with balanced datasets. However, when it comes to imbalanced datasets, SVMs produce suboptimal classification models. On the other hand, the SVM algorithm is sensitive to outliers and noise present in the datasets. Therefore, although the existing class imbalance learning (CIL) methods can make SVMs less sensitive to class imbalance, they can still suffer from the problem of outliers and noise. Fuzzy SVMs (FSVMs) is a variant of the SVM algorithm, which has been proposed to handle the problem of outliers and noise. In FSVMs, training examples are assigned different fuzzy-membership values based on their importance, and these membership values are incorporated into the SVM learning algorithm to make it less sensitive to outliers and noise. However, like the normal SVM algorithm, FSVMs can also suffer from the problem of class imbalance. In this paper, we present a method to improve FSVMs for CIL (called FSVM-CIL), which can be used to handle the class imbalance problem in the presence of outliers and noise. We thoroughly evaluated the proposed FSVM-CIL method on ten real-world imbalanced datasets and compared its performance with five existing CIL methods, which are available for normal SVM training. Based on the overall results, we can conclude that the proposed FSVM-CIL method is a very effective method for CIL, especially in the presence of outliers and noise in datasets.", "year": 2010, "referenceCount": 67, "citationCount": 336, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3214396", "name": "Rukshan Batuwita"}, {"authorId": "145940006", "name": "V. Palade"}]}, {"paperId": "8c581fe2f0054a4061dbd61eda65cb4b541dfa85", "url": "https://www.semanticscholar.org/paper/8c581fe2f0054a4061dbd61eda65cb4b541dfa85", "title": "Machine learning based interatomic potential for amorphous carbon", "abstract": "We introduce a Gaussian approximation potential (GAP) for atomistic simulations of liquid and amorphous elemental carbon. Based on a machine learning representation of the density-functional theory (DFT) potential-energy surface, such interatomic potentials enable materials simulations with close-to DFT accuracy but at much lower computational cost. We first determine the maximum accuracy that any finite-range potential can achieve in carbon structures; then, using a hierarchical set of two-, three-, and many-body structural descriptors, we construct a GAP model that can indeed reach the target accuracy. The potential yields accurate energetic and structural properties over a wide range of densities; it also correctly captures the structure of the liquid phases, at variance with a state-of-the-art empirical potential. Exemplary applications of the GAP model to surfaces of \u201cdiamondlike\u201d tetrahedral amorphous carbon ($\\textit{ta}$-C) are presented, including an estimate of the amorphous material\u2019s surface energy and simulations of high-temperature surface reconstructions (\u201cgraphitization\u201d). The presented interatomic potential appears to be promising for realistic and accurate simulations of nanoscale amorphous carbon structures.", "year": 2016, "referenceCount": 5, "citationCount": 321, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Materials Science"], "authors": [{"authorId": "2432235", "name": "Volker L. Deringer"}, {"authorId": "2559761", "name": "G\u00e1bor Cs\u00e1nyi"}]}, {"paperId": "3cc71ba4cbf96d5ce57c050a3451744a14182f97", "url": "https://www.semanticscholar.org/paper/3cc71ba4cbf96d5ce57c050a3451744a14182f97", "title": "Machine Learning as an Experimental Science", "abstract": null, "year": 1988, "referenceCount": 8, "citationCount": 42, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1713919", "name": "P. Langley"}]}, {"paperId": "ea7685f5ee65c4c152478111b5bfcb23a446d358", "url": "https://www.semanticscholar.org/paper/ea7685f5ee65c4c152478111b5bfcb23a446d358", "title": "A study on several Machine-learning methods for classification of Malignant and benign clustered microcalcifications", "abstract": "In this paper, we investigate several state-of-the-art machine-learning methods for automated classification of clustered microcalcifications (MCs). The classifier is part of a computer-aided diagnosis (CADx) scheme that is aimed to assisting radiologists in making more accurate diagnoses of breast cancer on mammograms. The methods we considered were: support vector machine (SVM), kernel Fisher discriminant (KFD), relevance vector machine (RVM), and committee machines (ensemble averaging and AdaBoost), of which most have been developed recently in statistical learning theory. We formulated differentiation of malignant from benign MCs as a supervised learning problem, and applied these learning methods to develop the classification algorithm. As input, these methods used image features automatically extracted from clustered MCs. We tested these methods using a database of 697 clinical mammograms from 386 cases, which included a wide spectrum of difficult-to-classify cases. We analyzed the distribution of the cases in this database using the multidimensional scaling technique, which reveals that in the feature space the malignant cases are not trivially separable from the benign ones. We used receiver operating characteristic (ROC) analysis to evaluate and to compare classification performance by the different methods. In addition, we also investigated how to combine information from multiple-view mammograms of the same case so that the best decision can be made by a classifier. In our experiments, the kernel-based methods (i.e., SVM, KFD, and RVM) yielded the best performance (A/sub z/=0.85, SVM), significantly outperforming a well-established, clinically-proven CADx approach that is based on neural network (A/sub z/=0.80).", "year": 2005, "referenceCount": 41, "citationCount": 311, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1774452", "name": "Liyang Wei"}, {"authorId": "46286398", "name": "Yongyi Yang"}, {"authorId": "1781483", "name": "R. Nishikawa"}, {"authorId": "1955240", "name": "Yulei Jiang"}]}, {"paperId": "0276aecb97ffa1f7f279e2768abb3484933eacfb", "url": "https://www.semanticscholar.org/paper/0276aecb97ffa1f7f279e2768abb3484933eacfb", "title": "From Machine Learning to Explainable AI", "abstract": "The success of statistical machine learning (ML) methods made the field of Artificial Intelligence (AI) so popular again, after the last AI winter. Meanwhile deep learning approaches even exceed human performance in particular tasks. However, such approaches have some disadvantages besides of needing big quality data, much computational power and engineering effort; those approaches are becoming increasingly opaque, and even if we understand the underlying mathematical principles of such models they still lack explicit declarative knowledge. For example, words are mapped to high-dimensional vectors, making them unintelligible to humans. What we need in the future are context-adaptive procedures, i.e. systems that construct contextual explanatory models for classes of real-world phenomena. This is the goal of explainable AI, which is not a new field; rather, the problem of explainability is as old as AI itself. While rule-based approaches of early AI were comprehensible \u201cglass-box\u201d approaches at least in narrow domains, their weakness was in dealing with uncertainties of the real world. Maybe one step further is in linking probabilistic learning methods with large knowledge representations (ontologies) and logical approaches, thus making results re-traceable, explainable and comprehensible on demand.", "year": 2018, "referenceCount": 102, "citationCount": 165, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1749801", "name": "Andreas Holzinger"}]}, {"paperId": "e72fdc7471e78adec50a6b41792254ce966ce70f", "url": "https://www.semanticscholar.org/paper/e72fdc7471e78adec50a6b41792254ce966ce70f", "title": "Learning to detect malicious executables in the wild", "abstract": "In this paper, we describe the development of a fielded application for detecting malicious executables in the wild. We gathered 1971 benign and 1651 malicious executables and encoded each as a training example using n-grams of byte codes as features. Such processing resulted in more than 255 million distinct n-grams. After selecting the most relevant n-grams for prediction, we evaluated a variety of inductive methods, including naive Bayes, decision trees, support vector machines, and boosting. Ultimately, boosted decision trees outperformed other methods with an area under the roc curve of 0.996. Results also suggest that our methodology will scale to larger collections of executables. To the best of our knowledge, ours is the only fielded application for this task developed using techniques from machine learning and data mining.", "year": 2004, "referenceCount": 51, "citationCount": 494, "influentialCitationCount": 39, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145116464", "name": "J. Z. Kolter"}, {"authorId": "1715421", "name": "M. Maloof"}]}, {"paperId": "303e907c49aa59338abb9be7a079faf7ae66c890", "url": "https://www.semanticscholar.org/paper/303e907c49aa59338abb9be7a079faf7ae66c890", "title": "Intelligent Machines?", "abstract": "Computer science \uf0b7 Parallel programming \uf0b7 Distributed systems* \uf0b7 Advanced algorithms** Cognitive science and machine learning \uf0b7 Neural networks/Deep learning* \uf0b7 Machine learning/ Pattern recognition \uf0b7 Neuroscience: Learning, Memory and cognition \uf0b7 Causal inference* Control and Signal processing \uf0b7 Robotic control 1 \uf0b7 Dynamical systems \uf0b7 Adaptive filters \uf0b7 Computer vision/Image processing Mathematics \uf0b7 Convex optimization (Graduate)/Numerical optimization \uf0b7 Random process \uf0b7 Estimation and detection theory \uf0b7 Fuzzy logics", "year": 2009, "referenceCount": 0, "citationCount": 75, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2059305323", "name": "H. Hauser"}]}, {"paperId": "6b8594a671878b64b11751b4af7a47c917253ccf", "url": "https://www.semanticscholar.org/paper/6b8594a671878b64b11751b4af7a47c917253ccf", "title": "Trivial Transfer Learning for Low-Resource Neural Machine Translation", "abstract": "Transfer learning has been proven as an effective technique for neural machine translation under low-resource conditions. Existing methods require a common target language, language relatedness, or specific training tricks and regimes. We present a simple transfer learning method, where we first train a \u201cparent\u201d model for a high-resource language pair and then continue the training on a low-resource pair only by replacing the training corpus. This \u201cchild\u201d model performs significantly better than the baseline trained for low-resource pair only. We are the first to show this for targeting different languages, and we observe the improvements even for unrelated languages with different alphabets.", "year": 2018, "referenceCount": 37, "citationCount": 123, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3452584", "name": "Tom Kocmi"}, {"authorId": "143832874", "name": "Ondrej Bojar"}]}, {"paperId": "e35338965b359217c3c8360f4c5d3e79beb5f9bc", "url": "https://www.semanticscholar.org/paper/e35338965b359217c3c8360f4c5d3e79beb5f9bc", "title": "A Comparison of ARIMA and LSTM in Forecasting Time Series", "abstract": "Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as \"epoch\" in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior.", "year": 2018, "referenceCount": 23, "citationCount": 323, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1410227947", "name": "Sima Siami\u2010Namini"}, {"authorId": "3463155", "name": "Neda Tavakoli"}, {"authorId": "2336007", "name": "A. Namin"}]}, {"paperId": "bcccb9dca51fbee1a69c13136a47894038ba80ae", "url": "https://www.semanticscholar.org/paper/bcccb9dca51fbee1a69c13136a47894038ba80ae", "title": "A Surrogate Modeling and Adaptive Sampling Toolbox for Computer Based Design", "abstract": "An exceedingly large number of scientific and engineering fields are confronted with the need for computer simulations to study complex, real world phenomena or solve challenging design problems. However, due to the computational cost of these high fidelity simulations, the use of neural networks, kernel methods, and other surrogate modeling techniques have become indispensable. Surrogate models are compact and cheap to evaluate, and have proven very useful for tasks such as optimization, design space exploration, prototyping, and sensitivity analysis. Consequently, in many fields there is great interest in tools and techniques that facilitate the construction of such regression models, while minimizing the computational cost and maximizing model accuracy. This paper presents a mature, flexible, and adaptive machine learning toolkit for regression modeling and active learning to tackle these issues. The toolkit brings together algorithms for data fitting, model selection, sample selection (active learning), hyperparameter optimization, and distributed computing in order to empower a domain expert to efficiently generate an accurate model for the problem or data at hand.", "year": 2010, "referenceCount": 12, "citationCount": 489, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2388822", "name": "D. Gorissen"}, {"authorId": "2426172", "name": "I. Couckuyt"}, {"authorId": "1742060", "name": "P. Demeester"}, {"authorId": "1806487", "name": "T. Dhaene"}, {"authorId": "2978499", "name": "K. Crombecq"}]}, {"paperId": "1b481d6f30a1bdabb896c1b4ccb0567ec6749d54", "url": "https://www.semanticscholar.org/paper/1b481d6f30a1bdabb896c1b4ccb0567ec6749d54", "title": "Comprehensive Review On Supervised Machine Learning Algorithms", "abstract": "Machine learning is an area of computer science in which the computer predicts the next task to perform by analyzing the data provided to it. The data accessed by the computer can be in the form of digitized training sets or via interaction with the environment. The algorithms of machine learning are constructed in such a way as to learn and make predictions from the data unlike the static programming algorithms that need explicit human instruction. There have been different supervised and unsupervised techniques proposed in order to solve problems, such as, Rule-based techniques, Logic-based techniques, Instance-based techniques, stochastic techniques. The primary objective of our paper is to provide a general comparison among various state-of-the-art supervised machine learning algorithms.", "year": 2017, "referenceCount": 19, "citationCount": 62, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3577861", "name": "Rishabh Choudhary"}, {"authorId": "31346552", "name": "Hemant Kumar Gianey"}]}, {"paperId": "d1fc877c124390f8d7fdefbfe19751cf0981a7a5", "url": "https://www.semanticscholar.org/paper/d1fc877c124390f8d7fdefbfe19751cf0981a7a5", "title": "Restricted Boltzmann machine learning for solving strongly correlated quantum systems", "abstract": "We develop a machine learning method to construct accurate ground-state wave functions of strongly interacting and entangled quantum spin as well as fermionic models on lattices. A restricted Boltzmann machine algorithm in the form of an artificial neural network is combined with a conventional variational Monte Carlo method with pair product (geminal) wave functions and quantum number projections. The combination allows an application of the machine learning scheme to interacting fermionic systems. The combined method substantially improves the accuracy beyond that ever achieved by each method separately, in the Heisenberg as well as Hubbard models on square lattices, thus proving its power as a highly accurate quantum many-body solver.", "year": 2017, "referenceCount": 113, "citationCount": 162, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "46385308", "name": "Y. Nomura"}, {"authorId": "32541663", "name": "Andrew S. Darmawan"}, {"authorId": "10140295", "name": "Y. Yamaji"}, {"authorId": "33492885", "name": "M. Imada"}]}, {"paperId": "d950f3280bb30131a874936add0cd375bcc363ef", "url": "https://www.semanticscholar.org/paper/d950f3280bb30131a874936add0cd375bcc363ef", "title": "Computer science: The learning machines", "abstract": null, "year": 2014, "referenceCount": 6, "citationCount": 145, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "143625831", "name": "N. Jones"}]}, {"paperId": "17f4a82822309d4ba0e9b2840afc5dfaa499be97", "url": "https://www.semanticscholar.org/paper/17f4a82822309d4ba0e9b2840afc5dfaa499be97", "title": "No Unbiased Estimator of the Variance of K-Fold Cross-Validation", "abstract": "Most machine learning researchers perform quantitative experiments to estimate generalization error and compare the performance of different algorithms (in particular, their proposed algorithm). In order to be able to draw statistically convincing conclusions, it is important to estimate the uncertainty of such estimates. This paper studies the very commonly used K-fold cross-validation estimator of generalization performance. The main theorem shows that there exists no universal (valid under all distributions) unbiased estimator of the variance of K-fold cross-validation. The analysis that accompanies this result is based on the eigen-decomposition of the covariance matrix of errors, which has only three different eigenvalues corresponding to three degrees of freedom of the matrix and three components of the total variance. This analysis helps to better understand the nature of the problem and how it can make naive estimators (that don't take into account the error correlations due to the overlap between training and test sets) grossly underestimate variance. This is confirmed by numerical experiments in which the three components of the variance are compared when the difficulty of the learning problem and the number of folds are varied.", "year": 2003, "referenceCount": 29, "citationCount": 830, "influentialCitationCount": 44, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1751762", "name": "Yoshua Bengio"}, {"authorId": "1802711", "name": "Yves Grandvalet"}]}, {"paperId": "5b63aafab7e54307b75297858aa0f5da2d59f71a", "url": "https://www.semanticscholar.org/paper/5b63aafab7e54307b75297858aa0f5da2d59f71a", "title": "Data mining, hypergraph transversals, and machine learning", "abstract": "Several data mining problems can be formulated as problems of finding maximally specific sentences that are interesting in a database. We first show that this problem has a close relationship with the hypergraph transversal problem. We then analyze two algorithms that have been previously used in data mining, proving upper bounds on their complexity. The first algorithm is useful when the maximally specific interesting sentences are \u201csmall\u201d. We show that this algorithm can also be used to efficiently solve a special case of the hypergraph transversal problem, improving on previous results. The second algorithm utilizes a subroutine for hypergraph transversals, and is applicable in more general situations, with complexity close to a lower bound for the problem. We also relate these problems to the model of exact learning in computational learning theory, and use the correspondence to derive some corollaries.", "year": 1997, "referenceCount": 16, "citationCount": 204, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1736832", "name": "D. Gunopulos"}, {"authorId": "1746048", "name": "R. Khardon"}, {"authorId": "1712654", "name": "H. Mannila"}, {"authorId": "143785973", "name": "Hannu (TT) Toivonen"}]}, {"paperId": "657dcaead090ce7ae0c84df19cfb781a8d933ee9", "url": "https://www.semanticscholar.org/paper/657dcaead090ce7ae0c84df19cfb781a8d933ee9", "title": "Fall Detection and Activity Recognition with Machine Learning", "abstract": "Due to the rapid aging of the European population, an effort needs to be made to ensure that the elderly can live longer independently with minimal support of the working-age population. The Confidence project aims to do this by unobtrusively monitoring their activity to recognize falls and other health problems. This is achieved by equipping the user with radio tags, from which the locations of body parts are determined, thus enabling posture and movement reconstruction. In the paper we first give a general overview of the research on fall detection and activity recognition. We proceed to describe the machine learning approach to activity recognition to be used in the Confidence project. In this approach, the attributes characterizing the user\u2019s behavior and a machine learning algorithm must be selected. The attributes we consider are the locations of body parts in the reference coordinate system (fixed with respect to the environment), the locations of body parts in a body coordinate system (affixed to the user\u2019s body) and the angles between adjacent body parts. Eight machine learning algorithms are compared. The highest classification accuracy of over 95 % is achieved by Support Vector Machine used on the reference attributes and angles.", "year": 2009, "referenceCount": 24, "citationCount": 226, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1723535", "name": "M. Lu\u0161trek"}, {"authorId": "2619188", "name": "Bostjan Kaluza"}]}, {"paperId": "8b8094aa35ae6619ad673f159d6944c79aa6df55", "url": "https://www.semanticscholar.org/paper/8b8094aa35ae6619ad673f159d6944c79aa6df55", "title": "Feature Selection for Knowledge Discovery and Data Mining", "abstract": null, "year": 1998, "referenceCount": 0, "citationCount": 1274, "influentialCitationCount": 70, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2146397025", "name": "Huan Liu"}, {"authorId": "1748072", "name": "H. Motoda"}]}, {"paperId": "ad49b47c51a0fc78b978ec8300d1fb04c4e962a8", "url": "https://www.semanticscholar.org/paper/ad49b47c51a0fc78b978ec8300d1fb04c4e962a8", "title": "Kalman filtering and smoothing solutions to temporal Gaussian process regression models", "abstract": "In this paper, we show how temporal (i.e., time-series) Gaussian process regression models in machine learning can be reformulated as linear-Gaussian state space models, which can be solved exactly with classical Kalman filtering theory. The result is an efficient non-parametric learning algorithm, whose computational complexity grows linearly with respect to number of observations. We show how the reformulation can be done for Mat\u00e9rn family of covariance functions analytically and for squared exponential covariance function by applying spectral Taylor series approximation. Advantages of the proposed approach are illustrated with two numerical experiments.", "year": 2010, "referenceCount": 20, "citationCount": 214, "influentialCitationCount": 45, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "34153908", "name": "Jouni Hartikainen"}, {"authorId": "9244403", "name": "S. Sarkka"}]}, {"paperId": "0ecb76c444814783848a256bb1a24bf384d479cb", "url": "https://www.semanticscholar.org/paper/0ecb76c444814783848a256bb1a24bf384d479cb", "title": "Integrating machine learning and multiscale modeling\u2014perspectives, challenges, and opportunities in the biological, biomedical, and behavioral sciences", "abstract": null, "year": 2019, "referenceCount": 98, "citationCount": 203, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Physics", "Medicine"], "authors": [{"authorId": "3490162", "name": "M. Alber"}, {"authorId": "8262551", "name": "A. Buganza Tepole"}, {"authorId": "26989769", "name": "W. R. Cannon"}, {"authorId": "145285175", "name": "S. De"}, {"authorId": "1403823239", "name": "S. Dura-Bernal"}, {"authorId": "2779870", "name": "K. Garikipati"}, {"authorId": "1720124", "name": "G. Karniadakis"}, {"authorId": "1779102", "name": "W. Lytton"}, {"authorId": "3410970", "name": "P. Perdikaris"}, {"authorId": "21038849", "name": "Linda Petzold"}, {"authorId": "2307122", "name": "E. Kuhl"}]}, {"paperId": "a0622cb2a1662293a0820f09ecd1301952a7485a", "url": "https://www.semanticscholar.org/paper/a0622cb2a1662293a0820f09ecd1301952a7485a", "title": "Learning a Distance Metric from Relative Comparisons", "abstract": "This paper presents a method for learning a distance metric from relative comparison such as \"A is closer to B than A is to C\". Taking a Support Vector Machine (SVM) approach, we develop an algorithm that provides a flexible way of describing qualitative training data as a set of constraints. We show that such constraints lead to a convex quadratic programming problem that can be solved by adapting standard methods for SVM training. We empirically evaluate the performance and the modelling flexibility of the algorithm on a collection of text documents.", "year": 2003, "referenceCount": 15, "citationCount": 682, "influentialCitationCount": 48, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "143892581", "name": "Matthew Schultz"}, {"authorId": "1680188", "name": "T. Joachims"}]}, {"paperId": "a620d007603111ae263c5769c9dc9ac37efd2ddb", "url": "https://www.semanticscholar.org/paper/a620d007603111ae263c5769c9dc9ac37efd2ddb", "title": "TensorFlow: learning functions at scale", "abstract": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Its computational model is based on dataflow graphs with mutable state. Graph nodes may be mapped to different machines in a cluster, and within each machine to CPUs, GPUs, and other devices. TensorFlow supports a variety of applications, but it particularly targets training and inference with deep neural networks. It serves as a platform for research and for deploying machine learning systems across many areas, such as speech recognition, computer vision, robotics, information retrieval, and natural language processing. In this talk, we describe TensorFlow and outline some of its applications. We also discuss the question of what TensorFlow and deep learning may have to do with functional programming. Although TensorFlow is not purely functional, many of its uses are concerned with optimizing functions (during training), then with applying those functions (during inference). These functions are defined as compositions of simple primitives (as is common in functional programming), with internal data representations that are learned rather than manually designed. TensorFlow is joint work with many other people in the Google Brain team and elsewhere. More information is available at tensorflow.org.", "year": 2016, "referenceCount": 0, "citationCount": 205, "influentialCitationCount": 24, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2057642721", "name": "Mart\u00edn Abadi"}]}, {"paperId": "ca6566f16b2057f531b13a44cefedb9baf46abc0", "url": "https://www.semanticscholar.org/paper/ca6566f16b2057f531b13a44cefedb9baf46abc0", "title": "Bridging logic and kernel machines", "abstract": null, "year": 2011, "referenceCount": 49, "citationCount": 62, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1767359", "name": "M. Diligenti"}, {"authorId": "145467467", "name": "M. Gori"}, {"authorId": "35251916", "name": "Marco Maggini"}, {"authorId": "3053033", "name": "Leonardo Rigutini"}]}, {"paperId": "a9606fe31a66df53cd36ceffbcb44a68e3b52d67", "url": "https://www.semanticscholar.org/paper/a9606fe31a66df53cd36ceffbcb44a68e3b52d67", "title": "Domain Adaptation: Learning Bounds and Algorithms", "abstract": "This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data. Building on previous work by Ben-David et al. (2007), we introduce a novel distance between distributions, discrepancy distance, that is tailored to adaptation problems with arbitrary loss functions. We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions. Using this distance, we derive new generalization bounds for domain adaptation for a wide family of loss functions. We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy. This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give several algorithms. We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation.", "year": 2009, "referenceCount": 37, "citationCount": 602, "influentialCitationCount": 73, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144830983", "name": "Y. Mansour"}, {"authorId": "81080659", "name": "M. Mohri"}, {"authorId": "2435268", "name": "Afshin Rostamizadeh"}]}, {"paperId": "3b4fd578d5806be86e5fe8c454e571ec6a76d457", "url": "https://www.semanticscholar.org/paper/3b4fd578d5806be86e5fe8c454e571ec6a76d457", "title": "Machine Learning in Healthcare Informatics", "abstract": null, "year": 2013, "referenceCount": 0, "citationCount": 41, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145201255", "name": "S. Dua"}, {"authorId": "2099555937", "name": "U. Acharya"}, {"authorId": "13904066", "name": "P. Dua"}]}, {"paperId": "60baa46784e8e9a30a57e1875907d008fbdc817b", "url": "https://www.semanticscholar.org/paper/60baa46784e8e9a30a57e1875907d008fbdc817b", "title": "InterpretML: A Unified Framework for Machine Learning Interpretability", "abstract": "InterpretML is an open-source Python package which exposes machine learning interpretability algorithms to practitioners and researchers. InterpretML exposes two types of interpretability - glassbox models, which are machine learning models designed for interpretability (ex: linear models, rule lists, generalized additive models), and blackbox explainability techniques for explaining existing systems (ex: Partial Dependence, LIME). The package enables practitioners to easily compare interpretability algorithms by exposing multiple methods under a unified API, and by having a built-in, extensible visualization platform. InterpretML also includes the first implementation of the Explainable Boosting Machine, a powerful, interpretable, glassbox model that can be as accurate as many blackbox models. The MIT licensed source code can be downloaded from github.com/microsoft/interpret.", "year": 2019, "referenceCount": 21, "citationCount": 214, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "40900039", "name": "Harsha Nori"}, {"authorId": "2057108610", "name": "Samuel Jenkins"}, {"authorId": "143831110", "name": "Paul Koch"}, {"authorId": "145727186", "name": "R. Caruana"}]}, {"paperId": "dc32a984b651256a8ec282be52310e6bd33d9815", "url": "https://www.semanticscholar.org/paper/dc32a984b651256a8ec282be52310e6bd33d9815", "title": "Highly accurate protein structure prediction with AlphaFold", "abstract": null, "year": 2021, "referenceCount": 91, "citationCount": 5597, "influentialCitationCount": 611, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "47921134", "name": "J. Jumper"}, {"authorId": "2115604214", "name": "Richard Evans"}, {"authorId": "1863250", "name": "A. Pritzel"}, {"authorId": "1484039896", "name": "Tim Green"}, {"authorId": "73776617", "name": "Michael Figurnov"}, {"authorId": "1737326", "name": "O. Ronneberger"}, {"authorId": "2119712884", "name": "Kathryn Tunyasuvunakool"}, {"authorId": "2119696840", "name": "Russ Bates"}, {"authorId": "40501144", "name": "Augustin Z\u00eddek"}, {"authorId": "13759734", "name": "Anna Potapenko"}, {"authorId": "1392692054", "name": "Alex Bridgland"}, {"authorId": "1406288863", "name": "Clemens Meyer"}, {"authorId": "2060176064", "name": "Simon A A Kohl"}, {"authorId": "3577056", "name": "Andy Ballard"}, {"authorId": "143964037", "name": "A. Cowie"}, {"authorId": "1403031665", "name": "Bernardino Romera-Paredes"}, {"authorId": "48206221", "name": "Stanislav Nikolov"}, {"authorId": "22418321", "name": "Rishub Jain"}, {"authorId": "40523747", "name": "J. Adler"}, {"authorId": "2830305", "name": "T. Back"}, {"authorId": "48348688", "name": "Stig Petersen"}, {"authorId": "2066483671", "name": "D. Reiman"}, {"authorId": "2072167521", "name": "Ellen Clancy"}, {"authorId": "2060760382", "name": "Michal Zielinski"}, {"authorId": "3396092", "name": "Martin Steinegger"}, {"authorId": "32358258", "name": "Michalina Pacholska"}, {"authorId": "2119712712", "name": "Tamas Berghammer"}, {"authorId": "144129056", "name": "S. Bodenstein"}, {"authorId": "145824029", "name": "David Silver"}, {"authorId": "1689108", "name": "Oriol Vinyals"}, {"authorId": "33666044", "name": "A. Senior"}, {"authorId": "2645384", "name": "K. Kavukcuoglu"}, {"authorId": "143967473", "name": "Pushmeet Kohli"}, {"authorId": "48987704", "name": "D. Hassabis"}]}, {"paperId": "7901981d585789369a96b6c5f5a34987ed5472a7", "url": "https://www.semanticscholar.org/paper/7901981d585789369a96b6c5f5a34987ed5472a7", "title": "Privacy-Preserving Machine Learning: Threats and Solutions", "abstract": "For privacy concerns to be addressed adequately in today's machine-learning (ML) systems, the knowledge gap between the ML and privacy communities must be bridged. This article aims to provide an introduction to the intersection of both fields with special emphasis on the techniques used to protect the data.", "year": 2018, "referenceCount": 30, "citationCount": 152, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1414046108", "name": "Mohammad Al-Rubaie"}, {"authorId": "2107318443", "name": "J. M. Chang"}]}, {"paperId": "4f582a003bc01f6cffeb3b6efb6fbcf8a2389245", "url": "https://www.semanticscholar.org/paper/4f582a003bc01f6cffeb3b6efb6fbcf8a2389245", "title": "Combining Data Mining and Machine Learning for Effective User Profiling", "abstract": "This paper describes the automatic design of methods for detecting fraudulent behavior. Much of the design is accomplished using a series of machine learning methods. In particular, we combine data mining and constructive induction with more standard machine learning techniques to design methods for detecting fraudulent usage of cellular telephones based on profiling customer behavior. Specifically, we use a rule-learning program to uncover indicators of fraudulent behavior from a large database of cellular calls. These indicators are used to create profilers, which then serve as features to a system that combines evidence from multiple profilers to generate high-confidence alarms. Experiments indicate that this automatic approach performs nearly as well as the best hand-tuned methods for detecting fraud.", "year": 1996, "referenceCount": 12, "citationCount": 220, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145421658", "name": "Tom Fawcett"}, {"authorId": "1752722", "name": "F. Provost"}]}, {"paperId": "6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e", "url": "https://www.semanticscholar.org/paper/6b67e38e488cdb6a5af8ae44fdbb2c069c9cea0e", "title": "Introduction to Machine Learning, Neural Networks, and Deep Learning", "abstract": "Purpose To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning. Methods A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology. Results A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background. Conclusions Artificial intelligence has a promising future in medicine; however, many challenges remain. Translational Relevance The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.", "year": 2020, "referenceCount": 33, "citationCount": 91, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "2113872426", "name": "Rene Y. Choi"}, {"authorId": "3719099", "name": "Aaron S. Coyner"}, {"authorId": "1401724111", "name": "Jayashree Kalpathy-Cramer"}, {"authorId": "1764601", "name": "M. Chiang"}, {"authorId": "2107231340", "name": "J. Campbell"}]}, {"paperId": "afdc6a0098388f22fe1718bb6ce70c4b670885a5", "url": "https://www.semanticscholar.org/paper/afdc6a0098388f22fe1718bb6ce70c4b670885a5", "title": "Applying machine learning classifiers to dynamic Android malware detection at scale", "abstract": "The widespread adoption and contextually sensitive nature of smartphone devices has increased concerns over smartphone malware. Machine learning classifiers are a current method for detecting malicious applications on smartphone systems. This paper presents the evaluation of a number of existing classifiers, using a dataset containing thousands of real (i.e. not synthetic) applications. We also present our STREAM framework, which was developed to enable rapid large-scale validation of mobile malware machine learning classifiers.", "year": 2013, "referenceCount": 30, "citationCount": 167, "influentialCitationCount": 21, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1773498", "name": "Brandon Amos"}, {"authorId": "38273752", "name": "Hamilton A. Turner"}, {"authorId": "39292798", "name": "Jules White"}]}, {"paperId": "18a3b1f8631f34b3f962b7bad3dcfc0a79c472e0", "url": "https://www.semanticscholar.org/paper/18a3b1f8631f34b3f962b7bad3dcfc0a79c472e0", "title": "Backward Machine Transliteration by Learning Phonetic Similarity", "abstract": "In many cross-lingual applications we need to convert a transliterated word into its original word. In this paper, we present a similarity-based framework to model the task of backward transliteration, and provide a learning algorithm to automatically acquire phonetic similarities from a corpus. The learning algorithm is based on Widrow-Hoff rule with some modifications. The experiment results show that the learning algorithm converges quickly, and the method using acquired phonetic similarities remarkably outperforms previous methods using pre-defined phonetic similarities or graphic similarities in a corpus of 1574 pairs of English names and transliterated Chinese names. The learning algorithm does not assume any underlying phonological structures or rules, and can be extended to other language pairs once a training corpus and a pronouncing dictionary are available.", "year": 2002, "referenceCount": 27, "citationCount": 90, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2472161", "name": "Wei-Hao Lin"}, {"authorId": "153924342", "name": "Hsin-Hsi Chen"}]}, {"paperId": "8adfe8e758377d824644e9822e2c1bae82eab81f", "url": "https://www.semanticscholar.org/paper/8adfe8e758377d824644e9822e2c1bae82eab81f", "title": "Compositional Falsification of Cyber-Physical Systems with Machine Learning Components", "abstract": null, "year": 2017, "referenceCount": 45, "citationCount": 183, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2468634", "name": "T. Dreossi"}, {"authorId": "2365146", "name": "Alexandre Donz\u00e9"}, {"authorId": "1775517", "name": "S. Seshia"}]}, {"paperId": "2a00d745958b8916e8044df1b68d11cdf6fcc000", "url": "https://www.semanticscholar.org/paper/2a00d745958b8916e8044df1b68d11cdf6fcc000", "title": "The Myth in the Methodology: Towards a Recontextualization of Fairness in Machine Learning", "abstract": "Even as machine learning has expanded into the realm of social decision-making, where concerns of bias and justice often rise above those of efficiency and accuracy, the field has remained committed to standard ML techniques that conceive of fairness in terms of statistical metrics and rely heavily on historical data as accurate and neutral representations of the world. So long as the field conforms to these methods and believes it can optimize systems according to universal notions of fairness, machine learning will be ill-suited to address the fundamentally political and ethical considerations at stake when deploying algorithms in the public sphere. The design and adoption of machine learning tools in high-stakes social contexts should be as much a matter of democratic deliberation as of technical analysis.", "year": 2018, "referenceCount": 19, "citationCount": 66, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "87122962", "name": "Ben Green"}, {"authorId": "26354178", "name": "Lily Hu"}]}, {"paperId": "3e3a2e08095fd7402a97aaf6e73b6dbfdd58de79", "url": "https://www.semanticscholar.org/paper/3e3a2e08095fd7402a97aaf6e73b6dbfdd58de79", "title": "Is Feature Selection Secure against Training Data Poisoning?", "abstract": "Learning in adversarial settings is becoming an important task for application domains where attackers may inject malicious data into the training set to subvert normal operation of data-driven technologies. Feature selection has been widely used in machine learning for security applications to improve generalization and computational efficiency, although it is not clear whether its use may be beneficial or even counterproductive when training data are poisoned by intelligent attackers. In this work, we shed light on this issue by providing a framework to investigate the robustness of popular feature selection methods, including LASSO, ridge regression and the elastic net. Our results on malware detection show that feature selection methods can be significantly compromised under attack (we can reduce LASSO to almost random choices of feature sets by careful insertion of less than 5% poisoned training samples), highlighting the need for specific countermeasures.", "year": 2015, "referenceCount": 43, "citationCount": 316, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2114239129", "name": "Huang Xiao"}, {"authorId": "1684175", "name": "B. Biggio"}, {"authorId": "145485821", "name": "Gavin Brown"}, {"authorId": "1716261", "name": "G. Fumera"}, {"authorId": "49601001", "name": "C. Eckert"}, {"authorId": "1710171", "name": "F. Roli"}]}, {"paperId": "74f3f3adff2cc80dc9af7b5b39016fd9d9ea3ad9", "url": "https://www.semanticscholar.org/paper/74f3f3adff2cc80dc9af7b5b39016fd9d9ea3ad9", "title": "Neural-network quantum state tomography", "abstract": null, "year": 2018, "referenceCount": 34, "citationCount": 422, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "3422999", "name": "G. Torlai"}, {"authorId": "6818118", "name": "G. Mazzola"}, {"authorId": "5048394", "name": "J. Carrasquilla"}, {"authorId": "1752096", "name": "M. Troyer"}, {"authorId": "3422513", "name": "R. Melko"}, {"authorId": "50666189", "name": "G. Carleo"}]}, {"paperId": "0dfcb3cce7ca12635d02ee0043a8bf2a58d76490", "url": "https://www.semanticscholar.org/paper/0dfcb3cce7ca12635d02ee0043a8bf2a58d76490", "title": "Foundations and Trends \u00ae in Machine Learning > Vol 7 > Issue 4-5 Ordering Info About Us Alerts Contact Help Log in Adaptation , Learning , and Optimization over Networks", "abstract": "Subjects Adaptive control and signal processing, Behavioral, cognitive and neural learning, Data mining, Graphical models, Online learning, Optimization, Statistical learning theory, Computational Learning, Distributed computing, Detection and estimation, Pattern recognition and learning, Signal processing for communications, Control/Graph-theoretic models, Dynamics and Asymptotic Behavior of Networks, Adaptive signal processing, Distributed and network signal processing, Statistical/machine learning, Statistical signal processing: Estimation and regression, Stochastic Networks, Stochastic Optimization, Control of Multi-agent Systems", "year": 2011, "referenceCount": 0, "citationCount": 193, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1740506", "name": "A. Sayed"}]}, {"paperId": "cc8379abcda8faa78e2c5e17deb96785ea447461", "url": "https://www.semanticscholar.org/paper/cc8379abcda8faa78e2c5e17deb96785ea447461", "title": "A Secure Federated Transfer Learning Framework", "abstract": "Machine learning relies on the availability of vast amounts of data for training. However, in reality, data are mostly scattered across different organizations and cannot be easily integrated due to many legal and practical constraints. To address this important challenge in the field of machine learning, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical modeling under a data federation. FTL allows knowledge to be shared without compromising user privacy and enables complementary knowledge to be transferred across domains in a data federation, thereby enabling a target-domain party to build flexible and effective models by leveraging rich labels from a source domain. This framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the nonprivacy-preserving transfer learning. It is flexible and can be effectively adapted to various secure multiparty machine learning tasks.", "year": 2020, "referenceCount": 29, "citationCount": 173, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "History"], "authors": [{"authorId": "1614034792", "name": "Yang Liu"}, {"authorId": "1505828520", "name": "Yan Kang"}, {"authorId": "39007380", "name": "C. Xing"}, {"authorId": "11573257", "name": "Tianjian Chen"}, {"authorId": "153096457", "name": "Qiang Yang"}]}, {"paperId": "c5e2057c8bda178fabfa0f5bed8f6f8dce933e8d", "url": "https://www.semanticscholar.org/paper/c5e2057c8bda178fabfa0f5bed8f6f8dce933e8d", "title": "Global discretization of continuous attributes as preprocessing for machine learning", "abstract": null, "year": 1996, "referenceCount": 23, "citationCount": 375, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "8760889", "name": "Michal R. Chmielewski"}, {"authorId": "1398620187", "name": "J. Grzymala-Busse"}]}, {"paperId": "38468437453ca338c31cb98789cff00bca47d285", "url": "https://www.semanticscholar.org/paper/38468437453ca338c31cb98789cff00bca47d285", "title": "Hybrid learning machines", "abstract": null, "year": 2009, "referenceCount": 0, "citationCount": 123, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145731499", "name": "A. Abraham"}, {"authorId": "84641297", "name": "E. Corchado"}, {"authorId": "1729096", "name": "J. Corchado"}]}, {"paperId": "98f2aff0a60c24b41bc5c916807e0edb4da73e3c", "url": "https://www.semanticscholar.org/paper/98f2aff0a60c24b41bc5c916807e0edb4da73e3c", "title": "Evaluation of Different Machine Learning Methods and Deep-Learning Convolutional Neural Networks for Landslide Detection", "abstract": "There is a growing demand for detailed and accurate landslide maps and inventories around the globe, but particularly in hazard-prone regions such as the Himalayas. Most standard mapping methods require expert knowledge, supervision and fieldwork. In this study, we use optical data from the Rapid Eye satellite and topographic factors to analyze the potential of machine learning methods, i.e., artificial neural network (ANN), support vector machines (SVM) and random forest (RF), and different deep-learning convolution neural networks (CNNs) for landslide detection. We use two training zones and one test zone to independently evaluate the performance of different methods in the highly landslide-prone Rasuwa district in Nepal. Twenty different maps are created using ANN, SVM and RF and different CNN instantiations and are compared against the results of extensive fieldwork through a mean intersection-over-union (mIOU) and other common metrics. This accuracy assessment yields the best result of 78.26% mIOU for a small window size CNN, which uses spectral information only. The additional information from a 5 m digital elevation model helps to discriminate between human settlements and landslides but does not improve the overall classification accuracy. CNNs do not automatically outperform ANN, SVM and RF, although this is sometimes claimed. Rather, the performance of CNNs strongly depends on their design, i.e., layer depth, input window sizes and training strategies. Here, we conclude that the CNN method is still in its infancy as most researchers will either use predefined parameters in solutions like Google TensorFlow or will apply different settings in a trial-and-error manner. Nevertheless, deep-learning can improve landslide mapping in the future if the effects of the different designs are better understood, enough training samples exist, and the effects of augmentation strategies to artificially increase the number of existing samples are better understood.", "year": 2019, "referenceCount": 68, "citationCount": 332, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31568077", "name": "O. Ghorbanzadeh"}, {"authorId": "50594282", "name": "T. Blaschke"}, {"authorId": "69898104", "name": "Khalil Gholamnia"}, {"authorId": "69936582", "name": "S. Meena"}, {"authorId": "2584015", "name": "D. Tiede"}, {"authorId": "2414452", "name": "J. Aryal"}]}, {"paperId": "333e80cb1be31236c6b20ab7813cb264604d5d9f", "url": "https://www.semanticscholar.org/paper/333e80cb1be31236c6b20ab7813cb264604d5d9f", "title": "Unifying machine learning and quantum chemistry with a deep neural network for molecular wavefunctions", "abstract": null, "year": 2019, "referenceCount": 58, "citationCount": 220, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Mathematics", "Materials Science", "Medicine", "Computer Science"], "authors": [{"authorId": "33075217", "name": "Kristof T. Sch\u00fctt"}, {"authorId": "5742764", "name": "M. Gastegger"}, {"authorId": "2462983", "name": "A. Tkatchenko"}, {"authorId": "145034054", "name": "K. M\u00fcller"}, {"authorId": "40653856", "name": "R. Maurer"}]}, {"paperId": "d7a7eb55e5fa728b149de03e3e78b12e6a271206", "url": "https://www.semanticscholar.org/paper/d7a7eb55e5fa728b149de03e3e78b12e6a271206", "title": "Stochastic Computing Systems", "abstract": null, "year": 1969, "referenceCount": 175, "citationCount": 588, "influentialCitationCount": 69, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145677147", "name": "B. Gaines"}]}, {"paperId": "e69e1d2e0d4c29ba4b92352f280fcae92587cc4c", "url": "https://www.semanticscholar.org/paper/e69e1d2e0d4c29ba4b92352f280fcae92587cc4c", "title": "Statistics, Data Mining, and Machine Learning in Astronomy", "abstract": "As telescopes, detectors, and computers grow ever more powerful, the volume of data at the disposal of astronomers and astrophysicists will enter the petabyte domain, providing accurate measurements for billions of celestial objects. This book provides a comprehensive and accessible introduction to the cutting-edge statistical methods needed to efficiently analyze complex data sets from astronomical surveys such as the Panoramic Survey Telescope and Rapid Response System, the Dark Energy Survey, and the upcoming Large Synoptic Survey Telescope. It serves as a practical handbook for graduate students and advanced undergraduates in physics and astronomy, and as an indispensable reference for researchers. Statistics, Data Mining, and Machine Learning in Astronomy presents a wealth of practical analysis problems, evaluates techniques for solving them, and explains how to use various approaches for different types and sizes of data sets. For all applications described in the book, Python code and example data sets are provided. The supporting data sets have been carefully selected from contemporary astronomical surveys (for example, the Sloan Digital Sky Survey) and are easy to download and use. The accompanying Python code is publicly available, well documented, and follows uniform coding standards. Together, the data sets and code enable readers to reproduce all the figures and examples, evaluate the methods, and adapt them to their own fields of interest. Describes the most useful statistical and data-mining methods for extracting knowledge from huge and complex astronomical data sets Features real-world data sets from contemporary astronomical surveys Uses a freely available Python codebase throughout Ideal for students and working astronomers", "year": 2014, "referenceCount": 2, "citationCount": 301, "influentialCitationCount": 41, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "113343324", "name": "\u017d. Ivezi\u0107"}, {"authorId": "3232661", "name": "A. Connolly"}, {"authorId": "2081469", "name": "J. Vanderplas"}, {"authorId": "50344099", "name": "Alexander Gray"}]}, {"paperId": "a042afeb1bee81f00191d5f8179fcd1ae149278e", "url": "https://www.semanticscholar.org/paper/a042afeb1bee81f00191d5f8179fcd1ae149278e", "title": "ModelTracker: Redesigning Performance Analysis Tools for Machine Learning", "abstract": "Model building in machine learning is an iterative process. The performance analysis and debugging step typically involves a disruptive cognitive switch from model building to error analysis, discouraging an informed approach to model building. We present ModelTracker, an interactive visualization that subsumes information contained in numerous traditional summary statistics and graphs while displaying example-level performance and enabling direct error examination and debugging. Usage analysis from machine learning practitioners building real models with ModelTracker over six months shows ModelTracker is used often and throughout model building. A controlled experiment focusing on ModelTracker's debugging capabilities shows participants prefer ModelTracker over traditional tools without a loss in model performance.", "year": 2015, "referenceCount": 25, "citationCount": 213, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1719124", "name": "Saleema Amershi"}, {"authorId": "1724065", "name": "D. M. Chickering"}, {"authorId": "2311676", "name": "S. Drucker"}, {"authorId": "49132427", "name": "Bongshin Lee"}, {"authorId": "2812486", "name": "P. Simard"}, {"authorId": "38972741", "name": "Jina Suh"}]}, {"paperId": "7b10cb38a75fc95ec2eef49c3985ca7cbc5125d2", "url": "https://www.semanticscholar.org/paper/7b10cb38a75fc95ec2eef49c3985ca7cbc5125d2", "title": "Preference Learning", "abstract": null, "year": 2010, "referenceCount": 71, "citationCount": 257, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "90563291", "name": "Johannes Frnkranz"}, {"authorId": "52386728", "name": "E. Hllermeier"}]}, {"paperId": "88a99980f1f7eeac5f36be2e4601898988bdf937", "url": "https://www.semanticscholar.org/paper/88a99980f1f7eeac5f36be2e4601898988bdf937", "title": "Mol2vec: Unsupervised Machine Learning Approach with Chemical Intuition", "abstract": "Inspired by natural language processing techniques, we here introduce Mol2vec, which is an unsupervised machine learning approach to learn vector representations of molecular substructures. Like the Word2vec models, where vectors of closely related words are in close proximity in the vector space, Mol2vec learns vector representations of molecular substructures that point in similar directions for chemically related substructures. Compounds can finally be encoded as vectors by summing the vectors of the individual substructures and, for instance, be fed into supervised machine learning approaches to predict compound properties. The underlying substructure vector embeddings are obtained by training an unsupervised machine learning approach on a so-called corpus of compounds that consists of all available chemical matter. The resulting Mol2vec model is pretrained once, yields dense vector representations, and overcomes drawbacks of common compound feature representations such as sparseness and bit collisions. The prediction capabilities are demonstrated on several compound property and bioactivity data sets and compared with results obtained for Morgan fingerprints as a reference compound representation. Mol2vec can be easily combined with ProtVec, which employs the same Word2vec concept on protein sequences, resulting in a proteochemometric approach that is alignment-independent and thus can also be easily used for proteins with low sequence similarities.", "year": 2018, "referenceCount": 36, "citationCount": 267, "influentialCitationCount": 17, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "153300145", "name": "Sabrina Jaeger"}, {"authorId": "2689594", "name": "S. Fulle"}, {"authorId": "2513057", "name": "S. Turk"}]}, {"paperId": "4c823e07f316b1a3ab88449912394d33b30786a1", "url": "https://www.semanticscholar.org/paper/4c823e07f316b1a3ab88449912394d33b30786a1", "title": "Machine learning for quantum matter", "abstract": "ABSTRACT Quantum matter, the research field studying phases of matter whose properties are intrinsically quantum mechanical, draws from areas as diverse as hard condensed matter physics, materials science, statistical mechanics, quantum information, quantum gravity, and large-scale numerical simulations. Recently, researchers interested in quantum matter and strongly correlated quantum systems have turned their attention to the algorithms underlying modern machine learning with an eye on making progress in their fields. Here we provide a short review on the recent development and adaptation of machine learning ideas for the purpose advancing research in quantum matter, including ideas ranging from algorithms that recognize conventional and topological states of matter in synthetic experimental data, to representations of quantum states in terms of neural networks and their applications to the simulation and control of quantum systems. We discuss the outlook for future developments in areas at the intersection between machine learning and quantum many-body physics. Graphical abstract", "year": 2020, "referenceCount": 299, "citationCount": 99, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "5048394", "name": "J. Carrasquilla"}]}, {"paperId": "8371978db157cd49488fecde9b3e9bd3b8146b04", "url": "https://www.semanticscholar.org/paper/8371978db157cd49488fecde9b3e9bd3b8146b04", "title": "Learning Patterns from Unix Process Execution Traces for Intrusion Detection", "abstract": "In this paper we describe our preliminary experiments to extend the work pioneered by Forrest (see Forrest et al. 1996) on learning the (normal abnormal) patterns of Unix processes. These patterns can be used to identify misuses of and intrusions in Unix systems. We formulated machine learning tasks on operating system call sequences of normal and abnormal (intrusion) executions of the Unix sendmail program. We show that our methods can accurately distinguish all abnormal executions of sendmail from the normal ones provided in a set of test traces. These preliminary results indicate that machine learning can play an important role by generalizing stored sequence information to perhaps provide broader intrusion detection services. The experiments also reveal some interesting and challenging problems for future research. much effort has been devoted to the problem of detecting intrusions as quickly as possible. There are two basic approaches to intrusion detection: \u00af Misuse Intrusion Detection: known patterns of (past", "year": 1997, "referenceCount": 17, "citationCount": 337, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1738428", "name": "Wenke Lee"}, {"authorId": "1807433", "name": "S. Stolfo"}, {"authorId": "144316325", "name": "P. Chan"}]}, {"paperId": "ab99c1f8981f65cb3d5d43511cda2450fef6bb99", "url": "https://www.semanticscholar.org/paper/ab99c1f8981f65cb3d5d43511cda2450fef6bb99", "title": "Principles and Theory for Data Mining and Machine Learning", "abstract": null, "year": 2009, "referenceCount": 0, "citationCount": 290, "influentialCitationCount": 20, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2177274", "name": "B. Clarke"}, {"authorId": "2547567", "name": "E. Fokoue"}, {"authorId": "1399987315", "name": "Hao Helen Zhang"}]}, {"paperId": "c9404262274a05987366a5b9085d14a66266f4f4", "url": "https://www.semanticscholar.org/paper/c9404262274a05987366a5b9085d14a66266f4f4", "title": "Introduction: The challenge of reinforcement learning", "abstract": null, "year": 1992, "referenceCount": 26, "citationCount": 115, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1699645", "name": "R. Sutton"}]}, {"paperId": "cbbbb5e1d2c02b37689082fe1ee9ab8f9414becd", "url": "https://www.semanticscholar.org/paper/cbbbb5e1d2c02b37689082fe1ee9ab8f9414becd", "title": "Diversity in Machine Learning", "abstract": "Machine learning methods have achieved good performance and been widely applied in various real-world applications. They can learn the model adaptively and be better fit for special requirements of different tasks. Generally, a good machine learning system is composed of plentiful training data, a good model training process, and an accurate inference. Many factors can affect the performance of the machine learning process, among which the diversity of the machine learning process is an important one. The diversity can help each procedure to guarantee a totally good machine learning: diversity of the training data ensures that the training data can provide more discriminative information for the model, diversity of the learned model (diversity in parameters of each model or diversity among different base models) makes each parameter/model capture unique or complement information and the diversity in inference can provide multiple choices each of which corresponds to a specific plausible local optimal result. Even though diversity plays an important role in the machine learning process, there is no systematical analysis of the diversification in the machine learning system. In this paper, we systematically summarize the methods to make data diversification, model diversification, and inference diversification in the machine learning process. In addition, the typical applications where the diversity technology improved the machine learning performance have been surveyed including the remote sensing imaging tasks, machine translation, camera relocalization, image segmentation, object detection, topic modeling, and others. Finally, we discuss some challenges of the diversity technology in machine learning and point out some directions in future work. Our analysis provides a deeper understanding of the diversity technology in machine learning tasks and hence can help design and learn more effective models for real-world applications.", "year": 2018, "referenceCount": 169, "citationCount": 76, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2605832", "name": "Z. Gong"}, {"authorId": "143741620", "name": "P. Zhong"}, {"authorId": "39739882", "name": "W. Hu"}]}, {"paperId": "54a5679a668d4942087aae79b31a7a8584553416", "url": "https://www.semanticscholar.org/paper/54a5679a668d4942087aae79b31a7a8584553416", "title": "Comparison of Supervised and Unsupervised Learning Algorithms for Pattern Classification", "abstract": "This paper presents a comparative account of unsupervised and supervised learning models and their pattern classification evaluations as applied to the higher education scenario. Classification plays a vital role in machine based learning algorithms and in the present study, we found that, though the error back-propagation learning algorithm as provided by supervised learning model is very efficient for a number of non-linear real-time problems, KSOM of unsupervised learning model, offers efficient solution and classification in the present study.", "year": 2013, "referenceCount": 24, "citationCount": 291, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145794118", "name": "R. Sathya"}, {"authorId": "2064038954", "name": "Annamma Abraham."}]}, {"paperId": "4e45a3f474bdb4b8263e3027bd0bf3197d920a9d", "url": "https://www.semanticscholar.org/paper/4e45a3f474bdb4b8263e3027bd0bf3197d920a9d", "title": "Analysis of Machine learning Techniques Used in Behavior-Based Malware Detection", "abstract": "The increase of malware that are exploiting the Internet daily has become a serious threat. The manual heuristic inspection of malware analysis is no longer considered effective and efficient compared against the high spreading rate of malware. Hence, automated behavior-based malware detection using machine learning techniques is considered a profound solution. The behavior of each malware on an emulated (sandbox) environment will be automatically analyzed and will generate behavior reports. These reports will be preprocessed into sparse vector models for further machine learning (classification). The classifiers used in this research are k-Nearest Neighbors (kNN), Na\u00efve Bayes, J48 Decision Tree, Support Vector Machine (SVM), and Multilayer Perceptron Neural Network (MlP). Based on the analysis of the tests and experimental results of all the 5 classifiers, the overall best performance was achieved by J48 decision tree with a recall of 95.9%, a false positive rate of 2.4%, a precision of 97.3%, and an accuracy of 96.8%. In summary, it can be concluded that a proof-of-concept based on automatic behavior-based malware analysis and the use of machine learning techniques could detect malware quite effectively and efficiently.", "year": 2010, "referenceCount": 8, "citationCount": 238, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31081648", "name": "Ivan Firdausi"}, {"authorId": "145981459", "name": "Charles Lim"}, {"authorId": "39240532", "name": "Alva Erwin"}, {"authorId": "2862751", "name": "A. Nugroho"}]}, {"paperId": "7942f0f793041dddefe084825ac907ab6755dab9", "url": "https://www.semanticscholar.org/paper/7942f0f793041dddefe084825ac907ab6755dab9", "title": "A review of advanced machine learning methods for the detection of biotic stress in precision crop protection", "abstract": null, "year": 2015, "referenceCount": 107, "citationCount": 232, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "2895826", "name": "J. Behmann"}, {"authorId": "2470933", "name": "Anne-Katrin Mahlein"}, {"authorId": "3338283", "name": "Till Rumpf"}, {"authorId": "2617093", "name": "Christoph R\u00f6mer"}, {"authorId": "1897102", "name": "L. Pl\u00fcmer"}]}, {"paperId": "899defb6a100af509547b8d74bb626533ee87da4", "url": "https://www.semanticscholar.org/paper/899defb6a100af509547b8d74bb626533ee87da4", "title": "Measuring the VC-Dimension of a Learning Machine", "abstract": "A method for measuring the capacity of learning machines is described. The method is based on fitting a theoretically derived function to empirical measurements of the maximal difference between the error rates on two separate data sets of varying sizes. Experimental measurements of the capacity of various types of linear classifiers are presented.", "year": 1994, "referenceCount": 12, "citationCount": 359, "influentialCitationCount": 35, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "50560492", "name": "V. Vapnik"}, {"authorId": "8992604", "name": "E. Levin"}, {"authorId": "1688882", "name": "Yann LeCun"}]}, {"paperId": "1fa6bb29c58f4fceb2f86b80bbec59acdc0aa46f", "url": "https://www.semanticscholar.org/paper/1fa6bb29c58f4fceb2f86b80bbec59acdc0aa46f", "title": "Machine Learning Based on Attribute Interactions", "abstract": "Two attributes $A$ and $B$ are said to interact when it helps to observe the attribute values of both attributes together. This is an example of a $2$-way interaction. In general, a group of attributes ${\\cal X}$ is involved in a $k$-way interaction when we cannot reconstruct their relationship merely with $\\ell$-way interactions, $\\ell < k$. These two definitions formalize the notion of an interaction in a nutshell. \n \nAn additional notion is the one of context. We interpret context as just another attribute. There are two ways in which we can consider context. Context can be something that specifies our focus: we may examine interactions only in a given context, only for the instances that are in the context. Alternatively, context can be something that we are interested in: if we seek to predict weather, only the interactions involving the weather will be interesting to us. This is especially relevant for classification: we only want to examine the interactions involving the labelled class attribute and other attributes (unless there are missing or uncertain attribute values). \n \nBut the definitions are not complete. We need to specify the model that assumes the interaction: how to we represent the pattern of co-appearance of several attributes? We also need to specify a model that does not assume the interaction: how do we reconstruct the pattern of co-appearance of several attributes without actually observing them all simultaneously? We need to specify a loss function that measures how good a particular model is, with respect to another model or with respect to the data. We need an algorithm that builds both models from the data. Finally, we need the data in order to assess whether it supports the hypothesis of interaction. \n \nThe present work shows that mutual information, information gain, correlation, attribute importance, association and many other concepts, are all merely special cases of the above principle. Furthermore, the analysis of interactions generalizes the notions of analysis of variance, variable clustering, structure learning of Bayesian networks, and several other problems. There is an intriguing history of reinvention in the area of information theory on the topic of interactions. \n \nIn our work, we focus on models founded on probability theory, and employ entropy and Kullback-Leibler divergence as our loss functions. Generally, whether an interaction exists or not, and to what extent, depends on what kind of models we are working with. The concept of McGill's interaction information in information theory, for example, is based upon Kullback-Leibler divergence as the loss function, and non-normalized Kirkwood superposition approximation models. Pearson's correlation coefficient is based on the proportion of explained standard deviation as the loss function, and on the multivariate Gaussian model. Most applications of mutual information are based on Kullback-Leibler divergence and the multinomial model. \n \nWhen there is a limited amount of data, it becomes unclear what model can be used to interpret it. Even if we fix the family of models, we remain uncertain about what would be the best choice of a model in the family. In all, uncertainty pervades the choice of the model. The underlying idea of Bayesian statistics is that the uncertainty about the model is to be handled in the same was as the uncertainty about the correct prediction in nondeterministic domains. The uncertainty, however, implies that we know neither if is an interaction with complete certainty, nor how important is the interaction. \n \nWe propose a Bayesian approach to performing significance tests: an interaction is significant if it is very unlikely that a model assuming the interaction would suffer a greater loss than a model not assuming it, even if the interaction truly exists, among all the foreseeable posterior models. We also propose Bayesian confidence intervals to assess the probability distribution of the expected loss of assuming that an interaction does not exist. We compare significance tests based on permutations, bootstrapping, cross-validation, Bayesian statistics and asymptotic theory, and find that they often disagree. It is important, therefore, to understand the assumptions that underlie the tests. \n \nInteractions are a natural way of understanding the regularities in the data. We propose interaction analysis, a methodology for analyzing the data. It has a long history, but our novel contribution is a series of diagrams that illustrate the discovered interactions in data. The diagrams include information graphs, interaction graphs and dendrograms. We use interactions to identify concept drift and ignorability of missing data. We use interactions to cluster attribute values and build taxonomies automatically. \n \nWhen we say that there is an interaction, we still need to explain what it looks like. Generally, the interaction can be explained by inferring a higher-order construction. For that purpose, we provide visualizations for several models that allow for interactions. We also provide a probabilistic account of rule inference: a rule can be interpreted as a constructed attribute. We also describe interactions involving individual attribute values with other attributes: this can help us break complex attributes down into simpler components. We also provide an approach to handling the curse of dimensionality: we dynamically maintain a structure of attributes as individual attributes are entering our model one by one. \n \nWe conclude this work by presenting two practical algorithms: an efficient heuristic for selecting attributes within the naive Bayesian classifier, and a complete approach to prediction with interaction models, the Kikuchi-Bayes model. Kikuchi-Bayes combines Bayesian model averaging, a parsimonious prior, and search for interactions that determine the model. Kikuchi-Bayes outperforms most popular machine learning methods, such as classification trees, logistic regression, the naive Bayesian classifier, and sometimes even the support vector machines. However, Kikuchi-Bayes models are highly interpretable and can be easily visualized as interaction graphs.", "year": 2005, "referenceCount": 259, "citationCount": 180, "influentialCitationCount": 25, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "2962063", "name": "Aleks Jakulin"}]}, {"paperId": "cf6b5797d922678f0f03a8bbad96b0d7482d8c02", "url": "https://www.semanticscholar.org/paper/cf6b5797d922678f0f03a8bbad96b0d7482d8c02", "title": "Evaluation of machine learning classifiers for mobile malware detection", "abstract": null, "year": 2016, "referenceCount": 55, "citationCount": 309, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2458760", "name": "F. Amalina"}, {"authorId": "2006150", "name": "Ali Feizollah"}, {"authorId": "1940692", "name": "N. B. Anuar"}, {"authorId": "143930319", "name": "A. Gani"}]}, {"paperId": "5d7f4d7d9acfe8b89a88ab45ee8480adb7fd0489", "url": "https://www.semanticscholar.org/paper/5d7f4d7d9acfe8b89a88ab45ee8480adb7fd0489", "title": "Bundle Methods for Regularized Risk Minimization", "abstract": "A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the unified framework we present tight convergence bounds, which show that our algorithm converges in O(1/e) steps to e precision for general convex problems and in O(log (1/e)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets.", "year": 2010, "referenceCount": 95, "citationCount": 275, "influentialCitationCount": 35, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "37077406", "name": "C. Teo"}, {"authorId": "145713876", "name": "S. Vishwanathan"}, {"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "2827616", "name": "Quoc V. Le"}]}, {"paperId": "726af4cfc44d1b8d20a104d2cf045d47f66b0428", "url": "https://www.semanticscholar.org/paper/726af4cfc44d1b8d20a104d2cf045d47f66b0428", "title": "The Intuitive Appeal of Explainable Machines", "abstract": "Algorithmic decision-making has become synonymous with inexplicable decision-making, but what makes algorithms so difficult to explain? This Article examines what sets machine learning apart from other ways of developing rules for decision-making and the problem these properties pose for explanation. We show that machine learning models can be both inscrutable and nonintuitive and that these are related, but distinct, properties. \n \nCalls for explanation have treated these problems as one and the same, but disentangling the two reveals that they demand very different responses. Dealing with inscrutability requires providing a sensible description of the rules; addressing nonintuitiveness requires providing a satisfying explanation for why the rules are what they are. Existing laws like the Fair Credit Reporting Act (FCRA), the Equal Credit Opportunity Act (ECOA), and the General Data Protection Regulation (GDPR), as well as techniques within machine learning, are focused almost entirely on the problem of inscrutability. While such techniques could allow a machine learning system to comply with existing law, doing so may not help if the goal is to assess whether the basis for decision-making is normatively defensible. \n \nIn most cases, intuition serves as the unacknowledged bridge between a descriptive account and a normative evaluation. But because machine learning is often valued for its ability to uncover statistical relationships that defy intuition, relying on intuition is not a satisfying approach. This Article thus argues for other mechanisms for normative evaluation. To know why the rules are what they are, one must seek explanations of the process behind a model\u2019s development, not just explanations of the model itself.", "year": 2018, "referenceCount": 1, "citationCount": 189, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46432110", "name": "Andrew D. Selbst"}, {"authorId": "2881033", "name": "Solon Barocas"}]}, {"paperId": "784ee73d5363c711118f784428d1ab89f019daa5", "url": "https://www.semanticscholar.org/paper/784ee73d5363c711118f784428d1ab89f019daa5", "title": "Hybrid computing using a neural network with dynamic external memory", "abstract": null, "year": 2016, "referenceCount": 42, "citationCount": 1302, "influentialCitationCount": 150, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1753223", "name": "A. Graves"}, {"authorId": "89504302", "name": "Greg Wayne"}, {"authorId": "47447264", "name": "Malcolm Reynolds"}, {"authorId": "3367786", "name": "Tim Harley"}, {"authorId": "1841008", "name": "Ivo Danihelka"}, {"authorId": "1398898827", "name": "Agnieszka Grabska-Barwinska"}, {"authorId": "2016840", "name": "Sergio Gomez Colmenarejo"}, {"authorId": "1864353", "name": "Edward Grefenstette"}, {"authorId": "34505275", "name": "Tiago Ramalho"}, {"authorId": "70495322", "name": "J. Agapiou"}, {"authorId": "36045539", "name": "Adri\u00e0 Puigdom\u00e8nech Badia"}, {"authorId": "2910877", "name": "K. Hermann"}, {"authorId": "3185820", "name": "Yori Zwols"}, {"authorId": "2273072", "name": "Georg Ostrovski"}, {"authorId": "2055913310", "name": "Adam Cain"}, {"authorId": "143776287", "name": "Helen King"}, {"authorId": "2372244", "name": "C. Summerfield"}, {"authorId": "1685771", "name": "P. Blunsom"}, {"authorId": "2645384", "name": "K. Kavukcuoglu"}, {"authorId": "48987704", "name": "D. Hassabis"}]}, {"paperId": "225fbfd99465033e993460a1bc838a87fbf42346", "url": "https://www.semanticscholar.org/paper/225fbfd99465033e993460a1bc838a87fbf42346", "title": "Gaussian-Bernoulli deep Boltzmann machine", "abstract": "In this paper, we study a model that we call Gaussian-Bernoulli deep Boltzmann machine (GDBM) and discuss potential improvements in training the model. GDBM is designed to be applicable to continuous data and it is constructed from Gaussian-Bernoulli restricted Boltzmann machine (GRBM) by adding multiple layers of binary hidden neurons. The studied improvements of the learning algorithm for GDBM include parallel tempering, enhanced gradient, adaptive learning rate and layer-wise pretraining. We empirically show that they help avoid some of the common difficulties found in training deep Boltzmann machines such as divergence of learning, the difficulty in choosing right learning rate scheduling, and the existence of meaningless higher layers.", "year": 2013, "referenceCount": 31, "citationCount": 126, "influentialCitationCount": 21, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1979489", "name": "Kyunghyun Cho"}, {"authorId": "2785022", "name": "T. Raiko"}, {"authorId": "145096481", "name": "A. Ilin"}]}, {"paperId": "4edd70173c73d7a0805124c25c1e7f1081633cc7", "url": "https://www.semanticscholar.org/paper/4edd70173c73d7a0805124c25c1e7f1081633cc7", "title": "Machine Learning Methods for Analysis of Metabolic Data and Metabolic Pathway Modeling", "abstract": "Machine learning uses experimental data to optimize clustering or classification of samples or features, or to develop, augment or verify models that can be used to predict behavior or properties of systems. It is expected that machine learning will help provide actionable knowledge from a variety of big data including metabolomics data, as well as results of metabolism models. A variety of machine learning methods has been applied in bioinformatics and metabolism analyses including self-organizing maps, support vector machines, the kernel machine, Bayesian networks or fuzzy logic. To a lesser extent, machine learning has also been utilized to take advantage of the increasing availability of genomics and metabolomics data for the optimization of metabolic network models and their analysis. In this context, machine learning has aided the development of metabolic networks, the calculation of parameters for stoichiometric and kinetic models, as well as the analysis of major features in the model for the optimal application of bioreactors. Examples of this very interesting, albeit highly complex, application of machine learning for metabolism modeling will be the primary focus of this review presenting several different types of applications for model optimization, parameter determination or system analysis using models, as well as the utilization of several different types of machine learning technologies.", "year": 2018, "referenceCount": 93, "citationCount": 92, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "102073354", "name": "M. \u010cuperlovi\u0107-Culf"}]}]}