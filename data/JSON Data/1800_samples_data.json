{"total": 5120627, "offset": 1700, "next": 1800, "data": [{"paperId": "403333e80da4be137710b7c48c2f0a15cd196455", "url": "https://www.semanticscholar.org/paper/403333e80da4be137710b7c48c2f0a15cd196455", "title": "Machine Learning Techniques in Optical Communication", "abstract": "Machine learning techniques relevant for nonlinearity mitigation, carrier recovery, and nanoscale device characterization are reviewed and employed. Markov Chain Monte Carlo in combination with Bayesian filtering is employed within the nonlinear state-space framework and demonstrated for parameter estimation. It is shown that the time-varying effects of cross-phase modulation (XPM) induced polarization scattering and phase noise can be formulated within the nonlinear state-space model (SSM). This allows for tracking and compensation of the XPM induced impairments by employing approximate stochastic filtering methods such as extended Kalman or particle filtering. The achievable gains are dependent on the autocorrelation (AC) function properties of the impairments under consideration which is strongly dependent on the transmissions scenario. The gain of the compensation method are therefore investigated by varying the parameters of the AC function describing XPM-induced polarization scattering and phase noise. It is shown that an increase in the nonlinear tolerance of more than 2 dB is achievable for 32 Gbaud QPSK and 16-quadratic-amplitude modulation (QAM). It is also reviewed how laser rate equations can be formulated within the nonlinear state-space framework which allows for tracking of nonLorentzian laser phase noise lineshapes. It is experimentally demonstrated for 28 Gbaud 16-QAM signals that if the laser phase noise shape strongly deviates from the Lorentzian, phase noise tracking algorithms employing rate equation-based SSM result in a significant performance improvement (>8 dB) compared to traditional approaches using digital phase-locked loop. Finally, Gaussian mixture model is reviewed and employed for nonlinear phase noise compensation and characterization of nanoscale devices structure variations.", "year": 2015, "referenceCount": 30, "citationCount": 162, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "2735803", "name": "D. Zibar"}, {"authorId": "3630976", "name": "M. Piels"}, {"authorId": "2158596750", "name": "R. Jones"}, {"authorId": "39228587", "name": "C. Schaeffer"}]}, {"paperId": "1fa6bb29c58f4fceb2f86b80bbec59acdc0aa46f", "url": "https://www.semanticscholar.org/paper/1fa6bb29c58f4fceb2f86b80bbec59acdc0aa46f", "title": "Machine Learning Based on Attribute Interactions", "abstract": "Two attributes $A$ and $B$ are said to interact when it helps to observe the attribute values of both attributes together. This is an example of a $2$-way interaction. In general, a group of attributes ${\\cal X}$ is involved in a $k$-way interaction when we cannot reconstruct their relationship merely with $\\ell$-way interactions, $\\ell < k$. These two definitions formalize the notion of an interaction in a nutshell. \n \nAn additional notion is the one of context. We interpret context as just another attribute. There are two ways in which we can consider context. Context can be something that specifies our focus: we may examine interactions only in a given context, only for the instances that are in the context. Alternatively, context can be something that we are interested in: if we seek to predict weather, only the interactions involving the weather will be interesting to us. This is especially relevant for classification: we only want to examine the interactions involving the labelled class attribute and other attributes (unless there are missing or uncertain attribute values). \n \nBut the definitions are not complete. We need to specify the model that assumes the interaction: how to we represent the pattern of co-appearance of several attributes? We also need to specify a model that does not assume the interaction: how do we reconstruct the pattern of co-appearance of several attributes without actually observing them all simultaneously? We need to specify a loss function that measures how good a particular model is, with respect to another model or with respect to the data. We need an algorithm that builds both models from the data. Finally, we need the data in order to assess whether it supports the hypothesis of interaction. \n \nThe present work shows that mutual information, information gain, correlation, attribute importance, association and many other concepts, are all merely special cases of the above principle. Furthermore, the analysis of interactions generalizes the notions of analysis of variance, variable clustering, structure learning of Bayesian networks, and several other problems. There is an intriguing history of reinvention in the area of information theory on the topic of interactions. \n \nIn our work, we focus on models founded on probability theory, and employ entropy and Kullback-Leibler divergence as our loss functions. Generally, whether an interaction exists or not, and to what extent, depends on what kind of models we are working with. The concept of McGill's interaction information in information theory, for example, is based upon Kullback-Leibler divergence as the loss function, and non-normalized Kirkwood superposition approximation models. Pearson's correlation coefficient is based on the proportion of explained standard deviation as the loss function, and on the multivariate Gaussian model. Most applications of mutual information are based on Kullback-Leibler divergence and the multinomial model. \n \nWhen there is a limited amount of data, it becomes unclear what model can be used to interpret it. Even if we fix the family of models, we remain uncertain about what would be the best choice of a model in the family. In all, uncertainty pervades the choice of the model. The underlying idea of Bayesian statistics is that the uncertainty about the model is to be handled in the same was as the uncertainty about the correct prediction in nondeterministic domains. The uncertainty, however, implies that we know neither if is an interaction with complete certainty, nor how important is the interaction. \n \nWe propose a Bayesian approach to performing significance tests: an interaction is significant if it is very unlikely that a model assuming the interaction would suffer a greater loss than a model not assuming it, even if the interaction truly exists, among all the foreseeable posterior models. We also propose Bayesian confidence intervals to assess the probability distribution of the expected loss of assuming that an interaction does not exist. We compare significance tests based on permutations, bootstrapping, cross-validation, Bayesian statistics and asymptotic theory, and find that they often disagree. It is important, therefore, to understand the assumptions that underlie the tests. \n \nInteractions are a natural way of understanding the regularities in the data. We propose interaction analysis, a methodology for analyzing the data. It has a long history, but our novel contribution is a series of diagrams that illustrate the discovered interactions in data. The diagrams include information graphs, interaction graphs and dendrograms. We use interactions to identify concept drift and ignorability of missing data. We use interactions to cluster attribute values and build taxonomies automatically. \n \nWhen we say that there is an interaction, we still need to explain what it looks like. Generally, the interaction can be explained by inferring a higher-order construction. For that purpose, we provide visualizations for several models that allow for interactions. We also provide a probabilistic account of rule inference: a rule can be interpreted as a constructed attribute. We also describe interactions involving individual attribute values with other attributes: this can help us break complex attributes down into simpler components. We also provide an approach to handling the curse of dimensionality: we dynamically maintain a structure of attributes as individual attributes are entering our model one by one. \n \nWe conclude this work by presenting two practical algorithms: an efficient heuristic for selecting attributes within the naive Bayesian classifier, and a complete approach to prediction with interaction models, the Kikuchi-Bayes model. Kikuchi-Bayes combines Bayesian model averaging, a parsimonious prior, and search for interactions that determine the model. Kikuchi-Bayes outperforms most popular machine learning methods, such as classification trees, logistic regression, the naive Bayesian classifier, and sometimes even the support vector machines. However, Kikuchi-Bayes models are highly interpretable and can be easily visualized as interaction graphs.", "year": 2005, "referenceCount": 259, "citationCount": 180, "influentialCitationCount": 25, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "2962063", "name": "Aleks Jakulin"}]}, {"paperId": "cf6b5797d922678f0f03a8bbad96b0d7482d8c02", "url": "https://www.semanticscholar.org/paper/cf6b5797d922678f0f03a8bbad96b0d7482d8c02", "title": "Evaluation of machine learning classifiers for mobile malware detection", "abstract": null, "year": 2016, "referenceCount": 55, "citationCount": 309, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2458760", "name": "F. Amalina"}, {"authorId": "2006150", "name": "Ali Feizollah"}, {"authorId": "1940692", "name": "N. B. Anuar"}, {"authorId": "143930319", "name": "A. Gani"}]}, {"paperId": "5d7f4d7d9acfe8b89a88ab45ee8480adb7fd0489", "url": "https://www.semanticscholar.org/paper/5d7f4d7d9acfe8b89a88ab45ee8480adb7fd0489", "title": "Bundle Methods for Regularized Risk Minimization", "abstract": "A wide variety of machine learning problems can be described as minimizing a regularized risk functional, with different algorithms using different notions of risk and different regularizers. Examples include linear Support Vector Machines (SVMs), Gaussian Processes, Logistic Regression, Conditional Random Fields (CRFs), and Lasso amongst others. This paper describes the theory and implementation of a scalable and modular convex solver which solves all these estimation problems. It can be parallelized on a cluster of workstations, allows for data-locality, and can deal with regularizers such as L1 and L2 penalties. In addition to the unified framework we present tight convergence bounds, which show that our algorithm converges in O(1/e) steps to e precision for general convex problems and in O(log (1/e)) steps for continuously differentiable problems. We demonstrate the performance of our general purpose solver on a variety of publicly available data sets.", "year": 2010, "referenceCount": 95, "citationCount": 275, "influentialCitationCount": 35, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "37077406", "name": "C. Teo"}, {"authorId": "145713876", "name": "S. Vishwanathan"}, {"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "2827616", "name": "Quoc V. Le"}]}, {"paperId": "726af4cfc44d1b8d20a104d2cf045d47f66b0428", "url": "https://www.semanticscholar.org/paper/726af4cfc44d1b8d20a104d2cf045d47f66b0428", "title": "The Intuitive Appeal of Explainable Machines", "abstract": "Algorithmic decision-making has become synonymous with inexplicable decision-making, but what makes algorithms so difficult to explain? This Article examines what sets machine learning apart from other ways of developing rules for decision-making and the problem these properties pose for explanation. We show that machine learning models can be both inscrutable and nonintuitive and that these are related, but distinct, properties. \n \nCalls for explanation have treated these problems as one and the same, but disentangling the two reveals that they demand very different responses. Dealing with inscrutability requires providing a sensible description of the rules; addressing nonintuitiveness requires providing a satisfying explanation for why the rules are what they are. Existing laws like the Fair Credit Reporting Act (FCRA), the Equal Credit Opportunity Act (ECOA), and the General Data Protection Regulation (GDPR), as well as techniques within machine learning, are focused almost entirely on the problem of inscrutability. While such techniques could allow a machine learning system to comply with existing law, doing so may not help if the goal is to assess whether the basis for decision-making is normatively defensible. \n \nIn most cases, intuition serves as the unacknowledged bridge between a descriptive account and a normative evaluation. But because machine learning is often valued for its ability to uncover statistical relationships that defy intuition, relying on intuition is not a satisfying approach. This Article thus argues for other mechanisms for normative evaluation. To know why the rules are what they are, one must seek explanations of the process behind a model\u2019s development, not just explanations of the model itself.", "year": 2018, "referenceCount": 1, "citationCount": 189, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46432110", "name": "Andrew D. Selbst"}, {"authorId": "2881033", "name": "Solon Barocas"}]}, {"paperId": "784ee73d5363c711118f784428d1ab89f019daa5", "url": "https://www.semanticscholar.org/paper/784ee73d5363c711118f784428d1ab89f019daa5", "title": "Hybrid computing using a neural network with dynamic external memory", "abstract": null, "year": 2016, "referenceCount": 42, "citationCount": 1302, "influentialCitationCount": 150, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1753223", "name": "A. Graves"}, {"authorId": "89504302", "name": "Greg Wayne"}, {"authorId": "47447264", "name": "Malcolm Reynolds"}, {"authorId": "3367786", "name": "Tim Harley"}, {"authorId": "1841008", "name": "Ivo Danihelka"}, {"authorId": "1398898827", "name": "Agnieszka Grabska-Barwinska"}, {"authorId": "2016840", "name": "Sergio Gomez Colmenarejo"}, {"authorId": "1864353", "name": "Edward Grefenstette"}, {"authorId": "34505275", "name": "Tiago Ramalho"}, {"authorId": "70495322", "name": "J. Agapiou"}, {"authorId": "36045539", "name": "Adri\u00e0 Puigdom\u00e8nech Badia"}, {"authorId": "2910877", "name": "K. Hermann"}, {"authorId": "3185820", "name": "Yori Zwols"}, {"authorId": "2273072", "name": "Georg Ostrovski"}, {"authorId": "2055913310", "name": "Adam Cain"}, {"authorId": "143776287", "name": "Helen King"}, {"authorId": "2372244", "name": "C. Summerfield"}, {"authorId": "1685771", "name": "P. Blunsom"}, {"authorId": "2645384", "name": "K. Kavukcuoglu"}, {"authorId": "48987704", "name": "D. Hassabis"}]}, {"paperId": "20b877e96201a08332b5dcd4e73a1a30c9ac5a9e", "url": "https://www.semanticscholar.org/paper/20b877e96201a08332b5dcd4e73a1a30c9ac5a9e", "title": "MapReduce : Distributed Computing for Machine Learning", "abstract": "We use Hadoop, an open-source implementation of Google\u2019s distributed file system and the MapReduce framework for distributed data processing, on modestly-sized compute clusters to evaluate its efficacy for standard machine learning tasks. We show benchmark performance on searching and sorting tasks to investigate the effects of various system configurations. We also distinguish classes of machine-learning problems that are reasonable to address within the MapReduce framework, and offer improvements to the Hadoop implementation. We conclude that MapReduce is a good choice for basic operations on large datasets, although there are complications to be addressed for more complex machine learning tasks.", "year": 2006, "referenceCount": 6, "citationCount": 116, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2396669", "name": "D. Gillick"}, {"authorId": "27001288", "name": "Arlo Faria"}]}, {"paperId": "5e761bc3b6028308dcd48f9ba0964533c2e6fe43", "url": "https://www.semanticscholar.org/paper/5e761bc3b6028308dcd48f9ba0964533c2e6fe43", "title": "The Kernel-Adatron Algorithm: A Fast and Simple Learning Procedure for Support Vector Machines", "abstract": "Support Vector Machines work by mapping training data for classiication tasks into a high dimensional feature space. In the feature space they then nd a maximal margin hyperplane which separates the data. This hyperplane is usually found using a quadratic programming routine which is computation-ally intensive, and is non trivial to implement. In this paper we propose an adaptation of the Adatron algorithm for clas-siication with kernels in high dimensional spaces. The algorithm is simple and can nd a solution very rapidly with an exponentially fast rate of convergence (in the number of iterations) towards the optimal solution. Experimental results with real and artiicial datasets are provided.", "year": 1998, "referenceCount": 26, "citationCount": 304, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "34999823", "name": "T. Frie\u00df"}, {"authorId": "1685083", "name": "N. Cristianini"}, {"authorId": "145990261", "name": "C. Campbell"}]}, {"paperId": "225fbfd99465033e993460a1bc838a87fbf42346", "url": "https://www.semanticscholar.org/paper/225fbfd99465033e993460a1bc838a87fbf42346", "title": "Gaussian-Bernoulli deep Boltzmann machine", "abstract": "In this paper, we study a model that we call Gaussian-Bernoulli deep Boltzmann machine (GDBM) and discuss potential improvements in training the model. GDBM is designed to be applicable to continuous data and it is constructed from Gaussian-Bernoulli restricted Boltzmann machine (GRBM) by adding multiple layers of binary hidden neurons. The studied improvements of the learning algorithm for GDBM include parallel tempering, enhanced gradient, adaptive learning rate and layer-wise pretraining. We empirically show that they help avoid some of the common difficulties found in training deep Boltzmann machines such as divergence of learning, the difficulty in choosing right learning rate scheduling, and the existence of meaningless higher layers.", "year": 2013, "referenceCount": 31, "citationCount": 126, "influentialCitationCount": 21, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1979489", "name": "Kyunghyun Cho"}, {"authorId": "2785022", "name": "T. Raiko"}, {"authorId": "145096481", "name": "A. Ilin"}]}, {"paperId": "4c8e6027cadcfb471de8b2954dd5ab555bae3c4b", "url": "https://www.semanticscholar.org/paper/4c8e6027cadcfb471de8b2954dd5ab555bae3c4b", "title": "Classification of sentiment reviews using n-gram machine learning approach", "abstract": null, "year": 2016, "referenceCount": 28, "citationCount": 412, "influentialCitationCount": 20, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2064351166", "name": "Abinash Tripathy"}, {"authorId": "1845826220", "name": "Ankit Agrawal"}, {"authorId": "7790877", "name": "S. K. Rath"}]}, {"paperId": "ad906fb0dc38f0e7a59f48c968647bd81ed778bb", "url": "https://www.semanticscholar.org/paper/ad906fb0dc38f0e7a59f48c968647bd81ed778bb", "title": "A Review of User Interface Design for Interactive Machine Learning", "abstract": "Interactive Machine Learning (IML) seeks to complement human perception and intelligence by tightly integrating these strengths with the computational power and speed of computers. The interactive process is designed to involve input from the user but does not require the background knowledge or experience that might be necessary to work with more traditional machine learning techniques. Under the IML process, non-experts can apply their domain knowledge and insight over otherwise unwieldy datasets to find patterns of interest or develop complex data-driven applications. This process is co-adaptive in nature and relies on careful management of the interaction between human and machine. User interface design is fundamental to the success of this approach, yet there is a lack of consolidated principles on how such an interface should be implemented. This article presents a detailed review and characterisation of Interactive Machine Learning from an interactive systems perspective. We propose and describe a structural and behavioural model of a generalised IML system and identify solution principles for building effective interfaces for IML. Where possible, these emergent solution principles are contextualised by reference to the broader human-computer interaction literature. Finally, we identify strands of user interface research key to unlocking more efficient and productive non-expert interactive machine learning applications.", "year": 2018, "referenceCount": 118, "citationCount": 156, "influentialCitationCount": 25, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31818759", "name": "John J. Dudley"}, {"authorId": "1683133", "name": "P. Kristensson"}]}, {"paperId": "74cd77a3f33ce48373277e7ce9f34d028410bbad", "url": "https://www.semanticscholar.org/paper/74cd77a3f33ce48373277e7ce9f34d028410bbad", "title": "Malware detection using machine learning", "abstract": "We propose a versatile framework in which one can employ different machine learning algorithms to successfully distinguish between malware files and clean files, while aiming to minimise the number of false positives. In this paper we present the ideas behind our framework by working firstly with cascade one-sided perceptrons and secondly with cascade kernelized one-sided perceptrons. After having been successfully tested on medium-size datasets of malware and clean files, the ideas behind this framework were submitted to a scaling-up process that enable us to work with very large datasets of malware and clean files.", "year": 2009, "referenceCount": 27, "citationCount": 102, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3172788", "name": "Dragos Gavrilut"}, {"authorId": "2332459", "name": "Mihai Cimpoesu"}, {"authorId": "2069835267", "name": "Dan Anton"}, {"authorId": "3214990", "name": "Liviu Ciortuz"}]}, {"paperId": "d74a1419d75e8743eb7e3da2bb425340c7753342", "url": "https://www.semanticscholar.org/paper/d74a1419d75e8743eb7e3da2bb425340c7753342", "title": "A Short Introduction to Learning to Rank", "abstract": "Learning to rank refers to machine learning techniques for training the model in a ranking task. Learning to rank is useful for many applications in Information Retrieval, Natural Language Processing, and Data Mining. Intensive studies have been conducted on the problem and significant progress has been made[1],[2]. This short paper gives an introduction to learning to rank, and it specifically explains the fundamental problems, existing approaches, and future work of learning to rank. Several learning to rank methods using SVM techniques are described in details.", "year": 2011, "referenceCount": 26, "citationCount": 314, "influentialCitationCount": 27, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "49404233", "name": "Hang Li"}]}, {"paperId": "640e70226454d4ed8934c40183b31ad4a057fbf8", "url": "https://www.semanticscholar.org/paper/640e70226454d4ed8934c40183b31ad4a057fbf8", "title": "Radiomic Machine-Learning Classifiers for Prognostic Biomarkers of Head and Neck Cancer", "abstract": "Introduction \u201cRadiomics\u201d extracts and mines a large number of medical imaging features in a non-invasive and cost-effective way. The underlying assumption of radiomics is that these imaging features quantify phenotypic characteristics of an entire tumor. In order to enhance applicability of radiomics in clinical oncology, highly accurate and reliable machine-learning approaches are required. In this radiomic study, 13 feature selection methods and 11 machine-learning classification methods were evaluated in terms of their performance and stability for predicting overall survival in head and neck cancer patients. Methods Two independent head and neck cancer cohorts were investigated. Training cohort HN1 consisted of 101 head and neck cancer patients. Cohort HN2 (n\u2009=\u200995) was used for validation. A total of 440 radiomic features were extracted from the segmented tumor regions in CT images. Feature selection and classification methods were compared using an unbiased evaluation framework. Results We observed that the three feature selection methods minimum redundancy maximum relevance (AUC\u2009=\u20090.69, Stability\u2009=\u20090.66), mutual information feature selection (AUC\u2009=\u20090.66, Stability\u2009=\u20090.69), and conditional infomax feature extraction (AUC\u2009=\u20090.68, Stability\u2009=\u20090.7) had high prognostic performance and stability. The three classifiers BY (AUC\u2009=\u20090.67, RSD\u2009=\u200911.28), RF (AUC\u2009=\u20090.61, RSD\u2009=\u20097.36), and NN (AUC\u2009=\u20090.62, RSD\u2009=\u200910.52) also showed high prognostic performance and stability. Analysis investigating performance variability indicated that the choice of classification method is the major factor driving the performance variation (29.02% of total variance). Conclusion Our study identified prognostic and reliable machine-learning methods for the prediction of overall survival of head and neck cancer patients. Identification of optimal machine-learning methods for radiomics-based prognostic analyses could broaden the scope of radiomics in precision oncology and cancer care.", "year": 2015, "referenceCount": 45, "citationCount": 281, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "40470674", "name": "C. Parmar"}, {"authorId": "49405431", "name": "P. Grossmann"}, {"authorId": "4383629", "name": "D. Rietveld"}, {"authorId": "143763610", "name": "M. Rietbergen"}, {"authorId": "1693233", "name": "P. Lambin"}, {"authorId": "143849569", "name": "H. Aerts"}]}, {"paperId": "1a700d6cce09f1711cdaf8f5f21b6ab2a8ce7bae", "url": "https://www.semanticscholar.org/paper/1a700d6cce09f1711cdaf8f5f21b6ab2a8ce7bae", "title": "Enhanced Gradient and Adaptive Learning Rate for Training Restricted Boltzmann Machines", "abstract": "Boltzmann machines are often used as building blocks in greedy learning of deep networks. However, training even a simplified model, known as restricted Boltzmann machine (RBM), can be extremely laborious: Traditional learning algorithms often converge only with the right choice of the learning rate scheduling and the scale of the initial weights. They are also sensitive to specific data representation: An equivalent RBM can be obtained by flipping some bits and changing the weights and biases accordingly, but traditional learning rules are not invariant to such transformations. Without careful tuning of these training settings, traditional algorithms can easily get stuck at plateaus or even diverge. In this work, we present an enhanced gradient which is derived such that it is invariant to bit-flipping transformations. We also propose a way to automatically adjust the learning rate by maximizing a local likelihood estimate. Our experiments confirm that the proposed improvements yield more stable training of RBMs.", "year": 2011, "referenceCount": 19, "citationCount": 83, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1979489", "name": "Kyunghyun Cho"}, {"authorId": "2785022", "name": "T. Raiko"}, {"authorId": "145096481", "name": "A. Ilin"}]}, {"paperId": "03e755815b69e3f37c2c9df6a1c6a8df7649706f", "url": "https://www.semanticscholar.org/paper/03e755815b69e3f37c2c9df6a1c6a8df7649706f", "title": "Incremental nonlinear dimensionality reduction by manifold learning", "abstract": "Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a \"batch\" mode and cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.", "year": 2006, "referenceCount": 55, "citationCount": 284, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "authors": [{"authorId": "40004085", "name": "Martin H. C. Law"}, {"authorId": "145295484", "name": "Anil K. Jain"}]}, {"paperId": "7c57eb0621c4b22f1c7872bb14bce831e66c09e4", "url": "https://www.semanticscholar.org/paper/7c57eb0621c4b22f1c7872bb14bce831e66c09e4", "title": "Bias detectives: the researchers striving to make algorithms fair", "abstract": null, "year": 2018, "referenceCount": 4, "citationCount": 121, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "8433196", "name": "R. Courtland"}]}, {"paperId": "b8381e24014d8ec3b77b1c53a7d0ccdf5cf2e77c", "url": "https://www.semanticscholar.org/paper/b8381e24014d8ec3b77b1c53a7d0ccdf5cf2e77c", "title": "Introduction to Machine Learning", "abstract": null, "year": 2020, "referenceCount": 129, "citationCount": 44, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "145713876", "name": "S. Vishwanathan"}]}, {"paperId": "be515da1f59addd8259764ddf1a4f10ec7be066c", "url": "https://www.semanticscholar.org/paper/be515da1f59addd8259764ddf1a4f10ec7be066c", "title": "K-Nearest Neighbors", "abstract": null, "year": 2013, "referenceCount": 0, "citationCount": 174, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144309134", "name": "Oliver Kramer"}]}, {"paperId": "d6c233d54e33e18dcec5090dcbac7cac3d168f95", "url": "https://www.semanticscholar.org/paper/d6c233d54e33e18dcec5090dcbac7cac3d168f95", "title": "Probability and computing: randomized algorithms and probabilistic analysis", "abstract": "Randomized algorithms (making random choices during their execution) play an important role in modern computer science, with applications ranging from combinatorial optimization and machine learning to communications networks and secure protocols. Two advantages of randomization over determinism are crucial in the design of algorithms: simplicity and speed. For many applications, a randomized algorithm is often the simplest algorithm available, the fastest, or both.", "year": 2006, "referenceCount": 0, "citationCount": 607, "influentialCitationCount": 56, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1713711", "name": "H. Niederreiter"}]}, {"paperId": "2aadb938af2f77a6ad9321ff873c1c9b9a579fcb", "url": "https://www.semanticscholar.org/paper/2aadb938af2f77a6ad9321ff873c1c9b9a579fcb", "title": "A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection", "abstract": "Cyber security is that the body of technologies, processes and practices designed to safeguard networks, computers, programs and knowledge from attack, harm or unauthorized access. During a computing context, the term security implies cyber security. This survey paper describes a targeted literature survey of machine learning (ML) and data processing (DM) strategies for cyber analytics in support of intrusion detection. This paper focuses totally on cyber intrusion detection as it applies to wired networks. With a wired network, associate oppose must experience many layers of defense at firewalls and operative systems, or gain physical access to the network. The quality of ML/DM algorithms is addressed, discussion of challenges for victimization ML/DM for cyber security is conferred, and some recommendations on once to use a given methodology area unit provided.", "year": 2017, "referenceCount": 13, "citationCount": 861, "influentialCitationCount": 70, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "100818765", "name": "Lalu Banoth"}, {"authorId": "70392354", "name": "M. S. Teja"}, {"authorId": "2102149819", "name": "M. Saicharan"}, {"authorId": "143612469", "name": "N. Chandra"}]}, {"paperId": "1c9f7ab57ad72e071344266a8066078da263092e", "url": "https://www.semanticscholar.org/paper/1c9f7ab57ad72e071344266a8066078da263092e", "title": "Machine Learning for Precision Psychiatry: Opportunities and Challenges.", "abstract": null, "year": 2017, "referenceCount": 62, "citationCount": 381, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Psychology", "Medicine"], "authors": [{"authorId": "1700231", "name": "D. Bzdok"}, {"authorId": "1397954143", "name": "A. Meyer-Lindenberg"}]}, {"paperId": "87da4c90c52b52eaae7aced8a9fbe17d28a27e9f", "url": "https://www.semanticscholar.org/paper/87da4c90c52b52eaae7aced8a9fbe17d28a27e9f", "title": "Exploring chemical compound space with quantum-based machine learning", "abstract": null, "year": 2019, "referenceCount": 175, "citationCount": 136, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "7847508", "name": "O. A. von Lilienfeld"}, {"authorId": "145034054", "name": "K. M\u00fcller"}, {"authorId": "2462983", "name": "A. Tkatchenko"}]}, {"paperId": "f3203d0bdefc9670ed508ca776d08aa9f024bafa", "url": "https://www.semanticscholar.org/paper/f3203d0bdefc9670ed508ca776d08aa9f024bafa", "title": "Neuro-fuzzy And Soft Computing: A Computational Approach To Learning And Machine Intelligence [Books in Brief]", "abstract": "Included in Prentice Hall's MATLAB Curriculum Series, this text provides a comprehensive treatment of the methodologies underlying neuro-fuzzy and soft computing. The book places equal emphasis on theoretical aspects of covered methodologies, empirical observations, and verifications of various applications in practice.", "year": 1997, "referenceCount": 0, "citationCount": 1332, "influentialCitationCount": 28, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144293175", "name": "J. Jang"}, {"authorId": "2166330393", "name": "Chuen-Tsai Sun"}]}, {"paperId": "7b753e096f6dfe61f397bd85e83f63d9dda23af1", "url": "https://www.semanticscholar.org/paper/7b753e096f6dfe61f397bd85e83f63d9dda23af1", "title": "Sentiment in short strength detection informal text", "abstract": "A huge number of informal messages are posted every day in social network sites, blogs, and discussion forums. Emotions seem to be frequently important in these texts for expressing friendship, showing social support or as part of online arguments. Algorithms to identify sentiment and sentiment strength are needed to help understand the role of emotion in this informal communication and also to identify inappropriate or anomalous affective utterances, potentially associated with threatening behavior to the self or others. Nevertheless, existing sentiment detection algorithms tend to be commercially oriented, designed to identify opinions about products rather than user behaviors. This article partly fills this gap with a new algorithm, SentiStrength, to extract sentiment strength from informal English text, using new methods to exploit the de facto grammars and spelling styles of cyberspace. Applied to MySpace comments and with a lookup table of term sentiment strengths optimized by machine learning, SentiStrength is able to predict positive emotion with 60.6p accuracy and negative emotion with 72.8p accuracy, both based upon strength scales of 1\u20135. The former, but not the latter, is better than baseline and a wide range of general machine learning approaches. \u00a9 2010 Wiley Periodicals, Inc.", "year": 2010, "referenceCount": 68, "citationCount": 1210, "influentialCitationCount": 57, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1701298", "name": "M. Thelwall"}, {"authorId": "144563108", "name": "K. Buckley"}, {"authorId": "1718676", "name": "G. Paltoglou"}, {"authorId": "2052543565", "name": "Di Cai"}, {"authorId": "1742554", "name": "A. Kappas"}]}, {"paperId": "21faf54f062bb3061885e407539ce43e7ce19156", "url": "https://www.semanticscholar.org/paper/21faf54f062bb3061885e407539ce43e7ce19156", "title": "Anticipating Cryptocurrency Prices Using Machine Learning", "abstract": "Machine learning and AI-assisted trading have attracted growing interest for the past few years. Here, we use this approach to test the hypothesis that the inefficiency of the cryptocurrency market can be exploited to generate abnormal profits. We analyse daily data for 1,681 cryptocurrencies for the period between Nov. 2015 and Apr. 2018. We show that simple trading strategies assisted by state-of-the-art machine learning algorithms outperform standard benchmarks. Our results show that nontrivial, but ultimately simple, algorithmic mechanisms can help anticipate the short-term evolution of the cryptocurrency market.", "year": 2018, "referenceCount": 98, "citationCount": 133, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Physics", "Economics"], "authors": [{"authorId": "2818774", "name": "Laura Alessandretti"}, {"authorId": "70058324", "name": "Abeer ElBahrawy"}, {"authorId": "2905635", "name": "L. Aiello"}, {"authorId": "2836702", "name": "A. Baronchelli"}]}, {"paperId": "8f1692be8abd2b2130107c3cf36e31b3abf86903", "url": "https://www.semanticscholar.org/paper/8f1692be8abd2b2130107c3cf36e31b3abf86903", "title": "mlpy: Machine Learning Python", "abstract": "mlpy is a Python Open Source Machine Learning library built on top of NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of state-of-the-art machine learning methods for supervised and unsupervised problems and it is aimed at finding a reasonable compromise among modularity, maintainability, reproducibility, usability and efficiency.mlpy is multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at the website http://mlpy.fbk.eu.", "year": 2012, "referenceCount": 12, "citationCount": 75, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2620660", "name": "D. Albanese"}, {"authorId": "1683587", "name": "R. Visintainer"}, {"authorId": "49446819", "name": "S. Merler"}, {"authorId": "1706884", "name": "S. Riccadonna"}, {"authorId": "1680819", "name": "Giuseppe Jurman"}, {"authorId": "1687584", "name": "Cesare Furlanello"}]}, {"paperId": "0a1574ce29eec463bd3e0b50b82157f3e5a1f81d", "url": "https://www.semanticscholar.org/paper/0a1574ce29eec463bd3e0b50b82157f3e5a1f81d", "title": "Local Model Poisoning Attacks to Byzantine-Robust Federated Learning", "abstract": "In federated learning, multiple client devices jointly learn a machine learning model: each client device maintains a local model for its local training dataset, while a master device maintains a global model via aggregating the local models from the client devices. The machine learning community recently proposed several federated learning methods that were claimed to be robust against Byzantine failures (e.g., system failures, adversarial manipulations) of certain client devices. In this work, we perform the first systematic study on local model poisoning attacks to federated learning. We assume an attacker has compromised some client devices, and the attacker manipulates the local model parameters on the compromised client devices during the learning process such that the global model has a large testing error rate. We formulate our attacks as optimization problems and apply our attacks to four recent Byzantine-robust federated learning methods. Our empirical results on four real-world datasets show that our attacks can substantially increase the error rates of the models learnt by the federated learning methods that were claimed to be robust against Byzantine failures of some client devices. We generalize two defenses for data poisoning attacks to defend against our local model poisoning attacks. Our evaluation results show that one defense can effectively defend against our attacks in some cases, but the defenses are not effective enough in other cases, highlighting the need for new defenses against our local model poisoning attacks to federated learning.", "year": 2019, "referenceCount": 65, "citationCount": 309, "influentialCitationCount": 60, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1732755", "name": "Minghong Fang"}, {"authorId": "47300733", "name": "Xiaoyu Cao"}, {"authorId": "143987304", "name": "Jinyuan Jia"}, {"authorId": "144516687", "name": "N. Gong"}]}, {"paperId": "c0ccddfb53728b04e50f0664050341791f1a19c7", "url": "https://www.semanticscholar.org/paper/c0ccddfb53728b04e50f0664050341791f1a19c7", "title": "Incremental support vector machine construction", "abstract": "SVMs (support vector machines) suffer from the problem of large memory requirement and CPU time when trained in batch mode on large data sets. We overcome these limitations, and at the same time make SVMs suitable for learning with data streams, by constructing incremental learning algorithms. We first introduce and compare different incremental learning techniques, and show that they are capable of producing performance results similar to the batch algorithm, and in some cases superior condensation properties. We then consider the problem of training SVMs using stream data. Our objective is to maintain an updated representation of recent batches of data. We apply incremental schemes to the problem and show that their accuracy is comparable to the batch algorithm.", "year": 2001, "referenceCount": 24, "citationCount": 171, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1741392", "name": "C. Domeniconi"}, {"authorId": "1736832", "name": "D. Gunopulos"}]}, {"paperId": "6e11521a3108093005c64c20fe338f3128317576", "url": "https://www.semanticscholar.org/paper/6e11521a3108093005c64c20fe338f3128317576", "title": "Active learning to recognize multiple types of plankton", "abstract": "Active learning has been applied with support vector machines to reduce the data labeling effort in pattern recognition domains. However, most of those applications only deal with two class problems. In this paper, we extend the active learning approach to multiple class support vector machines. The experimental results from a plankton recognition system indicate that our approach often requires significantly less labeled images to maintain the same accuracy level as random sampling.", "year": 2004, "referenceCount": 32, "citationCount": 247, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2068287017", "name": "Tong Luo"}, {"authorId": "2042525885", "name": "K. Kramer"}, {"authorId": "1698267", "name": "D. Goldgof"}, {"authorId": "25887296", "name": "L. Hall"}, {"authorId": "144643236", "name": "S. Samson"}, {"authorId": "2968607", "name": "A. Remsen"}, {"authorId": "89570466", "name": "T. Hopkins"}]}, {"paperId": "899720135a7ba02bc74d2e3d8e9932fa4f1063d8", "url": "https://www.semanticscholar.org/paper/899720135a7ba02bc74d2e3d8e9932fa4f1063d8", "title": "Machine learning and its applications: A review", "abstract": "Nowadays, large amount of data is available everywhere. Therefore, it is very important to analyze this data in order to extract some useful information and to develop an algorithm based on this analysis. This can be achieved through data mining and machine learning. Machine learning is an integral part of artificial intelligence, which is used to design algorithms based on the data trends and historical relationships between data. Machine learning is used in various fields such as bioinformatics, intrusion detection, Information retrieval, game playing, marketing, malware detection, image deconvolution and so on. This paper presents the work done by various authors in the field of machine learning in various application areas.", "year": 2017, "referenceCount": 16, "citationCount": 93, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "27057416", "name": "Sheena Angra"}, {"authorId": "3360312", "name": "S. Ahuja"}]}, {"paperId": "9e7fa5be24ddda41c9dc9283c94c52f1ae2add6b", "url": "https://www.semanticscholar.org/paper/9e7fa5be24ddda41c9dc9283c94c52f1ae2add6b", "title": "Improved SVM regression using mixtures of kernels", "abstract": "Kernels are used in support vector machines to map the learning data (nonlinearly) into a higher dimensional feature space where the computational power of the linear learning machine is increased. Every kernel has its advantages and disadvantages. A desirable characteristic for learning may not be a desirable characteristic for generalization. Preferably the 'good' characteristics of two or more kernels should be combined. It is shown that using mixtures of kernels can result in having both good interpolation and extrapolation abilities. The performance of this method is illustrated with an artificial as well as an industrial data set.", "year": 2002, "referenceCount": 5, "citationCount": 251, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "40524413", "name": "G. Smits"}, {"authorId": "2560465", "name": "E. Jordaan"}]}, {"paperId": "88d38cc3b0bd6c885ee3facb4d533fe81ee81f3a", "url": "https://www.semanticscholar.org/paper/88d38cc3b0bd6c885ee3facb4d533fe81ee81f3a", "title": "Deep Learning in Chemistry", "abstract": "Machine learning enables computers to address problems by learning from data. Deep learning is a type of machine learning that uses a hierarchical recombination of features to extract pertinent information and then learn the patterns represented in the data. Over the last eight years, its abilities have increasingly been applied to a wide variety of chemical challenges, from improving computational chemistry to drug and materials design and even synthesis planning. This review aims to explain the concepts of deep learning to chemists from any background and follows this with an overview of the diverse applications demonstrated in the literature. We hope that this will empower the broader chemical community to engage with this burgeoning field and foster the growing movement of deep learning accelerated chemistry.", "year": 2019, "referenceCount": 183, "citationCount": 217, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "31780855", "name": "Adam C. Mater"}, {"authorId": "1914666", "name": "M. Coote"}]}, {"paperId": "175e37bca3762b3a52c6a0e153060b98a251d061", "url": "https://www.semanticscholar.org/paper/175e37bca3762b3a52c6a0e153060b98a251d061", "title": "Inverse molecular design using machine learning: Generative models for matter engineering", "abstract": "The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.", "year": 2018, "referenceCount": 93, "citationCount": 839, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "1380248978", "name": "Benjam\u00edn S\u00e1nchez-Lengeling"}, {"authorId": "1380248954", "name": "Al\u00e1n Aspuru-Guzik"}]}, {"paperId": "f1b8f25aedbe3e06f9aae23ffb9f01f5168e7f38", "url": "https://www.semanticscholar.org/paper/f1b8f25aedbe3e06f9aae23ffb9f01f5168e7f38", "title": "High-Level Student Modeling with Machine Learning", "abstract": null, "year": 2000, "referenceCount": 15, "citationCount": 153, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "31794494", "name": "J. Beck"}, {"authorId": "3325410", "name": "B. Woolf"}]}, {"paperId": "0197f278e2dedd67ec5067f47037b8cdd3ae8509", "url": "https://www.semanticscholar.org/paper/0197f278e2dedd67ec5067f47037b8cdd3ae8509", "title": "Deep Multimodal Learning: A Survey on Recent Advances and Trends", "abstract": "The success of deep learning has been a catalyst to solving increasingly complex machine-learning problems, which often involve multiple data modalities. We review recent advances in deep multimodal learning and highlight the state-of the art, as well as gaps and challenges in this active research field. We first classify deep multimodal learning architectures and then discuss methods to fuse learned multimodal representations in deep-learning architectures. We highlight two areas of research&#x02013;regularization strategies and methods that learn or optimize multimodal fusion structures&#x02013;as exciting areas for future work.", "year": 2017, "referenceCount": 102, "citationCount": 336, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2751948", "name": "D. Ramachandram"}, {"authorId": "144639556", "name": "Graham W. Taylor"}]}, {"paperId": "28589070457f151a182d1b40564951ced4a99c71", "url": "https://www.semanticscholar.org/paper/28589070457f151a182d1b40564951ced4a99c71", "title": "COVID-19 Pandemic Prediction for Hungary; a Hybrid Machine Learning Approach", "abstract": "Several epidemiological models are being used around the world to project the number of infected individuals and the mortality rates of the COVID-19 outbreak. Advancing accurate prediction models is of utmost importance to take proper actions. Due to a high level of uncertainty or even lack of essential data, the standard epidemiological models have been challenged regarding the delivery of higher accuracy for long-term prediction. As an alternative to the susceptible-infected-resistant (SIR)-based models, this study proposes a hybrid machine learning approach to predict the COVID-19 and we exemplify its potential using data from Hungary. The hybrid machine learning methods of adaptive network-based fuzzy inference system (ANFIS) and multi-layered perceptron-imperialist competitive algorithm (MLP-ICA) are used to predict time series of infected individuals and mortality rate. The models predict that by late May, the outbreak and the total morality will drop substantially. The validation is performed for nine days with promising results, which confirms the model accuracy. It is expected that the model maintains its accuracy as long as no significant interruption occurs. Based on the results reported here, and due to the complex nature of the COVID-19 outbreak and variation in its behavior from nation-to-nation, this study suggests machine learning as an effective tool to model the outbreak. This paper provides an initial benchmarking to demonstrate the potential of machine learning for future research.", "year": 2020, "referenceCount": 104, "citationCount": 186, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "144632351", "name": "G. Pint\u00e9r"}, {"authorId": "2378938", "name": "I. Felde"}, {"authorId": "3081489", "name": "A. Mosavi"}, {"authorId": "2370080", "name": "Pedram Ghamisi"}, {"authorId": "2971695", "name": "R. Gloaguen"}]}, {"paperId": "8820f3de11dea84a70e9acb0b39c76cf69081d47", "url": "https://www.semanticscholar.org/paper/8820f3de11dea84a70e9acb0b39c76cf69081d47", "title": "Predicting subcellular localization of proteins using machine-learned classifiers", "abstract": "MOTIVATION\nIdentifying the destination or localization of proteins is key to understanding their function and facilitating their purification. A number of existing computational prediction methods are based on sequence analysis. However, these methods are limited in scope, accuracy and most particularly breadth of coverage. Rather than using sequence information alone, we have explored the use of database text annotations from homologs and machine learning to substantially improve the prediction of subcellular location.\n\n\nRESULTS\nWe have constructed five machine-learning classifiers for predicting subcellular localization of proteins from animals, plants, fungi, Gram-negative bacteria and Gram-positive bacteria, which are 81% accurate for fungi and 92-94% accurate for the other four categories. These are the most accurate subcellular predictors across the widest set of organisms ever published. Our predictors are part of the Proteome Analyst web-service.", "year": 2004, "referenceCount": 25, "citationCount": 357, "influentialCitationCount": 31, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science", "Biology"], "authors": [{"authorId": "144202084", "name": "Zhiyong Lu"}, {"authorId": "144617374", "name": "D. Szafron"}, {"authorId": "143686063", "name": "R. Greiner"}, {"authorId": "2093016", "name": "P. Lu"}, {"authorId": "2066145", "name": "D. Wishart"}, {"authorId": "33924896", "name": "B. Poulin"}, {"authorId": "2226695", "name": "J. Anvik"}, {"authorId": "2430671", "name": "Cam Macdonell"}, {"authorId": "3141411", "name": "Roman Eisner"}]}, {"paperId": "0ab99aa04e3a8340a7552355fb547374a5604b24", "url": "https://www.semanticscholar.org/paper/0ab99aa04e3a8340a7552355fb547374a5604b24", "title": "Guest Editorial Deep Learning in Medical Imaging: Overview and Future Promise of an Exciting New Technique", "abstract": "The papers in this special section focus on the technology and applications supported by deep learning. Deep learning is a growing trend in general data analysis and has been termed one of the 10 breakthrough technologies of 2013. Deep learning is an improvement of artificial neural networks, consisting of more layers that permit higher levels of abstraction and improved predictions from data. To date, it is emerging as the leading machine-learning tool in the general imaging and computer vision domains. In particular, convolutional neural networks (CNNs) have proven to be powerful tools for a broad range of computer vision tasks. Deep CNNs automatically learn mid-level and high-level abstractions obtained from raw data (e.g., images). Recent results indicate that the generic descriptors extracted from CNNs are extremely effective in object recognition and localization in natural images. Medical image analysis groups across the world are quickly entering the field and applying CNNs and other deep learning methodologies to a wide variety of applications.", "year": 2016, "referenceCount": 44, "citationCount": 1234, "influentialCitationCount": 28, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143942875", "name": "H. Greenspan"}, {"authorId": "8038506", "name": "B. Ginneken"}, {"authorId": "144838131", "name": "R. Summers"}]}, {"paperId": "ada0b87cd5c30d31186c38fb12e631d29426a3bf", "url": "https://www.semanticscholar.org/paper/ada0b87cd5c30d31186c38fb12e631d29426a3bf", "title": "Spark SQL: Relational Data Processing in Spark", "abstract": "Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.", "year": 2015, "referenceCount": 36, "citationCount": 1210, "influentialCitationCount": 216, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144482217", "name": "Michael Armbrust"}, {"authorId": "2066641", "name": "Reynold Xin"}, {"authorId": "1387529184", "name": "Cheng Lian"}, {"authorId": "40199213", "name": "Yin Huai"}, {"authorId": "2536434", "name": "Davies Liu"}, {"authorId": "2086593199", "name": "Joseph K. Bradley"}, {"authorId": "39309572", "name": "Xiangrui Meng"}, {"authorId": "2403754", "name": "Tomer Kaftan"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "38565890", "name": "A. Ghodsi"}, {"authorId": "143834867", "name": "M. Zaharia"}]}, {"paperId": "72c969a5dc5b236d511fbdaae88c443d14145ae8", "url": "https://www.semanticscholar.org/paper/72c969a5dc5b236d511fbdaae88c443d14145ae8", "title": "Learning-Based Frequency Estimation Algorithms", "abstract": "Estimating the frequencies of elements in a data stream is a fundamental task in data analysis and machine learning. The problem is typically addressed using streaming algorithms which can process very large data using limited storage. Today\u2019s streaming algorithms, however, cannot exploit patterns in their input to improve performance. We propose a new class of algorithms that automatically learn relevant patterns in the input data and use them to improve its frequency estimates. The proposed algorithms combine the benefits of machine learning with the formal guarantees available through algorithm theory. We prove that our learning-based algorithms have lower estimation errors than their non-learning counterparts. We also evaluate our algorithms on two real-world datasets and demonstrate empirically their performance gains.", "year": 2018, "referenceCount": 45, "citationCount": 99, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2502450", "name": "Chen-Yu Hsu"}, {"authorId": "1688317", "name": "P. Indyk"}, {"authorId": "1785714", "name": "D. Katabi"}, {"authorId": "2347383", "name": "A. Vakilian"}]}, {"paperId": "05b34ffcabdb2748f3172dc6b38e9222408ee23b", "url": "https://www.semanticscholar.org/paper/05b34ffcabdb2748f3172dc6b38e9222408ee23b", "title": "Finite Automata", "abstract": "I would like to make some further clarifying remarks about the nature of learning machines, or finite automata as they are more generally known these days. It is clear from much that has recently been written on this subject that there are still many misunderstandings about their capacity and significance.", "year": 1958, "referenceCount": 2, "citationCount": 700, "influentialCitationCount": 43, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "143875389", "name": "D. Perrin"}]}, {"paperId": "0d28c0390b21244cc52e9af856249cb601f6b22d", "url": "https://www.semanticscholar.org/paper/0d28c0390b21244cc52e9af856249cb601f6b22d", "title": "Feature selection for support vector machines by means of genetic algorithm", "abstract": "The problem of feature selection is a difficult combinatorial task in machine learning and of high practical relevance, e.g. in bioinformatics. genetic algorithms (GAs) offer a natural way to solve this problem. In this paper, we present a special genetic algorithm, which especially takes into account the existing bounds on the generalization error for support vector machines (SVMs). This new approach is compared to the traditional method of performing cross-validation and to other existing algorithms for feature selection.", "year": 2003, "referenceCount": 79, "citationCount": 346, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2064624524", "name": "Holger Fr\u00f6hlich"}, {"authorId": "1730609", "name": "O. Chapelle"}, {"authorId": "1707625", "name": "B. Sch\u00f6lkopf"}]}, {"paperId": "96f630295a6bef2e07715d9712e2597e1470bb0b", "url": "https://www.semanticscholar.org/paper/96f630295a6bef2e07715d9712e2597e1470bb0b", "title": "A new machine learning model based on induction of rules for autism detection", "abstract": "Autism spectrum disorder is a developmental disorder that describes certain challenges associated with communication (verbal and non-verbal), social skills, and repetitive behaviors. Typically, autism spectrum disorder is diagnosed in a clinical environment by licensed specialists using procedures which can be lengthy and cost-ineffective. Therefore, scholars in the medical, psychology, and applied behavioral science fields have in recent decades developed screening methods such as the Autism Spectrum Quotient and Modified Checklist for Autism in Toddlers for diagnosing autism and other pervasive developmental disorders. The accuracy and efficiency of these screening methods rely primarily on the experience and knowledge of the user, as well as the items designed in the screening method. One promising direction to improve the accuracy and efficiency of autism spectrum disorder detection is to build classification systems using intelligent technologies such as machine learning. Machine learning offers advanced techniques that construct automated classifiers that can be exploited by users and clinicians to significantly improve sensitivity, specificity, accuracy, and efficiency in diagnostic discovery. This article proposes a new machine learning method called Rules-Machine Learning that not only detects autistic traits of cases and controls but also offers users knowledge bases (rules) that can be utilized by domain experts in understanding the reasons behind the classification. Empirical results on three data sets related to children, adolescents, and adults show that Rules-Machine Learning offers classifiers with higher predictive accuracy, sensitivity, harmonic mean, and specificity than those of other machine learning approaches such as Boosting, Bagging, decision trees, and rule induction.", "year": 2020, "referenceCount": 67, "citationCount": 113, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science", "Psychology"], "authors": [{"authorId": "1692763", "name": "F. Thabtah"}, {"authorId": "145346793", "name": "David Peebles"}]}, {"paperId": "dd5fc40a6d306a8de3b79075b0d44aeb4848b19c", "url": "https://www.semanticscholar.org/paper/dd5fc40a6d306a8de3b79075b0d44aeb4848b19c", "title": "Automatic Speech Emotion Recognition Using Machine Learning", "abstract": "This chapter presents a comparative study of speech emotion recognition (SER) systems. Theoretical definition, categorization of affective state and the modalities of emotion expression are presented. To achieve this study, an SER system, based on different classifiers and different methods for features extraction, is developed. Mel-frequency cepstrum coefficients (MFCC) and modulation spectral (MS) features are extracted from the speech signals and used to train different classifiers. Feature selection (FS) was applied in order to seek for the most relevant feature subset. Several machine learning paradigms were used for the emotion classification task. A recurrent neural network (RNN) classifier is used first to classify seven emotions. Their performances are compared later to multivariate linear regression (MLR) and support vector machines (SVM) techniques, which are widely used in the field of emotion recognition for spoken audio signals. Berlin and Spanish databases are used as the experimental data set. This study shows that for Berlin database all classifiers achieve an accuracy of 83% when a speaker normalization (SN) and a feature selection are applied to the features. For Spanish database, the best accuracy (94 %) is achieved by RNN classifier without SN and with FS.", "year": 2019, "referenceCount": 60, "citationCount": 58, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "27097538", "name": "Leila Kerkeni"}, {"authorId": "2915285", "name": "Y. Serrestou"}, {"authorId": "46805293", "name": "M. Mbarki"}, {"authorId": "2149548", "name": "K. Raoof"}, {"authorId": "1707715", "name": "M. Mahjoub"}, {"authorId": "72143739", "name": "C. Cl\u00e9der"}]}, {"paperId": "f7c3b238c3041b1e6063875eaebdd8b2426cc73b", "url": "https://www.semanticscholar.org/paper/f7c3b238c3041b1e6063875eaebdd8b2426cc73b", "title": "Shark: SQL and rich analytics at scale", "abstract": "Shark is a new data analysis system that marries query processing with complex analytics on large clusters. It leverages a novel distributed memory abstraction to provide a unified engine that can run SQL queries and sophisticated analytics functions (e.g. iterative machine learning) at scale, and efficiently recovers from failures mid-query. This allows Shark to run SQL queries up to 100X faster than Apache Hive, and machine learning programs more than 100X faster than Hadoop. Unlike previous systems, Shark shows that it is possible to achieve these speedups while retaining a MapReduce-like execution engine, and the fine-grained fault tolerance properties that such engine provides. It extends such an engine in several ways, including column-oriented in-memory storage and dynamic mid-query replanning, to effectively execute SQL. The result is a system that matches the speedups reported for MPP analytic databases over MapReduce, while offering fault tolerance properties and complex analytics capabilities that they lack.", "year": 2012, "referenceCount": 37, "citationCount": 465, "influentialCitationCount": 46, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2066641", "name": "Reynold Xin"}, {"authorId": "27681729", "name": "Josh Rosen"}, {"authorId": "143834867", "name": "M. Zaharia"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "143838343", "name": "S. Shenker"}, {"authorId": "144467753", "name": "I. Stoica"}]}, {"paperId": "9b157903470e9478413df865b56b155ec670351a", "url": "https://www.semanticscholar.org/paper/9b157903470e9478413df865b56b155ec670351a", "title": "WebWatcher : A Learning Apprentice for the World Wide Web", "abstract": "We describe an information seeking assistant for the world wide web. This agent, called WebWatcher, interactively helps users locate desired information by employing learned knowledge about which hyperlinks are likely to lead to the target information. Our primary focus to date has been on two issues: (1) organizing WebWatcher to provide interactive advice to Mosaic users while logging their successful and unsuccessful searches as training data, and (2) incorporating machine learning methods to automatically acquire knowledge for selecting an appropriate hyperlink given the current web page viewed by the user and the user\u2019s information goal. We describe the initial design of WebWatcher, and the results of our preliminary learning experiments.", "year": 1995, "referenceCount": 11, "citationCount": 669, "influentialCitationCount": 35, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2054786149", "name": "Robert Armstrong"}, {"authorId": "1758106", "name": "D. Freitag"}, {"authorId": "1680188", "name": "T. Joachims"}, {"authorId": "40975594", "name": "Tom Michael Mitchell"}]}, {"paperId": "8f4edd71b1819eff95b669ea9042ab0f3705fe0b", "url": "https://www.semanticscholar.org/paper/8f4edd71b1819eff95b669ea9042ab0f3705fe0b", "title": "Learning to map between ontologies on the semantic web", "abstract": "Ontologies play a prominent role on the Semantic Web. They make possible the widespread publication of machine understandable data, opening myriad opportunities for automated information processing. However, because of the Semantic Web's distributed nature, data on it will inevitably come from many different ontologies. Information processing across ontologies is not possible without knowing the semantic mappings between their elements. Manually finding such mappings is tedious, error-prone, and clearly not possible at the Web scale. Hence, the development of tools to assist in the ontology mapping process is crucial to the success of the Semantic Web.We describe glue, a system that employs machine learning techniques to find such mappings. Given two ontologies, for each concept in one ontology glue finds the most similar concept in the other ontology. We give well-founded probabilistic definitions to several practical similarity measures, and show that glue can work with all of them. This is in contrast to most existing approaches, which deal with a single similarity measure. Another key feature of glue is that it uses multiple learning strategies, each of which exploits a different type of information either in the data instances or in the taxonomic structure of the ontologies. To further improve matching accuracy, we extend glue to incorporate commonsense knowledge and domain constraints into the matching process. For this purpose, we show that relaxation labeling, a well-known constraint optimization technique used in computer vision and other fields, can be adapted to work efficiently in our context. Our approach is thus distinguished in that it works with a variety of well-defined similarity notions and that it efficiently incorporates multiple types of knowledge. We describe a set of experiments on several real-world domains, and show that glue proposes highly accurate semantic mappings.", "year": 2002, "referenceCount": 38, "citationCount": 1075, "influentialCitationCount": 81, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3030274", "name": "A. Doan"}, {"authorId": "2224716", "name": "J. Madhavan"}, {"authorId": "1740213", "name": "Pedro M. Domingos"}, {"authorId": "1770962", "name": "A. Halevy"}]}, {"paperId": "68fd414d23cd1b177493a63ec3fdeebffec11c9d", "url": "https://www.semanticscholar.org/paper/68fd414d23cd1b177493a63ec3fdeebffec11c9d", "title": "Performance Comparison of Support Vector Machine, Random Forest, and Extreme Learning Machine for Intrusion Detection", "abstract": "Intrusion detection is a fundamental part of security tools, such as adaptive security appliances, intrusion detection systems, intrusion prevention systems, and firewalls. Various intrusion detection techniques are used, but their performance is an issue. Intrusion detection performance depends on accuracy, which needs to improve to decrease false alarms and to increase the detection rate. To resolve concerns on performance, multilayer perceptron, support vector machine (SVM), and other techniques have been used in recent work. Such techniques indicate limitations and are not efficient for use in large data sets, such as system and network data. The intrusion detection system is used in analyzing huge traffic data; thus, an efficient classification technique is necessary to overcome the issue. This problem is considered in this paper. Well-known machine learning techniques, namely, SVM, random forest, and extreme learning machine (ELM) are applied. These techniques are well-known because of their capability in classification. The NSL\u2013knowledge discovery and data mining data set is used, which is considered a benchmark in the evaluation of intrusion detection mechanisms. The results indicate that ELM outperforms other approaches.", "year": 2018, "referenceCount": 25, "citationCount": 281, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "37332774", "name": "Iftikhar Ahmad"}, {"authorId": "51042866", "name": "Mohammad Basheri"}, {"authorId": "8180449", "name": "M. Iqbal"}, {"authorId": "2053202184", "name": "Aneel Rahim"}]}, {"paperId": "c9934d684fcc0b8ac6ed25b34d96e726cf2d7b99", "url": "https://www.semanticscholar.org/paper/c9934d684fcc0b8ac6ed25b34d96e726cf2d7b99", "title": "Adaptive machine learning framework to accelerate ab initio molecular dynamics", "abstract": "Quantum mechanics-based ab initio molecular dynamics (MD) simulation schemes offer an accurate and direct means to monitor the time evolution of materials. Nevertheless, the expensive and repetitive energy and force computations required in such simulations lead to significant bottlenecks. Here, we lay the foundations for an accelerated ab initio MD approach integrated with a machine learning framework. The proposed algorithm learns from previously visited configurations in a continuous and adaptive manner on-the-fly, and predicts (with chemical accuracy) the energies and atomic forces of a new configuration at a minuscule fraction of the time taken by conventional ab initio methods. Key elements of this new accelerated ab initio MD paradigm include representations of atomic configurations by numerical fingerprints, a learning algorithm to map the fingerprints to the properties, a decision engine that guides the choice of the prediction scheme, and requisite amount of ab initio data. The performance of each aspect of the proposed scheme is critically evaluated for Al in several different chemical environments. This work has enormous implications beyond ab initio MD acceleration. It can also lead to accelerated structure and property prediction schemes, and accurate force fields. V C 2014 Wiley Periodicals, Inc.", "year": 2015, "referenceCount": 55, "citationCount": 281, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Chemistry"], "authors": [{"authorId": "8352724", "name": "V. Botu"}, {"authorId": "4063724", "name": "R. Ramprasad"}]}, {"paperId": "104715e1097b7ebee436058bfd9f45540f269845", "url": "https://www.semanticscholar.org/paper/104715e1097b7ebee436058bfd9f45540f269845", "title": "Reading Wikipedia to Answer Open-Domain Questions", "abstract": "This paper proposes to tackle open-domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.", "year": 2017, "referenceCount": 38, "citationCount": 1353, "influentialCitationCount": 319, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "50536468", "name": "Danqi Chen"}, {"authorId": "2064150446", "name": "Adam Fisch"}, {"authorId": "145183709", "name": "J. Weston"}, {"authorId": "1713934", "name": "Antoine Bordes"}]}, {"paperId": "f4c15e38073f22a600c84be9f5f799809f99712a", "url": "https://www.semanticscholar.org/paper/f4c15e38073f22a600c84be9f5f799809f99712a", "title": "The Challenge of Machine Learning in Space Weather: Nowcasting and Forecasting", "abstract": "The numerous recent breakthroughs in machine learning make imperative to carefully ponder how the scientific community can benefit from a technology that, although not necessarily new, is today living its golden age. This Grand Challenge review paper is focused on the present and future role of machine learning in Space Weather. The purpose is twofold. On one hand, we will discuss previous works that use machine learning for Space Weather forecasting, focusing in particular on the few areas that have seen most activity: the forecasting of geomagnetic indices, of relativistic electrons at geosynchronous orbits, of solar flares occurrence, of coronal mass ejection propagation time, and of solar wind speed. On the other hand, this paper serves as a gentle introduction to the field of machine learning tailored to the Space Weather community and as a pointer to a number of open challenges that we believe the community should undertake in the next decade. The recurring themes throughout the review are the need to shift our forecasting paradigm to a probabilistic approach focused on the reliable assessment of uncertainties, and the combination of physics\u2010based and machine learning approaches, known as gray box.", "year": 2019, "referenceCount": 312, "citationCount": 135, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "3142448", "name": "E. Camporeale"}]}, {"paperId": "0a6adafa542ddf4936917c7d99c90cbc9c966f12", "url": "https://www.semanticscholar.org/paper/0a6adafa542ddf4936917c7d99c90cbc9c966f12", "title": "Developing an optimal short\u2010form of the PTSD Checklist for DSM\u20105 (PCL\u20105)", "abstract": "Although several short\u2010forms of the posttraumatic stress disorder (PTSD) Checklist (PCL) exist, all were developed using heuristic methods. This report presents the results of analyses designed to create an optimal short\u2010form PCL for DSM\u20105 (PCL\u20105) using both machine learning and conventional scale development methods.", "year": 2019, "referenceCount": 56, "citationCount": 589, "influentialCitationCount": 122, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "5431019", "name": "Kelly L Zuromski"}, {"authorId": "48478714", "name": "Berk Ustun"}, {"authorId": "7493748", "name": "I. Hwang"}, {"authorId": "3599348", "name": "T. Keane"}, {"authorId": "3027455", "name": "B. Marx"}, {"authorId": "2863415", "name": "M. Stein"}, {"authorId": "4380262", "name": "R. Ursano"}, {"authorId": "2350669", "name": "R. Kessler"}]}, {"paperId": "e6ea09a42e99df7aaa0c62d98c049a02132b3105", "url": "https://www.semanticscholar.org/paper/e6ea09a42e99df7aaa0c62d98c049a02132b3105", "title": "Traffic Accident Analysis Using Machine Learning Paradigms", "abstract": "Engineers and researchers in the automobile industry have tried to design and build safer automobiles, but traffic accidents are unavoidable. Patterns involved in dangerous crashes could be detected if we develop accurate prediction models capable of automatic classification of type of injury severity of various traffic accidents. These behavioral and roadway accident patterns can be useful to develop traffic safety control policies. We believe that to obtain the greatest possible accident reduction effects with limited budgetary resources, it is important that measures be based on scientific and objective surveys of the causes of accidents and severity of injuries. This paper summarizes the performance of four machine learning paradigms applied to modeling the severity of injury that occurred during traffic accidents. We considered neural networks trained using hybrid learning approaches, support vector machines, decision trees and a concurrent hybrid model involving decision trees and neural networks. Experiment results reveal that among the machine learning paradigms considered the hybrid decision tree-neural network approach outperformed the individual approaches. Povzetek: Stirje pristopi strojnega ucenja so uporabljeni za preiskovanje zakonitosti poskodb v prometnih nesrecah.", "year": 2005, "referenceCount": 33, "citationCount": 150, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1986948", "name": "Miao M. Chong"}, {"authorId": "145731499", "name": "A. Abraham"}, {"authorId": "1702211", "name": "M. Paprzycki"}]}, {"paperId": "5ba3f64789fb54bee10a891bc21222964d83c687", "url": "https://www.semanticscholar.org/paper/5ba3f64789fb54bee10a891bc21222964d83c687", "title": "A Review of Challenges and Opportunities in Machine Learning for Health.", "abstract": "Modern electronic health records (EHRs) provide data to answer clinically meaningful questions. The growing data in EHRs makes healthcare ripe for the use of machine learning. However, learning in a clinical setting presents unique challenges that complicate the use of common machine learning methodologies. For example, diseases in EHRs are poorly labeled, conditions can encompass multiple underlying endotypes, and healthy individuals are underrepresented. This article serves as a primer to illuminate these challenges and highlights opportunities for members of the machine learning community to contribute to healthcare.", "year": 2018, "referenceCount": 126, "citationCount": 112, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine", "Psychology"], "authors": [{"authorId": "2804918", "name": "M. Ghassemi"}, {"authorId": "2113888405", "name": "Tristan Naumann"}, {"authorId": "145610328", "name": "Peter F. Schulam"}, {"authorId": "1507094362", "name": "A. Beam"}, {"authorId": "34574044", "name": "I. Chen"}, {"authorId": "2615814", "name": "R. Ranganath"}]}, {"paperId": "eb649971a40c7b0a28cff1d5aba14f8a3a37c773", "url": "https://www.semanticscholar.org/paper/eb649971a40c7b0a28cff1d5aba14f8a3a37c773", "title": "What is Local Optimality in Nonconvex-Nonconcave Minimax Optimization?", "abstract": "Minimax optimization has found extensive applications in modern machine learning, in settings such as generative adversarial networks (GANs), adversarial training and multi-agent reinforcement learning. As most of these applications involve continuous nonconvex-nonconcave formulations, a very basic question arises---\"what is a proper definition of local optima?\" \nMost previous work answers this question using classical notions of equilibria from simultaneous games, where the min-player and the max-player act simultaneously. In contrast, most applications in machine learning, including GANs and adversarial training, correspond to sequential games, where the order of which player acts first is crucial (since minimax is in general not equal to maximin due to the nonconvex-nonconcave nature of the problems). The main contribution of this paper is to propose a proper mathematical definition of local optimality for this sequential setting---local minimax, as well as to present its properties and existence results. Finally, we establish a strong connection to a basic local search algorithm---gradient descent ascent (GDA): under mild conditions, all stable limit points of GDA are exactly local minimax points up to some degenerate points.", "year": 2019, "referenceCount": 48, "citationCount": 188, "influentialCitationCount": 32, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3335298", "name": "Chi Jin"}, {"authorId": "1751626", "name": "Praneeth Netrapalli"}, {"authorId": "1694621", "name": "Michael I. Jordan"}]}, {"paperId": "b775225c627192ccbb410522750104b445fb244e", "url": "https://www.semanticscholar.org/paper/b775225c627192ccbb410522750104b445fb244e", "title": "Machine learning study of several classifiers trained with texture analysis features to differentiate benign from malignant soft\u2010tissue tumors in T1\u2010MRI images", "abstract": "To study, from a machine learning perspective, the performance of several machine learning classifiers that use texture analysis features extracted from soft\u2010tissue tumors in nonenhanced T1\u2010MRI images to discriminate between malignant and benign tumors.", "year": 2010, "referenceCount": 30, "citationCount": 116, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2299587", "name": "Jaber Juntu"}, {"authorId": "1778438", "name": "J. Sijbers"}, {"authorId": "134708056", "name": "S. de Backer"}, {"authorId": "1964297", "name": "Jeny Rajan"}, {"authorId": "40502701", "name": "D. Van dyck"}]}, {"paperId": "b49d10cbea23a476ae82d9c717e6380cc8129457", "url": "https://www.semanticscholar.org/paper/b49d10cbea23a476ae82d9c717e6380cc8129457", "title": "Bootstrapping ontology alignment methods with APFEL", "abstract": "Ontology alignment is a prerequisite in order to allow for interoperation between different ontologies and many alignment strategies have been proposed to facilitate the alignment task by (semi-)automatic means. Due to the complexity of the alignment task, manually defined methods for (semi-)automatic alignment rarely constitute an optimal configuration of substrategies from which they have been built. In fact, scrutinizing current ontology alignment methods, one may recognize that most are not optimized for given ontologies. Some few include machine learning for automating the task, but their optimization by machine learning means is mostly restricted to the extensional definition of ontology concepts. With APFEL (Alignment Process Feature Estimation and Learning) we present a machine learning approach that explores the user validation of initial alignments for optimizing alignment methods. The methods are based on extensional and intensional ontology definitions. Core to APFEL is the idea of a generic alignment process, the steps of which may be represented explicitly. APFEL then generates new hypotheses for what might be useful features and similarity assessments and weights them by machine learning approaches. APFEL compares favorably in our experiments to competing approaches.", "year": 2005, "referenceCount": 24, "citationCount": 210, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1728476", "name": "M. Ehrig"}, {"authorId": "1752093", "name": "Steffen Staab"}, {"authorId": "1401813995", "name": "York Sure-Vetter"}]}, {"paperId": "9b3443f877975bdcc4c12c3f9b23f135d914b852", "url": "https://www.semanticscholar.org/paper/9b3443f877975bdcc4c12c3f9b23f135d914b852", "title": "Boosting: Foundations and Algorithms", "abstract": "boosting foundations and algorithms, boosting foundations and algorithms amazon com, boosting foundations and algorithms read online, boosting foundations and algorithms in searchworks catalog, boosting foundations and algorithms adaptive computation, download e book for kindle boosting foundations and, contents, bhlmann hothorn boosting algorithms regularization, boosting foundations and algorithms by robert e schapire, boosting lagout, an introduction to boosting and leveraging face rec, explaining adaboost robert schapire, pdf boosting foundations and algorithms adaptive, boosting foundations and algorithms pdf machine learning, boosting foundations and algorithms 1 ebooks, boosting machine learning wikipedia, boosting foundations and algorithms free computer, boosting foundations and algorithms ieee, theoretical foundations and algorithms for outlier ensembles, ensemble methods foundations and algorithms, boosting foundations and algorithms kybernetes vol 42, the evolution of boosting algorithms arxiv, boosting foundations and algorithms paraglide com, foundations of machine learning boosting, boosting algorithms regularization prediction and model, boosting foundations and algorithms amazon co uk, chapter 3 boosting algorithms a review of methods theory, optimal and adaptive algorithms for online boosting, boosting foundations and algorithms adaptive computation, boosting the mit press, boosting foundations and algorithms ebook 2012, boosting foundations and algorithms amazon co uk, book review of boosting foundations and algorithms, boosting foundations and algorithms kybernetes vol 42, boosting foundations and algorithms indiebound org, download boosting foundations and algorithms adaptive, boosting foundations and algorithms adaptive computation, boosting foundations and algorithms adaptive computation, free download here pdfsdocuments2 com, boosting foundations and algorithms book 2012, boosting foundations and algorithms principal researcher, buy boosting foundations and algorithms adaptive, boosting foundations and algorithms adaptive computation, boosting foundations and algorithms request pdf, boosting foundations and algorithms beck shop de, new book boosting foundations and algorithms by robert, boosting the mit press, a short introduction to boosting computer science andboosting boosting general method of converting rough rules of thumb into highly accurate prediction rule technically assume given weak learning algorithm that can consistently nd classiers rules of thumb at least slightly better than random say accuracy 55, boosting foundations and algorithms adaptive computation and machine learning series robert e schapire yoav freund on amazon com free shipping on qualifying offers an accessible introduction and essential reference for an approach to machine learning that creates highly accurate prediction rules by combining many weak and inaccurate ones lt b gt lt p gt lt p gt lt i gt boosting lt i gt is an approach to, boosting foundations and algorithms by robert e schapire yoav freund publisher the mit press 2014 isbn 13 9780262310413 number of pages 544 description boosting is an approach to machine learning based on the idea of creating a highly accurate predictor by combining many weak and inaccurate rules of thumb, a remarkably rich theory has evolved around boosting with connections to a range of topics including statistics game theory convex optimization and information geometry boosting", "year": 2013, "referenceCount": 0, "citationCount": 481, "influentialCitationCount": 42, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1703768", "name": "A. Andrew"}]}, {"paperId": "8aa0c66236bc00ad27a7ad6928bd04f7494401eb", "url": "https://www.semanticscholar.org/paper/8aa0c66236bc00ad27a7ad6928bd04f7494401eb", "title": "Ensemble Classification and Regression-Recent Developments, Applications and Future Directions [Review Article]", "abstract": "Ensemble methods use multiple models to get better performance. Ensemble methods have been used in multiple research fields such as computational intelligence, statistics and machine learning. This paper reviews traditional as well as state-of-the-art ensemble methods and thus can serve as an extensive summary for practitioners and beginners. The ensemble methods are categorized into conventional ensemble methods such as bagging, boosting and random forest, decomposition methods, negative correlation learning methods, multi-objective optimization based ensemble methods, fuzzy ensemble methods, multiple kernel learning ensemble methods and deep learning based ensemble methods. Variations, improvements and typical applications are discussed. Finally this paper gives some recommendations for future research directions.", "year": 2016, "referenceCount": 212, "citationCount": 381, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2817070", "name": "Ye Ren"}, {"authorId": "2108005362", "name": "Le Zhang"}, {"authorId": "1688355", "name": "P. Suganthan"}]}, {"paperId": "c2f08b44b3f08bec2e19a0721874c788872c8c73", "url": "https://www.semanticscholar.org/paper/c2f08b44b3f08bec2e19a0721874c788872c8c73", "title": "Detecting Falls with Wearable Sensors Using Machine Learning Techniques", "abstract": "Falls are a serious public health problem and possibly life threatening for people in fall risk groups. We develop an automated fall detection system with wearable motion sensor units fitted to the subjects' body at six different positions. Each unit comprises three tri-axial devices (accelerometer, gyroscope, and magnetometer/compass). Fourteen volunteers perform a standardized set of movements including 20 voluntary falls and 16 activities of daily living (ADLs), resulting in a large dataset with 2520 trials. To reduce the computational complexity of training and testing the classifiers, we focus on the raw data for each sensor in a 4 s time window around the point of peak total acceleration of the waist sensor, and then perform feature extraction and reduction. Most earlier studies on fall detection employ rule-based approaches that rely on simple thresholding of the sensor outputs. We successfully distinguish falls from ADLs using six machine learning techniques (classifiers): the k-nearest neighbor (k-NN) classifier, least squares method (LSM), support vector machines (SVM), Bayesian decision making (BDM), dynamic time warping (DTW), and artificial neural networks (ANNs). We compare the performance and the computational complexity of the classifiers and achieve the best results with the k-NN classifier and LSM, with sensitivity, specificity, and accuracy all above 99%. These classifiers also have acceptable computational requirements for training and testing. Our approach would be applicable in real-world scenarios where data records of indeterminate length, containing multiple activities in sequence, are recorded.", "year": 2014, "referenceCount": 48, "citationCount": 263, "influentialCitationCount": 21, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Engineering", "Medicine"], "authors": [{"authorId": "13530079", "name": "A. \u00d6zdemir"}, {"authorId": "1804966", "name": "B. Barshan"}]}, {"paperId": "dc808ff4245403e6314ba2ff2ea2ce1c1776171b", "url": "https://www.semanticscholar.org/paper/dc808ff4245403e6314ba2ff2ea2ce1c1776171b", "title": "Signal processing of power quality disturbances", "abstract": "PREFACE. ACKNOWLEDGMENTS. 1 INTRODUCTION. 1.1 Modern View of Power Systems. 1.2 Power Quality. 1.3 Signal Processing and Power Quality. 1.4 Electromagnetic Compatibility Standards. 1.5 Overview of Power Quality Standards. 1.6 Compatibility Between Equipment and Supply. 1.7 Distributed Generation. 1.8 Conclusions. 1.9 About This Book. 2 ORIGIN OF POWER QUALITY VARIATIONS. 2.1 Voltage Frequency Variations. 2.2 Voltage Magnitude Variations. 2.3 Voltage Unbalance. 2.4 Voltage Fluctuations and Light Flicker. 2.5 Waveform Distortion. 2.6 Summary and Conclusions. 3 PROCESSING OF STATIONARY SIGNALS. 3.1 Overview of Methods. 3.2 Parameters That Characterize Variations. 3.3 Power Quality Indices. 3.4 Frequency-Domain Analysis and Signal Transformation. 3.5 Estimation of Harmonics and Interharmonics. 3.6 Estimation of Broadband Spectrum. 3.7 Summary and Conclusions. 3.8 Further Reading. 4 PROCESSING OF NONSTATIONARY SIGNALS. 4.1 Overview of Some Nonstationary Power Quality Data Analysis Methods. 4.2 Discrete STFT for Analyzing Time-Evolving Signal Components. 4.3 Discrete Wavelet Transforms for Time-Scale Analysis of Disturbances. 4.4 Block-Based Modeling. 4.5 Models Directly Applicable to Nonstationary Data. 4.6 Summary and Conclusion. 4.7 Further Reading. 5 STATISTICS OF VARIATIONS. 5.1 From Features to System Indices. 5.2 Time Aggregation. 5.3 Characteristics Versus Time. 5.4 Site Indices. 5.5 System Indices. 5.6 Power Quality Objectives. 5.7 Summary and Conclusions. 6 ORIGIN OF POWER QUALITY EVENTS. 6.1 Interruptions. 6.2 Voltage Dips. 6.3 Transients. 6.4 Summary and Conclusions. 7 TRIGGERING AND SEGMENTATION. 7.1 Overview of Existing Methods. 7.2 Basic Concepts of Triggering and Segmentation. 7.3 Triggering Methods. 7.4 Segmentation. 7.5 Summary and Conclusions. 8 CHARACTERIZATION OF POWER QUALITY EVENTS. 8.1 Voltage Magnitude Versus Time. 8.2 Phase Angle Versus Time. 8.3 Three-Phase Characteristics Versus Time. 8.4 Distortion During Event. 8.5 Single-Event Indices: Interruptions. 8.6 Single-Event Indices: Voltage Dips. 8.7 Single-Event Indices: Voltage Swells. 8.8 Single-Event Indices Based on Three-Phase Characteristics. 8.9 Additional Information from Dips and Interruptions. 8.10 Transients. 8.11 Summary and Conclusions. 9 EVENT CLASSIFICATION. 9.1 Overview of Machine Data Learning Methods for Event Classification. 9.2 Typical Steps Used in Classification System. 9.3 Learning Machines Using Linear Discriminants. 9.4 Learning and Classification Using Probability Distributions. 9.5 Learning and Classification Using Artificial Neural Networks. 9.6 Learning and Classification Using Support Vector Machines. 9.7 Rule-Based Expert Systems for Classification of Power System Events. 9.8 Summary and Conclusions. 10 EVENT STATISTICS. 10.1 Interruptions. 10.2 Voltage Dips: Site Indices. 10.3 Voltage Dips: Time Aggregation. 10.4 Voltage Dips: System Indices. 10.5 Summary and Conclusions. 11 CONCLUSIONS. 11.1 Events and Variations. 11.2 Power Quality Variations. 11.3 Power Quality Events. 11.4 Itemization of Power Quality. 11.5 Signal-Processing Needs. APPENDIX A IEC STANDARDS ON POWER QUALITY. APPENDIX B IEEE STANDARDS ON POWER QUALITY. BIBLIOGRAPHY. INDEX.", "year": 2006, "referenceCount": 0, "citationCount": 946, "influentialCitationCount": 68, "isOpenAccess": true, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "46525078", "name": "M. Bollen"}, {"authorId": "144515956", "name": "I. Gu"}]}, {"paperId": "e0fb0ed46830c224f5f0f5e92d5fba2a7062b1b4", "url": "https://www.semanticscholar.org/paper/e0fb0ed46830c224f5f0f5e92d5fba2a7062b1b4", "title": "A machine learning framework for network anomaly detection using SVM and GA", "abstract": "In today's world of computer security, Internet attacks such as Dos/DDos, worms, and spyware continue to evolve as detection techniques improve. It is not easy, however, to distinguish such new attacks using only knowledge of pre-existing attacks. In this paper the authors focused on machine learning techniques for detecting attacks from Internet anomalies. The machine learning framework consists of two major components: genetic algorithm (GA) for feature selection and support vector machine (SVM) for packet classification. By experiment it is also demonstrated that the proposed framework outperforms currently employed real-world NIDS.", "year": 2005, "referenceCount": 26, "citationCount": 159, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1745305", "name": "T. Shon"}, {"authorId": "2107910879", "name": "Yongdae Kim"}, {"authorId": "2194636", "name": "Cheolwon Lee"}, {"authorId": "1805429", "name": "Jongsub Moon"}]}, {"paperId": "00709ed019f7ddc5cd84740099066cd20e61625d", "url": "https://www.semanticscholar.org/paper/00709ed019f7ddc5cd84740099066cd20e61625d", "title": "Probabilistic Inductive Logic Programming", "abstract": null, "year": 2004, "referenceCount": 74, "citationCount": 413, "influentialCitationCount": 27, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1740042", "name": "L. D. Raedt"}, {"authorId": "1746871", "name": "K. Kersting"}]}, {"paperId": "d3f9a39e49abfdf084da558e305be5473c8740e5", "url": "https://www.semanticscholar.org/paper/d3f9a39e49abfdf084da558e305be5473c8740e5", "title": "Machine learning for alloys", "abstract": null, "year": 2021, "referenceCount": 378, "citationCount": 75, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2437145", "name": "G. Hart"}, {"authorId": "152456169", "name": "Tim O. Mueller"}, {"authorId": "3954852", "name": "C. Toher"}, {"authorId": "3445901", "name": "S. Curtarolo"}]}, {"paperId": "a049555721f17ed79a97fd492c8fc9a3f8f8aa17", "url": "https://www.semanticscholar.org/paper/a049555721f17ed79a97fd492c8fc9a3f8f8aa17", "title": "Self-Paced Learning for Latent Variable Models", "abstract": "Latent variable models are a powerful tool for addressing several tasks in machine learning. However, the algorithms for learning the parameters of latent variable models are prone to getting stuck in a bad local optimum. To alleviate this problem, we build on the intuition that, rather than considering all samples simultaneously, the algorithm should be presented with the training data in a meaningful order that facilitates learning. The order of the samples is determined by how easy they are. The main challenge is that often we are not provided with a readily computable measure of the easiness of samples. We address this issue by proposing a novel, iterative self-paced learning algorithm where each iteration simultaneously selects easy samples and learns a new parameter vector. The number of samples selected is governed by a weight that is annealed until the entire training data has been considered. We empirically demonstrate that the self-paced learning algorithm outperforms the state of the art method for learning a latent structural SVM on four applications: object localization, noun phrase coreference, motif finding and handwritten digit recognition.", "year": 2010, "referenceCount": 25, "citationCount": 1049, "influentialCitationCount": 195, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3717791", "name": "M. P. Kumar"}, {"authorId": "1409971380", "name": "Ben Packer"}, {"authorId": "1736370", "name": "D. Koller"}]}, {"paperId": "fbc7cca4aba5c04a0540a291a45817fd29e6e41b", "url": "https://www.semanticscholar.org/paper/fbc7cca4aba5c04a0540a291a45817fd29e6e41b", "title": "Analysis of Machine Learning Techniques for Heart Failure Readmissions", "abstract": "Background\u2014The current ability to predict readmissions in patients with heart failure is modest at best. It is unclear whether machine learning techniques that address higher dimensional, nonlinear relationships among variables would enhance prediction. We sought to compare the effectiveness of several machine learning algorithms for predicting readmissions. Methods and Results\u2014Using data from the Telemonitoring to Improve Heart Failure Outcomes trial, we compared the effectiveness of random forests, boosting, random forests combined hierarchically with support vector machines or logistic regression (LR), and Poisson regression against traditional LR to predict 30- and 180-day all-cause readmissions and readmissions because of heart failure. We randomly selected 50% of patients for a derivation set, and a validation set comprised the remaining patients, validated using 100 bootstrapped iterations. We compared C statistics for discrimination and distributions of observed outcomes in risk deciles for predictive range. In 30-day all-cause readmission prediction, the best performing machine learning model, random forests, provided a 17.8% improvement over LR (mean C statistics, 0.628 and 0.533, respectively). For readmissions because of heart failure, boosting improved the C statistic by 24.9% over LR (mean C statistic 0.678 and 0.543, respectively). For 30-day all-cause readmission, the observed readmission rates in the lowest and highest deciles of predicted risk with random forests (7.8% and 26.2%, respectively) showed a much wider separation than LR (14.2% and 16.4%, respectively). Conclusions\u2014Machine learning methods improved the prediction of readmission after hospitalization for heart failure compared with LR and provided the greatest predictive range in observed readmission rates.", "year": 2016, "referenceCount": 45, "citationCount": 211, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "2476394", "name": "B. Mortazavi"}, {"authorId": "2832666", "name": "Nicholas Downing"}, {"authorId": "1883747", "name": "E. Bucholz"}, {"authorId": "3825408", "name": "K. Dharmarajan"}, {"authorId": "4703954", "name": "A. Manhapra"}, {"authorId": "47319370", "name": "Shu-Xia Li"}, {"authorId": "145537739", "name": "S. Negahban"}, {"authorId": "2467795", "name": "H. Krumholz"}]}, {"paperId": "b1c883c8a6848d49eb1d154ef214faa859b0ddc3", "url": "https://www.semanticscholar.org/paper/b1c883c8a6848d49eb1d154ef214faa859b0ddc3", "title": "Machine Learning SNP Based Prediction for Precision Medicine", "abstract": "In the past decade, precision genomics based medicine has emerged to provide tailored and effective healthcare for patients depending upon their genetic features. Genome Wide Association Studies have also identified population based risk genetic variants for common and complex diseases. In order to meet the full promise of precision medicine, research is attempting to leverage our increasing genomic understanding and further develop personalized medical healthcare through ever more accurate disease risk prediction models. Polygenic risk scoring and machine learning are two primary approaches for disease risk prediction. Despite recent improvements, the results of polygenic risk scoring remain limited due to the approaches that are currently used. By contrast, machine learning algorithms have increased predictive abilities for complex disease risk. This increase in predictive abilities results from the ability of machine learning algorithms to handle multi-dimensional data. Here, we provide an overview of polygenic risk scoring and machine learning in complex disease risk prediction. We highlight recent machine learning application developments and describe how machine learning approaches can lead to improved complex disease prediction, which will help to incorporate genetic features into future personalized healthcare. Finally, we discuss how the future application of machine learning prediction models might help manage complex disease by providing tissue-specific targets for customized, preventive interventions.", "year": 2019, "referenceCount": 123, "citationCount": 94, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "144303027", "name": "D. Ho"}, {"authorId": "2376520", "name": "W. Schierding"}, {"authorId": "39978942", "name": "M. Wake"}, {"authorId": "5778567", "name": "R. Saffery"}, {"authorId": "1395754308", "name": "J. O\u2019Sullivan"}]}, {"paperId": "e96c9633a8230c82d8c9c332f136a78650d4fc09", "url": "https://www.semanticscholar.org/paper/e96c9633a8230c82d8c9c332f136a78650d4fc09", "title": "Abductive learning: towards bridging machine learning and logical reasoning", "abstract": null, "year": 2019, "referenceCount": 16, "citationCount": 78, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145624000", "name": "Zhi-Hua Zhou"}]}, {"paperId": "3b16bcb226bb1c87a6e63e0658be30067ed03f57", "url": "https://www.semanticscholar.org/paper/3b16bcb226bb1c87a6e63e0658be30067ed03f57", "title": "A Systematic Review on Supervised and Unsupervised Machine Learning Algorithms for Data Science", "abstract": null, "year": 2019, "referenceCount": 108, "citationCount": 94, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9147815", "name": "M. Alloghani"}, {"authorId": "1398585056", "name": "D. Al-Jumeily"}, {"authorId": "123894038", "name": "J. Mustafina"}, {"authorId": "145463079", "name": "A. Hussain"}, {"authorId": "2013933", "name": "A. Aljaaf"}]}, {"paperId": "fbf1c51548ffc9b9e538befcd71529365af23d15", "url": "https://www.semanticscholar.org/paper/fbf1c51548ffc9b9e538befcd71529365af23d15", "title": "Machine Recognition of Human Activities: A Survey", "abstract": "The past decade has witnessed a rapid proliferation of video cameras in all walks of life and has resulted in a tremendous explosion of video content. Several applications such as content-based video annotation and retrieval, highlight extraction and video summarization require recognition of the activities occurring in the video. The analysis of human activities in videos is an area with increasingly important consequences from security and surveillance to entertainment and personal archiving. Several challenges at various levels of processing-robustness against errors in low-level processing, view and rate-invariant representations at midlevel processing and semantic representation of human activities at higher level processing-make this problem hard to solve. In this review paper, we present a comprehensive survey of efforts in the past couple of decades to address the problems of representation, recognition, and learning of human activities from video and related applications. We discuss the problem at two major levels of complexity: 1) \"actions\" and 2) \"activities.\" \"Actions\" are characterized by simple motion patterns typically executed by a single human. \"Activities\" are more complex and involve coordinated actions among a small number of humans. We will discuss several approaches and classify them according to their ability to handle varying degrees of complexity as interpreted above. We begin with a discussion of approaches to model the simplest of action classes known as atomic or primitive actions that do not require sophisticated dynamical modeling. Then, methods to model actions with more complex dynamics are discussed. The discussion then leads naturally to methods for higher level representation of complex activities.", "year": 2008, "referenceCount": 233, "citationCount": 1420, "influentialCitationCount": 44, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143655174", "name": "P. Turaga"}, {"authorId": "9215658", "name": "R. Chellappa"}, {"authorId": "1728462", "name": "V. S. Subrahmanian"}, {"authorId": "2493008", "name": "O. Udrea"}]}, {"paperId": "727e1e16ede6eaad241bad11c525da07b154c688", "url": "https://www.semanticscholar.org/paper/727e1e16ede6eaad241bad11c525da07b154c688", "title": "A Model of Inductive Bias Learning", "abstract": "A major problem in machine learning is that of inductive bias: how to choose a learner's hypothesis space so that it is large enough to contain a solution to the problem being learnt, yet small enough to ensure reliable generalization from reasonably-sized training sets. Typically such bias is supplied by hand through the skill and insights of experts. In this paper a model for automatically learning bias is investigated. The central assumption of the model is that the learner is embedded within an environment of related learning tasks. Within such an environment the learner can sample from multiple tasks, and hence it can search for a hypothesis space that contains good solutions to many of the problems in the environment. Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment. Explicit bounds are also derived demonstrating that learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task.", "year": 2000, "referenceCount": 85, "citationCount": 1031, "influentialCitationCount": 111, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "47392513", "name": "Jonathan Baxter"}]}, {"paperId": "6c4e068c2e4b8f5cdc18bcf61cd7f66f6d22f8a7", "url": "https://www.semanticscholar.org/paper/6c4e068c2e4b8f5cdc18bcf61cd7f66f6d22f8a7", "title": "Competitive caching with machine learned advice", "abstract": "Traditional online algorithms encapsulate decision making under uncertainty, and give ways to hedge against all possible future events, while guaranteeing a nearly optimal solution, as compared to an offline optimum. On the other hand, machine learning algorithms are in the business of extrapolating patterns found in the data to predict the future, and usually come with strong guarantees on the expected generalization error.\n In this work, we develop a framework for augmenting online algorithms with a machine learned predictor to achieve competitive ratios that provably improve upon unconditional worst-case lower bounds when the predictor has low error. Our approach treats the predictor as a complete black box and is not dependent on its inner workings or the exact distribution of its errors.\n \n We apply this framework to the traditional caching problem\u2014creating an eviction strategy for a cache of size\n k\n . We demonstrate that naively following the oracle\u2019s recommendations may lead to very poor performance, even when the average error is quite low. Instead, we show how to modify the Marker algorithm to take into account the predictions and prove that this combined approach achieves a competitive ratio that both (i) decreases as the predictor\u2019s error decreases and (ii) is always capped by\n O\n (log\n k\n ), which can be achieved without any assistance from the predictor. We complement our results with an empirical evaluation of our algorithm on real-world datasets and show that it performs well empirically even when using simple off-the-shelf predictions.\n", "year": 2018, "referenceCount": 40, "citationCount": 190, "influentialCitationCount": 30, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2558458", "name": "Thodoris Lykouris"}, {"authorId": "1749789", "name": "Sergei Vassilvitskii"}]}, {"paperId": "874b006c5c1eaaa888cc471bb6db9c687b9029c0", "url": "https://www.semanticscholar.org/paper/874b006c5c1eaaa888cc471bb6db9c687b9029c0", "title": "Advances in Machine Learning Applications in Software Engineering", "abstract": "Depicting applications of several machine learning approaches in software systems development and deployment, this text provides analysis, characterization, and refinement of software engineering data in terms of machine learning methods.", "year": 2007, "referenceCount": 0, "citationCount": 102, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109577811", "name": "Du Zhang"}, {"authorId": "145118476", "name": "J. Tsai"}]}, {"paperId": "b03e0ff4753f1ae7ba171a5a100550e13ad9dc0a", "url": "https://www.semanticscholar.org/paper/b03e0ff4753f1ae7ba171a5a100550e13ad9dc0a", "title": "The Construction of Shared Knowledge in Collaborative Problem Solving", "abstract": null, "year": 1995, "referenceCount": 31, "citationCount": 1982, "influentialCitationCount": 84, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1802395", "name": "J. Roschelle"}, {"authorId": "1723988", "name": "Stephanie D. Teasley"}]}, {"paperId": "065bc4a562e21c6645d56076738e494b5873e06b", "url": "https://www.semanticscholar.org/paper/065bc4a562e21c6645d56076738e494b5873e06b", "title": "Machine Learning Methods in the Environmental Sciences: Neural Networks and Kernels", "abstract": "Machine learning methods originated from artificial intelligence and are now used in various fields in environmental sciences today. This is the first single-authored textbook providing a unified treatment of machine learning methods and their applications in the environmental sciences. Due to their powerful nonlinear modeling capability, machine learning methods today are used in satellite data processing, general circulation models(GCM), weather and climate prediction, air quality forecasting, analysis and modeling of environmental data, oceanographic and hydrological forecasting, ecological modeling, and monitoring of snow, ice and forests. The book includes end-of-chapter review questions and an appendix listing web sites for downloading computer code and data sources. A resources website containing datasets for exercises, and password-protected solutions are available. The book is suitable for first-year graduate students and advanced undergraduates. It is also valuable for researchers and practitioners in environmental sciences interested in applying these new methods to their own work. Preface Excerpt Machine learning is a major subfield in computational intelligence (also called artificial intelligence). Its main objective is to use computational methods to extract information from data. Neural network methods, generally regarded as forming the first wave of breakthrough in machine learning, became popular in the late 1980s, while kernel methods arrived in a second wave in the second half of the 1990s. This is the first single-authored textbook to give a unified treatment of machine learning methods and their applications in the environmental sciences. Machine learning methods began to infiltrate the environmental sciences in the 1990s. Today, thanks to their powerful nonlinear modeling capability, they are no longer an exotic fringe species, as they are heavily used in satellite data processing, in general circulation models (GCM), in weather and climate prediction, air quality forecasting, analysis and modeling of environmental data, oceanographic and hydrological forecasting, ecological modeling, and in the monitoring of snow, ice and forests, etc. This book presents machine learning methods and their applications in the environmental sciences (including satellite remote sensing, atmospheric science, climate science, oceanography, hydrology and ecology), written at a level suitable for beginning graduate students and advanced undergraduates. It is also valuable for researchers and practitioners in environmental sciences interested in applying these new methods to their own work. Chapters 1-3, intended mainly as background material for students, cover the standard statistical methods used in environmental sciences. The machine learning methods of chapters 4-12 provide powerful nonlinear generalizations for many of these standard linear statistical methods. End-of-chapter review questions are included, allowing readers to develop their problem-solving skills and monitor their understanding of the material presented. An appendix lists websites available for downloading computer code and data sources. A resources website is available containing datasets for exercises, and additional material to keep the book completely up-to-date. About the Author WILLIAM W. HSIEH is a Professor in the Department of Earth and Ocean Sciences and in the Department of Physics and Astronomy, as well as Chair of the Atmospheric Science Programme, at the University of British Columbia. He is internationally known for his pioneering work in developing and applying machine learning methods in environmental sciences. He has published over 80 peer-reviewed journal publications covering areas of climate variability, machine learning, oceanography, atmospheric science and hydrology.", "year": 2009, "referenceCount": 0, "citationCount": 142, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "1781249", "name": "W. Hsieh"}]}, {"paperId": "087c8bd1f0ddf4bed9699668014ca5e8121398ef", "url": "https://www.semanticscholar.org/paper/087c8bd1f0ddf4bed9699668014ca5e8121398ef", "title": "Comparison of Cox regression with other methods for determining prediction models and nomograms.", "abstract": "PURPOSE\nThere is controversy as to whether artificial neural networks and other machine learning methods provide predictions that are more accurate than those provided by traditional statistical models when applied to censored data.\n\n\nMATERIALS AND METHODS\nSeveral machine learning prediction methods are compared with Cox proportional hazards regression using 3 large urological datasets. As a measure of predictive ability, discrimination that is similar to an area under the receiver operating characteristic curve is computed for each.\n\n\nRESULTS\nIn all 3 datasets Cox regression provided comparable or superior predictions compared with neural networks and other machine learning techniques. In general, this finding is consistent with the literature.\n\n\nCONCLUSIONS\nAlthough theoretically attractive, artificial neural networks and other machine learning techniques do not often provide an improvement in predictive accuracy over Cox regression.", "year": 2003, "referenceCount": 17, "citationCount": 152, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "143772497", "name": "M. Kattan"}]}, {"paperId": "f22d50504a79cfb8f01b3dacb9a4d8f613f049b1", "url": "https://www.semanticscholar.org/paper/f22d50504a79cfb8f01b3dacb9a4d8f613f049b1", "title": "Statistical Learning from a Regression Perspective", "abstract": "Statistical Learning as a Regression Problem.- Regression Splines and Regression Smoothers.- Classification and Regression Trees (CART).- Bagging.- Random Forests.- Boosting.- Support Vector Machines.- Broader Implications and a Bit of Craft Lore.", "year": 2008, "referenceCount": 2, "citationCount": 301, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "1974692", "name": "J. Maindonald"}]}, {"paperId": "d5bbb65e6257204298f2c4fff01b25aa62b86389", "url": "https://www.semanticscholar.org/paper/d5bbb65e6257204298f2c4fff01b25aa62b86389", "title": "Deep learning for computational chemistry", "abstract": "The rise and fall of artificial neural networks is well documented in the scientific literature of both computer science and computational chemistry. Yet almost two decades later, we are now seeing a resurgence of interest in deep learning, a machine learning algorithm based on multilayer neural networks. Within the last few years, we have seen the transformative impact of deep learning in many domains, particularly in speech recognition and computer vision, to the extent that the majority of expert practitioners in those field are now regularly eschewing prior established models in favor of deep learning models. In this review, we provide an introductory overview into the theory of deep neural networks and their unique properties that distinguish them from traditional machine learning algorithms used in cheminformatics. By providing an overview of the variety of emerging applications of deep neural networks, we highlight its ubiquity and broad applicability to a wide range of challenges in the field, including quantitative structure activity relationship, virtual screening, protein structure prediction, quantum chemistry, materials design, and property prediction. In reviewing the performance of deep neural networks, we observed a consistent outperformance against non\u2010neural networks state\u2010of\u2010the\u2010art models across disparate research topics, and deep neural network\u2010based models often exceeded the \u201cglass ceiling\u201d expectations of their respective tasks. Coupled with the maturity of GPU\u2010accelerated computing for training deep neural networks and the exponential growth of chemical data on which to train these networks on, we anticipate that deep learning algorithms will be a valuable tool for computational chemistry. \u00a9 2017 Wiley Periodicals, Inc.", "year": 2017, "referenceCount": 215, "citationCount": 474, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science", "Physics", "Medicine"], "authors": [{"authorId": "2990128", "name": "Garrett B. Goh"}, {"authorId": "1811944", "name": "Nathan Oken Hodas"}, {"authorId": "144549760", "name": "A. Vishnu"}]}, {"paperId": "e0ea008f23921d5d25dd150352b64e0c0c8cdd97", "url": "https://www.semanticscholar.org/paper/e0ea008f23921d5d25dd150352b64e0c0c8cdd97", "title": "Overview of deep learning in medical imaging", "abstract": null, "year": 2017, "referenceCount": 119, "citationCount": 529, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2118855751", "name": "Kenji Suzuki"}]}, {"paperId": "4e71a4c7fde40e1010100a7b8a79a633a692207b", "url": "https://www.semanticscholar.org/paper/4e71a4c7fde40e1010100a7b8a79a633a692207b", "title": "Causal inference in economics and marketing", "abstract": "This is an elementary introduction to causal inference in economics written for readers familiar with machine learning methods. The critical step in any causal analysis is estimating the counterfactual\u2014a prediction of what would have happened in the absence of the treatment. The powerful techniques used in machine learning may be useful for developing better estimates of the counterfactual, potentially improving causal inference.", "year": 2016, "referenceCount": 38, "citationCount": 166, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2070970", "name": "H. Varian"}]}, {"paperId": "b6bb63654ccf50e8b938f30b3724b0856f192982", "url": "https://www.semanticscholar.org/paper/b6bb63654ccf50e8b938f30b3724b0856f192982", "title": "Active learning with support vector machines", "abstract": "In machine learning, active learning refers to algorithms that autonomously select the data points from which they will learn. There are many data mining applications in which large amounts of unlabeled data are readily available, but labels (e.g., human annotations or results coming from complex experiments) are costly to obtain. In such scenarios, an active learning algorithm aims at identifying data points that, if labeled and used for training, would most improve the learned model. Labels are then obtained only for the most promising data points. This speeds up learning and reduces labeling costs. Support vector machine (SVM) classifiers are particularly well\u2010suited for active learning due to their convenient mathematical properties. They perform linear classification, typically in a kernel\u2010induced feature space, which makes expressing the distance of a data point from the decision boundary straightforward. Furthermore, heuristics can efficiently help estimate how strongly learning from a data point influences the current model. This information can be used to actively select training samples. After a brief introduction to the active learning problem, we discuss different query strategies for selecting informative data points and review how these strategies give rise to different variants of active learning with SVMs.", "year": 2014, "referenceCount": 88, "citationCount": 131, "influentialCitationCount": 8, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2065374889", "name": "Jan Kremer"}, {"authorId": "1925447", "name": "K. S. Pedersen"}, {"authorId": "1748824", "name": "C. Igel"}]}, {"paperId": "bab710afa6f2b36d161571fe48467efd80e3d0ad", "url": "https://www.semanticscholar.org/paper/bab710afa6f2b36d161571fe48467efd80e3d0ad", "title": "Foundations for a New Science of Learning", "abstract": "Dissecting Dyslexia and Learning Difficulties in learning to read, despite reasonable effort and instruction, form the basis of dyslexia. Gabrieli (p. 280; see the cover) now reviews the latest research into the causes of dyslexia. Neuroimaging studies may give early notice of impending dyslexia, and it is hoped that early interventions may lessen the impact of dyslexia. Learning occurs in many settings. Humans uniquely use the formalized settings of schools and curriculum. Infants and children also do plenty of learning outside these settings, often intermingling social interactions. Meltzoff et al. (p. 284) survey the variety of learning contexts that people experience and discuss how recent advances in neuroscience and robotics are driving a new synthesis of learning. Human learning is distinguished by the range and complexity of skills that can be learned and the degree of abstraction that can be achieved compared with those of other species. Homo sapiens is also the only species that has developed formal ways to enhance learning: teachers, schools, and curricula. Human infants have an intense interest in people and their behavior and possess powerful implicit learning mechanisms that are affected by social interaction. Neuroscientists are beginning to understand the brain mechanisms underlying learning and how shared brain systems for perception and action support social learning. Machine learning algorithms are being developed that allow robots and computers to learn autonomously. New insights from many different fields are converging to create a new science of learning that may transform educational practices.", "year": 2009, "referenceCount": 137, "citationCount": 619, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "3053914", "name": "A. Meltzoff"}, {"authorId": "2454342", "name": "P. Kuhl"}, {"authorId": "1741200", "name": "J. Movellan"}, {"authorId": "1714528", "name": "T. Sejnowski"}]}, {"paperId": "4ced4175eadc44e070224c62f9c01e03e64e1b02", "url": "https://www.semanticscholar.org/paper/4ced4175eadc44e070224c62f9c01e03e64e1b02", "title": "Genetic algorithms for computational materials discovery accelerated by machine learning", "abstract": null, "year": 2019, "referenceCount": 53, "citationCount": 94, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144047632", "name": "P. C. Jennings"}, {"authorId": "16116186", "name": "S. Lysgaard"}, {"authorId": "153852825", "name": "J. Hummelsh\u00f8j"}, {"authorId": "7304881", "name": "T. Vegge"}, {"authorId": "2784394", "name": "T. Bligaard"}]}, {"paperId": "a335ff8a76e15c80b10c6d7698d94cf59bfd9520", "url": "https://www.semanticscholar.org/paper/a335ff8a76e15c80b10c6d7698d94cf59bfd9520", "title": "Neural Decoding of Visual Imagery During Sleep", "abstract": "Reading Dreams How specific visual dream contents are represented by brain activity is unclear. Machine-learning\u2013based analyses can decode the stimulus- and task-induced brain activity patterns that represent specific visual contents. Horikawa et al. (p. 639, published online 4 April) examined patterns of brain activity during dreaming and compared these to waking responses to visual stimuli. The findings suggest that the visual content of dreams is represented by the same neural substrate as observed during awake perception. Machine-learning models can predict specific visual dream contents from brain activity measurement alone. Visual imagery during sleep has long been a topic of persistent speculation, but its private nature has hampered objective analysis. Here we present a neural decoding approach in which machine-learning models predict the contents of visual imagery during the sleep-onset period, given measured brain activity, by discovering links between human functional magnetic resonance imaging patterns and verbal reports with the assistance of lexical and image databases. Decoding models trained on stimulus-induced brain activity in visual cortical areas showed accurate classification, detection, and identification of contents. Our findings demonstrate that specific visual experience during sleep is represented by brain activity patterns shared by stimulus perception, providing a means to uncover subjective contents of dreaming using objective neural measurement.", "year": 2013, "referenceCount": 48, "citationCount": 395, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "3094859", "name": "T. Horikawa"}, {"authorId": "49239549", "name": "M. Tamaki"}, {"authorId": "50411743", "name": "Y. Miyawaki"}, {"authorId": "2350433", "name": "Y. Kamitani"}]}, {"paperId": "e107107749cce2468c3a432396e57b3b879cee16", "url": "https://www.semanticscholar.org/paper/e107107749cce2468c3a432396e57b3b879cee16", "title": "Learning with Genetic Algorithms: An Overview", "abstract": null, "year": 2005, "referenceCount": 60, "citationCount": 137, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": null, "authors": [{"authorId": "145502027", "name": "K. D. Jong"}]}, {"paperId": "2ee6d382f5a34d04fa2b61b2e2c6bd9fb57ef8c3", "url": "https://www.semanticscholar.org/paper/2ee6d382f5a34d04fa2b61b2e2c6bd9fb57ef8c3", "title": "On the Scaling of Machine Learning Attacks on PUFs with Application to Noise Bifurcation", "abstract": null, "year": 2015, "referenceCount": 16, "citationCount": 96, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2869144", "name": "Johannes Tobisch"}, {"authorId": "4277384", "name": "G. Becker"}]}, {"paperId": "77024583e21d0cb7591900795f43f1a42dd6acf8", "url": "https://www.semanticscholar.org/paper/77024583e21d0cb7591900795f43f1a42dd6acf8", "title": "Learning to search: Functional gradient techniques for imitation learning", "abstract": null, "year": 2009, "referenceCount": 70, "citationCount": 218, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "13693897", "name": "Nathan D. Ratliff"}, {"authorId": "2059473735", "name": "David Silver"}, {"authorId": "1756566", "name": "J. Bagnell"}]}, {"paperId": "44f4b1b90f8d5515f2486e07e4cb4b9589c27518", "url": "https://www.semanticscholar.org/paper/44f4b1b90f8d5515f2486e07e4cb4b9589c27518", "title": "Deep Learning and Its Applications to Machine Health Monitoring: A Survey", "abstract": "Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed.", "year": 2016, "referenceCount": 112, "citationCount": 142, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "49832912", "name": "Rui Zhao"}, {"authorId": "35374692", "name": "Ruqiang Yan"}, {"authorId": "48354147", "name": "Zhenghua Chen"}, {"authorId": "144067957", "name": "K. Mao"}, {"authorId": "48319740", "name": "Peng Wang"}, {"authorId": "1700762", "name": "R. Gao"}]}, {"paperId": "180a03aa6f09e2b06417b86e8f1828861633bd37", "url": "https://www.semanticscholar.org/paper/180a03aa6f09e2b06417b86e8f1828861633bd37", "title": "Privacy-preserving Machine Learning as a Service", "abstract": "Abstract Machine learning algorithms based on deep Neural Networks (NN) have achieved remarkable results and are being extensively used in different domains. On the other hand, with increasing growth of cloud services, several Machine Learning as a Service (MLaaS) are offered where training and deploying machine learning models are performed on cloud providers\u2019 infrastructure. However, machine learning algorithms require access to the raw data which is often privacy sensitive and can create potential security and privacy risks. To address this issue, we present CryptoDL, a framework that develops new techniques to provide solutions for applying deep neural network algorithms to encrypted data. In this paper, we provide the theoretical foundation for implementing deep neural network algorithms in encrypted domain and develop techniques to adopt neural networks within practical limitations of current homomorphic encryption schemes. We show that it is feasible and practical to train neural networks using encrypted data and to make encrypted predictions, and also return the predictions in an encrypted form. We demonstrate applicability of the proposed CryptoDL using a large number of datasets and evaluate its performance. The empirical results show that it provides accurate privacy-preserving training and classification.", "year": 2018, "referenceCount": 44, "citationCount": 136, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2599072", "name": "Ehsan Hesamifard"}, {"authorId": "1718305", "name": "H. Takabi"}, {"authorId": "2053305594", "name": "Mehdi Ghasemi"}, {"authorId": "1701402", "name": "Rebecca N. Wright"}]}, {"paperId": "ce2fa0dbf76d20369f793c11d2d8803880a9ab2d", "url": "https://www.semanticscholar.org/paper/ce2fa0dbf76d20369f793c11d2d8803880a9ab2d", "title": "Data Classification: Algorithms and Applications", "abstract": "Comprehensive Coverage of the Entire Area of Classification Research on the problem of classification tends to be fragmented across such areas as pattern recognition, database, data mining, and machine learning. Addressing the work of these different communities in a unified way, Data Classification: Algorithms and Applications explores the underlying algorithms of classification as well as applications of classification in a variety of problem domains, including text, multimedia, social network, and biological data. This comprehensive book focuses on three primary aspects of data classification: Methods-The book first describes common techniques used for classification, including probabilistic methods, decision trees, rule-based methods, instance-based methods, support vector machine methods, and neural networks. Domains-The book then examines specific methods used for data domains such as multimedia, text, time-series, network, discrete sequence, and uncertain data. It also covers large data sets and data streams due to the recent importance of the big data paradigm. Variations-The book concludes with insight on variations of the classification process. It discusses ensembles, rare-class learning, distance function learning, active learning, visual learning, transfer learning, and semi-supervised learning as well as evaluation aspects of classifiers.", "year": 2014, "referenceCount": 0, "citationCount": 351, "influentialCitationCount": 16, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1682418", "name": "C. Aggarwal"}]}, {"paperId": "3c20df69865df6a627cc45c524869ccc0297048f", "url": "https://www.semanticscholar.org/paper/3c20df69865df6a627cc45c524869ccc0297048f", "title": "Learning with Marginalized Corrupted Features", "abstract": "The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on very large (infinite) training data sets that capture all variations in the data distribution. In the case of finite training data, an effective solution is to extend the training set with artificially created examples--which, however, is also computationally costly. We propose to corrupt training examples with noise from known distributions within the exponential family and present a novel learning algorithm, called marginalized corrupted features (MCF), that trains robust predictors by minimizing the expected value of the loss function under the corrupting distribution-- essentially learning with infinitely many (corrupted) training examples. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are more robust to feature deletion at test time.", "year": 2013, "referenceCount": 31, "citationCount": 162, "influentialCitationCount": 24, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1803520", "name": "L. V. D. Maaten"}, {"authorId": "1743082", "name": "Minmin Chen"}, {"authorId": "2342481", "name": "Stephen Tyree"}, {"authorId": "7446832", "name": "Kilian Q. Weinberger"}]}, {"paperId": "057c8d8fbc57a6170a72460da69a45bf133a1f1b", "url": "https://www.semanticscholar.org/paper/057c8d8fbc57a6170a72460da69a45bf133a1f1b", "title": "EffectorP: predicting fungal effector proteins from secretomes using machine learning.", "abstract": "Eukaryotic filamentous plant pathogens secrete effector proteins that modulate the host cell to facilitate infection. Computational effector candidate identification and subsequent functional characterization delivers valuable insights into plant-pathogen interactions. However, effector prediction in fungi has been challenging due to a lack of unifying sequence features such as conserved N-terminal sequence motifs. Fungal effectors are commonly predicted from secretomes based on criteria such as small size and cysteine-rich, which suffers from poor accuracy. We present EffectorP which pioneers the application of machine learning to fungal effector prediction. EffectorP improves fungal effector prediction from secretomes based on a robust signal of sequence-derived properties, achieving sensitivity and specificity of over 80%. Features that discriminate fungal effectors from secreted noneffectors are predominantly sequence length, molecular weight and protein net charge, as well as cysteine, serine and tryptophan content. We demonstrate that EffectorP is powerful when combined with in planta expression data for predicting high-priority effector candidates. EffectorP is the first prediction program for fungal effectors based on machine learning. Our findings will facilitate functional fungal effector studies and improve our understanding of effectors in plant-pathogen interactions. EffectorP is available at http://effectorp.csiro.au.", "year": 2016, "referenceCount": 85, "citationCount": 269, "influentialCitationCount": 27, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "3094326", "name": "Jana Sperschneider"}, {"authorId": "4867744", "name": "D. Gardiner"}, {"authorId": "7825710", "name": "P. Dodds"}, {"authorId": "9871628", "name": "F. Tini"}, {"authorId": "5638619", "name": "L. Covarelli"}, {"authorId": "2109143596", "name": "Karam B. Singh"}, {"authorId": "144846456", "name": "J. Manners"}, {"authorId": "2110029613", "name": "Jennifer M. Taylor"}]}, {"paperId": "898f507d92bf88de087a5f858c5c73046a7cdea9", "url": "https://www.semanticscholar.org/paper/898f507d92bf88de087a5f858c5c73046a7cdea9", "title": "A Learning Machine: Part II", "abstract": "An effort is made to improve the performance of the learning machine described in Part I, and the over-all effect of various changes is considered. Comparative runs by machines without the scoring mechanism indicate that the grading of individual instructions can aid in the learning process. A releted study is mQde in which eutemetie debugging of programs is taken as a special case of machine search. The ability to partition problems and fo deal with parts in order of difficulty proves helpful.", "year": 1959, "referenceCount": 0, "citationCount": 116, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "40425341", "name": "R. Friedberg"}, {"authorId": "100649252", "name": "B. Dunham"}, {"authorId": "46741777", "name": "J. H. North"}]}, {"paperId": "79248f0f7808b10675756371dd9f2ceb18153655", "url": "https://www.semanticscholar.org/paper/79248f0f7808b10675756371dd9f2ceb18153655", "title": "Learning and Soft Computing: Support Vector Machines, Neural Networks, and Fuzzy Logic Models", "abstract": "This textbook provides a thorough introduction to the field of learning from experimental data and soft computing. Support vector machines (SVM) and neural networks (NN) are the mathematical structures, or models, that underlie learning, while fuzzy logic systems (FLS) enable us to embed structured human knowledge into workable algorithms. The book assumes that it is not only useful, but necessary, to treat SVM, NN, and FLS as parts of a connected whole. Throughout, the theory and algorithms are illustrated by practical examples, as well as by problem sets and simulated experiments. This approach enables the reader to develop SVM, NN, and FLS in addition to understanding them. The book also presents three case studies: on NN-based control, financial time series analysis, and computer graphics. A solutions manual and all of the MATLAB programs needed for the simulated experiments are available.", "year": 2001, "referenceCount": 0, "citationCount": 679, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2886979", "name": "V. Kecman"}]}, {"paperId": "c8a05fae8d715685c22a8360c61b5f641e7a7025", "url": "https://www.semanticscholar.org/paper/c8a05fae8d715685c22a8360c61b5f641e7a7025", "title": "Cached Sufficient Statistics for Efficient Machine Learning with Large Datasets", "abstract": "This paper introduces new algorithms and data structures for quick counting for machine learning datasets. We focus on the counting task of constructing contingency tables, but our approach is also applicable to counting the number of records in a dataset that match conjunctive queries. Subject to certain assumptions, the costs of these operations can be shown to be independent of the number of records in the dataset and loglinear in the number of non-zero entries in the contingency table. \n \nWe provide a very sparse data structure, the ADtree, to minimize memory use. We provide analytical worst-case bounds for this structure for several models of data distribution. We empirically demonstrate that tractably-sized data structures can be produced for large real-world datasets by (a) using a sparse tree structure that never allocates memory for counts of zero, (b) never allocating memory for counts that can be deduced from other counts, and (c) not bothering to expand the tree fully near its leaves. \n \nWe show how the ADtree can be used to accelerate Bayes net structure finding algorithms, rule learning algorithms, and feature selection algorithms, and we provide a number of empirical results comparing ADtree methods against traditional direct counting approaches. We also discuss the possible uses of ADtrees in other machine learning methods, and discuss the merits of ADtrees in comparison with alternative representations such as kd-trees, R-trees and Frequent Sets.", "year": 1998, "referenceCount": 31, "citationCount": 266, "influentialCitationCount": 29, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1760402", "name": "A. Moore"}, {"authorId": "2115790999", "name": "Mary S. Lee"}]}, {"paperId": "cc98f98e9cda57eaf9f217dc7f288e2eea334bbd", "url": "https://www.semanticscholar.org/paper/cc98f98e9cda57eaf9f217dc7f288e2eea334bbd", "title": "Multidimensional Particle Swarm Optimization for Machine Learning and Pattern Recognition", "abstract": null, "year": 2013, "referenceCount": 1, "citationCount": 132, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1741196", "name": "S. Kiranyaz"}, {"authorId": "73777322", "name": "T. Ince"}, {"authorId": "9219875", "name": "M. Gabbouj"}]}, {"paperId": "706253fafc50bb126c1d78058952ef92270bf72d", "url": "https://www.semanticscholar.org/paper/706253fafc50bb126c1d78058952ef92270bf72d", "title": "Teaching machines and programmed learning", "abstract": null, "year": 1960, "referenceCount": 0, "citationCount": 151, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "50066563", "name": "A. A. Lumsdaine"}, {"authorId": "31813000", "name": "R. Glaser"}]}, {"paperId": "32a0afb242a6f31f6cdd143d5635de6889220687", "url": "https://www.semanticscholar.org/paper/32a0afb242a6f31f6cdd143d5635de6889220687", "title": "Use of Sentiment Analysis for Capturing Patient Experience From Free-Text Comments Posted Online", "abstract": "Background There are large amounts of unstructured, free-text information about quality of health care available on the Internet in blogs, social networks, and on physician rating websites that are not captured in a systematic way. New analytical techniques, such as sentiment analysis, may allow us to understand and use this information more effectively to improve the quality of health care. Objective We attempted to use machine learning to understand patients\u2019 unstructured comments about their care. We used sentiment analysis techniques to categorize online free-text comments by patients as either positive or negative descriptions of their health care. We tried to automatically predict whether a patient would recommend a hospital, whether the hospital was clean, and whether they were treated with dignity from their free-text description, compared to the patient\u2019s own quantitative rating of their care. Methods We applied machine learning techniques to all 6412 online comments about hospitals on the English National Health Service website in 2010 using Weka data-mining software. We also compared the results obtained from sentiment analysis with the paper-based national inpatient survey results at the hospital level using Spearman rank correlation for all 161 acute adult hospital trusts in England. Results There was 81%, 84%, and 89% agreement between quantitative ratings of care and those derived from free-text comments using sentiment analysis for cleanliness, being treated with dignity, and overall recommendation of hospital respectively (kappa scores: .40\u2013.74, P<.001 for all). We observed mild to moderate associations between our machine learning predictions and responses to the large patient survey for the three categories examined (Spearman rho 0.37-0.51, P<.001 for all). Conclusions The prediction accuracy that we have achieved using this machine learning process suggests that we are able to predict, from free-text, a reasonably accurate assessment of patients\u2019 opinion about different performance aspects of a hospital and that these machine learning predictions are associated with results of more conventional surveys.", "year": 2013, "referenceCount": 39, "citationCount": 230, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Psychology"], "authors": [{"authorId": "4721608", "name": "F. Greaves"}, {"authorId": "1402253773", "name": "Daniel Ramirez-Cano"}, {"authorId": "6754112", "name": "C. Millett"}, {"authorId": "11388466", "name": "A. Darzi"}, {"authorId": "2687307", "name": "L. Donaldson"}]}, {"paperId": "955fe2ee26d888ae22749b0853981b8b581b133d", "url": "https://www.semanticscholar.org/paper/955fe2ee26d888ae22749b0853981b8b581b133d", "title": "Holographic Embeddings of Knowledge Graphs", "abstract": "\n \n Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.\n \n", "year": 2015, "referenceCount": 35, "citationCount": 832, "influentialCitationCount": 147, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1729762", "name": "Maximilian Nickel"}, {"authorId": "1690976", "name": "L. Rosasco"}, {"authorId": "1685292", "name": "T. Poggio"}]}]}