{"total": 5120627, "offset": 3000, "next": 3100, "data": [{"paperId": "14c7b1c4ba952c990901053ad92a000b71c09c73", "url": "https://www.semanticscholar.org/paper/14c7b1c4ba952c990901053ad92a000b71c09c73", "title": "A New Method for Crude Oil Price Forecasting Based on Support Vector Machines", "abstract": null, "year": 2006, "referenceCount": 12, "citationCount": 218, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2113722331", "name": "Wen Xie"}, {"authorId": "34208320", "name": "Lean Yu"}, {"authorId": "1847097", "name": "Shanying Xu"}, {"authorId": "34203815", "name": "Shouyang Wang"}]}, {"paperId": "eea4ca46542125e02cd7b6de60f28c3710b3f7a3", "url": "https://www.semanticscholar.org/paper/eea4ca46542125e02cd7b6de60f28c3710b3f7a3", "title": "Enhancing one-class support vector machines for unsupervised anomaly detection", "abstract": "Support Vector Machines (SVMs) have been one of the most successful machine learning techniques for the past decade. For anomaly detection, also a semi-supervised variant, the one-class SVM, exists. Here, only normal data is required for training before anomalies can be detected. In theory, the one-class SVM could also be used in an unsupervised anomaly detection setup, where no prior training is conducted. Unfortunately, it turns out that a one-class SVM is sensitive to outliers in the data. In this work, we apply two modifications in order to make one-class SVMs more suitable for unsupervised anomaly detection: Robust one-class SVMs and eta one-class SVMs. The key idea of both modifications is, that outliers should contribute less to the decision boundary as normal instances. Experiments performed on datasets from UCI machine learning repository show that our modifications are very promising: Comparing with other standard unsupervised anomaly detection algorithms, the enhanced one-class SVMs are superior on two out of four datasets. In particular, the proposed eta one-class SVM has shown the most promising results.", "year": 2013, "referenceCount": 76, "citationCount": 293, "influentialCitationCount": 34, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "11137394", "name": "Mennatallah Amer"}, {"authorId": "2060959597", "name": "Markus Goldstein"}, {"authorId": "2890092", "name": "S. Abdennadher"}]}, {"paperId": "a9c1379fa08a07e28bb85343f7f7d4d09c302bac", "url": "https://www.semanticscholar.org/paper/a9c1379fa08a07e28bb85343f7f7d4d09c302bac", "title": "Early exit optimizations for additive machine learned ranking systems", "abstract": "Some commercial web search engines rely on sophisticated machine learning systems for ranking web documents. Due to very large collection sizes and tight constraints on query response times, online efficiency of these learning systems forms a bottleneck. An important problem in such systems is to speedup the ranking process without sacrificing much from the quality of results. In this paper, we propose optimization strategies that allow short-circuiting score computations in additive learning systems. The strategies are evaluated over a state-of-the-art machine learning system and a large, real-life query log, obtained from Yahoo!. By the proposed strategies, we are able to speedup the score computations by more than four times with almost no loss in result quality.", "year": 2010, "referenceCount": 37, "citationCount": 131, "influentialCitationCount": 16, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1776940", "name": "B. B. Cambazoglu"}, {"authorId": "2833561", "name": "H. Zaragoza"}, {"authorId": "1730609", "name": "O. Chapelle"}, {"authorId": "2108311747", "name": "Jiang Chen"}, {"authorId": "2922252", "name": "Ciya Liao"}, {"authorId": "1749245", "name": "Zhaohui Zheng"}, {"authorId": "144090996", "name": "Jon Degenhardt"}]}, {"paperId": "01a22723901061bfa7728f7fdfced2c1f54a3f57", "url": "https://www.semanticscholar.org/paper/01a22723901061bfa7728f7fdfced2c1f54a3f57", "title": "UP-Fall Detection Dataset: A Multimodal Approach", "abstract": "Falls, especially in elderly persons, are an important health problem worldwide. Reliable fall detection systems can mitigate negative consequences of falls. Among the important challenges and issues reported in literature is the difficulty of fair comparison between fall detection systems and machine learning techniques for detection. In this paper, we present UP-Fall Detection Dataset. The dataset comprises raw and feature sets retrieved from 17 healthy young individuals without any impairment that performed 11 activities and falls, with three attempts each. The dataset also summarizes more than 850 GB of information from wearable sensors, ambient sensors and vision devices. Two experimental use cases were shown. The aim of our dataset is to help human activity recognition and machine learning research communities to fairly compare their fall detection solutions. It also provides many experimental possibilities for the signal recognition, vision, and machine learning community.", "year": 2019, "referenceCount": 50, "citationCount": 133, "influentialCitationCount": 17, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "1390004875", "name": "Mar\u00eda de Lourdes Mart\u00ednez-Villase\u00f1or"}, {"authorId": "1963352", "name": "Hiram Ponce"}, {"authorId": "145273511", "name": "J. Brieva"}, {"authorId": "1409244306", "name": "E. Moya-Albor"}, {"authorId": "1399280617", "name": "Jos\u00e9 N\u00fa\u00f1ez-Mart\u00ednez"}, {"authorId": "1404743114", "name": "Carlos Pe\u00f1afort-Asturiano"}]}, {"paperId": "ab60160e402f9154b41cae540a8f620478ed6708", "url": "https://www.semanticscholar.org/paper/ab60160e402f9154b41cae540a8f620478ed6708", "title": "Bond Risk Premiums with Machine Learning", "abstract": "\n We show that machine learning methods, in particular, extreme trees and neural networks (NNs), provide strong statistical evidence in favor of bond return predictability. NN forecasts based on macroeconomic and yield information translate into economic gains that are larger than those obtained using yields alone. Interestingly, the nature of unspanned factors changes along the yield curve: stock- and labor-market-related variables are more relevant for short-term maturities, whereas output and income variables matter more for longer maturities. Finally, NN forecasts correlate with proxies for time-varying risk aversion and uncertainty, lending support to models featuring both channels.", "year": 2020, "referenceCount": 101, "citationCount": 92, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "146467911", "name": "Daniele Bianchi"}, {"authorId": "48556577", "name": "M. B\u00fcchner"}, {"authorId": "2468965", "name": "A. Tamoni"}]}, {"paperId": "f8388dd1a13a8852bf926fed4beeabfd6405ca75", "url": "https://www.semanticscholar.org/paper/f8388dd1a13a8852bf926fed4beeabfd6405ca75", "title": "COVID-19 diagnosis prediction in emergency care patients: a machine learning approach", "abstract": "The coronavirus disease (COVID-19) pandemic has increased the necessity of immediate clinical decisions and effective usage of healthcare resources. Currently, the most validated diagnosis test for COVID-19 (RT-PCR) is in shortage in most developing countries, which may increase infection rates and delay important preventive measures. The objective of this study was to predict the risk of positive COVID-19 diagnosis with machine learning, using as predictors only results from emergency care admission exams. We collected data from a sample of 235 adult patients from the Hospital Israelita Albert Einstein in Sao Paulo, Brazil, from 17 to 30 of March, 2020, of which 102 (43%) received a positive diagnosis of COVID-19 from RT-PCR tests. Five machine learning algorithms (neural networks, random forests, gradient boosting trees, logistic regression and support vector machines) were trained on a random sample of 70% of the patients, and performance was tested on new unseen data (30%). The best predictive performance was obtained by the support vector machines algorithm (AUC: 0.85; Sensitivity: 0.68; Specificity: 0.85; Brier Score: 0.16). In conclusion, we found that targeted decisions for receiving COVID-19 tests using only routinely-collected data is a promising new area with the use of machine learning algorithms.", "year": 2020, "referenceCount": 14, "citationCount": 117, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "145837621", "name": "A. F. M. Batista"}, {"authorId": "2936012", "name": "J. Miraglia"}, {"authorId": "150318677", "name": "T. H. R. Donato"}, {"authorId": "66195683", "name": "A. C. Chiavegatto Filho"}]}, {"paperId": "9eb47e857cdf1f97413de0e3993f8429d7c33503", "url": "https://www.semanticscholar.org/paper/9eb47e857cdf1f97413de0e3993f8429d7c33503", "title": "Deep convolutional neural network based medical image classification for disease diagnosis", "abstract": null, "year": 2019, "referenceCount": 44, "citationCount": 308, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "121055148", "name": "Samir S. Yadav"}, {"authorId": "35925236", "name": "S. Jadhav"}]}, {"paperId": "8bd14b13cbeb28f8a6aa9ea54fac1cfe6df2caee", "url": "https://www.semanticscholar.org/paper/8bd14b13cbeb28f8a6aa9ea54fac1cfe6df2caee", "title": "A Machine Learning Approach to TCP Throughput Prediction", "abstract": "TCP throughput prediction is an important capability for networks where multiple paths exist between data senders and receivers. In this paper, we describe a new lightweight method for TCP throughput prediction. Our predictor uses Support Vector Regression (SVR); prediction is based on both prior file transfer history and measurements of simple path properties. We evaluate our predictor in a laboratory setting where ground truth can be measured with perfect accuracy. We report the performance of our predictor for oracular and practical measurements of path properties over a wide range of traffic conditions and transfer sizes. For bulk transfers in heavy traffic using oracular measurements, TCP throughput is predicted within 10% of the actual value 87% of the time, representing nearly a threefold improvement in accuracy over prior history-based methods. For practical measurements of path properties, predictions can be made within 10% of the actual value nearly 50% of the time, approximately a 60% improvement over history-based methods, and with much lower measurement traffic overhead. We implement our predictor in a tool called PathPerf, test it in the wide area, and show that PathPerf predicts TCP throughput accurately over diverse wide area paths.", "year": 2007, "referenceCount": 46, "citationCount": 209, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "40182120", "name": "Mariyam Mirza"}, {"authorId": "145966807", "name": "J. Sommers"}, {"authorId": "1917752", "name": "P. Barford"}, {"authorId": "1832364", "name": "Xiaojin Zhu"}]}, {"paperId": "443fddff5e76c79c58f224535feedf280b41d32f", "url": "https://www.semanticscholar.org/paper/443fddff5e76c79c58f224535feedf280b41d32f", "title": "Intelligent Machine Homicide - Breaking Cryptographic Devices Using Support Vector Machines", "abstract": null, "year": 2012, "referenceCount": 24, "citationCount": 152, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "2563182", "name": "Annelie Heuser"}, {"authorId": "1744880", "name": "Michael Zohner"}]}, {"paperId": "95358dafae9cb7a7506167b5c96d55b4acb2ddcf", "url": "https://www.semanticscholar.org/paper/95358dafae9cb7a7506167b5c96d55b4acb2ddcf", "title": "Automated software vulnerability detection with machine learning", "abstract": "Thousands of security vulnerabilities are discovered in production software each year, either reported publicly to the Common Vulnerabilities and Exposures database or discovered internally in proprietary code. Vulnerabilities often manifest themselves in subtle ways that are not obvious to code reviewers or the developers themselves. With the wealth of open source code available for analysis, there is an opportunity to learn the patterns of bugs that can lead to security vulnerabilities directly from data. In this paper, we present a data-driven approach to vulnerability detection using machine learning, specifically applied to C and C++ programs. We first compile a large dataset of hundreds of thousands of open-source functions labeled with the outputs of a static analyzer. We then compare methods applied directly to source code with methods applied to artifacts extracted from the build process, finding that source-based models perform better. We also compare the application of deep neural network models with more traditional models such as random forests and find the best performance comes from combining features learned by deep models with tree-based models. Ultimately, our highest performing model achieves an area under the precision-recall curve of 0.49 and an area under the ROC curve of 0.87.", "year": 2018, "referenceCount": 26, "citationCount": 100, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "4413381", "name": "Jacob A. Harer"}, {"authorId": "47714368", "name": "Louis Y. Kim"}, {"authorId": "2070634196", "name": "Rebecca L. Russell"}, {"authorId": "2066070614", "name": "Onur Ozdemir"}, {"authorId": "49875163", "name": "Leonard Kosta"}, {"authorId": "1872494", "name": "Akshay Rangamani"}, {"authorId": "40902376", "name": "Lei H. Hamilton"}, {"authorId": "2074038188", "name": "Gabriel I. Centeno"}, {"authorId": "144007473", "name": "Jonathan R. Key"}, {"authorId": "40900236", "name": "Paul M. Ellingwood"}, {"authorId": "1940574", "name": "M. McConley"}, {"authorId": "2156875", "name": "J. M. Opper"}, {"authorId": "2065786106", "name": "Peter Chin"}, {"authorId": "40900798", "name": "T. Lazovich"}]}, {"paperId": "e8b3c5e2cf19768b61a263ed4762db98be60c3cb", "url": "https://www.semanticscholar.org/paper/e8b3c5e2cf19768b61a263ed4762db98be60c3cb", "title": "Inductive logic programming - from machine learning to software engineering", "abstract": "From the Publisher: \nAlthough Inductive Logic Programming (ILP) is generally thought of as a research area at the intersection of machine learning and computational logic, Bergadano and Gunetti propose that most of the research in ILP has in fact come from machine learning, particularly in the evolution of inductive reasoning from pattern recognition, through initial approaches to symbolic machine learning, to recent techniques for learning relational concepts. In this book they provide an extended, up-to-date survey of ILP, emphasizing methods and systems suitable for software engineering applications, including inductive program development, testing, and maintenance. \nInductive Logic Programming includes a definition of the basic ILP problem and its variations (incremental, with queries, for multiple predicates and predicate invention capabilities), a description of bottom-up operators and techniques (such as least general generalization, inverse resolution, and inverse implication), an analysis of top-down methods (mainly MIS and FOIL-like systems), and a survey of methods and languages for specifying inductive bias. \nLogic Programming series", "year": 1995, "referenceCount": 0, "citationCount": 126, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2080984", "name": "F. Bergadano"}, {"authorId": "1792257", "name": "D. Gunetti"}]}, {"paperId": "a4f981c06d398849eb78894e98e7c16ae4372d7e", "url": "https://www.semanticscholar.org/paper/a4f981c06d398849eb78894e98e7c16ae4372d7e", "title": "Learning multidimensional signal processing", "abstract": "This paper presents our general strategy for designing learning machines as well as a number of particular designs. The search for methods allowing a sufficient level of adaptivity are based on two main principles: 1) simple adaptive local models; and 2) adaptive model distribution. Particularly important concepts in our work is mutual information and canonical correlation. Examples are given on learning feature descriptors, modeling disparity, synthesis of a global 3-mode model and a setup for reinforcement learning of online video coder parameter control.", "year": 1998, "referenceCount": 192, "citationCount": 224, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3117916", "name": "H. Knutsson"}, {"authorId": "145290346", "name": "M. Borga"}, {"authorId": "2976013", "name": "T. Landelius"}]}, {"paperId": "a01d887ff15ec43f945c785917dbb5aade46148f", "url": "https://www.semanticscholar.org/paper/a01d887ff15ec43f945c785917dbb5aade46148f", "title": "Bioinformatics The Machine Learning Approach 2nd ed.", "abstract": null, "year": 2001, "referenceCount": 0, "citationCount": 125, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144299726", "name": "Thomas G. Dietterich"}]}, {"paperId": "1a61117710e2c089182b939a1978c928b3de7f5a", "url": "https://www.semanticscholar.org/paper/1a61117710e2c089182b939a1978c928b3de7f5a", "title": "Universal Approximation of Extreme Learning Machine With Adaptive Growth of Hidden Nodes", "abstract": "Extreme learning machines (ELMs) have been proposed for generalized single-hidden-layer feedforward networks which need not be neuron-like and perform well in both regression and classification applications. In this brief, we propose an ELM with adaptive growth of hidden nodes (AG-ELM), which provides a new approach for the automated design of networks. Different from other incremental ELMs (I-ELMs) whose existing hidden nodes are frozen when the new hidden nodes are added one by one, in AG-ELM the number of hidden nodes is determined in an adaptive way in the sense that the existing networks may be replaced by newly generated networks which have fewer hidden nodes and better generalization performance. We then prove that such an AG-ELM using Lebesgue p-integrable hidden activation functions can approximate any Lebesgue p-integrable function on a compact input set. Simulation results demonstrate and verify that this new approach can achieve a more compact network architecture than the I-ELM.", "year": 2012, "referenceCount": 51, "citationCount": 204, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2118403946", "name": "Rui Zhang"}, {"authorId": "1770395", "name": "Yuan Lan"}, {"authorId": "145678691", "name": "G. Huang"}, {"authorId": "98220533", "name": "Zongben Xu"}]}, {"paperId": "5c8c2a2c725f2f9da095045e35cf0f7322c360d5", "url": "https://www.semanticscholar.org/paper/5c8c2a2c725f2f9da095045e35cf0f7322c360d5", "title": "Differentially Private Learning Needs Better Features (or Much More Data)", "abstract": "We demonstrate that differentially private machine learning has not yet reached its \"AlexNet moment\" on many canonical vision tasks: linear models trained on handcrafted features significantly outperform end-to-end deep neural networks for moderate privacy budgets. To exceed the performance of handcrafted features, we show that private learning requires either much more private data, or access to features learned on public data from a similar domain. Our work introduces simple yet strong baselines for differentially private learning that can inform the evaluation of future progress in this area.", "year": 2020, "referenceCount": 84, "citationCount": 95, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2444919", "name": "Florian Tram\u00e8r"}, {"authorId": "1752788", "name": "D. Boneh"}]}, {"paperId": "913d09a4484c56b53e55ca41946ec36f359e0056", "url": "https://www.semanticscholar.org/paper/913d09a4484c56b53e55ca41946ec36f359e0056", "title": "Using human brain activity to guide machine learning", "abstract": null, "year": 2017, "referenceCount": 82, "citationCount": 62, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "145891577", "name": "Ruth Fong"}, {"authorId": "2613438", "name": "W. Scheirer"}, {"authorId": "2042941", "name": "D. Cox"}]}, {"paperId": "60b5e9e616fde8a50bb016c8b7ecf95e0ab3a6f5", "url": "https://www.semanticscholar.org/paper/60b5e9e616fde8a50bb016c8b7ecf95e0ab3a6f5", "title": "Machine Learning Based Toxicity Prediction: From Chemical Structural Description to Transcriptome Analysis", "abstract": "Toxicity prediction is very important to public health. Among its many applications, toxicity prediction is essential to reduce the cost and labor of a drug\u2019s preclinical and clinical trials, because a lot of drug evaluations (cellular, animal, and clinical) can be spared due to the predicted toxicity. In the era of Big Data and artificial intelligence, toxicity prediction can benefit from machine learning, which has been widely used in many fields such as natural language processing, speech recognition, image recognition, computational chemistry, and bioinformatics, with excellent performance. In this article, we review machine learning methods that have been applied to toxicity prediction, including deep learning, random forests, k-nearest neighbors, and support vector machines. We also discuss the input parameter to the machine learning algorithm, especially its shift from chemical structural description only to that combined with human transcriptome data analysis, which can greatly enhance prediction accuracy.", "year": 2018, "referenceCount": 182, "citationCount": 78, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2108407123", "name": "Yunyi Wu"}, {"authorId": "50248198", "name": "Guanyu Wang"}]}, {"paperId": "2d8eaad2d960c5f073f464c3e8c7ba8c91458703", "url": "https://www.semanticscholar.org/paper/2d8eaad2d960c5f073f464c3e8c7ba8c91458703", "title": "Fast SDP Relaxations of Graph Cut Clustering, Transduction, and Other Combinatorial Problem", "abstract": "The rise of convex programming has changed the face of many research fields in recent years, machine learning being one of the ones that benefitted the most. A very recent developement, the relaxation of combinatorial problems to semi-definite programs (SDP), has gained considerable attention over the last decade (Helmberg, 2000; De Bie and Cristianini, 2004a). Although SDP problems can be solved in polynomial time, for many relaxations the exponent in the polynomial complexity bounds is too high for scaling to large problem sizes. This has hampered their uptake as a powerful new tool in machine learning. \n \nIn this paper, we present a new and fast SDP relaxation of the normalized graph cut problem, and investigate its usefulness in unsupervised and semi-supervised learning. In particular, this provides a convex algorithm for transduction, as well as approaches to clustering. We further propose a whole cascade of fast relaxations that all hold the middle between older spectral relaxations and the new SDP relaxation, allowing one to trade off computational cost versus relaxation accuracy. Finally, we discuss how the methodology developed in this paper can be applied to other combinatorial problems in machine learning, and we treat the max-cut problem as an example.", "year": 2006, "referenceCount": 21, "citationCount": 62, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "51204489", "name": "T. D. Bie"}, {"authorId": "1685083", "name": "N. Cristianini"}]}, {"paperId": "7582e26105e37fcf63ce21dc05734cf7878a268d", "url": "https://www.semanticscholar.org/paper/7582e26105e37fcf63ce21dc05734cf7878a268d", "title": "Cardiovascular Event Prediction by Machine Learning: The Multi-Ethnic Study of Atherosclerosis", "abstract": "Rationale: Machine learning may be useful to characterize cardiovascular risk, predict outcomes, and identify biomarkers in population studies. Objective: To test the ability of random survival forests, a machine learning technique, to predict 6 cardiovascular outcomes in comparison to standard cardiovascular risk scores. Methods and Results: We included participants from the MESA (Multi-Ethnic Study of Atherosclerosis). Baseline measurements were used to predict cardiovascular outcomes over 12 years of follow-up. MESA was designed to study progression of subclinical disease to cardiovascular events where participants were initially free of cardiovascular disease. All 6814 participants from MESA, aged 45 to 84 years, from 4 ethnicities, and 6 centers across the United States were included. Seven-hundred thirty-five variables from imaging and noninvasive tests, questionnaires, and biomarker panels were obtained. We used the random survival forests technique to identify the top-20 predictors of each outcome. Imaging, electrocardiography, and serum biomarkers featured heavily on the top-20 lists as opposed to traditional cardiovascular risk factors. Age was the most important predictor for all-cause mortality. Fasting glucose levels and carotid ultrasonography measures were important predictors of stroke. Coronary Artery Calcium score was the most important predictor of coronary heart disease and all atherosclerotic cardiovascular disease combined outcomes. Left ventricular structure and function and cardiac troponin-T were among the top predictors for incident heart failure. Creatinine, age, and ankle-brachial index were among the top predictors of atrial fibrillation. TNF-&agr; (tissue necrosis factor-&agr;) and IL (interleukin)-2 soluble receptors and NT-proBNP (N-Terminal Pro-B-Type Natriuretic Peptide) levels were important across all outcomes. The random survival forests technique performed better than established risk scores with increased prediction accuracy (decreased Brier score by 10%\u201325%). Conclusions: Machine learning in conjunction with deep phenotyping improves prediction accuracy in cardiovascular event prediction in an initially asymptomatic population. These methods may lead to greater insights on subclinical disease markers without apriori assumptions of causality. Clinical Trial Registration: URL: http://www.clinicaltrials.gov. Unique identifier: NCT00005487.", "year": 2017, "referenceCount": 63, "citationCount": 278, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Biology"], "authors": [{"authorId": "1387460830", "name": "B. Ambale-Venkatesh"}, {"authorId": "2112090830", "name": "Xiaoying Yang"}, {"authorId": "46740592", "name": "C. Wu"}, {"authorId": "46578369", "name": "Kiang Liu"}, {"authorId": "2488070", "name": "W. Hundley"}, {"authorId": "7667244", "name": "R. McClelland"}, {"authorId": "144782189", "name": "A. Gomes"}, {"authorId": "3633886", "name": "A. Folsom"}, {"authorId": "143665417", "name": "S. Shea"}, {"authorId": "2801530", "name": "E. Guallar"}, {"authorId": "1768320", "name": "D. Bluemke"}, {"authorId": "144536034", "name": "J. Lima"}]}, {"paperId": "516511ea09ee736dced455253dfd961ab8d7d00f", "url": "https://www.semanticscholar.org/paper/516511ea09ee736dced455253dfd961ab8d7d00f", "title": "Advancing machine learning for MR image reconstruction with an open competition: Overview of the 2019 fastMRI challenge", "abstract": "To advance research in the field of machine learning for MR image reconstruction with an open challenge.", "year": 2020, "referenceCount": 67, "citationCount": 117, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Engineering", "Medicine"], "authors": [{"authorId": "3597472", "name": "F. Knoll"}, {"authorId": "1388373582", "name": "Tullie Murrell"}, {"authorId": "8401284", "name": "Anuroop Sriram"}, {"authorId": "6584461", "name": "N. Yakubova"}, {"authorId": "3105120", "name": "Jure Zbontar"}, {"authorId": "2066127975", "name": "Michael G. Rabbat"}, {"authorId": "34597877", "name": "Aaron Defazio"}, {"authorId": "2954796", "name": "Matthew Muckley"}, {"authorId": "2827060", "name": "D. Sodickson"}, {"authorId": "1699161", "name": "C. L. Zitnick"}, {"authorId": "5677770", "name": "M. Recht"}]}, {"paperId": "f34f14faa6f6144adb626fa8dee1286f0b734772", "url": "https://www.semanticscholar.org/paper/f34f14faa6f6144adb626fa8dee1286f0b734772", "title": "High-Fidelity Image Generation With Fewer Labels", "abstract": "Deep generative models are becoming a cornerstone of modern machine learning. Recent work on conditional generative adversarial networks has shown that learning complex, high-dimensional distributions over natural images is within reach. While the latest models are able to generate high-fidelity, diverse natural images at high resolution, they rely on a vast quantity of labeled data. In this work we demonstrate how one can benefit from recent work on self- and semi-supervised learning to outperform the state of the art on both unsupervised ImageNet synthesis, as well as in the conditional setting. In particular, the proposed approach is able to match the sample quality (as measured by FID) of the current state-of-the-art conditional model BigGAN on ImageNet using only 10% of the labels and outperform it using 20% of the labels.", "year": 2019, "referenceCount": 44, "citationCount": 118, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "34302129", "name": "Mario Lucic"}, {"authorId": "143902495", "name": "M. Tschannen"}, {"authorId": "39687627", "name": "Marvin Ritter"}, {"authorId": "2743563", "name": "Xiaohua Zhai"}, {"authorId": "1936951", "name": "Olivier Bachem"}, {"authorId": "1802148", "name": "S. Gelly"}]}, {"paperId": "3bd8c180acd9363c5d177c04b2973f2a3ffef068", "url": "https://www.semanticscholar.org/paper/3bd8c180acd9363c5d177c04b2973f2a3ffef068", "title": "Limits of End-to-End Learning", "abstract": "End-to-end learning refers to training a possibly complex learning system by applying gradient-based learning to the system as a whole. End-to-end learning system is specifically designed so that all modules are differentiable. In effect, not only a central learning machine, but also all \"peripheral\" modules like representation learning and memory formation are covered by a holistic learning process. The power of end-to-end learning has been demonstrated on many tasks, like playing a whole array of Atari video games with a single architecture. While pushing for solutions to more challenging tasks, network architectures keep growing more and more complex. \nIn this paper we ask the question whether and to what extent end-to-end learning is a future-proof technique in the sense of scaling to complex and diverse data processing architectures. We point out potential inefficiencies, and we argue in particular that end-to-end learning does not make optimal use of the modular design of present neural networks. Our surprisingly simple experiments demonstrate these inefficiencies, up to the complete breakdown of learning.", "year": 2017, "referenceCount": 36, "citationCount": 108, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1756710", "name": "T. Glasmachers"}]}, {"paperId": "ecb20324e3f6eaf4f3d19a03206eb98b9cc917dc", "url": "https://www.semanticscholar.org/paper/ecb20324e3f6eaf4f3d19a03206eb98b9cc917dc", "title": "Prediction of Diabetes Using Machine Learning Algorithms in Healthcare", "abstract": "There are several machine learning techniques that are used to perform predictive analytics over big data in various fields. Predictive analytics in healthcare is a challenging task but ultimately can help practitioners make big data-informed timely decisions about patient's health and treatment. This paper discusses the predictive analytics in healthcare, six different machine learning algorithms are used in this research work. For experiment purpose, a dataset of patient's medical record is obtained and six different machine learning algorithms are applied on the dataset. Performance and accuracy of the applied algorithms is discussed and compared. Comparison of the different machine learning techniques used in this study reveals which algorithm is best suited for prediction of diabetes. This paper aims to help doctors and practitioners in early prediction of diabetes using machine learning techniques.", "year": 2018, "referenceCount": 24, "citationCount": 62, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "29860788", "name": "M. A. Sarwar"}, {"authorId": "2077943450", "name": "Nasir Kamal"}, {"authorId": "150337370", "name": "Wajeeha Hamid"}, {"authorId": "35191617", "name": "M. A. Shah"}]}, {"paperId": "a1abe16a6bc50b1e06e0a23282105db367854188", "url": "https://www.semanticscholar.org/paper/a1abe16a6bc50b1e06e0a23282105db367854188", "title": "Combinatorial screening for new materials in unconstrained composition space with machine learning", "abstract": "Typically, computational screens for new materials sharply constrain the compositional search space, structural search space, or both, for the sake of tractability. To lift these constraints, we construct a machine learning model from a database of thousands of density functional theory (DFT) calculations. The resulting model can predict the thermodynamic stability of arbitrary compositions without any other input and with six orders of magnitude less computer time than DFT. We use this model to scan roughly 1.6 million candidate compositions for novel ternary compounds (AxByCz), and predict 4500 new stable materials. Our method can be readily applied to other descriptors of interest to accelerate domain-specific materials discovery.", "year": 2014, "referenceCount": 54, "citationCount": 433, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Materials Science"], "authors": [{"authorId": "8839934", "name": "B. Meredig"}, {"authorId": "2075308233", "name": "Amit Agrawal"}, {"authorId": "8407652", "name": "S. Kirklin"}, {"authorId": "39280442", "name": "J. Saal"}, {"authorId": "1907763", "name": "J. Doak"}, {"authorId": "2117429617", "name": "Alan J Thompson"}, {"authorId": "2119017058", "name": "Kunpeng Zhang"}, {"authorId": "143975793", "name": "A. Choudhary"}, {"authorId": "2088553", "name": "C. Wolverton"}]}, {"paperId": "7da1c2d2ea8f51011b1a3006eabc03b342f792d4", "url": "https://www.semanticscholar.org/paper/7da1c2d2ea8f51011b1a3006eabc03b342f792d4", "title": "DLID: Deep Learning for Domain Adaptation by Interpolating between Domains", "abstract": "In many real world applications of machine learning, the distribution of the training data (on which the machine learning model is trained) is dierent from the distribution of the test data (where the learnt model is actually deployed). This is known as the problem of Domain Adaptation. We propose a novel deep learning model for domain adaptation which attempts to learn a predictively useful representation of the data by taking into account information from the distribution shift between the training and test data. Our key proposal is to successively learn multiple intermediate representations along an \\interpolating path\" between the train and test domains. Our experiments on a standard object recognition dataset show a signicant performance improvement over the state-of-the-art.", "year": 2013, "referenceCount": 30, "citationCount": 190, "influentialCitationCount": 17, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3295092", "name": "S. Chopra"}, {"authorId": "5246203", "name": "Suhrid Balakrishnan"}, {"authorId": "33692583", "name": "Raghuraman Gopalan"}]}, {"paperId": "22bb3bfc083ef3bc0523231d35dcb7ddd20861d5", "url": "https://www.semanticscholar.org/paper/22bb3bfc083ef3bc0523231d35dcb7ddd20861d5", "title": "Trends in microbiology", "abstract": null, "year": 1992, "referenceCount": 83, "citationCount": 207, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Biology"], "authors": [{"authorId": "9902313", "name": "P. Sajdl"}, {"authorId": "4224928", "name": "M. Kocur"}]}, {"paperId": "9646c61e9cbf3dd1fadc9e03d5581eaa34da7047", "url": "https://www.semanticscholar.org/paper/9646c61e9cbf3dd1fadc9e03d5581eaa34da7047", "title": "Machine Learning Control \u2013 Taming Nonlinear Dynamics and Turbulence", "abstract": null, "year": 2016, "referenceCount": 277, "citationCount": 175, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144875384", "name": "B. R. Noack"}, {"authorId": "12914771", "name": "Thomas Duriez"}, {"authorId": "3083169", "name": "S. Brunton"}]}, {"paperId": "10d7e74cfaaac6f86ddb084a441fe76e65fc9626", "url": "https://www.semanticscholar.org/paper/10d7e74cfaaac6f86ddb084a441fe76e65fc9626", "title": "Orbital-free bond breaking via machine learning.", "abstract": "Using a one-dimensional model, we explore the ability of machine learning to approximate the non-interacting kinetic energy density functional of diatomics. This nonlinear interpolation between Kohn-Sham reference calculations can (i) accurately dissociate a diatomic, (ii) be systematically improved with increased reference data and (iii) generate accurate self-consistent densities via a projection method that avoids directions with no data. With relatively few densities, the error due to the interpolation is smaller than typical errors in standard exchange-correlation functionals.", "year": 2013, "referenceCount": 50, "citationCount": 91, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Mathematics", "Medicine", "Chemistry"], "authors": [{"authorId": "27796226", "name": "John C. Snyder"}, {"authorId": "48041657", "name": "M. Rupp"}, {"authorId": "39960184", "name": "K. Hansen"}, {"authorId": "118171535", "name": "Leo Blooston"}, {"authorId": "145034054", "name": "K. M\u00fcller"}, {"authorId": "2544144", "name": "K. Burke"}]}, {"paperId": "3136dd4036331b4559b341560712942ca2e765e3", "url": "https://www.semanticscholar.org/paper/3136dd4036331b4559b341560712942ca2e765e3", "title": "Machine Learning Security: Threats, Countermeasures, and Evaluations", "abstract": "Machine learning has been pervasively used in a wide range of applications due to its technical breakthroughs in recent years. It has demonstrated significant success in dealing with various complex problems, and shows capabilities close to humans or even beyond humans. However, recent studies show that machine learning models are vulnerable to various attacks, which will compromise the security of the models themselves and the application systems. Moreover, such attacks are stealthy due to the unexplained nature of the deep learning models. In this survey, we systematically analyze the security issues of machine learning, focusing on existing attacks on machine learning systems, corresponding defenses or secure learning techniques, and security evaluation methods. Instead of focusing on one stage or one type of attack, this paper covers all the aspects of machine learning security from the training phase to the test phase. First, the machine learning model in the presence of adversaries is presented, and the reasons why machine learning can be attacked are analyzed. Then, the machine learning security-related issues are classified into five categories: training set poisoning; backdoors in the training set; adversarial example attacks; model theft; recovery of sensitive training data. The threat models, attack approaches, and defense techniques are analyzed systematically. To demonstrate that these threats are real concerns in the physical world, we also reviewed the attacks in real-world conditions. Several suggestions on security evaluations of machine learning systems are also provided. Last, future directions for machine learning security are also presented.", "year": 2020, "referenceCount": 127, "citationCount": 46, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46301056", "name": "Mingfu Xue"}, {"authorId": "1984508", "name": "Chengxiang Yuan"}, {"authorId": "1421758751", "name": "Heyi Wu"}, {"authorId": "2108051942", "name": "Yushu Zhang"}, {"authorId": "2109335717", "name": "Weiqiang Liu"}]}, {"paperId": "5894ff08f8ea1b4aa57d80780d4fc3525f430dc0", "url": "https://www.semanticscholar.org/paper/5894ff08f8ea1b4aa57d80780d4fc3525f430dc0", "title": "Using machine learning to predict student difficulties from learning session data", "abstract": null, "year": 2019, "referenceCount": 60, "citationCount": 91, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1576911326", "name": "M. Hussain"}, {"authorId": "8480832", "name": "Wenhao Zhu"}, {"authorId": "70584500", "name": "Wu Zhang"}, {"authorId": "35427966", "name": "S. Abidi"}, {"authorId": "2115366793", "name": "Sadaqat Ali"}]}, {"paperId": "2ccc855b23888cea4afd3e946fe1e7fa38bd75ca", "url": "https://www.semanticscholar.org/paper/2ccc855b23888cea4afd3e946fe1e7fa38bd75ca", "title": "Machine learning for ecosystem services", "abstract": null, "year": 2018, "referenceCount": 86, "citationCount": 86, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "50499034", "name": "S. Willcock"}, {"authorId": "1400821516", "name": "J. Mart\u00ednez-L\u00f3pez"}, {"authorId": "144690213", "name": "Danny A. P. Hooftman"}, {"authorId": "2401775", "name": "K. Bagstad"}, {"authorId": "2532027", "name": "S. Balbi"}, {"authorId": "38174154", "name": "A. Marzo"}, {"authorId": "98176867", "name": "C. Prato"}, {"authorId": "4404920", "name": "S. Sciandrello"}, {"authorId": "35672394", "name": "G. Signorello"}, {"authorId": "21823432", "name": "B. Voigt"}, {"authorId": "2360945", "name": "F. Villa"}, {"authorId": "2446334", "name": "J. Bullock"}, {"authorId": "144373046", "name": "I. Athanasiadis"}]}, {"paperId": "caaab0a3f51428ad9f28bb440e39fdb9516909c4", "url": "https://www.semanticscholar.org/paper/caaab0a3f51428ad9f28bb440e39fdb9516909c4", "title": "Machine Learning and Health Care Disparities in Dermatology.", "abstract": null, "year": 2018, "referenceCount": 6, "citationCount": 221, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "40225185", "name": "A. Adamson"}, {"authorId": "2116833665", "name": "Avery Smith"}]}, {"paperId": "01c6a61f0e43689f7e4efad21aca1282642107a3", "url": "https://www.semanticscholar.org/paper/01c6a61f0e43689f7e4efad21aca1282642107a3", "title": "Optimal Solutions for Sparse Principal Component Analysis", "abstract": "Given a sample covariance matrix, we examine the problem of maximizing the variance explained by a linear combination of the input variables while constraining the number of nonzero coefficients in this combination. This is known as sparse principal component analysis and has a wide array of applications in machine learning and engineering. We formulate a new semidefinite relaxation to this problem and derive a greedy algorithm that computes a full set of good solutions for all target numbers of non zero coefficients, with total complexity O(n3), where n is the number of variables. We then use the same relaxation to derive sufficient conditions for global optimality of a solution, which can be tested in O(n3), per pattern. We discuss applications in subset selection and sparse recovery and show on artificial examples and biological data that our algorithm does provide globally optimal solutions in many cases.", "year": 2007, "referenceCount": 36, "citationCount": 335, "influentialCitationCount": 33, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1387902104", "name": "A. d\u2019Aspremont"}, {"authorId": "144570279", "name": "F. Bach"}, {"authorId": "1701847", "name": "L. Ghaoui"}]}, {"paperId": "c0cd4b4844c31a27a7900a754d0a91b160b00e55", "url": "https://www.semanticscholar.org/paper/c0cd4b4844c31a27a7900a754d0a91b160b00e55", "title": "Advancing mathematics by guiding human intuition with AI", "abstract": null, "year": 2021, "referenceCount": 48, "citationCount": 107, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2151580217", "name": "A. Davies"}, {"authorId": "3444569", "name": "Petar Velickovic"}, {"authorId": "1981334", "name": "Lars Buesing"}, {"authorId": "40031167", "name": "Sam Blackwell"}, {"authorId": "2153430240", "name": "Daniel Zheng"}, {"authorId": "2213266", "name": "Nenad Toma\u0161ev"}, {"authorId": "1825728", "name": "Richard Tanburn"}, {"authorId": "2019153", "name": "P. Battaglia"}, {"authorId": "1723876", "name": "C. Blundell"}, {"authorId": "2142973185", "name": "Andr\u00e1s Juh\u00e1sz"}, {"authorId": "2538845", "name": "M. Lackenby"}, {"authorId": "35869532", "name": "G. Williamson"}, {"authorId": "48987704", "name": "D. Hassabis"}, {"authorId": "143967473", "name": "Pushmeet Kohli"}]}, {"paperId": "882b6899d07ce3498a04195885150ef87c02d1c3", "url": "https://www.semanticscholar.org/paper/882b6899d07ce3498a04195885150ef87c02d1c3", "title": "Statistical Theory of Learning Curves under Entropic Loss Criterion", "abstract": "The present paper elucidates a universal property of learning curves, which shows how the generalization error, training error, and the complexity of the underlying stochastic machine are related and how the behavior of a stochastic machine is improved as the number of training examples increases. The error is measured by the entropic loss. It is proved that the generalization error converges to H0, the entropy of the conditional distribution of the true machine, as H0 + m/(2t), while the training error converges as H0 - m/(2t), where t is the number of examples and m shows the complexity of the network. When the model is faithful, implying that the true machine is in the model, m is reduced to m, the number of modifiable parameters. This is a universal law because it holds for any regular machine irrespective of its structure under the maximum likelihood estimator. Similar relations are obtained for the Bayes and Gibbs learning algorithms. These learning curves show the relation among the accuracy of learning, the complexity of a model, and the number of training examples.", "year": 1993, "referenceCount": 55, "citationCount": 142, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144362425", "name": "S. Amari"}, {"authorId": "2653061", "name": "N. Murata"}]}, {"paperId": "ff6682ed50a568c1da0deda671585a094abb7b47", "url": "https://www.semanticscholar.org/paper/ff6682ed50a568c1da0deda671585a094abb7b47", "title": "Application of Machine Learning in Microbiology", "abstract": "Microorganisms are ubiquitous and closely related to people\u2019s daily lives. Since they were first discovered in the 19th century, researchers have shown great interest in microorganisms. People studied microorganisms through cultivation, but this method is expensive and time consuming. However, the cultivation method cannot keep a pace with the development of high-throughput sequencing technology. To deal with this problem, machine learning (ML) methods have been widely applied to the field of microbiology. Literature reviews have shown that ML can be used in many aspects of microbiology research, especially classification problems, and for exploring the interaction between microorganisms and the surrounding environment. In this study, we summarize the application of ML in microbiology.", "year": 2019, "referenceCount": 175, "citationCount": 93, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "26953868", "name": "Kaiyang Qu"}, {"authorId": "144199653", "name": "Fei Guo"}, {"authorId": "46522058", "name": "Xiangrong Liu"}, {"authorId": "47904186", "name": "Yuan Lin"}, {"authorId": "144268946", "name": "Q. Zou"}]}, {"paperId": "a75869d69cc86f501939c237ae4711aa2885f6a6", "url": "https://www.semanticscholar.org/paper/a75869d69cc86f501939c237ae4711aa2885f6a6", "title": "Meta-Learning for Low-Resource Neural Machine Translation", "abstract": "In this paper, we propose to extend the recently introduced model-agnostic meta-learning algorithm (MAML, Finn, et al., 2017) for low-resource neural machine translation (NMT). We frame low-resource translation as a meta-learning problem where we learn to adapt to low-resource languages based on multilingual high-resource language tasks. We use the universal lexical representation (Gu et al., 2018b) to overcome the input-output mismatch across different languages. We evaluate the proposed meta-learning strategy using eighteen European languages (Bg, Cs, Da, De, El, Es, Et, Fr, Hu, It, Lt, Nl, Pl, Pt, Sk, Sl, Sv and Ru) as source tasks and five diverse languages (Ro,Lv, Fi, Tr and Ko) as target tasks. We show that the proposed approach significantly outperforms the multilingual, transfer learning based approach (Zoph et al., 2016) and enables us to train a competitive NMT system with only a fraction of training examples. For instance, the proposed approach can achieve as high as 22.04 BLEU on Romanian-English WMT\u201916 by seeing only 16,000 translated words (~600 parallel sentences)", "year": 2018, "referenceCount": 46, "citationCount": 170, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3016273", "name": "Jiatao Gu"}, {"authorId": "1683878", "name": "Yong Wang"}, {"authorId": "47558643", "name": "Yun Chen"}, {"authorId": "1979489", "name": "Kyunghyun Cho"}, {"authorId": "2052674293", "name": "V. Li"}]}, {"paperId": "c9430434487bd65fd8f7f48c748216f1d00be9fe", "url": "https://www.semanticscholar.org/paper/c9430434487bd65fd8f7f48c748216f1d00be9fe", "title": "Automatic selection of atomic fingerprints and reference configurations for machine-learning potentials.", "abstract": "Machine learning of atomic-scale properties is revolutionizing molecular modeling, making it possible to evaluate inter-atomic potentials with first-principles accuracy, at a fraction of the costs. The accuracy, speed, and reliability of machine learning potentials, however, depend strongly on the way atomic configurations are represented, i.e., the choice of descriptors used as input for the machine learning method. The raw Cartesian coordinates are typically transformed in \"fingerprints,\" or \"symmetry functions,\" that are designed to encode, in addition to the structure, important properties of the potential energy surface like its invariances with respect to rotation, translation, and permutation of like atoms. Here we discuss automatic protocols to select a number of fingerprints out of a large pool of candidates, based on the correlations that are intrinsic to the training data. This procedure can greatly simplify the construction of neural network potentials that strike the best balance between accuracy and computational efficiency and has the potential to accelerate by orders of magnitude the evaluation of Gaussian approximation potentials based on the smooth overlap of atomic positions kernel. We present applications to the construction of neural network potentials for water and for an Al-Mg-Si alloy and to the prediction of the formation energies of small organic molecules using Gaussian process regression.", "year": 2018, "referenceCount": 96, "citationCount": 175, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Medicine"], "authors": [{"authorId": "50983068", "name": "G. Imbalzano"}, {"authorId": "47389217", "name": "Andrea Anelli"}, {"authorId": "7930582", "name": "Daniele Giofr\u00e9"}, {"authorId": "50991188", "name": "Sinja Klees"}, {"authorId": "144136091", "name": "J. Behler"}, {"authorId": "1917770", "name": "M. Ceriotti"}]}, {"paperId": "f8d6eafbb6a3af6c6463f672850ef9cca3f15f6c", "url": "https://www.semanticscholar.org/paper/f8d6eafbb6a3af6c6463f672850ef9cca3f15f6c", "title": "Machine Learning Methods for Data-Driven Turbulence Modeling", "abstract": "As part of a larger effort on data-driven turbulence modeling, this paper investigates machine learning models in their capability to reconstruct the functional forms of spatially distributed quantities extracted from high fidelity simulation and experimental data. Such datasets typically involve very high dimensional feature spaces with sparsely populated and noisy data. A new multiscale Gaussian process regression technique is described and is compared to \u2018conventional\u2019 Gaussian process regression and artificial neural networks. All these techniques are applied to the reconstruction of functions arising from Bayesian inference applied to turbulent channel flow and bypass transition. The efficiency, accuracy and effectiveness of each learning algorithm as well as factors that influence their output is assessed. The results highlight the potential of machine learning as an enabling tool in data-driven turbulence modeling.", "year": 2015, "referenceCount": 15, "citationCount": 116, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2118690189", "name": "Z. Zhang"}, {"authorId": "1974037", "name": "K. Duraisamy"}]}, {"paperId": "584dcf00d07bbe9fc2c34de6ef1a6ce63734eef5", "url": "https://www.semanticscholar.org/paper/584dcf00d07bbe9fc2c34de6ef1a6ce63734eef5", "title": "Max-Margin Action Prediction Machine", "abstract": "The speed with which intelligent systems can react to an action depends on how soon it can be recognized. The ability to recognize ongoing actions is critical in many applications, for example, spotting criminal activity. It is challenging, since decisions have to be made based on partial videos of temporally incomplete action executions. In this paper, we propose a novel discriminative multi-scale kernelized model for predicting the action class from a partially observed video. The proposed model captures temporal dynamics of human actions by explicitly considering all the history of observed features as well as features in smaller temporal segments. A compositional kernel is proposed to hierarchically capture the relationships between partial observations as well as the temporal segments, respectively. We develop a new learning formulation, which elegantly captures the temporal evolution over time, and enforces the label consistency between segments and corresponding partial videos. We prove that the proposed learning formulation minimizes the upper bound of the empirical risk. Experimental results on four public datasets show that the proposed approach outperforms state-of-the-art action prediction methods.", "year": 2016, "referenceCount": 58, "citationCount": 81, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "145873652", "name": "Yu Kong"}, {"authorId": "46956675", "name": "Y. Fu"}]}, {"paperId": "86970090de4df895c3b24902a3c41b94be82f8ab", "url": "https://www.semanticscholar.org/paper/86970090de4df895c3b24902a3c41b94be82f8ab", "title": "Evaluation of machine learning algorithms for prediction of regions of high Reynolds averaged Navier Stokes uncertainty", "abstract": "Reynolds Averaged Navier Stokes (RANS) models are widely used in industry to predict fluid flows, despite their acknowledged deficiencies. Not only do RANS models often produce inaccurate flow predictions, but there are very limited diagnostics available to assess RANS accuracy for a given flow configuration. If experimental or higher fidelity simulation results are not available for RANS validation, there is no reliable method to evaluate RANS accuracy. This paper explores the potential of utilizing machine learning algorithms to identify regions of high RANS uncertainty. Three different machine learning algorithms were evaluated: support vector machines, Adaboost decision trees, and random forests. The algorithms were trained on a database of canonical flow configurations for which validated direct numerical simulation or large eddy simulation results were available, and were used to classify RANS results on a point-by-point basis as having either high or low uncertainty, based on the breakdown of specific RANS modeling assumptions. Classifiers were developed for three different basic RANS eddy viscosity model assumptions: the isotropy of the eddy viscosity, the linearity of the Boussinesq hypothesis, and the non-negativity of the eddy viscosity. It is shown that these classifiers are able to generalize to flows substantially different from those on which they were trained. Feature selection techniques, model evaluation, and extrapolation detection are discussed in the context of turbulence modeling applications.", "year": 2015, "referenceCount": 47, "citationCount": 256, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "40540679", "name": "J. Templeton"}]}, {"paperId": "74db87eb3ec2abbfa81ea8729c2512f01cc3fdd1", "url": "https://www.semanticscholar.org/paper/74db87eb3ec2abbfa81ea8729c2512f01cc3fdd1", "title": "Object correspondence as a machine learning problem", "abstract": "We propose machine learning methods for the estimation of deformation fields that transform two given objects into each other, thereby establishing a dense point to point correspondence. The fields are computed using a modified support vector machine containing a penalty enforcing that points of one object will be mapped to \"similar\" points on the other one. Our system, which contains little engineering or domain knowledge, delivers state of the art performance. We present application results including close to photorealistic morphs of 3D head models.", "year": 2005, "referenceCount": 34, "citationCount": 36, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1707625", "name": "B. Sch\u00f6lkopf"}, {"authorId": "2083878667", "name": "F. Steinke"}, {"authorId": "2880906", "name": "V. Blanz"}]}, {"paperId": "099433d10f81fddf310514e8fc8692cc3aa34a7f", "url": "https://www.semanticscholar.org/paper/099433d10f81fddf310514e8fc8692cc3aa34a7f", "title": "Support vector machine for regression and applications to financial forecasting", "abstract": "The main purpose of the paper is to compare the support vector machine (SVM) developed by Cortes and Vapnik (1995) with other techniques such as backpropagation and radial basis function (RBF) networks for financial forecasting applications. The theory of the SVM algorithm is based on statistical learning theory. Training of SVMs leads to a quadratic programming (QP) problem. Preliminary computational results for stock price prediction are also presented.", "year": 2000, "referenceCount": 10, "citationCount": 295, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1824282", "name": "T. Trafalis"}, {"authorId": "3128326", "name": "H. Ince"}]}, {"paperId": "1f8f0329c8c4a9d006ec44dd80338b937afdb216", "url": "https://www.semanticscholar.org/paper/1f8f0329c8c4a9d006ec44dd80338b937afdb216", "title": "Detection of Phishing Attacks: A Machine Learning Approach", "abstract": null, "year": 2008, "referenceCount": 13, "citationCount": 211, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2500317", "name": "Ram B. Basnet"}, {"authorId": "1718382", "name": "S. Mukkamala"}, {"authorId": "1742050", "name": "A. Sung"}]}, {"paperId": "c64f9f42601d6766a37636df1d02dbd0d5afd834", "url": "https://www.semanticscholar.org/paper/c64f9f42601d6766a37636df1d02dbd0d5afd834", "title": "Robust ordinal regression in preference learning and ranking", "abstract": null, "year": 2013, "referenceCount": 82, "citationCount": 143, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1792561", "name": "Salvatore Corrente"}, {"authorId": "1710715", "name": "S. Greco"}, {"authorId": "2320157", "name": "M. Kadzi\u0144ski"}, {"authorId": "1754252", "name": "R. S\u0142owi\u0144ski"}]}, {"paperId": "f71687796caa7d2a5d68406b53b51cb9ed57f586", "url": "https://www.semanticscholar.org/paper/f71687796caa7d2a5d68406b53b51cb9ed57f586", "title": "SecureBoost: A Lossless Federated Learning Framework", "abstract": "The protection of user privacy is an important concern in machine learning, as evidenced by the rolling out of the General Data Protection Regulation (GDPR) in the European Union (EU) in May 2018. The GDPR is designed to give users more control over their personal data, which motivates us to explore machine learning frameworks for data sharing that do not violate user privacy. To meet this goal, in this article, we propose a novel lossless privacy-preserving tree-boosting system known as SecureBoost in the setting of federated learning. SecureBoost first conducts entity alignment under a privacy-preserving protocol and then constructs boosting trees across multiple parties with a carefully designed encryption strategy. This federated learning system allows the learning process to be jointly conducted over multiple parties with common user samples but different feature sets, which corresponds to a vertically partitioned dataset. An advantage of SecureBoost is that it provides the same level of accuracy as the non -privacy-preserving approach while at the same time, reveals no information of each private data provider. We show that the SecureBoost framework is as accurate as other nonfederated gradient tree-boosting algorithms that require centralized data, and thus, it is highly scalable and practical for industrial applications such as credit risk analysis. To this end, we discuss information leakage during the protocol execution and propose ways to provably reduce it.", "year": 2019, "referenceCount": 41, "citationCount": 246, "influentialCitationCount": 38, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3161399", "name": "Kewei Cheng"}, {"authorId": "2072650627", "name": "Tao Fan"}, {"authorId": "9372198", "name": "Yilun Jin"}, {"authorId": "1614034792", "name": "Yang Liu"}, {"authorId": "11573257", "name": "Tianjian Chen"}, {"authorId": "152290618", "name": "Qiang Yang"}]}, {"paperId": "9adb484a477e77e9defa9cd022d142c7b1b578e4", "url": "https://www.semanticscholar.org/paper/9adb484a477e77e9defa9cd022d142c7b1b578e4", "title": "A survey of learning-based techniques of email spam filtering", "abstract": null, "year": 2008, "referenceCount": 112, "citationCount": 424, "influentialCitationCount": 28, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2930903", "name": "E. Blanzieri"}, {"authorId": "2549958", "name": "Anton Bryl"}]}, {"paperId": "a67980c3fb10a7679b7592eb27b64e0b350e3dfc", "url": "https://www.semanticscholar.org/paper/a67980c3fb10a7679b7592eb27b64e0b350e3dfc", "title": "Machine Learning Approaches in Cardiovascular Imaging", "abstract": "Cardiovascular imaging technologies continue to increase in their capacity to capture and store large quantities of data. Modern computational methods, developed in the field of machine learning, offer new approaches to leveraging the growing volume of imaging data available for analyses. Machine learning methods can now address data-related problems ranging from simple analytic queries of existing measurement data to the more complex challenges involved in analyzing raw images. To date, machine learning has been used in 2 broad and highly interconnected areas: automation of tasks that might otherwise be performed by a human and generation of clinically important new knowledge. Most cardiovascular imaging studies have focused on task-oriented problems, but more studies involving algorithms aimed at generating new clinical insights are emerging. Continued expansion in the size and dimensionality of cardiovascular imaging databases is driving strong interest in applying powerful deep learning methods, in particular, to analyze these data. Overall, the most effective approaches will require an investment in the resources needed to appropriately prepare such large data sets for analyses. Notwithstanding current technical and logistical challenges, machine learning and especially deep learning methods have much to offer and will substantially impact the future practice and science of cardiovascular imaging.", "year": 2017, "referenceCount": 38, "citationCount": 75, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "6062062", "name": "M. Henglin"}, {"authorId": "40639570", "name": "G. Stein"}, {"authorId": "25904274", "name": "Pavel Hushcha"}, {"authorId": "1714516", "name": "Jasper Snoek"}, {"authorId": "49398909", "name": "Alexander B. Wiltschko"}, {"authorId": "152434470", "name": "Susan Cheng"}]}, {"paperId": "24f8b9d8b9ec39322a6e141f5bd99f2e947fd22e", "url": "https://www.semanticscholar.org/paper/24f8b9d8b9ec39322a6e141f5bd99f2e947fd22e", "title": "Discovering phase transitions with unsupervised learning", "abstract": "Unsupervised learning is a discipline of machine learning which aims at discovering patterns in large data sets or classifying the data into several categories without being trained explicitly. We show that unsupervised learning techniques can be readily used to identify phases and phases transitions of many-body systems. Starting with raw spin configurations of a prototypical Ising model, we use principal component analysis to extract relevant low-dimensional representations of the original data and use clustering analysis to identify distinct phases in the feature space. This approach successfully finds physical concepts such as the order parameter and structure factor to be indicators of a phase transition. We discuss the future prospects of discovering more complex phases and phase transitions using unsupervised learning techniques.", "year": 2016, "referenceCount": 16, "citationCount": 346, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Mathematics"], "authors": [{"authorId": "2152511187", "name": "Lei Wang"}]}, {"paperId": "ef536d80c56d9c49f4fac229715beb7886cd3b55", "url": "https://www.semanticscholar.org/paper/ef536d80c56d9c49f4fac229715beb7886cd3b55", "title": "De novo composite design based on machine learning algorithm", "abstract": null, "year": 2018, "referenceCount": 39, "citationCount": 226, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "11329466", "name": "Grace X. Gu"}, {"authorId": "153246325", "name": "Chun\u2010Teh Chen"}, {"authorId": "2273480", "name": "M. Buehler"}]}, {"paperId": "60b779cc6b8147768fdafd1a223fb18ade6d72cf", "url": "https://www.semanticscholar.org/paper/60b779cc6b8147768fdafd1a223fb18ade6d72cf", "title": "Symmetry-Adapted Machine Learning for Tensorial Properties of Atomistic Systems.", "abstract": "Statistical learning methods show great promise in providing an accurate prediction of materials and molecular properties, while minimizing the need for computationally demanding electronic structure calculations. The accuracy and transferability of these models are increased significantly by encoding into the learning procedure the fundamental symmetries of rotational and permutational invariance of scalar properties. However, the prediction of tensorial properties requires that the model respects the appropriate geometric transformations, rather than invariance, when the reference frame is rotated. We introduce a formalism that extends existing schemes and makes it possible to perform machine learning of tensorial properties of arbitrary rank, and for general molecular geometries. To demonstrate it, we derive a tensor kernel adapted to rotational symmetry, which is the natural generalization of the smooth overlap of atomic positions kernel commonly used for the prediction of scalar properties at the atomic scale. The performance and generality of the approach is demonstrated by learning the instantaneous response to an external electric field of water oligomers of increasing complexity, from the isolated molecule to the condensed phase.", "year": 2017, "referenceCount": 74, "citationCount": 140, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science", "Medicine"], "authors": [{"authorId": "3371253", "name": "Andrea Grisafi"}, {"authorId": "6287077", "name": "D. Wilkins"}, {"authorId": "2559761", "name": "G\u00e1bor Cs\u00e1nyi"}, {"authorId": "1917770", "name": "M. Ceriotti"}]}, {"paperId": "93a71e6168839a05609fd6d579e783762d8eca4d", "url": "https://www.semanticscholar.org/paper/93a71e6168839a05609fd6d579e783762d8eca4d", "title": "Preference-based reinforcement learning: a formal framework and a policy iteration algorithm", "abstract": null, "year": 2012, "referenceCount": 96, "citationCount": 103, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1747752", "name": "Johannes F\u00fcrnkranz"}, {"authorId": "1691955", "name": "E. H\u00fcllermeier"}, {"authorId": "49767752", "name": "Weiwei Cheng"}, {"authorId": "2829854", "name": "Sang-Hyeun Park"}]}, {"paperId": "d9f199ccad6d4ed7fe48f1d16cec334061f7e6c0", "url": "https://www.semanticscholar.org/paper/d9f199ccad6d4ed7fe48f1d16cec334061f7e6c0", "title": "Machine learning inverse problem for topological photonics", "abstract": null, "year": 2018, "referenceCount": 87, "citationCount": 89, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "15117621", "name": "L. Pilozzi"}, {"authorId": "69016813", "name": "F. Farrelly"}, {"authorId": "46893096", "name": "G. Marcucci"}, {"authorId": "1983655", "name": "C. Conti"}]}, {"paperId": "3f10804d53644a47ce141a5ac273081b1ec6e62c", "url": "https://www.semanticscholar.org/paper/3f10804d53644a47ce141a5ac273081b1ec6e62c", "title": "On the use of support vector machines for phonetic classification", "abstract": "Support vector machines (SVMs) represent a new approach to pattern classification which has attracted a great deal of interest in the machine learning community. Their appeal lies in their strong connection to the underlying statistical learning theory, in particular the theory of structural risk minimization. SVMs have been shown to be particularly successful in fields such as image identification and face recognition; in many problems SVM classifiers have been shown to perform much better than other nonlinear classifiers such as artificial neural networks and k-nearest neighbors. This paper explores the issues involved in applying SVMs to phonetic classification as a first step to speech recognition. We present results on several standard vowel and phonetic classification tasks and show better performance than Gaussian mixture classifiers. We also present an analysis of the difficulties we foresee in applying SVMs to continuous speech recognition problems.", "year": 1999, "referenceCount": 18, "citationCount": 208, "influentialCitationCount": 18, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2066017394", "name": "P. Clarkson"}, {"authorId": "47690405", "name": "P. Moreno"}]}, {"paperId": "497d645d7b81dd0a6e8db2deccd77097ac94bc4e", "url": "https://www.semanticscholar.org/paper/497d645d7b81dd0a6e8db2deccd77097ac94bc4e", "title": "Explainable Artificial Intelligence: Understanding, Visualizing and Interpreting Deep Learning Models", "abstract": "With the availability of large databases and recent improvements in deep learning methodology, the performance of AI systems is reaching or even exceeding the human level on an increasing number of complex tasks. Impressive examples of this development can be found in domains such as image classification, sentiment analysis, speech understanding or strategic game playing. However, because of their nested non-linear structure, these highly successful machine learning and artificial intelligence models are usually applied in a black box manner, i.e., no information is provided about what exactly makes them arrive at their predictions. Since this lack of transparency can be a major drawback, e.g., in medical applications, the development of methods for visualizing, explaining and interpreting deep learning models has recently attracted increasing attention. This paper summarizes recent developments in this field and makes a plea for more interpretability in artificial intelligence. Furthermore, it presents two approaches to explaining predictions of deep learning models, one method which computes the sensitivity of the prediction with respect to changes in the input and one approach which meaningfully decomposes the decision in terms of the input variables. These methods are evaluated on three classification tasks.", "year": 2017, "referenceCount": 41, "citationCount": 807, "influentialCitationCount": 26, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1699054", "name": "W. Samek"}, {"authorId": "1745395", "name": "T. Wiegand"}, {"authorId": "145034054", "name": "K. M\u00fcller"}]}, {"paperId": "3e3bb1e6f2e2971a7d4da229ba6a8064e0c1c020", "url": "https://www.semanticscholar.org/paper/3e3bb1e6f2e2971a7d4da229ba6a8064e0c1c020", "title": "Machine learning in materials design and discovery: Examples from the present and suggestions for the future", "abstract": "Much is being currently written about machine learning applied to materials science, but, what is machine learning? It is certainly not physics, chemistry, or materials science, in which case how do these sciences enter? In this Research Update the authors examine what machine learning is and is not, review several applications of machine learning methods for predicting new materials, noting some of the cases where the predictions have been experimentally validated, and illustrate the spectrum of applications possible. The emphasis is on the broader picture where they discuss some newer methods and more importantly reference their successes. Thus, the paper looks more towards the future than to the past, sharing some of the lessons the authors have learned from their own experience in the field.", "year": 2018, "referenceCount": 106, "citationCount": 76, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Materials Science"], "authors": [{"authorId": "3122483", "name": "J. Gubernatis"}, {"authorId": "2891010", "name": "T. Lookman"}]}, {"paperId": "83c137c3ca9e14b3d87f5b2c96ff021a3ba76b1a", "url": "https://www.semanticscholar.org/paper/83c137c3ca9e14b3d87f5b2c96ff021a3ba76b1a", "title": "Journal of Machine Learning Technologies", "abstract": "The Journal of Machine Learning Technologies, ISSN: 2229\u20133981 & ISSN: 2229-399X, aims to publish all the latest and outstanding research articles, reviews and letters in all areas of Machine Learning Technologie. Each issue contains a series of timely, in-depth written articles by leaders in the field, covering a wide range of the integration of multidimensional challenges of research including integration issues of Machine Learning Technologie.", "year": 2013, "referenceCount": 4, "citationCount": 56, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "52022340", "name": "Publisher Bioinfo Publications"}]}, {"paperId": "4a0d35989d91b3b7d2318802b1de6d10e4e6e830", "url": "https://www.semanticscholar.org/paper/4a0d35989d91b3b7d2318802b1de6d10e4e6e830", "title": "Wasserstein Distributionally Robust Optimization: Theory and Applications in Machine Learning", "abstract": "Many decision problems in science, engineering and economics are affected by uncertain parameters whose distribution is only indirectly observable through samples. The goal of data-driven decision-making is to learn a decision from finitely many training samples that will perform well on unseen test samples. This learning task is difficult even if all training and test samples are drawn from the same distribution---especially if the dimension of the uncertainty is large relative to the training sample size. Wasserstein distributionally robust optimization seeks data-driven decisions that perform well under the most adverse distribution within a certain Wasserstein distance from a nominal distribution constructed from the training samples. In this tutorial we will argue that this approach has many conceptual and computational benefits. Most prominently, the optimal decisions can often be computed by solving tractable convex optimization problems, and they enjoy rigorous out-of-sample and asymptotic consistency guarantees. We will also show that Wasserstein distributionally robust optimization has interesting ramifications for statistical learning and motivates new approaches for fundamental learning tasks such as classification, regression, maximum likelihood estimation or minimum mean square error estimation, among others.", "year": 2019, "referenceCount": 115, "citationCount": 203, "influentialCitationCount": 20, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2500534", "name": "D. Kuhn"}, {"authorId": "1787177", "name": "Peyman Mohajerin Esfahani"}, {"authorId": "2075327618", "name": "Viet Anh Nguyen"}, {"authorId": "1380260325", "name": "Soroosh Shafieezadeh-Abadeh"}]}, {"paperId": "e0653631b4a476abf5276a264f6bbff40b132061", "url": "https://www.semanticscholar.org/paper/e0653631b4a476abf5276a264f6bbff40b132061", "title": "Automated Bitcoin Trading via Machine Learning Algorithms", "abstract": "In this project, we attempt to apply machine-learning algorithms to predict Bitcoin price. For the first phase of our investigation, we aimed to understand and better identify daily trends in the Bitcoin market while gaining insight into optimal features surrounding Bitcoin price. Our data set consists of over 25 features relating to the Bitcoin price and payment network over the course of five years, recorded daily. Using this information we were able to predict the sign of the daily price change with an accuracy of 98.7%. For the second phase of our investigation, we focused on the Bitcoin price data alone and leveraged data at 10-minute and 10-second interval timepoints, as we saw an opportunity to evaluate price predictions at varying levels of granularity and noisiness. By predicting the sign of the future change in price, we are modeling the price prediction problem as a binomial classification task, experimenting with a custom algorithm that leverages both random forests and generalized linear models. These results had 50-55% accuracy in predicting the sign of future price change using 10 minute time intervals.", "year": 2014, "referenceCount": 1, "citationCount": 100, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3998505", "name": "Isaac Madan"}]}, {"paperId": "f409da263cfc82f0dd98a9b22992a850e7016a90", "url": "https://www.semanticscholar.org/paper/f409da263cfc82f0dd98a9b22992a850e7016a90", "title": "Causal Discovery via MML", "abstract": "Automating the learning of causal models from sample data is a key step toward incorporating machine learning into decisionmaking and reasoning under uncertainty. This paper presents a Bayesian approach to the discovery of causal models, using a Minimum Message Length (MML) method. We have developed encoding and search methods for discovering linear causal models. The initial experimental results presented in this paper show that the MML induction approach can recover causal models from generated data which are quite accurate re ections of the original models and compare favorably with those of TETRAD II (Spirtes et al. 1994) even when it is supplied with prior temporal information and MML is not.", "year": 1996, "referenceCount": 33, "citationCount": 99, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "8635127", "name": "C. S. Wallace"}, {"authorId": "1730706", "name": "K. Korb"}, {"authorId": "2732405", "name": "H. Dai"}]}, {"paperId": "b3139012b29462f1f2585949a94ef9a2a0ac0b21", "url": "https://www.semanticscholar.org/paper/b3139012b29462f1f2585949a94ef9a2a0ac0b21", "title": "Are Accuracy and Robustness Correlated", "abstract": "Machine learning models are vulnerable to adversarial examples formed by applying small carefully chosen perturbations to inputs that cause unexpected classification errors. In this paper, we perform experiments on various adversarial example generation approaches with multiple deep convolutional neural networks including Residual Networks, the best performing models on ImageNet Large-Scale Visual Recognition Challenge 2015. We compare the adversarial example generation techniques with respect to the quality of the produced images, and measure the robustness of the tested machine learning models to adversarial examples. Finally, we conduct large-scale experiments on cross-model adversarial portability. We find that adversarial examples are mostly transferable across similar network topologies, and we demonstrate that better machine learning models are less vulnerable to adversarial examples.", "year": 2016, "referenceCount": 23, "citationCount": 49, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2974221", "name": "Andras Rozsa"}, {"authorId": "38636666", "name": "Manuel G\u00fcnther"}, {"authorId": "32163276", "name": "T. Boult"}]}, {"paperId": "75c4d189fc9607b02948cfb65b47005d142bb1e3", "url": "https://www.semanticscholar.org/paper/75c4d189fc9607b02948cfb65b47005d142bb1e3", "title": "Learning to Route", "abstract": "Recently, much attention has been devoted to the question of whether/when traditional network protocol design, which relies on the application of algorithmic insights by human experts, can be replaced by a data-driven (i.e., machine learning) approach. We explore this question in the context of the arguably most fundamental networking task: routing. Can ideas and techniques from machine learning (ML) be leveraged to automatically generate \"good\" routing configurations? We focus on the classical setting of intradomain traffic engineering. We observe that this context poses significant challenges for data-driven protocol design. Our preliminary results regarding the power of data-driven routing suggest that applying ML (specifically, deep reinforcement learning) to this context yields high performance and is a promising direction for further research. We outline a research agenda for ML-guided routing.", "year": 2017, "referenceCount": 50, "citationCount": 130, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3338812", "name": "Asaf Valadarsky"}, {"authorId": "1718880", "name": "Michael Schapira"}, {"authorId": "1805894", "name": "Dafna Shahaf"}, {"authorId": "3025260", "name": "Aviv Tamar"}]}, {"paperId": "3502b5ef1afb16f76bcae33db17179195bbcdaae", "url": "https://www.semanticscholar.org/paper/3502b5ef1afb16f76bcae33db17179195bbcdaae", "title": "Generating Natural Adversarial Examples", "abstract": "Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers for a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.", "year": 2017, "referenceCount": 33, "citationCount": 438, "influentialCitationCount": 50, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2708739", "name": "Zhengli Zhao"}, {"authorId": "33546336", "name": "Dheeru Dua"}, {"authorId": "34650964", "name": "Sameer Singh"}]}, {"paperId": "9f51a9f05e9a295262999a37278f8b07dd4f4a91", "url": "https://www.semanticscholar.org/paper/9f51a9f05e9a295262999a37278f8b07dd4f4a91", "title": "Recommender Systems", "abstract": "Beyond NDCG: behavioral testing of recommender systems Collaborative Knowledge Base Embedding for Recommender ...Recommender Systems Based On Personality Traits: Could GitHub microsoft/recommenders: Best Practices on Classifying Different Types of Recommender Systems | BluePi5 Problems of Recommender Systems ReadWriteBuilding recommender systems with Azure Machine Learning Building Recommender Systems with Machine Learning and AI Research paper recommender systems a random-walk based In-Depth Guide: How Recommender Systems Work | Built InRecSys \u2013 ACM Recommender SystemsR Pubsure Check Research Manuscript Online To Avoid Desk Matrix factorization (recommender systems) WikipediaIntroduction to Recommender Systems | Tryolabs[1606.07792] Wide & Deep Learning for Recommender Systems13 The Net?ix Recommender System: Algorithms, Business 10 Datasets One Must Know To Build Recommender SystemsRecommender Systems in Keras | Movie Recommendations using Deep Matrix Factorization Models for Recommender Systems(PDF) Recommender Systems Handbook ResearchGateIntroduction to recommender systems | by Baptiste Rocca An Easy Introduction to Machine Learning Recommender SystemsRecommender Systems Datasets Computer ScienceDeep Learning Based Recommender Systems | by Sciforce Towards the Next Generation of Recommender Systems: A Cold-Start Problem in Recommender Systems and its Recommender System Application Developments: A SurveyRUCAIBox \u00b7 GitHub16. Recommender Systems \u2014 Dive into Deep Learning 0.17.1 Recommendation Systems Stanford UniversityRecommender system WikipediaMachine Learning for Recommender systems \u2014 Part 1 Five Types of Recommender Systems and The APP SolutionsRecSys 2020 (Online) ACM Recommender Systems\"A Theory-Driven Design Framework for Social Recommender Evaluation Metrics for Recommender Systems | by Claire Jun 03, 2018 \u00b7 Recommender systems are one of the most successful and widespread application of machine learning technologies in business. There were many people on waiting list that could not attend our MLMU Essay about racial inequality essay on earthquake of nepal 2015 history essay graphic organizer, essay on man alexander pope anemia case study nursing systems based a paper recommender random-walk approach Research, violence essay romeo and juliet, soccer essay scholarships media and culture essay topics. Dystopian argumentative essay.Avoid desk rejection and make sure your research manuscript is submission ready with R Pubsure. Journal submission was never easier. Get your personalized manuscript check report online and revise your manuscript to make it perfect. Explore new features like plagiarism check, journal recommender and downloadable word file with R Pubsure Pro Plan.Apr 30, 2021 \u00b7 Recommender systems are lifesavers in the infinite seething sea of ecommerce, improving customer experience. Recommender engines are eliminating the tyranny of choice, smoothing the way for Jun 02, 2019 \u00b7 Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. As a proof of the importance of recommender systems, we can mention that, a few years ago, Netflix organised a challenges (the \u201cNetflix prize\u201d) where Recommender systems can be defined as programs which attempt to recommend the most suitable items (products or services) to particular users (individuals or businesses) by predicting a user\u2019s interest in an item based on related information about the items, the users and the interactions between items and users [1]. TheRecommender Systems Based On Personality Traits: Could Human Psychological Aspects Influence The Computer Decision Making Process?|Maria Augusta Silveira Netto Nunes, Aiaa/Asme Adaptive Structures Forum: April 18-19, 1996/Salt Lake City, Ut|AIAA (American Institute Of Aeronautics, Alzheimers Disease (Encyclopedia Of Health)|William A. Check, ...Sep 27, 2010 \u00b7 Social recommender systems utilize data regarding users\u2019 social relationships in filtering relevant information to users. To date, results show that incorporating social relationship data \u2013 beyond consumption profile similarity \u2013 is beneficial only in a very limited set of cases. The main conjecture of this study is that the inconclusive results are, at least to some extent, due ...Nov 14, 2015 \u00b7 Recommender systems are defined as recommendation inputs given by the people, which the system then aggregates and directs to appropriate recipients. It can be further defined as a system that produces individualized recommendations as output or has the effect of guiding the user in a personalized way to interesting objects in a larger space of Jun 24, 2016 \u00b7 In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps.Jan 28, 2009 \u00b7 On the topic of user preferences, recommender systems may also incorrectly label users \u2013 a la this classic Wall St Journal story from 2002, If TiVo Thinks You Are Gay, The 16th ACM Recommender Systems Conference will take place in Seattle from Sept. 18 23, 2022. Latest News Sept 30, 2021: RecSys 2022 will come back to the United States.Sep 26, 2021 \u00b7 The recommender systems face a problem in recommending items to users in case there is very little data available related to the user or item. This is called the cold-start problem. Here in this article, we will discuss the cold-start problems faced by the recommender system with their causes and approaches to overcome this issue.The Net?ix Recommender System: Algorithms, Business Value, and Innovation CARLOS A. GOMEZ-URIBE and NEIL HUNT, Net?ix, Inc. This article discusses the various algorithms that make up the Net?ix recommender system, and describes its business purpose. We also describe the role of search and related algorithms, which for us turns into a16. Recommender Systems\u00b6. Shuai Zhang (Amazon), Aston Zhang (Amazon), and Yi Tay (Google). Recommender systems are widely employed in industry and are ubiquitous in our daily lives. These systems are utilized in a number of areas such as online shopping sites (e.g., amazon.com), music/movie services site (e.g., Netflix and Spotify), mobile application stores ...Recommender Systems (RSs) are software tools and techniques providing suggestions for items to be of use to a user. In this introductory chapter we ...The ACM Recommender Systems conference (RecSys) is the premier international forum for the presentation of new research results, systems and techniques in the broad field of recommender systems. Recommendation is a particular form of information filtering, that exploits past behaviors and user similarities to generate a list of information May 09, 2018 \u00b7 Recommender systems have different ways of being evaluated and the answer which evaluation method to choose depends on your goal. If you're solely interested in recommending the top 5 items (i.e. the most probable items the user will interact with), you don\u2019t need to consider the predictions regarding the rest of the items when conducting the Nov 27, 2021 \u00b7 Building Recommender Systems with Machine Learning and AI: Help people discover new products and content with deep learning, neural networks, and machine learning recommendations, 2nd Edition. Learn how to build recommender systems from one of Amazon\u2019s pioneers in the field.Recommender systems usually make personalized recommendation with user-item interaction ratings, implicit feedback and auxiliary information. Matrix factorization is the basic idea to predict a per-sonalized ranking over a set of items for an indi-vidual user with the similarities among users and items. In this paper, we propose a novel matrixrecommender systems are attracting increasing attention. For ex-ample, Yu et al. [30] uses a heterogeneous information network to represent users, items, item attributes, and the interlinked relation-ships in a knowledge base. They extract meta-path based latentMay 01, 2019 \u00b7 Recommender systems keep customers on a businesses\u2019 site longer, they interact with more products/content, and it suggests products or content a customer is likely to purchase or engage with as a store sales associate might. Below, we\u2019ll show you what this repository is, and how it eases pain points for data scientists building and Recommender Systems and Personalization Datasets. Julian McAuley, UCSD. Description. This page contains a collection of datasets that have been collected for research by our lab. Datasets contain the following features: user/item interactions; star ratings; timestamps; product reviews; social networks; item-to-item relationships (e.g May 02, 2021 \u00b7 This article was published as a part of the Data Science Blogathon.. Introduction. With the ever-increasing data on the web over years, Recommender Systems (RS) have come in to the picture ranging from e-commerce to e-resource. Today, big giants like Netflix, Amazon, YouTube, etc. use RS to help users find information of use to improve their experience and ...recommender systems.", "year": 2012, "referenceCount": 0, "citationCount": 2219, "influentialCitationCount": 93, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "29241448", "name": "S. Ahrens"}]}, {"paperId": "f7da65e5e249083be84071fd244782720d326b6c", "url": "https://www.semanticscholar.org/paper/f7da65e5e249083be84071fd244782720d326b6c", "title": "Complete Mining of Frequent Patterns from Graphs: Mining Graph Data", "abstract": null, "year": 2003, "referenceCount": 29, "citationCount": 309, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "35237557", "name": "Akihiro Inokuchi"}, {"authorId": "1704749", "name": "T. Washio"}, {"authorId": "1748072", "name": "H. Motoda"}]}, {"paperId": "7aafdb1ab2c2cdee25d415d934d99fd17948f1b7", "url": "https://www.semanticscholar.org/paper/7aafdb1ab2c2cdee25d415d934d99fd17948f1b7", "title": "KeystoneML: Optimizing Pipelines for Large-Scale Advanced Analytics", "abstract": "Modern advanced analytics applications make use of machine learning techniques and contain multiple steps of domain-specific and general-purpose processing with high resource requirements. We present KeystoneML, a system that captures and optimizes the end-to-end large-scale machine learning applications for high-throughput training in a distributed environment with a high-level API. This approach offers increased ease of use and higher performance over existing systems for large scale learning. We demonstrate the effectiveness of KeystoneML in achieving high quality statistical accuracy and scalable training using real world datasets in several domains.", "year": 2016, "referenceCount": 90, "citationCount": 127, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144752747", "name": "Evan R. Sparks"}, {"authorId": "2697906", "name": "S. Venkataraman"}, {"authorId": "2403754", "name": "Tomer Kaftan"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "9229182", "name": "B. Recht"}]}, {"paperId": "d70cd4cb5c7acd651c684e1b03e1d079226cac74", "url": "https://www.semanticscholar.org/paper/d70cd4cb5c7acd651c684e1b03e1d079226cac74", "title": "A data mining approach to strategy prediction", "abstract": "We present a data mining approach to opponent modeling in strategy games. Expert gameplay is learned by applying machine learning techniques to large collections of game logs. This approach enables domain independent algorithms to acquire domain knowledge and perform opponent modeling. Machine learning algorithms are applied to the task of detecting an opponent's strategy before it is executed and predicting when an opponent will perform strategic actions. Our approach involves encoding game logs as a feature vector representation, where each feature describes when a unit or building type is first produced. We compare our representation to a state lattice representation in perfect and imperfect information environments and the results show that our representation has higher predictive capabilities and is more tolerant of noise. We also discuss how to incorporate our data mining approach into a full game playing agent.", "year": 2009, "referenceCount": 30, "citationCount": 258, "influentialCitationCount": 20, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2415755", "name": "B. Weber"}, {"authorId": "114402462", "name": "M. Mateas"}]}, {"paperId": "5c2776cef4186e5a436c63c7b016a0c9a0b9879b", "url": "https://www.semanticscholar.org/paper/5c2776cef4186e5a436c63c7b016a0c9a0b9879b", "title": "Better medicine through machine learning: What\u2019s real, and what\u2019s artificial?", "abstract": "Machine Learning Special Issue Guest Editors Suchi Saria, Atul Butte, and Aziz Sheikh cut through the hyperbole with an accessible and accurate portrayal of the forefront of machine learning in clinical translation.", "year": 2018, "referenceCount": 26, "citationCount": 68, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1932128", "name": "S. Saria"}, {"authorId": "1716151", "name": "A. Butte"}, {"authorId": "145386473", "name": "A. Sheikh"}]}, {"paperId": "0c908739fbff75f03469d13d4a1a07de3414ee19", "url": "https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19", "title": "Distilling the Knowledge in a Neural Network", "abstract": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.", "year": 2015, "referenceCount": 9, "citationCount": 10411, "influentialCitationCount": 1539, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1695689", "name": "Geoffrey E. Hinton"}, {"authorId": "1689108", "name": "Oriol Vinyals"}, {"authorId": "49959210", "name": "J. Dean"}]}, {"paperId": "c92b3e90219d6f96964714e3c489f970fed14b11", "url": "https://www.semanticscholar.org/paper/c92b3e90219d6f96964714e3c489f970fed14b11", "title": "Local-Learning-Based Feature Selection for High-Dimensional Data Analysis", "abstract": "This paper considers feature selection for data classification in the presence of a huge number of irrelevant features. We propose a new feature-selection algorithm that addresses several major issues with prior work, including problems with algorithm implementation, computational complexity, and solution accuracy. The key idea is to decompose an arbitrarily complex nonlinear problem into a set of locally linear ones through local learning, and then learn feature relevance globally within the large margin framework. The proposed algorithm is based on well-established machine learning and numerical analysis techniques, without making any assumptions about the underlying data distribution. It is capable of processing many thousands of features within minutes on a personal computer while maintaining a very high accuracy that is nearly insensitive to a growing number of irrelevant features. Theoretical analyses of the algorithm's sample complexity suggest that the algorithm has a logarithmical sample complexity with respect to the number of features. Experiments on 11 synthetic and real-world data sets demonstrate the viability of our formulation of the feature-selection problem for supervised learning and the effectiveness of our algorithm.", "year": 2010, "referenceCount": 53, "citationCount": 318, "influentialCitationCount": 29, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "49696868", "name": "Yijun Sun"}, {"authorId": "143856428", "name": "S. Todorovic"}, {"authorId": "1749476", "name": "S. Goodison"}]}, {"paperId": "288f5d916d90d986b23d06660d89c71adfb1bf92", "url": "https://www.semanticscholar.org/paper/288f5d916d90d986b23d06660d89c71adfb1bf92", "title": "A machine learning approach to reading level assessment", "abstract": null, "year": 2009, "referenceCount": 59, "citationCount": 201, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "21129694", "name": "S. E. Petersen"}, {"authorId": "144339506", "name": "Mari Ostendorf"}]}, {"paperId": "2ce5060cf6dd54857504a0563d314d6090483dfa", "url": "https://www.semanticscholar.org/paper/2ce5060cf6dd54857504a0563d314d6090483dfa", "title": "Bayesian Averaging of Classifiers and the Overfitting Problem", "abstract": "Although Bayesian model averaging is theoretically the optimal method for combining learned models, it has seen very little use in machine learning. In this paper we study its application to combining rule sets, and compare it with bagging and partitioning, two popular but more ad hoc alternatives. Our experiments show that, surprisingly, Bayesian model averaging\u2019s error rates are consistently higher than the other methods\u2019. Further investigation shows this to be due to a marked tendency to overfit on the part of Bayesian model averaging, contradicting previous beliefs that it solves (or avoids) the overfitting problem.", "year": 2000, "referenceCount": 25, "citationCount": 175, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1740213", "name": "Pedro M. Domingos"}]}, {"paperId": "ab0378836e5123d94fd5d46773c80d3e6c7742e0", "url": "https://www.semanticscholar.org/paper/ab0378836e5123d94fd5d46773c80d3e6c7742e0", "title": "QuEst - A translation quality estimation framework", "abstract": "We describe QUEST, an open source framework for machine translation quality estimation. The framework allows the extraction of several quality indicators from source segments, their translations, external resources (corpora, language models, topic models, etc.), as well as language tools (parsers, part-of-speech tags, etc.). It also provides machine learning algorithms to build quality estimation models. We benchmark the framework on a number of datasets and discuss the efficacy of features and algorithms.", "year": 2013, "referenceCount": 13, "citationCount": 210, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1702974", "name": "Lucia Specia"}, {"authorId": "39888194", "name": "Kashif Shah"}, {"authorId": "34876539", "name": "Jos\u00e9 G. C. de Souza"}, {"authorId": "143620680", "name": "Trevor Cohn"}]}, {"paperId": "f6d918d1c9b7bb1e45b9ca750bd9618bf8ef4ad7", "url": "https://www.semanticscholar.org/paper/f6d918d1c9b7bb1e45b9ca750bd9618bf8ef4ad7", "title": "Crop yield prediction using machine learning: A systematic literature review", "abstract": null, "year": 2020, "referenceCount": 75, "citationCount": 221, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1944680782", "name": "Thomas van Klompenburg"}, {"authorId": "2805164", "name": "A. Kassahun"}, {"authorId": "3213443", "name": "C. Catal"}]}, {"paperId": "37f239603ce77e8f10be255be0a2cff7070122ad", "url": "https://www.semanticscholar.org/paper/37f239603ce77e8f10be255be0a2cff7070122ad", "title": "Enhancing gravitational-wave science with machine learning", "abstract": "Machine learning has emerged as a popular and powerful approach for solving problems in astrophysics. We review applications of machine learning techniques for the analysis of ground-based gravitational-wave (GW) detector data. Examples include techniques for improving the sensitivity of Advanced Laser Interferometer GW Observatory and Advanced Virgo GW searches, methods for fast measurements of the astrophysical parameters of GW sources, and algorithms for reduction and characterization of non-astrophysical detector noise. These applications demonstrate how machine learning techniques may be harnessed to enhance the science that is possible with current and future GW detectors.", "year": 2020, "referenceCount": 227, "citationCount": 74, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "114728464", "name": "E. Cuoco"}, {"authorId": "152265306", "name": "J. Powell"}, {"authorId": "3180530", "name": "M. Cavagli\u00e0"}, {"authorId": "134237646", "name": "K. Ackley"}, {"authorId": "41186371", "name": "M. Bejger"}, {"authorId": "103378230", "name": "C. Chatterjee"}, {"authorId": "1380955296", "name": "M. Coughlin"}, {"authorId": "39507823", "name": "S. Coughlin"}, {"authorId": "1380288971", "name": "P. Easter"}, {"authorId": "114667899", "name": "R. Essick"}, {"authorId": "82620197", "name": "H. Gabbard"}, {"authorId": "143733079", "name": "Timothy D. Gebhard"}, {"authorId": "49870703", "name": "Shaon Ghosh"}, {"authorId": "1381205122", "name": "L. Haegel"}, {"authorId": "51918071", "name": "A. Iess"}, {"authorId": "94813340", "name": "D. Keitel"}, {"authorId": "40412024", "name": "Z. Marka"}, {"authorId": "50184636", "name": "S. M\u00e1rka"}, {"authorId": "151001524", "name": "F. Morawski"}, {"authorId": "2116108017", "name": "Tri Nguyen"}, {"authorId": "121389315", "name": "R. Ormiston"}, {"authorId": "2066063815", "name": "M. Puerrer"}, {"authorId": "69036661", "name": "M. Razzano"}, {"authorId": "47023388", "name": "K. Staats"}, {"authorId": "3051130", "name": "G. Vajente"}, {"authorId": "2152726806", "name": "Daniel Williams"}]}, {"paperId": "6804cfe98379f00d9fe304babc66677114201d82", "url": "https://www.semanticscholar.org/paper/6804cfe98379f00d9fe304babc66677114201d82", "title": "A quantum-inspired classical algorithm for recommendation systems", "abstract": "We give a classical analogue to Kerenidis and Prakash\u2019s quantum recommendation system, previously believed to be one of the strongest candidates for provably exponential speedups in quantum machine learning. Our main result is an algorithm that, given an m \u00d7 n matrix in a data structure supporting certain \u21132-norm sampling operations, outputs an \u21132-norm sample from a rank-k approximation of that matrix in time O(poly(k)log(mn)), only polynomially slower than the quantum algorithm. As a consequence, Kerenidis and Prakash\u2019s algorithm does not in fact give an exponential speedup over classical algorithms. Further, under strong input assumptions, the classical recommendation system resulting from our algorithm produces recommendations exponentially faster than previous classical systems, which run in time linear in m and n. The main insight of this work is the use of simple routines to manipulate \u21132-norm sampling distributions, which play the role of quantum superpositions in the classical setting. This correspondence indicates a potentially fruitful framework for formally comparing quantum machine learning algorithms to classical machine learning algorithms.", "year": 2018, "referenceCount": 29, "citationCount": 224, "influentialCitationCount": 22, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "5831431", "name": "Ewin Tang"}]}, {"paperId": "ca914bd3cfced5f10907d642b2d64b2f9260d67d", "url": "https://www.semanticscholar.org/paper/ca914bd3cfced5f10907d642b2d64b2f9260d67d", "title": "Machine Learning for Quantum Mechanical Properties of Atoms in Molecules", "abstract": "We introduce machine learning models of quantum mechanical observables of atoms in molecules. Instant out-of-sample predictions for proton and carbon nuclear chemical shifts, atomic core level excitations, and forces on atoms reach accuracies on par with density functional theory reference. Locality is exploited within nonlinear regression via local atom-centered coordinate systems. The approach is validated on a diverse set of 9 k small organic molecules. Linear scaling of computational cost in system size is demonstrated for saturated polymers with up to submesoscale lengths.", "year": 2015, "referenceCount": 45, "citationCount": 158, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Physics"], "authors": [{"authorId": "48041657", "name": "M. Rupp"}, {"authorId": "6781829", "name": "R. Ramakrishnan"}, {"authorId": "11615881", "name": "O. A. V. Lilienfeld"}]}, {"paperId": "7fd672653caaf3876b7fea945c65b250eeaad912", "url": "https://www.semanticscholar.org/paper/7fd672653caaf3876b7fea945c65b250eeaad912", "title": "scikit-survival: A Library for Time-to-Event Analysis Built on Top of scikit-learn", "abstract": "scikit-survival is an open-source Python package for time-to-event analysis fully compatible with scikit-learn. It provides implementations of many popular machine learning techniques for time-to-event analysis, including penalized Cox model, Random Survival Forest, and Survival Support Vector Machine. In addition, the library includes tools to evaluate model performance on censored time-to-event data. The documentation contains installation instructions, interactive notebooks, and a full description of the API. scikit-survival is distributed under the GPL-3 license with the source code and detailed instructions available at https://github.com/sebp/scikit-survival", "year": 2020, "referenceCount": 17, "citationCount": 89, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1852286", "name": "Sebastian P\u00f6lsterl"}]}, {"paperId": "192e7880535131f28b76a4bb6936105c45c6f485", "url": "https://www.semanticscholar.org/paper/192e7880535131f28b76a4bb6936105c45c6f485", "title": "Can Children Understand Machine Learning Concepts?: The Effect of Uncovering Black Boxes", "abstract": "Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children's understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children's interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them.", "year": 2019, "referenceCount": 44, "citationCount": 65, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "19190271", "name": "Tom Hitron"}, {"authorId": "17787357", "name": "Yoav Orlev"}, {"authorId": "40521060", "name": "I. Wald"}, {"authorId": "2947946", "name": "Ariel Shamir"}, {"authorId": "49983945", "name": "H. Erel"}, {"authorId": "1790753", "name": "Oren Zuckerman"}]}, {"paperId": "8058d7aa0b6d0bb046c725f3b17788b66aa3f320", "url": "https://www.semanticscholar.org/paper/8058d7aa0b6d0bb046c725f3b17788b66aa3f320", "title": "A machine learning approach against a masked AES", "abstract": null, "year": 2013, "referenceCount": 54, "citationCount": 147, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "39319437", "name": "Liran Lerman"}, {"authorId": "1772497", "name": "Gianluca Bontempi"}, {"authorId": "1802747", "name": "O. Markowitch"}]}, {"paperId": "c2c52ccca6981b52c9a4dfa02da430da3d0fd121", "url": "https://www.semanticscholar.org/paper/c2c52ccca6981b52c9a4dfa02da430da3d0fd121", "title": "Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments", "abstract": "We propose strategies to estimate and make inference on key features of heterogeneous effects in randomized experiments. These key features include best linear predictors of the effects using machine learning proxies, average effects sorted by impact groups, and average characteristics of most and least impacted units. The approach is valid in high dimensional settings, where the effects are proxied by machine learning methods. We post-process these proxies into the estimates of the key features. Our approach is generic, it can be used in conjunction with penalized methods, deep and shallow neural networks, canonical and new random forests, boosted trees, and ensemble methods. Our approach is agnostic and does not make unrealistic or hard-to-check assumptions; we don\u2019t require conditions for consistency of the ML methods. Estimation and inference relies on repeated data splitting to avoid overfitting and achieve validity. For inference, we take medians of p-values and medians of confidence intervals, resulting from many different data splits, and then adjust their nominal level to guarantee uniform validity. This variational inference method is shown to be uniformly valid and quantifies the uncertainty coming from both parameter estimation and data splitting. The inference method could be of substantial independent interest in many machine learning applications. An empirical application to the impact of micro-credit on economic development illustrates the use of the approach in randomized experiments. An additional application to the impact of the gender discrimination on wages illustrates the potential use of the approach in observational studies, where machine learning methods can be used to condition flexibly on very high-dimensional controls.", "year": 2017, "referenceCount": 100, "citationCount": 152, "influentialCitationCount": 51, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Economics", "Computer Science"], "authors": [{"authorId": "26331346", "name": "V. Chernozhukov"}, {"authorId": "88741890", "name": "Mert Demirer"}, {"authorId": "2259683", "name": "E. Duflo"}, {"authorId": "1388539993", "name": "Iv\u00e1n Fern\u00e1ndez-Val"}]}, {"paperId": "990a17a9f9d02bf489a25e2e2980fab4e6f52642", "url": "https://www.semanticscholar.org/paper/990a17a9f9d02bf489a25e2e2980fab4e6f52642", "title": "Asynchronous Distributed ADMM for Consensus Optimization", "abstract": "Distributed optimization algorithms are highly attractive for solving big data problems. In particular, many machine learning problems can be formulated as the global consensus optimization problem, which can then be solved in a distributed manner by the alternating direction method of multipliers (ADMM) algorithm. However, this suffers from the straggler problem as its updates have to be synchronized. In this paper, we propose an asynchronous ADMM algorithm by using two conditions to control the asynchrony: partial barrier and bounded delay. The proposed algorithm has a simple structure and good convergence guarantees (its convergence rate can be reduced to that of its synchronous counterpart). Experiments on different distributed ADMM applications show that asynchrony reduces the time on network waiting, and achieves faster convergence than its synchronous counterpart in terms of the wall clock time.", "year": 2014, "referenceCount": 24, "citationCount": 325, "influentialCitationCount": 25, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109972030", "name": "Ruiliang Zhang"}, {"authorId": "145193332", "name": "J. Kwok"}]}, {"paperId": "968ddce1daf30c0e6f6fc4cd7dd07e793f51e833", "url": "https://www.semanticscholar.org/paper/968ddce1daf30c0e6f6fc4cd7dd07e793f51e833", "title": "Theory of Convex Optimization for Machine Learning", "abstract": "This monograph presents the main mathematical ideas in convex optimization. Starting from the fundamental theory of black-box optimization, the material progresses towards recent advances in structural optimization and stochastic optimization. Our presentation of black-box optimization, strongly influenced by the seminal book of Nesterov, includes the analysis of the Ellipsoid Method, as well as (accelerated) gradient descent schemes. We also pay special attention to non-Euclidean settings (relevant algorithms include Frank-Wolfe, Mirror Descent, and Dual Averaging) and discuss their relevance in machine learning. We provide a gentle introduction to structural optimization with FISTA (to optimize a sum of a smooth and a simple non-smooth term), Saddle-Point Mirror Prox (Nemirovski's alternative to Nesterov's smoothing), and a concise description of Interior Point Methods. In stochastic optimization we discuss Stochastic Gradient Descent, mini-batches, Random Coordinate Descent, and sublinear algorithms. We also briefly touch upon convex relaxation of combinatorial problems and the use of randomness to round solutions, as well as random walks based methods.", "year": 2014, "referenceCount": 54, "citationCount": 98, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1815542", "name": "S\u00e9bastien Bubeck"}]}, {"paperId": "dbbb3272236a3188b7332ff929627bb7414e6e68", "url": "https://www.semanticscholar.org/paper/dbbb3272236a3188b7332ff929627bb7414e6e68", "title": "Unsupervised and Semi-Supervised Multi-Class Support Vector Machines", "abstract": "We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion: find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.", "year": 2005, "referenceCount": 23, "citationCount": 166, "influentialCitationCount": 16, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2230211", "name": "Linli Xu"}, {"authorId": "1714772", "name": "Dale Schuurmans"}]}, {"paperId": "59444b096f7c8a561d540102e8b5bfb189edabc6", "url": "https://www.semanticscholar.org/paper/59444b096f7c8a561d540102e8b5bfb189edabc6", "title": "Perspectives on the Impact of Machine Learning, Deep Learning, and Artificial Intelligence on Materials, Processes, and Structures Engineering", "abstract": null, "year": 2018, "referenceCount": 216, "citationCount": 147, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": null, "authors": [{"authorId": "4022088", "name": "D. Dimiduk"}, {"authorId": "3163251", "name": "E. Holm"}, {"authorId": "1969237", "name": "S. Niezgoda"}]}, {"paperId": "cd8e4c9d01615d86c0f1c0a5a9ebf1b2a64f62f8", "url": "https://www.semanticscholar.org/paper/cd8e4c9d01615d86c0f1c0a5a9ebf1b2a64f62f8", "title": "Imputation of Missing Data Using Machine Learning Techniques", "abstract": "A serious problem in mining industrial data bases is that they are often incomplete, and a significant amount of data is missing, or erroneously entered. This paper explores the use of machine-learning based alternatives to standard statistical data completion (data imputation) methods, for dealing with missing data. We have approached the data completion problem using two well-known machine learning techniques. The first is an unsupervised clustering strategy which uses a Bayesian approach to cluster the data into classes. The classes so obtained are then used to predict multiple choices for the attribute of interest. The second technique involves modeling missing variables by supervised induction of a decision tree-based classifier. This predicts the most likely value for the attribute of interest. Empirical tests using extracts from industrial databases maintained by Honeywell customers have been done in order to compare the two techniques. These tests show both approaches are useful and have advantages and disadvantages. We argue that the choice between unsupervised and supervised classification techniques should be influenced by the motivation for solving the missing data problem, and discuss potential applications for the procedures we are developing.", "year": 1996, "referenceCount": 8, "citationCount": 142, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1831282", "name": "K. Lakshminarayan"}, {"authorId": "1685484", "name": "S. Harp"}, {"authorId": "2473054", "name": "R. Goldman"}, {"authorId": "47083033", "name": "T. Samad"}]}, {"paperId": "72d905475e7b822e90b02b96b89db42259615812", "url": "https://www.semanticscholar.org/paper/72d905475e7b822e90b02b96b89db42259615812", "title": "Atmospheric Temperature Prediction using Support Vector Machines", "abstract": "\u2014Weather prediction is a challenging task for researchers and has drawn a lot of research interest in the recent years. Literature studies have shown that machine learning techniques achieved better performance than traditional statistical methods. This paper presents an application of Support Vector Machines (SVMs) for weather prediction. Time series data of daily maximum temperature at a location is analyzed to predict the maximum temperature of the next day at that location based on the daily maximum temperatures for a span of previous n days referred to as order of the input. Performance of the system is observed over various spans of 2 to 10 days by using optimal values of the kernel function. Non linear regression method is found to be suitable to train the SVM for this application. The results are compared with Multi Layer Perceptron (MLP) trained with back-propagation algorithm and the performance of SVM is found to be consistently better.", "year": 2009, "referenceCount": 13, "citationCount": 274, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3382818", "name": "Y. Radhika"}, {"authorId": "144078801", "name": "M. Shashi"}]}, {"paperId": "8077a34c426acff10f0717c0cf0b99958fc3c5ed", "url": "https://www.semanticscholar.org/paper/8077a34c426acff10f0717c0cf0b99958fc3c5ed", "title": "AUTOMATIC TEXT CLASSIFICATION: A TECHNICAL REVIEW", "abstract": "Automatic Text Classification is a semi-supervised machine learning task that automatically assigns a given document to a set of pre-defined categories based on its textual content and extracted features. Automatic Text Classification has important applications in content management, contextual search, opinion mining, product review analysis, spam filtering and text sentiment mining. This paper explains the generic strategy for automatic text classification and surveys existing solutions to major issues such as dealing with unstructured text, handling large number of attributes and selecting a machine learning technique appropriate to the text-classification application.", "year": 2011, "referenceCount": 32, "citationCount": 160, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "36244416", "name": "M. K. Dalal"}, {"authorId": "144123655", "name": "M. Zaveri"}]}, {"paperId": "4f00b72bc7d62b363f12e54843e9166fd27bef0f", "url": "https://www.semanticscholar.org/paper/4f00b72bc7d62b363f12e54843e9166fd27bef0f", "title": "Epileptic Seizures Prediction Using Machine Learning Methods", "abstract": "Epileptic seizures occur due to disorder in brain functionality which can affect patient's health. Prediction of epileptic seizures before the beginning of the onset is quite useful for preventing the seizure by medication. Machine learning techniques and computational methods are used for predicting epileptic seizures from Electroencephalograms (EEG) signals. However, preprocessing of EEG signals for noise removal and features extraction are two major issues that have an adverse effect on both anticipation time and true positive prediction rate. Therefore, we propose a model that provides reliable methods of both preprocessing and feature extraction. Our model predicts epileptic seizures' sufficient time before the onset of seizure starts and provides a better true positive rate. We have applied empirical mode decomposition (EMD) for preprocessing and have extracted time and frequency domain features for training a prediction model. The proposed model detects the start of the preictal state, which is the state that starts few minutes before the onset of the seizure, with a higher true positive rate compared to traditional methods, 92.23%, and maximum anticipation time of 33 minutes and average prediction time of 23.6 minutes on scalp EEG CHB-MIT dataset of 22 subjects.", "year": 2017, "referenceCount": 34, "citationCount": 95, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "5845405", "name": "Syed Muhammad Usman"}, {"authorId": "2143664793", "name": "Muhammad Usman"}, {"authorId": "143601468", "name": "S. Fong"}]}, {"paperId": "0a60ee396e9585ba7610e49bd9906a3d4f9401ab", "url": "https://www.semanticscholar.org/paper/0a60ee396e9585ba7610e49bd9906a3d4f9401ab", "title": "Advances in quantum machine learning", "abstract": "Here we discuss advances in the field of quantum machine learning. The following document offers a hybrid discussion; both reviewing the field as it is currently, and suggesting directions for further research. We include both algorithms and experimental implementations in the discussion. The field's outlook is generally positive, showing significant promise. However, we believe there are appreciable hurdles to overcome before one can claim that it is a primary application of quantum computation.", "year": 2015, "referenceCount": 94, "citationCount": 65, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Computer Science"], "authors": [{"authorId": "51182322", "name": "J. Adcock"}, {"authorId": "51182301", "name": "E. Allen"}, {"authorId": "2065542441", "name": "Matthew L. Day"}, {"authorId": "2060665530", "name": "S. Frick"}, {"authorId": "37039701", "name": "J. Hinchliff"}, {"authorId": "2124469255", "name": "Mack Johnson"}, {"authorId": "1403854914", "name": "S. Morley-Short"}, {"authorId": "41078318", "name": "S. Pallister"}, {"authorId": "35817604", "name": "A. Price"}, {"authorId": "46258497", "name": "S. Stanisic"}]}, {"paperId": "6f79e82b19470a78eb1f597e1662674b9320a6d9", "url": "https://www.semanticscholar.org/paper/6f79e82b19470a78eb1f597e1662674b9320a6d9", "title": "GamePad: A Learning Environment for Theorem Proving", "abstract": "In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.", "year": 2018, "referenceCount": 27, "citationCount": 73, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "46307329", "name": "Daniel Huang"}, {"authorId": "6515819", "name": "Prafulla Dhariwal"}, {"authorId": "143711382", "name": "D. Song"}, {"authorId": "1701686", "name": "Ilya Sutskever"}]}, {"paperId": "486c93a171650cdf1fff68cbbe646393517fca36", "url": "https://www.semanticscholar.org/paper/486c93a171650cdf1fff68cbbe646393517fca36", "title": "Variational Quantum Circuits for Deep Reinforcement Learning", "abstract": "The state-of-the-art machine learning approaches are based on classical von Neumann computing architectures and have been widely used in many industrial and academic domains. With the recent development of quantum computing, researchers and tech-giants have attempted new quantum circuits for machine learning tasks. However, the existing quantum computing platforms are hard to simulate classical deep learning models or problems because of the intractability of deep quantum circuits. Thus, it is necessary to design feasible quantum algorithms for quantum machine learning for noisy intermediate scale quantum (NISQ) devices. This work explores variational quantum circuits for deep reinforcement learning. Specifically, we reshape classical deep reinforcement learning algorithms like experience replay and target network into a representation of variational quantum circuits. Moreover, we use a quantum information encoding scheme to reduce the number of model parameters compared to classical neural networks. To the best of our knowledge, this work is the first proof-of-principle demonstration of variational quantum circuits to approximate the deep $Q$ -value function for decision-making and policy-selection reinforcement learning with experience replay and target network. Besides, our variational quantum circuits can be deployed in many near-term NISQ machines.", "year": 2019, "referenceCount": 76, "citationCount": 105, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Mathematics"], "authors": [{"authorId": "2107968379", "name": "Samuel Yen-Chi Chen"}, {"authorId": "46962482", "name": "C. Yang"}, {"authorId": "145913380", "name": "Jun Qi"}, {"authorId": "153191489", "name": "Pin-Yu Chen"}, {"authorId": "2116287993", "name": "Xiaoli Ma"}, {"authorId": "1865679", "name": "H. Goan"}]}, {"paperId": "40e5a40ae66d44e6c00d562d068d35db6922715d", "url": "https://www.semanticscholar.org/paper/40e5a40ae66d44e6c00d562d068d35db6922715d", "title": "Improving the Accuracy and Speed of Support Vector Machines", "abstract": "Support Vector Learning Machines (SVM) are finding application in pattern recognition, regression estimation, and operator inversion for ill-posed problems. Against this very general backdrop, any methods for improving the generalization performance, or for improving the speed in test phase, of SVMs are of increasing interest. In this paper we combine two such techniques on a pattern recognition problem. The method for improving generalization performance (the \"virtual support vector\" method) does so by incorporating known invariances of the problem. This method achieves a drop in the error rate on 10,000 NIST test digit images of 1.4% to 1.0%. The method for improving the speed (the \"reduced set\" method) does so by approximating the support vector decision surface. We apply this method to achieve a factor of fifty speedup in test phase over the virtual support vector machine. The combined approach yields a machine which is both 22 times faster than the original machine, and which has better generalization performance, achieving 1.1 % error. The virtual support vector method is applicable to any SVM problem with known invariances. The reduced set method is applicable to any support vector machine.", "year": 1996, "referenceCount": 10, "citationCount": 424, "influentialCitationCount": 30, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2676309", "name": "C. Burges"}, {"authorId": "1707625", "name": "B. Sch\u00f6lkopf"}]}, {"paperId": "1cf6a15921ee7377044e99a3d58c1d5ecef5da1b", "url": "https://www.semanticscholar.org/paper/1cf6a15921ee7377044e99a3d58c1d5ecef5da1b", "title": "Dynamic Multicore Resource Management: A Machine Learning Approach", "abstract": "A machine learning approach to multicore resource management produces self-optimizing on-chip hardware agents capable of learning, planning, and continuously adapting to changing workload demands. Machine learning is the study of computer programs and algorithms that learn about their environment and improve automatically with experience.This approach thus contrasts with today's predominant approach of directly specifying at design time how the hardware should accomplish the desired goal. This results in more efficient and flexible management of critical hardware resources at runtime.", "year": 2009, "referenceCount": 28, "citationCount": 78, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109798451", "name": "Jos\u00e9 F. Mart\u00ednez"}, {"authorId": "1787439", "name": "Engin Ipek"}]}, {"paperId": "21ae9d6358ee090162b10d3a9da43e0d85ef4c7e", "url": "https://www.semanticscholar.org/paper/21ae9d6358ee090162b10d3a9da43e0d85ef4c7e", "title": "Design pattern mining enhanced by machine learning", "abstract": "Design patterns present good solutions to frequently occurring problems in object-oriented software design. Thus their correct application in a system's design may significantly improve its internal quality attributes such as reusability and maintainability. In software maintenance the existence of up-to-date documentation is crucial, so the discovery of as yet unknown design pattern instances can help improve the documentation. Hence a reliable design pattern recognition system is very desirable. However, simpler methods (based on pattern matching) may give imprecise results due to the vague nature of the patterns' structural description. In previous work we presented a pattern matching-based system using the Columbus framework with which we were able to find pattern instances from the source code by considering the patterns' structural descriptions only, and therefore we could not identify false hits and distinguish similar design patterns such as state and strategy. In the present work we use machine learning to enhance pattern mining by filtering out as many false hits as possible. To do so we distinguish true and false pattern instances with the help of a learning database created by manually tagging a large C++ system.", "year": 2005, "referenceCount": 27, "citationCount": 93, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3172077", "name": "R. Ferenc"}, {"authorId": "1752419", "name": "\u00c1rp\u00e1d Besz\u00e9des"}, {"authorId": "3025233", "name": "Lajos Jeno F\u00fcl\u00f6p"}, {"authorId": "46603077", "name": "Janos Lele"}]}, {"paperId": "05f39431776d2b8858132b2118b68a6a68bf4f14", "url": "https://www.semanticscholar.org/paper/05f39431776d2b8858132b2118b68a6a68bf4f14", "title": "Revolt: Collaborative Crowdsourcing for Labeling Machine Learning Datasets", "abstract": "Crowdsourcing provides a scalable and efficient way to construct labeled datasets for training machine learning systems. However, creating comprehensive label guidelines for crowdworkers is often prohibitive even for seemingly simple concepts. Incomplete or ambiguous label guidelines can then result in differing interpretations of concepts and inconsistent labels. Existing approaches for improving label quality, such as worker screening or detection of poor work, are ineffective for this problem and can lead to rejection of honest work and a missed opportunity to capture rich interpretations about data. We introduce Revolt, a collaborative approach that brings ideas from expert annotation workflows to crowd-based labeling. Revolt eliminates the burden of creating detailed label guidelines by harnessing crowd disagreements to identify ambiguous concepts and create rich structures (groups of semantically related items) for post-hoc label decisions. Experiments comparing Revolt to traditional crowdsourced labeling show that Revolt produces high quality labels without requiring label guidelines in turn for an increase in monetary cost. This up front cost, however, is mitigated by Revolt's ability to produce reusable structures that can accommodate a variety of label boundaries without requiring new data to be collected. Further comparisons of Revolt's collaborative and non-collaborative variants show that collaboration reaches higher label accuracy with lower monetary cost.", "year": 2017, "referenceCount": 61, "citationCount": 170, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "48808806", "name": "Joseph Chee Chang"}, {"authorId": "1719124", "name": "Saleema Amershi"}, {"authorId": "1783184", "name": "Ece Kamar"}]}, {"paperId": "57df42bf288114e0b98c0b02d2ba79efa2750135", "url": "https://www.semanticscholar.org/paper/57df42bf288114e0b98c0b02d2ba79efa2750135", "title": "Artificial intelligence approaches for rational drug design and discovery.", "abstract": "Pattern recognition, machine learning and artificial intelligence approaches play an increasingly important role in rational drug design, screening and identification of candidate molecules and studies on quantitative structure-activity relationships (QSAR). In this review, we present an overview of basic concepts and methodology in the fields of machine learning and artificial intelligence (AI). An emphasis is put on methods that enable an intuitive interpretation of the results and facilitate gaining an insight into the structure of the problem at hand. We also discuss representative applications of AI methods to docking, screening and QSAR studies. The growing trend to integrate computational and experimental efforts in that regard and some future developments are discussed. In addition, we comment on a broader role of machine learning and artificial intelligence approaches in biomedical research.", "year": 2007, "referenceCount": 124, "citationCount": 128, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1679601", "name": "Wlodzislaw Duch"}, {"authorId": "2368884", "name": "Karthikeyan Swaminathan"}, {"authorId": "49806460", "name": "J. Meller"}]}, {"paperId": "1e4694dd26047f7ca7ff11f851f48652f68c7bde", "url": "https://www.semanticscholar.org/paper/1e4694dd26047f7ca7ff11f851f48652f68c7bde", "title": "SAT Based Abstraction-Refinement Using ILP and Machine Learning Techniques", "abstract": null, "year": 2002, "referenceCount": 17, "citationCount": 160, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "143877541", "name": "E. Clarke"}, {"authorId": "2110761762", "name": "Anubhav Gupta"}, {"authorId": "3249755", "name": "J. Kukula"}, {"authorId": "1747890", "name": "O. Strichman"}]}, {"paperId": "c2dec7253ffd530689745bbacad04b4017996363", "url": "https://www.semanticscholar.org/paper/c2dec7253ffd530689745bbacad04b4017996363", "title": "Discovering phases, phase transitions, and crossovers through unsupervised machine learning: A critical examination.", "abstract": "We apply unsupervised machine learning techniques, mainly principal component analysis (PCA), to compare and contrast the phase behavior and phase transitions in several classical spin models-the square- and triangular-lattice Ising models, the Blume-Capel model, a highly degenerate biquadratic-exchange spin-1 Ising (BSI) model, and the two-dimensional XY model-and we examine critically what machine learning is teaching us. We find that quantified principal components from PCA not only allow the exploration of different phases and symmetry-breaking, but they can distinguish phase-transition types and locate critical points. We show that the corresponding weight vectors have a clear physical interpretation, which is particularly interesting in the frustrated models such as the triangular antiferromagnet, where they can point to incipient orders. Unlike the other well-studied models, the properties of the BSI model are less well known. Using both PCA and conventional Monte Carlo analysis, we demonstrate that the BSI model shows an absence of phase transition and macroscopic ground-state degeneracy. The failure to capture the \"charge\" correlations (vorticity) in the BSI model (XY model) from raw spin configurations points to some of the limitations of PCA. Finally, we employ a nonlinear unsupervised machine learning procedure, the \"autoencoder method,\" and we demonstrate that it too can be trained to capture phase transitions and critical points.", "year": 2017, "referenceCount": 82, "citationCount": 171, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Medicine"], "authors": [{"authorId": "13827135", "name": "Wenjian Hu"}, {"authorId": "49120926", "name": "Rajiv R. P. Singh"}, {"authorId": "2542621", "name": "R. Scalettar"}]}, {"paperId": "d609864662c40713a4b2df091a2bbf7b2b31c20f", "url": "https://www.semanticscholar.org/paper/d609864662c40713a4b2df091a2bbf7b2b31c20f", "title": "Intelligent Scheduling with Machine Learning Capabilities: The Induction of Scheduling Knowledge\u00a7", "abstract": "Abstract Dynamic scheduling of manufacturing systems has primarily involved the use of dispatching rules. In the context of conventional job shops, the relative performance of these rules has been found to depend upon the system attributes, and no single rule is dominant across all possible scenarios. This indicates die need for developing a scheduling approach which adopts a state-dependent dispatching rule selection policy. The importance of adapting the dispatching rule employed to the current state of the system is even more critical in a flexible manufacturing system because of alternative machine routing possibilities and me need for increased coordination among various machines. This study develops a framework for incorporating machine learning capabilities in intelligent scheduling. A pattern-directed method, with a built-in inductive learning module, is developed for heuristic acquisition and refinement. This method enables the scheduler to classify distinct manufacturing patterns and to generate...", "year": 1992, "referenceCount": 81, "citationCount": 139, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "145504307", "name": "M. Shaw"}, {"authorId": "46569913", "name": "Sang C. Park"}, {"authorId": "145548968", "name": "N. Raman"}]}]}