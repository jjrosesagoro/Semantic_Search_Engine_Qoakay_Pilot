{"total": 5798131, "offset": 300, "next": 400, "data": [{"paperId": "f743833c22961537791171ef1d3fb42db8f357a3", "url": "https://www.semanticscholar.org/paper/f743833c22961537791171ef1d3fb42db8f357a3", "title": "Machine Learning Methods for Attack Detection in the Smart Grid", "abstract": "Attack detection problems in the smart grid are posed as statistical learning problems for different attack scenarios in which the measurements are observed in batch or online settings. In this approach, machine learning algorithms are used to classify measurements as being either secure or attacked. An attack detection framework is provided to exploit any available prior knowledge about the system and surmount constraints arising from the sparse structure of the problem in the proposed approach. Well-known batch and online learning algorithms (supervised and semisupervised) are employed with decision- and feature-level fusion to model the attack detection problem. The relationships between statistical and geometric properties of attack vectors employed in the attack scenarios and learning algorithms are analyzed to detect unobservable attacks using statistical learning methods. The proposed algorithms are examined on various IEEE test systems. Experimental analyses show that machine learning algorithms can detect attacks with performances higher than attack detection algorithms that employ state vector estimation methods in the proposed attack detection framework.", "year": 2015, "referenceCount": 82, "citationCount": 352, "influentialCitationCount": 26, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2159942", "name": "M. Ozay"}, {"authorId": "2549673", "name": "I. Esnaola"}, {"authorId": "1398326708", "name": "F. Yarman-Vural"}, {"authorId": "1697413", "name": "S. Kulkarni"}, {"authorId": "145967056", "name": "H. Poor"}]}, {"paperId": "92ace17730c2173e642934d64f96d359697b7a93", "url": "https://www.semanticscholar.org/paper/92ace17730c2173e642934d64f96d359697b7a93", "title": "Bayesian reasoning and machine learning", "abstract": "Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.", "year": 2012, "referenceCount": 323, "citationCount": 1386, "influentialCitationCount": 143, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145617808", "name": "D. Barber"}]}, {"paperId": "f15367ed93c3505b1d62d802f3f4b769ae0f4ba5", "url": "https://www.semanticscholar.org/paper/f15367ed93c3505b1d62d802f3f4b769ae0f4ba5", "title": "Machine learning for neuroimaging with scikit-learn", "abstract": "Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g., multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g., resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain.", "year": 2014, "referenceCount": 42, "citationCount": 1057, "influentialCitationCount": 91, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics", "Medicine"], "authors": [{"authorId": "2958954", "name": "A. Abraham"}, {"authorId": "2570016", "name": "Fabian Pedregosa"}, {"authorId": "1823753", "name": "Michael Eickenberg"}, {"authorId": "1643887240", "name": "Philippe Gervais"}, {"authorId": "2086994888", "name": "Andreas Mueller"}, {"authorId": "3125761", "name": "Jean Kossaifi"}, {"authorId": "1797840", "name": "Alexandre Gramfort"}, {"authorId": "8493461", "name": "B. Thirion"}, {"authorId": "3025780", "name": "G. Varoquaux"}]}, {"paperId": "dbde7dfa6cae81df8ac19ef500c42db96c3d1edd", "url": "https://www.semanticscholar.org/paper/dbde7dfa6cae81df8ac19ef500c42db96c3d1edd", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", "abstract": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.", "year": 2016, "referenceCount": 53, "citationCount": 5113, "influentialCitationCount": 388, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "48607963", "name": "Yonghui Wu"}, {"authorId": "144927151", "name": "M. Schuster"}, {"authorId": "2545358", "name": "Z. Chen"}, {"authorId": "2827616", "name": "Quoc V. Le"}, {"authorId": "144739074", "name": "Mohammad Norouzi"}, {"authorId": "3153147", "name": "Wolfgang Macherey"}, {"authorId": "2048712", "name": "M. Krikun"}, {"authorId": "145144022", "name": "Yuan Cao"}, {"authorId": "145312180", "name": "Qin Gao"}, {"authorId": "113439369", "name": "Klaus Macherey"}, {"authorId": "2367620", "name": "J. Klingner"}, {"authorId": "145825976", "name": "Apurva Shah"}, {"authorId": "145657834", "name": "Melvin Johnson"}, {"authorId": "2109059862", "name": "Xiaobing Liu"}, {"authorId": "40527594", "name": "Lukasz Kaiser"}, {"authorId": "2776283", "name": "Stephan Gouws"}, {"authorId": "2739610", "name": "Y. Kato"}, {"authorId": "1765329", "name": "Taku Kudo"}, {"authorId": "1754386", "name": "H. Kazawa"}, {"authorId": "144077726", "name": "K. Stevens"}, {"authorId": "1753079661", "name": "George Kurian"}, {"authorId": "2056800684", "name": "Nishant Patil"}, {"authorId": "49337181", "name": "Wei Wang"}, {"authorId": "39660914", "name": "C. Young"}, {"authorId": "2119125158", "name": "Jason R. Smith"}, {"authorId": "2909504", "name": "Jason Riesa"}, {"authorId": "29951847", "name": "Alex Rudnick"}, {"authorId": "1689108", "name": "Oriol Vinyals"}, {"authorId": "32131713", "name": "G. Corrado"}, {"authorId": "48342565", "name": "Macduff Hughes"}, {"authorId": "49959210", "name": "J. Dean"}]}, {"paperId": "765d93759b7888fa1f7b2f3576809ad558c60caf", "url": "https://www.semanticscholar.org/paper/765d93759b7888fa1f7b2f3576809ad558c60caf", "title": "Machine-learning-assisted materials discovery using failed experiments", "abstract": null, "year": 2016, "referenceCount": 45, "citationCount": 834, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "3430287", "name": "Paul Raccuglia"}, {"authorId": "5219966", "name": "Katherine C. Elbert"}, {"authorId": "2058592864", "name": "Philip Adler"}, {"authorId": "38601860", "name": "Casey Falk"}, {"authorId": "9616758", "name": "Malia B. Wenny"}, {"authorId": "48742335", "name": "Aurelio Mollo"}, {"authorId": "1885911", "name": "M. Zeller"}, {"authorId": "34597147", "name": "Sorelle A. Friedler"}, {"authorId": "49916345", "name": "Joshua Schrier"}, {"authorId": "5787497", "name": "A. Norquist"}]}, {"paperId": "d68725804eadecf83d707d89e12c5132bf376187", "url": "https://www.semanticscholar.org/paper/d68725804eadecf83d707d89e12c5132bf376187", "title": "Sparse Bayesian Learning and the Relevance Vector Machine", "abstract": null, "year": 2001, "referenceCount": 21, "citationCount": 4649, "influentialCitationCount": 1029, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "70345806", "name": "George Eastman House"}, {"authorId": "117676260", "name": "Guildhall StreetCambridge"}]}, {"paperId": "ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7", "url": "https://www.semanticscholar.org/paper/ebe14ab38c7bc8187737c8aed7fef3d7cd2becf7", "title": "Machine Learning methods for Quantitative Radiomic Biomarkers", "abstract": null, "year": 2015, "referenceCount": 53, "citationCount": 667, "influentialCitationCount": 20, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "40470674", "name": "C. Parmar"}, {"authorId": "49405431", "name": "P. Grossmann"}, {"authorId": "48938629", "name": "J. Bussink"}, {"authorId": "1693233", "name": "P. Lambin"}, {"authorId": "143849569", "name": "H. Aerts"}]}, {"paperId": "32e29041fa352a9df0889f42807ed6141bc0b5ff", "url": "https://www.semanticscholar.org/paper/32e29041fa352a9df0889f42807ed6141bc0b5ff", "title": "Machine learning in geosciences and remote sensing", "abstract": null, "year": 2016, "referenceCount": 87, "citationCount": 580, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46965265", "name": "David John Lary"}, {"authorId": "8422959", "name": "A. Alavi"}, {"authorId": "1764455", "name": "A. Gandomi"}, {"authorId": "50640741", "name": "A. Walker"}]}, {"paperId": "a09a9f69ff145508a12e6dbb81ccd7f5be4bd2fc", "url": "https://www.semanticscholar.org/paper/a09a9f69ff145508a12e6dbb81ccd7f5be4bd2fc", "title": "Machine Learning for High-Throughput Stress Phenotyping in Plants.", "abstract": null, "year": 2016, "referenceCount": 84, "citationCount": 531, "influentialCitationCount": 11, "isOpenAccess": true, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "1712215532", "name": "Arti Singh"}, {"authorId": "3042938", "name": "B. Ganapathysubramanian"}, {"authorId": "152395021", "name": "Asheesh K Singh"}, {"authorId": "144016196", "name": "S. Sarkar"}]}, {"paperId": "bf5cf36407ece2569f0717f2b5593c4bd2140ebb", "url": "https://www.semanticscholar.org/paper/bf5cf36407ece2569f0717f2b5593c4bd2140ebb", "title": "Machine Learning for Predictive Maintenance: A Multiple Classifier Approach", "abstract": "In this paper, a multiple classifier machine learning (ML) methodology for predictive maintenance (PdM) is presented. PdM is a prominent strategy for dealing with maintenance issues given the increasing need to minimize downtime and associated costs. One of the challenges with PdM is generating the so-called \u201chealth factors,\u201d or quantitative indicators, of the status of a system associated with a given maintenance issue, and determining their relationship to operating costs and failure risk. The proposed PdM methodology allows dynamical decision rules to be adopted for maintenance management, and can be used with high-dimensional and censored data problems. This is achieved by training multiple classification modules with different prediction horizons to provide different performance tradeoffs in terms of frequency of unexpected breaks and unexploited lifetime, and then employing this information in an operating cost-based maintenance decision system to minimize expected costs. The effectiveness of the methodology is demonstrated using a simulated example and a benchmark semiconductor manufacturing maintenance problem.", "year": 2015, "referenceCount": 31, "citationCount": 446, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "3126083", "name": "Gian Antonio Susto"}, {"authorId": "2979820", "name": "A. Schirru"}, {"authorId": "2383035", "name": "S. Pampuri"}, {"authorId": "48147378", "name": "S. McLoone"}, {"authorId": "1744705", "name": "A. Beghi"}]}, {"paperId": "f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "url": "https://www.semanticscholar.org/paper/f35de4f9b1a7c4d3fa96a0d2ab1bf8937671f6b6", "title": "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning", "abstract": "Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs -- extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout's uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout's uncertainty in deep reinforcement learning.", "year": 2015, "referenceCount": 56, "citationCount": 5307, "influentialCitationCount": 952, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2681954", "name": "Y. Gal"}, {"authorId": "1744700", "name": "Zoubin Ghahramani"}]}, {"paperId": "be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6", "url": "https://www.semanticscholar.org/paper/be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6", "title": "Matching Networks for One Shot Learning", "abstract": "Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.", "year": 2016, "referenceCount": 34, "citationCount": 4426, "influentialCitationCount": 1073, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "1689108", "name": "Oriol Vinyals"}, {"authorId": "1723876", "name": "C. Blundell"}, {"authorId": "2542999", "name": "T. Lillicrap"}, {"authorId": "2645384", "name": "K. Kavukcuoglu"}, {"authorId": "1688276", "name": "Daan Wierstra"}]}, {"paperId": "a8797f1d253c75669d96e6fcceda2be3f8534e1d", "url": "https://www.semanticscholar.org/paper/a8797f1d253c75669d96e6fcceda2be3f8534e1d", "title": "Support Vector Machine Active Learning with Applications to Text Classification", "abstract": "Support vector machines have met with significant success in numerous real-world learning tasks. However, like most machine learning algorithms, they are generally applied using a randomly selected training set classified in advance. In many settings, we also have the option of using pool-based active learning. Instead of using a randomly selected training set, the learner has access to a pool of unlabeled instances and can request the labels for some number of them. We introduce a new algorithm for performing active learning with support vector machines, i.e., an algorithm for choosing which instances to request next. We provide a theoretical motivation for the algorithm using the notion of a version space. We present experimental results showing that employing our active learning method can significantly reduce the need for labeled training instances in both the standard inductive and transductive settings.", "year": 2002, "referenceCount": 37, "citationCount": 3250, "influentialCitationCount": 277, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2058177533", "name": "Simon Tong"}, {"authorId": "1736370", "name": "D. Koller"}]}, {"paperId": "f38513dc4350cfb987a8f0b774fc361c4d910a17", "url": "https://www.semanticscholar.org/paper/f38513dc4350cfb987a8f0b774fc361c4d910a17", "title": "Fundamentals of Machine Learning for Predictive Data Analytics: Algorithms, Worked Examples, and Case Studies", "abstract": "Machine learning is often used to build predictive models by extracting patterns from large datasets. These models are used in predictive data analytics applications including price prediction, risk assessment, predicting customer behavior, and document classification. This introductory textbook offers a detailed and focused treatment of the most important machine learning approaches used in predictive data analytics, covering both theoretical concepts and practical applications. Technical and mathematical material is augmented with explanatory worked examples, and case studies illustrate the application of these models in the broader business context. After discussing the trajectory from data to insight to decision, the book describes four approaches to machine learning: information-based learning, similarity-based learning, probability-based learning, and error-based learning. Each of these approaches is introduced by a nontechnical explanation of the underlying concept, followed by mathematical models and algorithms illustrated by detailed worked examples. Finally, the book considers techniques for evaluating prediction models and offers two case studies that describe specific data analytics projects through each phase of development, from formulating the business problem to implementation of the analytics solution. The book, informed by the authors' many years of teaching machine learning, and working on predictive data analytics projects, is suitable for use by undergraduates in computer science, engineering, mathematics, or statistics; by graduate students in disciplines with applications for predictive data analytics; and as a reference for professionals.", "year": 2015, "referenceCount": 283, "citationCount": 403, "influentialCitationCount": 38, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "34967075", "name": "John D. Kelleher"}, {"authorId": "7616304", "name": "Brian Mac Namee"}, {"authorId": "1409191033", "name": "Aoife D'Arcy"}]}, {"paperId": "73811a7f8b89de1b8bdad6bb938e58059a9076d3", "url": "https://www.semanticscholar.org/paper/73811a7f8b89de1b8bdad6bb938e58059a9076d3", "title": "Introduction to machine learning: k-nearest neighbors.", "abstract": "Machine learning techniques have been widely used in many scientific fields, but its use in medical literature is limited partly because of technical difficulties. k-nearest neighbors (kNN) is a simple method of machine learning. The article introduces some basic ideas underlying the kNN algorithm, and then focuses on how to perform kNN modeling with R. The dataset should be prepared before running the knn() function in R. After prediction of outcome with kNN algorithm, the diagnostic performance of the model should be checked. Average accuracy is the mostly widely used statistic to reflect the kNN algorithm. Factors such as k value, distance calculation and choice of appropriate predictors all have significant impact on the model performance.", "year": 2016, "referenceCount": 12, "citationCount": 308, "influentialCitationCount": 14, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "7969555", "name": "Zhongheng Zhang"}]}, {"paperId": "227e0591634cef50d0bcfc73fe6c5b34a2256e5f", "url": "https://www.semanticscholar.org/paper/227e0591634cef50d0bcfc73fe6c5b34a2256e5f", "title": "Radio Machine Learning Dataset Generation with GNU Radio", "abstract": "This paper surveys emerging applications of Machine Learning (ML) to the Radio Signal Processing domain. \u00a0Provides some brief background on enabling methods and discusses some of the potential advancements for the field. \u00a0It discusses the critical importance of good datasets for model learning, testing, and evaluation and introduces several public open source synthetic datasets for various radio machine learning tasks. \u00a0These are intended to provide a robust common baselines for those working in the field and to provide a benchmark measure against which many techniques can be rapidly evaluated and compared.", "year": 2016, "referenceCount": 21, "citationCount": 247, "influentialCitationCount": 31, "isOpenAccess": false, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "1388350203", "name": "Tim O'Shea"}, {"authorId": "145028728", "name": "Nathan E. West"}]}, {"paperId": "53b55682222692323a3a0d546d9e1a3de29454f0", "url": "https://www.semanticscholar.org/paper/53b55682222692323a3a0d546d9e1a3de29454f0", "title": "A review of supervised machine learning algorithms", "abstract": "Supervised machine learning is the construction of algorithms that are able to produce general patterns and hypotheses by using externally supplied instances to predict the fate of future instances. Supervised machine learning classification algorithms aim at categorizing data from prior information. Classification is carried out very frequently in data science problems. Various successful techniques have been proposed to solve such problems viz. Rule-based techniques, Logic-based techniques, Instance-based techniques, stochastic techniques. This paper discusses the efficacy of supervised machine learning algorithms in terms of the accuracy, speed of learning, complexity and risk of over fitting measures. The main objective of this paper is to provide a general comparison with state of art machine learning algorithms.", "year": 2016, "referenceCount": 2, "citationCount": 263, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2116287748", "name": "Amanpreet Singh"}, {"authorId": "2675918", "name": "Narina Thakur"}, {"authorId": "2109261490", "name": "Aakanksha Sharma"}]}, {"paperId": "aaa76e15235d937d093a7063c0be86ed84494dee", "url": "https://www.semanticscholar.org/paper/aaa76e15235d937d093a7063c0be86ed84494dee", "title": "Machine Learning: A Bayesian and Optimization Perspective", "abstract": "This tutorial text gives a unifying perspective on machine learning by covering bothprobabilistic and deterministic approaches -which are based on optimization techniques together with the Bayesian inference approach, whose essence liesin the use of a hierarchy of probabilistic models. The book presents the major machine learning methods as they have been developed in different disciplines, such as statistics, statistical and adaptive signal processing and computer science. Focusing on the physical reasoning behind the mathematics, all the various methods and techniques are explained in depth, supported by examples and problems, giving an invaluable resource to the student and researcher for understanding and applying machine learning concepts. The book builds carefully from the basic classical methods to the most recent trends, with chapters written to be as self-contained as possible, making the text suitable for different courses: pattern recognition, statistical/adaptive signal processing, statistical/Bayesian learning, as well as short courses on sparse modeling, deep learning, and probabilistic graphical models. All major classical techniques: Mean/Least-Squares regression and filtering, Kalman filtering, stochastic approximation and online learning, Bayesian classification, decision trees, logistic regression and boosting methods. The latest trends: Sparsity, convex analysis and optimization, online distributed algorithms, learning in RKH spaces, Bayesian inference, graphical and hidden Markov models, particle filtering, deep learning, dictionary learning and latent variables modeling. Case studies - protein folding prediction, optical character recognition, text authorship identification, fMRI data analysis, change point detection, hyperspectral image unmixing, target localization, channel equalization and echo cancellation, show how the theory can be applied. MATLAB code for all the main algorithms are available on an accompanying website, enabling the reader to experiment with the code.", "year": 2015, "referenceCount": 0, "citationCount": 389, "influentialCitationCount": 31, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9261284", "name": "S. Theodoridis"}]}, {"paperId": "596dac923657992a817d3d68ae83f2fba9cf1ab8", "url": "https://www.semanticscholar.org/paper/596dac923657992a817d3d68ae83f2fba9cf1ab8", "title": "An Introduction to MCMC for Machine Learning", "abstract": null, "year": 2004, "referenceCount": 169, "citationCount": 2413, "influentialCitationCount": 210, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "49630843", "name": "C. Andrieu"}, {"authorId": "1737568", "name": "N. D. Freitas"}, {"authorId": "1701800", "name": "A. Doucet"}, {"authorId": "1694621", "name": "Michael I. Jordan"}]}, {"paperId": "e5278af5fd3ac8796992cb291e23fa8d47b5460f", "url": "https://www.semanticscholar.org/paper/e5278af5fd3ac8796992cb291e23fa8d47b5460f", "title": "Kernel Methods for Machine Learning", "abstract": null, "year": 2015, "referenceCount": 1, "citationCount": 481, "influentialCitationCount": 34, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "7668649", "name": "Michael Rabadi"}]}, {"paperId": "ad0d1149875291d9b1177bc47e53e09237beeca0", "url": "https://www.semanticscholar.org/paper/ad0d1149875291d9b1177bc47e53e09237beeca0", "title": "Quantum-enhanced machine learning", "abstract": "The emerging field of quantum machine learning has the potential to substantially aid in the problems and scope of artificial intelligence. This is only enhanced by recent successes in the field of classical machine learning. In this work we propose an approach for the systematic treatment of machine learning, from the perspective of quantum information. Our approach is general and covers all three main branches of machine learning: supervised, unsupervised, and reinforcement learning. While quantum improvements in supervised and unsupervised learning have been reported, reinforcement learning has received much less attention. Within our approach, we tackle the problem of quantum enhancements in reinforcement learning as well, and propose a systematic scheme for providing improvements. As an example, we show that quadratic improvements in learning efficiency, and exponential improvements in performance over limited time periods, can be obtained for a broad class of learning problems.", "year": 2016, "referenceCount": 44, "citationCount": 225, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Computer Science", "Medicine"], "authors": [{"authorId": "2878563", "name": "V. Dunjko"}, {"authorId": "2110747638", "name": "Jacob M. Taylor"}, {"authorId": "32534184", "name": "H. Briegel"}]}, {"paperId": "9f86366feecbcfdf6c5be165fcf38c679164cc89", "url": "https://www.semanticscholar.org/paper/9f86366feecbcfdf6c5be165fcf38c679164cc89", "title": "Machine Learning and the Profession of Medicine.", "abstract": "This Viewpoint discusses the opportunities and ethical implications of using machine learning technologies, which can rapidly collect and learn from large amounts of personal data, to provide individalized patient care.", "year": 2016, "referenceCount": 10, "citationCount": 279, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "6120000", "name": "Alison M Darcy"}, {"authorId": "7172935", "name": "A. Louie"}, {"authorId": "34934943", "name": "L. Roberts"}]}, {"paperId": "9bbf8ca712bca3e93c898aea56d021a0317a30c1", "url": "https://www.semanticscholar.org/paper/9bbf8ca712bca3e93c898aea56d021a0317a30c1", "title": "Machine-learning approaches in drug discovery: methods and applications.", "abstract": null, "year": 2015, "referenceCount": 146, "citationCount": 458, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "4280352", "name": "A. Lavecchia"}]}, {"paperId": "a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e", "url": "https://www.semanticscholar.org/paper/a5d3a937e5ee43ab1542657ea2baf0c5cb139d6e", "title": "Faster and Better: A Machine Learning Approach to Corner Detection", "abstract": "The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is important because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection and, using machine learning, we derive a feature detector from this which can fully process live PAL video using less than 5 percent of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115 percent, SIFT 195 percent). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that, despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and of very high quality.", "year": 2008, "referenceCount": 112, "citationCount": 1713, "influentialCitationCount": 182, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1721991", "name": "E. Rosten"}, {"authorId": "145881323", "name": "R. Porter"}, {"authorId": "144418842", "name": "T. Drummond"}]}, {"paperId": "a73f4e905834f72ecd7e65c88aebebaea1153fd0", "url": "https://www.semanticscholar.org/paper/a73f4e905834f72ecd7e65c88aebebaea1153fd0", "title": "Data mining - practical machine learning tools and techniques, Second Edition", "abstract": "As with any burgeoning technology that enjoys commercial attention, the use of data mining is surrounded by a great deal of hype. Exaggerated reports tell of secrets that can be uncovered by setting algorithms loose on oceans of data. But there is no magic in machine learning, no hidden power, no alchemy. Instead there is an identifiable body of practical techniques that can extract useful information from raw data. This book describes these techniques and shows how they work.", "year": 2005, "referenceCount": 0, "citationCount": 1970, "influentialCitationCount": 231, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9419406", "name": "I. Witten"}, {"authorId": "143713826", "name": "Eibe Frank"}]}, {"paperId": "2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0", "url": "https://www.semanticscholar.org/paper/2b9c0e4d1d473aadbe1c2a76f75bc02bfa6416b0", "title": "Extreme learning machine: a new learning scheme of feedforward neural networks", "abstract": "It is clear that the learning speed of feedforward neural networks is in general far slower than required and it has been a major bottleneck in their applications for past decades. Two key reasons behind may be: 1) the slow gradient-based learning algorithms are extensively used to train neural networks, and 2) all the parameters of the networks are tuned iteratively by using such learning algorithms. Unlike these traditional implementations, this paper proposes a new learning algorithm called extreme learning machine (ELM) for single-hidden layer feedforward neural networks (SLFNs) which randomly chooses the input weights and analytically determines the output weights of SLFNs. In theory, this algorithm tends to provide the best generalization performance at extremely fast learning speed. The experimental results based on real-world benchmarking function approximation and classification problems including large complex applications show that the new algorithm can produce best generalization performance in some cases and can learn much faster than traditional popular learning algorithms for feedforward neural networks.", "year": 2004, "referenceCount": 17, "citationCount": 3466, "influentialCitationCount": 328, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145678691", "name": "G. Huang"}, {"authorId": "50736254", "name": "Q. Zhu"}, {"authorId": "1683268", "name": "C. Siew"}]}, {"paperId": "0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a", "url": "https://www.semanticscholar.org/paper/0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a", "title": "A review of automatic selection methods for machine learning algorithms and hyper-parameter values", "abstract": null, "year": 2016, "referenceCount": 86, "citationCount": 187, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144050855", "name": "Gang Luo"}]}, {"paperId": "24e6c5bfe9bb0751e5708b501d04e860011b2953", "url": "https://www.semanticscholar.org/paper/24e6c5bfe9bb0751e5708b501d04e860011b2953", "title": "Applications of Support Vector Machine (SVM) Learning in Cancer Genomics.", "abstract": "Machine learning with maximization (support) of separating margin (vector), called support vector machine (SVM) learning, is a powerful classification tool that has been used for cancer genomic classification or subtyping. Today, as advancements in high-throughput technologies lead to production of large amounts of genomic and epigenomic data, the classification feature of SVMs is expanding its use in cancer genomics, leading to the discovery of new biomarkers, new drug targets, and a better understanding of cancer driver genes. Herein we reviewed the recent progress of SVMs in cancer genomic studies. We intend to comprehend the strength of the SVM learning and its future perspective in cancer genomic applications.", "year": 2018, "referenceCount": 76, "citationCount": 496, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "47156522", "name": "Shujun Huang"}, {"authorId": "27122362", "name": "Nianguang Cai"}, {"authorId": "47479574", "name": "Pedro Penzuti Pacheco"}, {"authorId": "32286482", "name": "Shavira Narrandes"}, {"authorId": "46396571", "name": "Yang Wang"}, {"authorId": "50232365", "name": "Wayne Xu"}]}, {"paperId": "825ca26af5a2a510dbc1a7b97587212bc98ae968", "url": "https://www.semanticscholar.org/paper/825ca26af5a2a510dbc1a7b97587212bc98ae968", "title": "Power to the People: The Role of Humans in Interactive Machine Learning", "abstract": "Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.", "year": 2014, "referenceCount": 54, "citationCount": 682, "influentialCitationCount": 58, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1719124", "name": "Saleema Amershi"}, {"authorId": "35096370", "name": "M. Cakmak"}, {"authorId": "144288136", "name": "W. B. Knox"}, {"authorId": "1847827", "name": "T. Kulesza"}]}, {"paperId": "8accfb94a0729e0670999641d5f3e691a48056bb", "url": "https://www.semanticscholar.org/paper/8accfb94a0729e0670999641d5f3e691a48056bb", "title": "Neuro-Fuzzy and Soft Computing-A Computational Approach to Learning and Machine Intelligence [Book Review]", "abstract": "Interestingly, neuro fuzzy and soft computing a computational approach to learning and machine intelligence that you really wait for now is coming. It's significant to wait for the representative and beneficial books to read. Every book that is provided in better way and utterance will be expected by many peoples. Even you are a good reader or not, feeling to read this book will always appear when you find it. But, when you feel hard to find it as yours, what to do? Borrow to your friends and don't know when to give back it to her or him.", "year": 1997, "referenceCount": 4, "citationCount": 4049, "influentialCitationCount": 272, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144293175", "name": "J. Jang"}, {"authorId": "2166330393", "name": "Chuen-Tsai Sun"}, {"authorId": "2091316365", "name": "Eiji Mizutani"}]}, {"paperId": "3449b65008b27f6e60a73d80c1fd990f0481126b", "url": "https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b", "title": "Torch7: A Matlab-like Environment for Machine Learning", "abstract": "Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be interfaced to third-party software thanks to Lua\u2019s light interface.", "year": 2011, "referenceCount": 3, "citationCount": 1520, "influentialCitationCount": 128, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2939803", "name": "Ronan Collobert"}, {"authorId": "2645384", "name": "K. Kavukcuoglu"}, {"authorId": "2256269", "name": "C. Farabet"}]}, {"paperId": "19469939ee1c6cb51db757b71338c61fcfe8ee76", "url": "https://www.semanticscholar.org/paper/19469939ee1c6cb51db757b71338c61fcfe8ee76", "title": "A survey of open source tools for machine learning with big data in the Hadoop ecosystem", "abstract": null, "year": 2015, "referenceCount": 122, "citationCount": 372, "influentialCitationCount": 26, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2099007", "name": "Sara Landset"}, {"authorId": "1725285", "name": "T. Khoshgoftaar"}, {"authorId": "2099109", "name": "Aaron N. Richter"}, {"authorId": "3204505", "name": "Tawfiq Hasanin"}]}, {"paperId": "fad1bd501aa769f7701c1016f8a4d1473ca77601", "url": "https://www.semanticscholar.org/paper/fad1bd501aa769f7701c1016f8a4d1473ca77601", "title": "Machine Learning, Neural and Statistical Classification", "abstract": "Survey of previous comparisons and theoretical work descriptions of methods dataset descriptions criteria for comparison and methodology (including validation) empirical results machine learning on machine learning.", "year": 2009, "referenceCount": 125, "citationCount": 2731, "influentialCitationCount": 168, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145878706", "name": "D. Michie"}, {"authorId": "48616434", "name": "D. Spiegelhalter"}, {"authorId": "2107314775", "name": "C. C. Taylor"}]}, {"paperId": "48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016", "url": "https://www.semanticscholar.org/paper/48a17d25d76f9bdf90fdd86d2b3e2739e5bb8016", "title": "Determinantal Point Processes for Machine Learning", "abstract": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. While they have been studied extensively by mathematicians, giving rise to a deep and beautiful theory, DPPs are relatively new in machine learning. Determinantal Point Processes for Machine Learning provides a comprehensible introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and shows how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling non-overlapping human poses in images or video, and automatically building timelines of important news stories. It presents the general mathematical background to DPPs along with a range of modeling extensions, efficient algorithms, and theoretical results that aim to enable practical modeling and learning.", "year": 2012, "referenceCount": 163, "citationCount": 826, "influentialCitationCount": 188, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "145500336", "name": "Alex Kulesza"}, {"authorId": "1685978", "name": "B. Taskar"}]}, {"paperId": "74d8094f967be96ac1d1212e1957b97ac0674d5d", "url": "https://www.semanticscholar.org/paper/74d8094f967be96ac1d1212e1957b97ac0674d5d", "title": "Machine Learning: The New AI", "abstract": "Today, machine learning underlies a range of applications we use every day, from product recommendations to voice recognition -- as well as some we don't yet use everyday, including driverless cars. It is the basis of the new approach in computing where we do not write programs but collect data; the idea is to learn the algorithms for the tasks automatically from data. As computing devices grow more ubiquitous, a larger part of our lives and work is recorded digitally, and as \"Big Data\" has gotten bigger, the theory of machine learning -- the foundation of efforts to process that data into knowledge -- has also advanced. In this book, machine learning expert Ethem Alpaydin offers a concise overview of the subject for the general reader, describing its evolution, explaining important learning algorithms, and presenting example applications. Alpaydin offers an account of how digital technology advanced from number-crunching mainframes to mobile devices, putting today's machine learning boom in context. He describes the basics of machine learning and some applications; the use of machine learning algorithms for pattern recognition; artificial neural networks inspired by the human brain; algorithms that learn associations between instances, with such applications as customer segmentation and learning recommendations; and reinforcement learning, when an autonomous agent learns act so as to maximize reward and minimize penalty. Alpaydin then considers some future directions for machine learning and the new field of \"data science,\" and discusses the ethical and legal implications for data privacy and security.", "year": 2016, "referenceCount": 0, "citationCount": 140, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1691898", "name": "Ethem Alpaydin"}]}, {"paperId": "7f8c7783a92d4c2f388902fffb3b378921f9e8ad", "url": "https://www.semanticscholar.org/paper/7f8c7783a92d4c2f388902fffb3b378921f9e8ad", "title": "Machine Learning in Wireless Sensor Networks: Algorithms, Strategies, and Applications", "abstract": "Wireless sensor networks (WSNs) monitor dynamic environments that change rapidly over time. This dynamic behavior is either caused by external factors or initiated by the system designers themselves. To adapt to such conditions, sensor networks often adopt machine learning techniques to eliminate the need for unnecessary redesign. Machine learning also inspires many practical solutions that maximize resource utilization and prolong the lifespan of the network. In this paper, we present an extensive literature review over the period 2002-2013 of machine learning methods that were used to address common issues in WSNs. The advantages and disadvantages of each proposed algorithm are evaluated against the corresponding problem. We also provide a comparative guide to aid WSN designers in developing suitable machine learning solutions for their specific application challenges.", "year": 2014, "referenceCount": 255, "citationCount": 663, "influentialCitationCount": 39, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "34714099", "name": "Mohammad Abu Alsheikh"}, {"authorId": "2047908196", "name": "Shaowei Lin"}, {"authorId": "1713586", "name": "D. Niyato"}, {"authorId": "145858985", "name": "H. Tan"}]}, {"paperId": "c162fb5f54dae3689908fe1b2615fa680172f9b5", "url": "https://www.semanticscholar.org/paper/c162fb5f54dae3689908fe1b2615fa680172f9b5", "title": "Scikit-learn: Machine Learning Without Learning the Machinery", "abstract": "Machine learning is a pervasive development at the intersection of statistics and computer science. While it can benefit many data-related applications, the technical nature of the research literature and the corresponding algorithms slows down its adoption. Scikit-learn is an open-source software project that aims at making machine learning accessible to all, whether it be in academia or in industry. It benefits from the general-purpose Python language, which is both broadly adopted in the scientific world, and supported by a thriving ecosystem of contributors. Here we give a quick introduction to scikit-learn as well as to machine-learning basics.", "year": 2015, "referenceCount": 20, "citationCount": 307, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3025780", "name": "G. Varoquaux"}, {"authorId": "2286302", "name": "L. Buitinck"}, {"authorId": "1881041", "name": "Gilles Louppe"}, {"authorId": "2958756", "name": "O. Grisel"}, {"authorId": "2570016", "name": "Fabian Pedregosa"}, {"authorId": "2086994888", "name": "Andreas Mueller"}]}, {"paperId": "68837728232463651283edbb7ef0c93b2f502b2b", "url": "https://www.semanticscholar.org/paper/68837728232463651283edbb7ef0c93b2f502b2b", "title": "PuDianNao: A Polyvalent Machine Learning Accelerator", "abstract": "Machine Learning (ML) techniques are pervasive tools in various emerging commercial applications, but have to be accommodated by powerful computer systems to process very large data. Although general-purpose CPUs and GPUs have provided straightforward solutions, their energy-efficiencies are limited due to their excessive supports for flexibility. Hardware accelerators may achieve better energy-efficiencies, but each accelerator often accommodates only a single ML technique (family). According to the famous No-Free-Lunch theorem in the ML domain, however, an ML technique performs well on a dataset may perform poorly on another dataset, which implies that such accelerator may sometimes lead to poor learning accuracy. Even if regardless of the learning accuracy, such accelerator can still become inapplicable simply because the concrete ML task is altered, or the user chooses another ML technique. In this study, we present an ML accelerator called PuDianNao, which accommodates seven representative ML techniques, including k-means, k-nearest neighbors, naive bayes, support vector machine, linear regression, classification tree, and deep neural network. Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, PuDianNao can perform up to 1056 GOP/s (e.g., additions and multiplications) in an area of 3.51 mm^2, and consumes 596 mW only. Compared with the NVIDIA K20M GPU (28nm process), PuDianNao (65nm process) is 1.20x faster, and can reduce the energy by 128.41x.", "year": 2015, "referenceCount": 42, "citationCount": 287, "influentialCitationCount": 16, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2115490017", "name": "Dao-Fu Liu"}, {"authorId": "144049725", "name": "Tianshi Chen"}, {"authorId": "39419985", "name": "Shaoli Liu"}, {"authorId": "2069662", "name": "Jinhong Zhou"}, {"authorId": "2115867314", "name": "Shengyuan Zhou"}, {"authorId": "1731764", "name": "O. Temam"}, {"authorId": "32215073", "name": "Xiaobing Feng"}, {"authorId": "8453780", "name": "Xuehai Zhou"}, {"authorId": "7377735", "name": "Yunji Chen"}]}, {"paperId": "c61134ada9f0e3f3373d635c31a8b3caa37f9977", "url": "https://www.semanticscholar.org/paper/c61134ada9f0e3f3373d635c31a8b3caa37f9977", "title": "Genetic Algorithms and Machine Learning", "abstract": null, "year": 1988, "referenceCount": 12, "citationCount": 2776, "influentialCitationCount": 93, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1715339", "name": "D. Goldberg"}, {"authorId": "144404817", "name": "J. Holland"}]}, {"paperId": "85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175", "url": "https://www.semanticscholar.org/paper/85d2d4cb2ca1dcd9da2d5a765cc2aa4911b0a175", "title": "An introduction to quantum machine learning", "abstract": "Machine learning algorithms learn a desired input-output relation from examples in order to interpret new inputs. This is important for tasks such as image and speech recognition or strategy optimisation, with growing applications in the IT industry. In the last couple of years, researchers investigated if quantum computing can help to improve classical machine learning algorithms. Ideas range from running computationally costly algorithms or their subroutines efficiently on a quantum computer to the translation of stochastic methods into the language of quantum theory. This contribution gives a systematic overview of the emerging field of quantum machine learning. It presents the approaches as well as technical details in an accessible way, and discusses the potential of a future theory of quantum learning.", "year": 2014, "referenceCount": 79, "citationCount": 541, "influentialCitationCount": 23, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "3048564", "name": "M. Schuld"}, {"authorId": "2498866", "name": "I. Sinayskiy"}, {"authorId": "2258749", "name": "Francesco Petruccione"}]}, {"paperId": "44c04f1f6af260cd3d36cd88bb27cec550339b9e", "url": "https://www.semanticscholar.org/paper/44c04f1f6af260cd3d36cd88bb27cec550339b9e", "title": "Machine learning bandgaps of double perovskites", "abstract": null, "year": 2016, "referenceCount": 80, "citationCount": 294, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Materials Science", "Medicine"], "authors": [{"authorId": "49542803", "name": "G. Pilania"}, {"authorId": "1398852745", "name": "A. Mannodi-Kanakkithodi"}, {"authorId": "2521298", "name": "B. Uberuaga"}, {"authorId": "4063724", "name": "R. Ramprasad"}, {"authorId": "3122483", "name": "J. Gubernatis"}, {"authorId": "2891010", "name": "T. Lookman"}]}, {"paperId": "bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6", "url": "https://www.semanticscholar.org/paper/bdb5f7fc1608dd80e2d3fdb1575cec2d3c074ad6", "title": "A survey of feature selection and feature extraction techniques in machine learning", "abstract": "Dimensionality reduction as a preprocessing step to machine learning is effective in removing irrelevant and redundant data, increasing learning accuracy, and improving result comprehensibility. However, the recent increase of dimensionality of data poses a severe challenge to many existing feature selection and feature extraction methods with respect to efficiency and effectiveness. In the field of machine learning and pattern recognition, dimensionality reduction is important area, where many approaches have been proposed. In this paper, some widely used feature selection and feature extraction techniques have analyzed with the purpose of how effectively these techniques can be used to achieve high performance of learning algorithms that ultimately improves predictive accuracy of classifier. An endeavor to analyze dimensionality reduction techniques briefly with the purpose to investigate strengths and weaknesses of some widely used dimensionality reduction methods is presented.", "year": 2014, "referenceCount": 35, "citationCount": 555, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2257398", "name": "S. Khalid"}, {"authorId": "33075067", "name": "Tehmina Khalil"}, {"authorId": "49538771", "name": "Shamila Nasreen"}]}, {"paperId": "da71c787c20a4ca14528e3c87edbb1432ee78135", "url": "https://www.semanticscholar.org/paper/da71c787c20a4ca14528e3c87edbb1432ee78135", "title": "Machine Learning", "abstract": null, "year": 2018, "referenceCount": 16, "citationCount": 1, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "1951155", "name": "M. Fattore"}]}, {"paperId": "df2a7756382540e92895f10703cec32d50c4f316", "url": "https://www.semanticscholar.org/paper/df2a7756382540e92895f10703cec32d50c4f316", "title": "Fast and accurate modeling of molecular atomization energies with machine learning.", "abstract": "We introduce a machine learning model to predict atomization energies of a diverse set of organic molecules, based on nuclear charges and atomic positions only. The problem of solving the molecular Schr\u00f6dinger equation is mapped onto a nonlinear statistical regression problem of reduced complexity. Regression models are trained on and compared to atomization energies computed with hybrid density-functional theory. Cross validation over more than seven thousand organic molecules yields a mean absolute error of \u223c10\u2009\u2009kcal/mol. Applicability is demonstrated for the prediction of molecular atomization potential energy curves.", "year": 2011, "referenceCount": 23, "citationCount": 1187, "influentialCitationCount": 26, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Mathematics", "Medicine"], "authors": [{"authorId": "48041657", "name": "M. Rupp"}, {"authorId": "2462983", "name": "A. Tkatchenko"}, {"authorId": "145034054", "name": "K. M\u00fcller"}, {"authorId": "7847508", "name": "O. A. von Lilienfeld"}]}, {"paperId": "04ca5de59edbdd49a9c0502c58331524d220bc8c", "url": "https://www.semanticscholar.org/paper/04ca5de59edbdd49a9c0502c58331524d220bc8c", "title": "Communication Efficient Distributed Machine Learning with the Parameter Server", "abstract": "This paper describes a third-generation parameter server framework for distributed machine learning. This framework offers two relaxations to balance system performance and algorithm efficiency. We propose a new algorithm that takes advantage of this framework to solve non-convex non-smooth problems with convergence guarantees. We present an in-depth analysis of two large scale machine learning problems ranging from l1 -regularized logistic regression on CPUs to reconstruction ICA on GPUs, using 636TB of real data with hundreds of billions of samples and dimensions. We demonstrate using these examples that the parameter server framework is an effective and straightforward way to scale machine learning to larger problems and systems than have been previously achieved.", "year": 2014, "referenceCount": 39, "citationCount": 476, "influentialCitationCount": 25, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2124778071", "name": "Mu Li"}, {"authorId": "34752743", "name": "D. Andersen"}, {"authorId": "46234526", "name": "Alex Smola"}, {"authorId": "144782042", "name": "Kai Yu"}]}, {"paperId": "0173ca962e4ab3d084c89568345e06f67d3d7efc", "url": "https://www.semanticscholar.org/paper/0173ca962e4ab3d084c89568345e06f67d3d7efc", "title": "Hyperparameter Search in Machine Learning", "abstract": "We introduce the hyperparameter search problem in the field of machine learning and discuss its main challenges from an optimization perspective. Machine learning methods attempt to build models that capture some element of interest based on given data. Most common learning algorithms feature a set of hyperparameters that must be determined before training commences. The choice of hyperparameters can significantly affect the resulting model's performance, but determining good values can be complex; hence a disciplined, theoretically sound search strategy is essential.", "year": 2015, "referenceCount": 74, "citationCount": 273, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "48461464", "name": "Marc Claesen"}, {"authorId": "143750713", "name": "B. Moor"}]}, {"paperId": "29b9ff8f4a26acc90e6182e1e749f15f688bc7cf", "url": "https://www.semanticscholar.org/paper/29b9ff8f4a26acc90e6182e1e749f15f688bc7cf", "title": "Machine learning for quantum mechanics in a nutshell", "abstract": "Models that combine quantum mechanics (QM) with machine learning (ML) promise to deliver the accuracy of QM at the speed of ML. This hands-on tutorial introduces the reader to QM/ML models based on kernel learning, an elegant, systematically nonlinear form of ML. Pseudocode and a reference implementation are provided, enabling the reader to reproduce results from recent publications where atomization energies of small organic molecules are predicted using kernel ridge regression. \u00a9 2015 Wiley Periodicals, Inc.", "year": 2015, "referenceCount": 148, "citationCount": 271, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "48041657", "name": "M. Rupp"}]}, {"paperId": "f83ca18f3834d45a70e9b54578e2c33870dde67d", "url": "https://www.semanticscholar.org/paper/f83ca18f3834d45a70e9b54578e2c33870dde67d", "title": "Machine Teaching: An Inverse Problem to Machine Learning and an Approach Toward Optimal Education", "abstract": "\n \n I draw the reader's attention to machine teaching, the problem of finding an optimal training set given a machine learning algorithm and a target model. In addition to generating fascinating mathematical questions for computer scientists to ponder, machine teaching holds the promise of enhancing education and personnel training. The Socratic dialogue style aims to stimulate critical thinking.\n \n", "year": 2015, "referenceCount": 39, "citationCount": 223, "influentialCitationCount": 8, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1832364", "name": "Xiaojin Zhu"}]}, {"paperId": "ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30", "url": "https://www.semanticscholar.org/paper/ed5ab1cff7dd3a902eea4a811b15aa5ea3a36b30", "title": "MLaaS: Machine Learning as a Service", "abstract": "The demand for knowledge extraction has been increasing. With the growing amount of data being generated by global data sources (e.g., social media and mobile apps) and the popularization of context-specific data (e.g., the Internet of Things), companies and researchers need to connect all these data and extract valuable information. Machine learning has been gaining much attention in data mining, leveraging the birth of new solutions. This paper proposes an architecture to create a flexible and scalable machine learning as a service. An open source solution was implemented and presented. As a case study, a forecast of electricity demand was generated using real-world sensor and weather data by running different algorithms at the same time.", "year": 2015, "referenceCount": 14, "citationCount": 195, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2067582822", "name": "Mauro Ribeiro"}, {"authorId": "2222599", "name": "Katarina Grolinger"}, {"authorId": "1711826", "name": "Miriam A. M. Capretz"}]}, {"paperId": "bcb46edd9262251da16f7442a170471f2a81a6bd", "url": "https://www.semanticscholar.org/paper/bcb46edd9262251da16f7442a170471f2a81a6bd", "title": "Machine Learning in Materials Science", "abstract": null, "year": 2016, "referenceCount": 182, "citationCount": 212, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "46199341", "name": "Tim Mueller"}, {"authorId": "4833974", "name": "A. Kusne"}, {"authorId": "4063724", "name": "R. Ramprasad"}]}, {"paperId": "3fdd37c3a30da1dd0e376889bf2bdddc637b0b34", "url": "https://www.semanticscholar.org/paper/3fdd37c3a30da1dd0e376889bf2bdddc637b0b34", "title": "A survey of multi-view machine learning", "abstract": null, "year": 2013, "referenceCount": 60, "citationCount": 693, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "20632291", "name": "Shiliang Sun"}]}, {"paperId": "61ce67533d2dd6605c907146658ccdbc4778a5d8", "url": "https://www.semanticscholar.org/paper/61ce67533d2dd6605c907146658ccdbc4778a5d8", "title": "Learning a Multi-View Stereo Machine", "abstract": "We present a learnt system for multi-view stereopsis. In contrast to recent learning based methods for 3D reconstruction, we leverage the underlying 3D geometry of the problem through feature projection and unprojection along viewing rays. By formulating these operations in a differentiable manner, we are able to learn the system end-to-end for the task of metric 3D reconstruction. End-to-end learning allows us to jointly reason about shape priors while conforming geometric constraints, enabling reconstruction from much fewer images (even a single image) than required by classical approaches as well as completion of unseen surfaces. We thoroughly evaluate our approach on the ShapeNet dataset and demonstrate the benefits over classical approaches as well as recent learning based methods.", "year": 2017, "referenceCount": 62, "citationCount": 353, "influentialCitationCount": 37, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145579476", "name": "Abhishek Kar"}, {"authorId": "2172959", "name": "Christian H\u00e4ne"}, {"authorId": "143751119", "name": "Jitendra Malik"}]}, {"paperId": "9b0aa51901f05278928bdfcb4e9826a429a81293", "url": "https://www.semanticscholar.org/paper/9b0aa51901f05278928bdfcb4e9826a429a81293", "title": "Quantum algorithms for supervised and unsupervised machine learning", "abstract": "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers of vectors in high-dimensional spaces. Classical algorithms for solving such problems typically take time polynomial in the number of vectors and the dimension of the space. Quantum computers are good at manipulating high-dimensional vectors in large tensor product spaces. This paper provides supervised and unsupervised quantum machine learning algorithms for cluster assignment and cluster finding. Quantum machine learning can take time logarithmic in both the number of vectors and their dimension, an exponential speed-up over classical algorithms.", "year": 2013, "referenceCount": 21, "citationCount": 523, "influentialCitationCount": 28, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Mathematics"], "authors": [{"authorId": "145762777", "name": "S. Lloyd"}, {"authorId": "145233982", "name": "M. Mohseni"}, {"authorId": "3157522", "name": "P. Rebentrost"}]}, {"paperId": "5888c776e38f39efb9b96d0ba2713981008a86b1", "url": "https://www.semanticscholar.org/paper/5888c776e38f39efb9b96d0ba2713981008a86b1", "title": "Structural Health Monitoring: A Machine Learning Perspective", "abstract": "This book focuses on structural health monitoring in the context of machine learning. The authors review the technical literature and include case studies. Chapters include: operational evaluation, sensing and data acquisition, introduction to probability and statistics, machine learning and statistical pattern recognition, and data prognosis.", "year": 2012, "referenceCount": 78, "citationCount": 1022, "influentialCitationCount": 84, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3151407", "name": "C. Farrar"}, {"authorId": "144789804", "name": "K. Worden"}]}, {"paperId": "b430afae080f51c925da240aef5c2ec65c9ab2ae", "url": "https://www.semanticscholar.org/paper/b430afae080f51c925da240aef5c2ec65c9ab2ae", "title": "Entanglement-based machine learning on a quantum computer.", "abstract": "Machine learning, a branch of artificial intelligence, learns from previous experience to optimize performance, which is ubiquitous in various fields such as computer sciences, financial analysis, robotics, and bioinformatics. A challenge is that machine learning with the rapidly growing \"big data\" could become intractable for classical computers. Recently, quantum machine learning algorithms [Lloyd, Mohseni, and Rebentrost, arXiv.1307.0411] were proposed which could offer an exponential speedup over classical algorithms. Here, we report the first experimental entanglement-based classification of two-, four-, and eight-dimensional vectors to different clusters using a small-scale photonic quantum computer, which are then used to implement supervised and unsupervised machine learning. The results demonstrate the working principle of using quantum computers to manipulate and classify high-dimensional vectors, the core mathematical routine in machine learning. The method can, in principle, be scaled to larger numbers of qubits, and may provide a new route to accelerate machine learning.", "year": 2014, "referenceCount": 44, "citationCount": 146, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Physics", "Medicine", "Computer Science"], "authors": [{"authorId": "122553461", "name": "X. Cai"}, {"authorId": "2107534376", "name": "D. Wu"}, {"authorId": "6117117", "name": "Z. Su"}, {"authorId": "2143478388", "name": "M.-C. Chen"}, {"authorId": "2108098460", "name": "X.-L. Wang"}, {"authorId": "2156059765", "name": "Li Li"}, {"authorId": "2137975072", "name": "N-L Liu"}, {"authorId": "11614424", "name": "C.-Y. Lu"}, {"authorId": "123442198", "name": "J.-W. Pan"}]}, {"paperId": "5df0a0e9ceec70a9321b0555288222bf53216342", "url": "https://www.semanticscholar.org/paper/5df0a0e9ceec70a9321b0555288222bf53216342", "title": "Neural Networks in Machine Learning", "abstract": "Machine Learning is associated with the study and construction of systems that can learn on their own rather than following instructions. It is used in search engines, optical character recognition, computer vision etc. Neural networks are one of the several techniques used in machine learning. Here we are trying to discuss neural network approaches used in machine learning.", "year": 2014, "referenceCount": 11, "citationCount": 334, "influentialCitationCount": 41, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "72270297", "name": "Parul Parashar"}]}, {"paperId": "6eabf6e67c29778265bc9fef3b58b2756c739c83", "url": "https://www.semanticscholar.org/paper/6eabf6e67c29778265bc9fef3b58b2756c739c83", "title": "Machine Learning for Aerial Image Labeling", "abstract": "Information extracted from aerial photographs has found applications in a wide range of areas including urban planning, crop and forest management, disaster relief, and climate modeling. At present, much of the extraction is still performed by human experts, making the process slow, costly, and error prone. The goal of this thesis is to develop methods for automatically extracting the locations of objects such as roads, buildings, and trees directly from aerial images. \nWe investigate the use of machine learning methods trained on aligned aerial images and possibly outdated maps for labeling the pixels of an aerial image with semantic labels. We show how deep neural networks implemented on modern GPUs can be used to efficiently learn highly discriminative image features. We then introduce new loss functions for training neural networks that are partially robust to incomplete and poorly registered target maps. Finally, we propose two ways of improving the predictions of our system by introducing structure into the outputs of the neural networks. \nWe evaluate our system on the largest and most-challenging road and building detection datasets considered in the literature and show that it works reliably under a wide variety of conditions. Furthermore, we are releasing the first large-scale road and building detection datasets to the public in order to facilitate future comparisons with other methods.", "year": 2013, "referenceCount": 61, "citationCount": 446, "influentialCitationCount": 92, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Engineering"], "authors": [{"authorId": "1695689", "name": "Geoffrey E. Hinton"}, {"authorId": "3255983", "name": "Volodymyr Mnih"}]}, {"paperId": "184ac0766262312ba76bbdece4e7ffad0aa8180b", "url": "https://www.semanticscholar.org/paper/184ac0766262312ba76bbdece4e7ffad0aa8180b", "title": "Representation Learning: A Review and New Perspectives", "abstract": "The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.", "year": 2012, "referenceCount": 262, "citationCount": 9422, "influentialCitationCount": 510, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine", "Mathematics"], "authors": [{"authorId": "1751762", "name": "Yoshua Bengio"}, {"authorId": "1760871", "name": "Aaron C. Courville"}, {"authorId": "145467703", "name": "Pascal Vincent"}]}, {"paperId": "2878d9936f494ed7d0c8aec47e9bcc5e51609f9a", "url": "https://www.semanticscholar.org/paper/2878d9936f494ed7d0c8aec47e9bcc5e51609f9a", "title": "Extreme Learning Machine for Multilayer Perceptron", "abstract": "Extreme learning machine (ELM) is an emerging learning algorithm for the generalized single hidden layer feedforward neural networks, of which the hidden node parameters are randomly generated and the output weights are analytically computed. However, due to its shallow architecture, feature learning using ELM may not be effective for natural signals (e.g., images/videos), even with a large number of hidden nodes. To address this issue, in this paper, a new ELM-based hierarchical learning framework is proposed for multilayer perceptron. The proposed architecture is divided into two main components: 1) self-taught feature extraction followed by supervised feature classification and 2) they are bridged by random initialized hidden weights. The novelties of this paper are as follows: 1) unsupervised multilayer encoding is conducted for feature extraction, and an ELM-based sparse autoencoder is developed via \u21131 constraint. By doing so, it achieves more compact and meaningful feature representations than the original ELM; 2) by exploiting the advantages of ELM random feature mapping, the hierarchically encoded outputs are randomly projected before final decision making, which leads to a better generalization with faster learning speed; and 3) unlike the greedy layerwise training of deep learning (DL), the hidden layers of the proposed framework are trained in a forward manner. Once the previous layer is established, the weights of the current layer are fixed without fine-tuning. Therefore, it has much better learning efficiency than the DL. Extensive experiments on various widely used classification data sets show that the proposed algorithm achieves better and faster convergence than the existing state-of-the-art hierarchical learning methods. Furthermore, multiple applications in computer vision further confirm the generality and capability of the proposed learning scheme.", "year": 2016, "referenceCount": 35, "citationCount": 989, "influentialCitationCount": 93, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2967405", "name": "Jiexiong Tang"}, {"authorId": "7175017", "name": "Chenwei Deng"}, {"authorId": "145678691", "name": "G. Huang"}]}, {"paperId": "b4adef6c659ab62943ce1e68db4d9409d2ce3878", "url": "https://www.semanticscholar.org/paper/b4adef6c659ab62943ce1e68db4d9409d2ce3878", "title": "Machine learning methods in chemoinformatics", "abstract": "Machine learning algorithms are generally developed in computer science or adjacent disciplines and find their way into chemical modeling by a process of diffusion. Though particular machine learning methods are popular in chemoinformatics and quantitative structure\u2013activity relationships (QSAR), many others exist in the technical literature. This discussion is methods\u2010based and focused on some algorithms that chemoinformatics researchers frequently use. It makes no claim to be exhaustive. We concentrate on methods for supervised learning, predicting the unknown property values of a test set of instances, usually molecules, based on the known values for a training set. Particularly relevant approaches include Artificial Neural Networks, Random Forest, Support Vector Machine, k\u2010Nearest Neighbors and na\u00efve Bayes classifiers. WIREs Comput Mol Sci 2014, 4:468\u2013481.", "year": 2014, "referenceCount": 120, "citationCount": 318, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "35405821", "name": "John B. O. Mitchell"}]}, {"paperId": "1be4e7a87c509d8647144f9e8fa66756fd289111", "url": "https://www.semanticscholar.org/paper/1be4e7a87c509d8647144f9e8fa66756fd289111", "title": "Big data classification: problems and challenges in network intrusion prediction with machine learning", "abstract": "This paper focuses on the specific problem of Big Data classification of network intrusion traffic. It discusses the system challenges presented by the Big Data problems associated with network intrusion prediction. The prediction of a possible intrusion attack in a network requires continuous collection of traffic data and learning of their characteristics on the fly. The continuous collection of traffic data by the network leads to Big Data problems that are caused by the volume, variety and velocity properties of Big Data. The learning of the network characteristics require machine learning techniques that capture global knowledge of the traffic patterns. The Big Data properties will lead to significant system challenges to implement machine learning frameworks. This paper discusses the problems and challenges in handling Big Data classification using geometric representation-learning techniques and the modern Big Data networking technologies. In particular this paper discusses the issues related to combining supervised learning techniques, representation-learning techniques, machine lifelong learning techniques and Big Data technologies (e.g. Hadoop, Hive and Cloud) for solving network traffic classification problems.", "year": 2014, "referenceCount": 20, "citationCount": 309, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3339259", "name": "S. Suthaharan"}]}, {"paperId": "8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92", "url": "https://www.semanticscholar.org/paper/8346b9a8e156d6e7a7012bcd47bc4f5d4be59e92", "title": "Outside the Closed World: On Using Machine Learning for Network Intrusion Detection", "abstract": "In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational \"real world\" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection.", "year": 2010, "referenceCount": 65, "citationCount": 1293, "influentialCitationCount": 126, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1690799", "name": "Robin Sommer"}, {"authorId": "1744800", "name": "V. Paxson"}]}, {"paperId": "1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6", "url": "https://www.semanticscholar.org/paper/1cd7f2c74bd7ffb3a8b1527bec8795d0876a40b6", "title": "Transfer Learning for Low-Resource Neural Machine Translation", "abstract": "The encoder-decoder framework for neural machine translation (NMT) has been shown effective in large data scenarios, but is much less effective for low-resource languages. We present a transfer learning method that significantly improves Bleu scores across a range of low-resource languages. Our key idea is to first train a high-resource language pair (the parent model), then transfer some of the learned parameters to the low-resource pair (the child model) to initialize and constrain training. Using our transfer learning method we improve baseline NMT models by an average of 5.6 Bleu on four low-resource language pairs. Ensembling and unknown word replacement add another 2 Bleu which brings the NMT performance on low-resource machine translation close to a strong syntax based machine translation (SBMT) system, exceeding its performance on one language pair. Additionally, using the transfer learning model for re-scoring, we can improve the SBMT system by an average of 1.3 Bleu, improving the state-of-the-art on low-resource machine translation.", "year": 2016, "referenceCount": 37, "citationCount": 604, "influentialCitationCount": 83, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2368067", "name": "Barret Zoph"}, {"authorId": "2808366", "name": "Deniz Yuret"}, {"authorId": "143823227", "name": "Jonathan May"}, {"authorId": "152971314", "name": "Kevin Knight"}]}, {"paperId": "4efe53a9653d1481e50382a2c95bce6eb4f6de9d", "url": "https://www.semanticscholar.org/paper/4efe53a9653d1481e50382a2c95bce6eb4f6de9d", "title": "Kernel Methods and Machine Learning", "abstract": "Part I. Machine Learning and Kernel Vector Spaces: 1. Fundamentals of machine learning 2. Kernel-induced vector spaces Part II. Dimension-Reduction: Feature Selection and PCA/KPCA: 3. Feature selection 4. PCA and Kernel-PCA Part III. Unsupervised Learning Models for Cluster Analysis: 5. Unsupervised learning for cluster discovery 6. Kernel methods for cluster discovery Part IV. Kernel Ridge Regressors and Variants: 7. Kernel-based regression and regularization analysis 8. Linear regression and discriminant analysis for supervised classification 9. Kernel ridge regression for supervised classification Part V. Support Vector Machines and Variants: 10. Support vector machines 11. Support vector learning models for outlier detection 12. Ridge-SVM learning models Part VI. Kernel Methods for Green Machine Learning Technologies: 13. Efficient kernel methods for learning and classifcation Part VII. Kernel Methods and Statistical Estimation Theory: 14. Statistical regression analysis and errors-in-variables models 15: Kernel methods for estimation, prediction, and system identification Part VIII. Appendices: Appendix A. Validation and test of learning models Appendix B. kNN, PNN, and Bayes classifiers References Index.", "year": 2014, "referenceCount": 287, "citationCount": 212, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics"], "authors": [{"authorId": "144410963", "name": "S. Kung"}]}, {"paperId": "51891710e30da33c4ced4ae7daee1593e0cb5cc4", "url": "https://www.semanticscholar.org/paper/51891710e30da33c4ced4ae7daee1593e0cb5cc4", "title": "Machine Learning: The High Interest Credit Card of Technical Debt", "abstract": "Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns. 1 Machine Learning and Complex Systems Real world software engineers are often faced with the challenge of moving quickly to ship new products or services, which can lead to a dilemma between speed of execution and quality of engineering. The concept of technical debt was first introduced by Ward Cunningham in 1992 as a way to help quantify the cost of such decisions. Like incurring fiscal debt, there are often sound strategic reasons to take on technical debt. Not all debt is necessarily bad, but technical debt does tend to compound. Deferring the work to pay it off results in increasing costs, system brittleness, and reduced rates of innovation. Traditional methods of paying off technical debt include refactoring, increasing coverage of unit tests, deleting dead code, reducing dependencies, tightening APIs, and improving documentation [4]. The goal of these activities is not to add new functionality, but to make it easier to add future improvements, be cheaper to maintain, and reduce the likelihood of bugs. One of the basic arguments in this paper is that machine learning packages have all the basic code complexity issues as normal code, but also have a larger system-level complexity that can create hidden debt. Thus, refactoring these libraries, adding better unit tests, and associated activity is time well spent but does not necessarily address debt at a systems level. In this paper, we focus on the system-level interaction between machine learning code and larger systems as an area where hidden technical debt may rapidly accumulate. At a system-level, a machine learning model may subtly erode abstraction boundaries. It may be tempting to re-use input signals in ways that create unintended tight coupling of otherwise disjoint systems. Machine learning packages may often be treated as black boxes, resulting in large masses of \u201cglue code\u201d or calibration layers that can lock in assumptions. Changes in the external world may make models or input signals change behavior in unintended ways, ratcheting up maintenance cost and the burden of any debt. Even monitoring that the system as a whole is operating as intended may be difficult without careful design.", "year": 2014, "referenceCount": 10, "citationCount": 259, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Business"], "authors": [{"authorId": "1733143", "name": "D. Sculley"}, {"authorId": "144510728", "name": "Gary Holt"}, {"authorId": "145973657", "name": "D. Golovin"}, {"authorId": "143698521", "name": "Eugene Davydov"}, {"authorId": "2054375101", "name": "Todd Phillips"}, {"authorId": "49236095", "name": "D. Ebner"}, {"authorId": "2055477158", "name": "Vinay Chaudhary"}, {"authorId": "2114084357", "name": "Michael Young"}]}, {"paperId": "06a81f63fc4ccfcf02934647a7c17454b91853b0", "url": "https://www.semanticscholar.org/paper/06a81f63fc4ccfcf02934647a7c17454b91853b0", "title": "Machine Learning - The Art and Science of Algorithms that Make Sense of Data", "abstract": "As one of the most comprehensive machine learning texts around, this book does justice to the field's incredible richness, but without losing sight of the unifying principles. Peter Flach's clear, example-based approach begins by discussing how a spam filter works, which gives an immediate introduction to machine learning in action, with a minimum of technical fuss. Flach provides case studies of increasing complexity and variety with well-chosen examples and illustrations throughout. He covers a wide range of logical, geometric and statistical models and state-of-the-art topics such as matrix factorisation and ROC analysis. Particular attention is paid to the central role played by features. The use of established terminology is balanced with the introduction of new and useful concepts, and summaries of relevant background material are provided with pointers for revision if necessary. These features ensure Machine Learning will set a new standard as an introductory textbook.", "year": 2012, "referenceCount": 184, "citationCount": 775, "influentialCitationCount": 75, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144474086", "name": "P. Flach"}]}, {"paperId": "b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e", "url": "https://www.semanticscholar.org/paper/b6df5c2ac2f91d71b1d08d76135e2a470ac1ad1e", "title": "Machine learning - an artificial intelligence approach", "abstract": "This book contains tutorial overviews and research papers on contemporary trends in the area of machine learning viewed from an AI perspective. Research directions covered include: learning from examples, modeling human learning strategies, knowledge acquisition for expert systems, learning heuristics, discovery systems, and conceptual data analysis.", "year": 1982, "referenceCount": 37, "citationCount": 2826, "influentialCitationCount": 53, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2421006", "name": "R. Michalski"}, {"authorId": "2122137868", "name": "John R. Anderson"}]}, {"paperId": "e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39", "url": "https://www.semanticscholar.org/paper/e8dccfb88a6524a67b6239f6b38a8fdaf15f6b39", "title": "Quantum Machine Learning: What Quantum Computing Means to Data Mining", "abstract": "Quantum Machine Learning bridges the gap between abstract developments in quantum computing and the applied research on machine learning. Paring down the complexity of the disciplines involved, it ...", "year": 2014, "referenceCount": 210, "citationCount": 236, "influentialCitationCount": 16, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1756871", "name": "P. Wittek"}]}, {"paperId": "8f566001453bc6be0a935bf69ffd90d9db3af32b", "url": "https://www.semanticscholar.org/paper/8f566001453bc6be0a935bf69ffd90d9db3af32b", "title": "Toward Causal Representation Learning", "abstract": "The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.", "year": 2021, "referenceCount": 282, "citationCount": 360, "influentialCitationCount": 57, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "4080509", "name": "B. Scholkopf"}, {"authorId": "9557137", "name": "Francesco Locatello"}, {"authorId": "153125952", "name": "Stefan Bauer"}, {"authorId": "145604319", "name": "Nan Rosemary Ke"}, {"authorId": "2583391", "name": "Nal Kalchbrenner"}, {"authorId": "1996705", "name": "Anirudh Goyal"}, {"authorId": "1751762", "name": "Yoshua Bengio"}]}, {"paperId": "3ced109e0c16014cf4cdd677aeb1b95acf1c35d6", "url": "https://www.semanticscholar.org/paper/3ced109e0c16014cf4cdd677aeb1b95acf1c35d6", "title": "How to represent crystal structures for machine learning: Towards fast prediction of electronic properties", "abstract": "High-throughput density functional calculations of solids are highly time-consuming. As an alternative, we propose a machine learning approach for the fast prediction of solid-state properties. To achieve this, local spin-density approximation calculations are used as a training set. We focus on predicting the value of the density of electronic states at the Fermi energy. We find that conventional representations of the input data, such as the Coulomb matrix, are not suitable for the training of learning machines in the case of periodic solids. We propose a novel crystal structure representation for which learning and competitive prediction accuracies become possible within an unrestricted class of spd systems of arbitrary unit-cell size.", "year": 2013, "referenceCount": 42, "citationCount": 291, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics"], "authors": [{"authorId": "51257580", "name": "K. T. Schutt"}, {"authorId": "50359998", "name": "H. Glawe"}, {"authorId": "3468686", "name": "F. Brockherde"}, {"authorId": "50750682", "name": "A. Sanna"}, {"authorId": "116099820", "name": "K. Muller"}, {"authorId": "145191157", "name": "E. Gross"}]}, {"paperId": "23b559b5ab27f2fca6f56c0a7b6478bcf69db509", "url": "https://www.semanticscholar.org/paper/23b559b5ab27f2fca6f56c0a7b6478bcf69db509", "title": "Dual Learning for Machine Translation", "abstract": "While neural machine translation (NMT) is making good progress in the past two years, tens of millions of bilingual sentence pairs are needed for its training. However, human labeling is very costly. To tackle this training data bottleneck, we develop a dual-learning mechanism, which can enable an NMT system to automatically learn from unlabeled data through a dual-learning game. This mechanism is inspired by the following observation: any machine translation task has a dual task, e.g., English-to-French translation (primal) versus French-to-English translation (dual); the primal and dual tasks can form a closed loop, and generate informative feedback signals to train the translation models, even if without the involvement of a human labeler. In the dual-learning mechanism, we use one agent to represent the model for the primal task and the other agent to represent the model for the dual task, then ask them to teach each other through a reinforcement learning process. Based on the feedback signals generated during this process (e.g., the language-model likelihood of the output of a model, and the reconstruction error of the original sentence after the primal and dual translations), we can iteratively update the two models until convergence (e.g., using the policy gradient methods). We call the corresponding approach to neural machine translation dual-NMT. Experiments show that dual-NMT works very well on English \u2194 French translation; especially, by learning from monolingual data (with 10% bilingual data for warm start), it achieves a comparable accuracy to NMT trained from the full bilingual data for the French-to-English translation task.", "year": 2016, "referenceCount": 18, "citationCount": 681, "influentialCitationCount": 54, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1391126980", "name": "Di He"}, {"authorId": "2794096", "name": "Yingce Xia"}, {"authorId": "143826491", "name": "Tao Qin"}, {"authorId": "24952249", "name": "Liwei Wang"}, {"authorId": "1708598", "name": "Nenghai Yu"}, {"authorId": "2110264337", "name": "Tie-Yan Liu"}, {"authorId": "1712167", "name": "Wei-Ying Ma"}]}, {"paperId": "3bb6d5834bfb355553588e382ac5f9fa8a8d831d", "url": "https://www.semanticscholar.org/paper/3bb6d5834bfb355553588e382ac5f9fa8a8d831d", "title": "Distributed GraphLab: A Framework for Machine Learning in the Cloud", "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. \n \nWe develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.", "year": 2012, "referenceCount": 39, "citationCount": 738, "influentialCitationCount": 52, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1680638", "name": "Y. Low"}, {"authorId": "49988044", "name": "Joseph E. Gonzalez"}, {"authorId": "1717990", "name": "Aapo Kyrola"}, {"authorId": "1741745", "name": "D. Bickson"}, {"authorId": "1730156", "name": "Carlos Guestrin"}, {"authorId": "1695576", "name": "J. Hellerstein"}]}, {"paperId": "92a314bf9ae817836389cc97af5a9f42c561a772", "url": "https://www.semanticscholar.org/paper/92a314bf9ae817836389cc97af5a9f42c561a772", "title": "Accelerating materials property predictions using machine learning", "abstract": null, "year": 2013, "referenceCount": 49, "citationCount": 510, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "49542803", "name": "G. Pilania"}, {"authorId": "2108707708", "name": "Chenchen Wang"}, {"authorId": "2144282447", "name": "Xun Jiang"}, {"authorId": "143856869", "name": "S. Rajasekaran"}, {"authorId": "83280215", "name": "R. Ramprasad"}]}, {"paperId": "01e1fa7924b3eb76b73f1828c93805f3ba028bae", "url": "https://www.semanticscholar.org/paper/01e1fa7924b3eb76b73f1828c93805f3ba028bae", "title": "MLbase: A Distributed Machine-learning System", "abstract": "Machine learning (ML) and statistical techniques are key to transforming big data into actionable knowledge. In spite of the modern primacy of data, the complexity of existing ML algorithms is often overwhelming|many users do not understand the trade-os and challenges of parameterizing and choosing between dierent learning techniques. Furthermore, existing scalable systems that support machine learning are typically not accessible to ML researchers without a strong background in distributed systems and low-level primitives. In this work, we present our vision for MLbase, a novel system harnessing the power of machine learning for both end-users and ML researchers. MLbase provides (1) a simple declarative way to specify ML tasks, (2) a novel optimizer to select and dynamically adapt the choice of learning algorithm, (3) a set of high-level operators to enable ML researchers to scalably implement a wide range of ML methods without deep systems knowledge, and (4) a new run-time optimized for the data-access patterns of these high-level operators.", "year": 2013, "referenceCount": 26, "citationCount": 341, "influentialCitationCount": 21, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1746961", "name": "Tim Kraska"}, {"authorId": "145532827", "name": "Ameet S. Talwalkar"}, {"authorId": "1734693", "name": "John C. Duchi"}, {"authorId": "50331526", "name": "R. Griffith"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "1694621", "name": "Michael I. Jordan"}]}, {"paperId": "6aa8f8ae07a57a2025d6adc27a0bc53f6a7ee385", "url": "https://www.semanticscholar.org/paper/6aa8f8ae07a57a2025d6adc27a0bc53f6a7ee385", "title": "Machine learning for targeted display advertising: transfer learning in action", "abstract": null, "year": 2013, "referenceCount": 33, "citationCount": 153, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1933403", "name": "Claudia Perlich"}, {"authorId": "3242748", "name": "Brian Dalessandro"}, {"authorId": "2468485", "name": "Troy Raeder"}, {"authorId": "2147050", "name": "Ori Stitelman"}, {"authorId": "1752722", "name": "F. Provost"}]}, {"paperId": "5776d0fea69d826519ee3649f620e8755a490efe", "url": "https://www.semanticscholar.org/paper/5776d0fea69d826519ee3649f620e8755a490efe", "title": "Lifelong Machine Learning Systems: Beyond Learning Algorithms", "abstract": "Lifelong Machine Learning, or LML, considers systems that can learn many tasks from one or more domains over its lifetime. The goal is to sequentially retain learned knowledge and to selectively transfer that knowledge when learning a new task so as to develop more accurate hypotheses or policies. Following a review of prior work on LML, we propose that it is now appropriate for the AI community to move beyond learning algorithms to more seriously consider the nature of systems that are capable of learning over a lifetime. Reasons for our position are presented and potential counter-arguments are discussed. The remainder of the paper contributes by defining LML, presenting a reference framework that considers all forms of machine learning, and listing several key challenges for and benefits from LML research. We conclude with ideas for next steps to advance the field.", "year": 2013, "referenceCount": 36, "citationCount": 327, "influentialCitationCount": 19, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "49601276", "name": "D. Silver"}, {"authorId": "152290618", "name": "Qiang Yang"}, {"authorId": "2048948347", "name": "Lianghao Li"}]}, {"paperId": "0d39cc42f2186dac99898121bbc8bb2b965ba93d", "url": "https://www.semanticscholar.org/paper/0d39cc42f2186dac99898121bbc8bb2b965ba93d", "title": "Assessment and Validation of Machine Learning Methods for Predicting Molecular Atomization Energies.", "abstract": "The accurate and reliable prediction of properties of molecules typically requires computationally intensive quantum-chemical calculations. Recently, machine learning techniques applied to ab initio calculations have been proposed as an efficient approach for describing the energies of molecules in their given ground-state structure throughout chemical compound space (Rupp et al. Phys. Rev. Lett. 2012, 108, 058301). In this paper we outline a number of established machine learning techniques and investigate the influence of the molecular representation on the methods performance. The best methods achieve prediction errors of 3 kcal/mol for the atomization energies of a wide variety of molecules. Rationales for this performance improvement are given together with pitfalls and challenges when applying machine learning approaches to the prediction of quantum-mechanical observables.", "year": 2013, "referenceCount": 79, "citationCount": 475, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "39960184", "name": "K. Hansen"}, {"authorId": "144535526", "name": "G. Montavon"}, {"authorId": "3022604", "name": "Franziska Biegler"}, {"authorId": "3050606", "name": "S. Fazli"}, {"authorId": "48041657", "name": "M. Rupp"}, {"authorId": "145310714", "name": "M. Scheffler"}, {"authorId": "7847508", "name": "O. A. von Lilienfeld"}, {"authorId": "2462983", "name": "A. Tkatchenko"}, {"authorId": "145034054", "name": "K. M\u00fcller"}]}, {"paperId": "836acf6fc99ebf81d219e2b67f7ab25efc29a6a4", "url": "https://www.semanticscholar.org/paper/836acf6fc99ebf81d219e2b67f7ab25efc29a6a4", "title": "Pylearn2: a machine learning research library", "abstract": "Pylearn2 is a machine learning research library. This does not just mean that it is a collection of machine learning algorithms that share a common API; it means that it has been designed for flexibility and extensibility in order to facilitate research projects that involve new or unusual use cases. In this paper we give a brief history of the library, an overview of its basic philosophy, a summary of the library's architecture, and a description of how the Pylearn2 community functions socially.", "year": 2013, "referenceCount": 60, "citationCount": 304, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "153440022", "name": "Ian J. Goodfellow"}, {"authorId": "1393680089", "name": "David Warde-Farley"}, {"authorId": "3087941", "name": "Pascal Lamblin"}, {"authorId": "3074927", "name": "Vincent Dumoulin"}, {"authorId": "153583218", "name": "Mehdi Mirza"}, {"authorId": "1996134", "name": "Razvan Pascanu"}, {"authorId": "32837403", "name": "J. Bergstra"}, {"authorId": "3227028", "name": "Fr\u00e9d\u00e9ric Bastien"}, {"authorId": "1751762", "name": "Yoshua Bengio"}]}, {"paperId": "bc745811e231d1b4e37d2c56cbd2d67e37ba9032", "url": "https://www.semanticscholar.org/paper/bc745811e231d1b4e37d2c56cbd2d67e37ba9032", "title": "Machine Learning Paradigms for Speech Recognition: An Overview", "abstract": "Automatic Speech Recognition (ASR) has historically been a driving force behind many machine learning (ML) techniques, including the ubiquitously used hidden Markov model, discriminative learning, structured sequence learning, Bayesian learning, and adaptive learning. Moreover, ML can and occasionally does use ASR as a large-scale, realistic application to rigorously test the effectiveness of a given technique, and to inspire new problems arising from the inherently sequential and dynamic nature of speech. On the other hand, even though ASR is available commercially for some applications, it is largely an unsolved problem - for almost all applications, the performance of ASR is not on par with human performance. New insight from modern ML methodology shows great promise to advance the state-of-the-art in ASR technology. This overview article provides readers with an overview of modern ML techniques as utilized in the current and as relevant to future ASR research and systems. The intent is to foster further cross-pollination between the ML and ASR communities than has occurred in the past. The article is organized according to the major ML paradigms that are either popular already or have potential for making significant contributions to ASR technology. The paradigms presented and elaborated in this overview include: generative and discriminative learning; supervised, unsupervised, semi-supervised, and active learning; adaptive and multi-task learning; and Bayesian learning. These learning paradigms are motivated and discussed in the context of ASR technology and applications. We finally present and analyze recent developments of deep learning and learning with sparse representations, focusing on their direct relevance to advancing ASR technology.", "year": 2013, "referenceCount": 296, "citationCount": 314, "influentialCitationCount": 15, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144718788", "name": "L. Deng"}, {"authorId": "2108787178", "name": "Xiao Li"}]}, {"paperId": "d82f27f4a8dcee6cbab41ff954cc6c2b7709a693", "url": "https://www.semanticscholar.org/paper/d82f27f4a8dcee6cbab41ff954cc6c2b7709a693", "title": "Mastering Machine Learning With scikit-learn", "abstract": "Apply effective learning algorithms to real-world problems using scikit-learn About This BookDesign and troubleshoot machine learning systems for common tasks including regression, classification, and clusteringAcquaint yourself with popular machine learning algorithms, including decision trees, logistic regression, and support vector machinesA practical example-based guide to help you gain expertise in implementing and evaluating machine learning systems using scikit-learnWho This Book Is ForIf you are a software developer who wants to learn how machine learning models work and how to apply them effectively, this book is for you. Familiarity with machine learning fundamentals and Python will be helpful, but is not essential. In Detail This book examines machine learning models including logistic regression, decision trees, and support vector machines, and applies them to common problems such as categorizing documents and classifying images. It begins with the fundamentals of machine learning, introducing you to the supervised-unsupervised spectrum, the uses of training and test data, and evaluating models. You will learn how to use generalized linear models in regression problems, as well as solve problems with text and categorical features.You will be acquainted with the use of logistic regression, regularization, and the various loss functions that are used by generalized linear models. The book will also walk you through an example project that prompts you to label the most uncertain training examples. You will also use an unsupervised Hidden Markov Model to predict stock prices.By the end of the book, you will be an expert in scikit-learn and will be well versed in machine learning", "year": 2014, "referenceCount": 0, "citationCount": 160, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "69904096", "name": "Gavin Hackeling"}]}, {"paperId": "64ad89855f829d0587e0f77d1be52030616c67cb", "url": "https://www.semanticscholar.org/paper/64ad89855f829d0587e0f77d1be52030616c67cb", "title": "Sentiment analysis in twitter using machine learning techniques", "abstract": "Sentiment analysis deals with identifying and classifying opinions or sentiments expressed in source text. Social media is generating a vast amount of sentiment rich data in the form of tweets, status updates, blog posts etc. Sentiment analysis of this user generated data is very useful in knowing the opinion of the crowd. Twitter sentiment analysis is difficult compared to general sentiment analysis due to the presence of slang words and misspellings. The maximum limit of characters that are allowed in Twitter is 140. Knowledge base approach and Machine learning approach are the two strategies used for analyzing sentiments from the text. In this paper, we try to analyze the twitter posts about electronic products like mobiles, laptops etc using Machine Learning approach. By doing sentiment analysis in a specific domain, it is possible to identify the effect of domain information in sentiment classification. We present a new feature vector for classifying the tweets as positive, negative and extract peoples' opinion about products.", "year": 2013, "referenceCount": 18, "citationCount": 316, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "9388856", "name": "M. Neethu"}, {"authorId": "144357907", "name": "R. Rajasree"}]}, {"paperId": "d8ed6678758f9200bd23fcf11dd733c8f4d9d71c", "url": "https://www.semanticscholar.org/paper/d8ed6678758f9200bd23fcf11dd733c8f4d9d71c", "title": "IEEE Transactions on Pattern Analysis and Machine Intelligence Information for Authors", "abstract": "In the real world, a realistic setting for computer vision or multimedia recognition problems is that we have some classes containing lots of training data and many classes contain a small amount of training data. Therefore, how to use frequent classes to help learning rare classes for which it is harder to collect the training data is an open question. Learning with Shared Information is an emerging topic in machine learning, computer vision and multimedia analysis. There are different level of components that can be shared during concept modeling and machine learning stages, such as sharing generic object parts, sharing attributes, sharing transformations, sharing regularization parameters and sharing training examples, etc. Regarding the specific methods, multi-task learning, transfer learning and deep learning can be seen as using different strategies to share information. These learning with shared information methods are very effective in solving real-world large-scale problems. This special issue aims at gathering the recent advances in learning with shared information methods and their applications in computer vision and multimedia analysis. Both state-of-the-art works, as well as literature reviews, are welcome for submission. Papers addressing interesting real-world computer vision and multimedia applications are especially encouraged. Topics of interest include, but are not limited to:  \u2022 Multi-task learning or transfer learning for large-scale computer vision and multimedia analysis \u2022 Deep learning for large-scale computer vision and multimedia analysis \u2022 Multi-modal approach for large-scale computer vision and multimedia analysis \u2022 Different sharing strategies, e.g., sharing generic object parts, sharing attributes, sharing transformations, sharing regularization parameters and sharing training examples, \u2022 Real-world computer vision and multimedia applications based on learning with shared information, e.g., event detection, object recognition, object detection, action recognition, human head pose estimation, object tracking, location-based services, semantic indexing. \u2022 New datasets and metrics to evaluate the benefit of the proposed sharing ability for the specific computer vision or multimedia problem. \u2022 Survey papers regarding the topic of learning with shared information.  Authors who are unsure whether their planned submission is in scope may contact the guest editors prior to the submission deadline with an abstract, in order to receive feedback.", "year": 2022, "referenceCount": 0, "citationCount": 1428, "influentialCitationCount": 110, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "69424391", "name": "Ieee Xplore"}]}, {"paperId": "ccf73e723d8308f28a98cb435dfb585581f59e2c", "url": "https://www.semanticscholar.org/paper/ccf73e723d8308f28a98cb435dfb585581f59e2c", "title": "Genetic Algorithms in Search, Optimization & Machine Learning", "abstract": null, "year": 1989, "referenceCount": 0, "citationCount": 2501, "influentialCitationCount": 137, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2060983236", "name": "D. E. Goldberg"}]}, {"paperId": "8ed390c98912ab8d27a398ab583d358c5a41fee9", "url": "https://www.semanticscholar.org/paper/8ed390c98912ab8d27a398ab583d358c5a41fee9", "title": "Machine learning for science and society", "abstract": null, "year": 2013, "referenceCount": 36, "citationCount": 85, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "48395540", "name": "C. Rudin"}, {"authorId": "6541629", "name": "K. Wagstaff"}]}, {"paperId": "cb7853c5d609081ea12cd4db3863a87da2d51808", "url": "https://www.semanticscholar.org/paper/cb7853c5d609081ea12cd4db3863a87da2d51808", "title": "From machine learning to machine reasoning", "abstract": null, "year": 2011, "referenceCount": 68, "citationCount": 220, "influentialCitationCount": 6, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "52184096", "name": "L. Bottou"}]}, {"paperId": "a15067563a18378dac71a206c6cc2e2d8c871301", "url": "https://www.semanticscholar.org/paper/a15067563a18378dac71a206c6cc2e2d8c871301", "title": "Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning", "abstract": "Algorithms for feature selection fall into two broad categories: wrappers that use the learning algorithm itself to evaluate the usefulness of features and filters that evaluate features according to heuristics based on general characteristics of the data. For application to large databases, filters have proven to be more practical than wrappers because they are much faster. However, most existing filter algorithms only work with discrete classification problems. This paper describes a fast, correlation-based filter algorithm that can be applied to continuous and discrete problems. The algorithm often outperforms the well-known ReliefF attribute estimator when used as a preprocessing step for naive Bayes, instance-based learning, decision trees, locally weighted regression, and model trees. It performs more feature selection than ReliefF does\u2014reducing the data dimensionality by fifty percent in most cases. Also, decision and model trees built from the preprocessed data are often significantly smaller.", "year": 1999, "referenceCount": 27, "citationCount": 1887, "influentialCitationCount": 221, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "118860642", "name": "M. Hall"}]}, {"paperId": "b90d44f59fcb74c71d3e31f67a3f09efab187a4e", "url": "https://www.semanticscholar.org/paper/b90d44f59fcb74c71d3e31f67a3f09efab187a4e", "title": "Machine learning in cell biology \u2013 teaching computers to recognize phenotypes", "abstract": "Summary Recent advances in microscope automation provide new opportunities for high-throughput cell biology, such as image-based screening. High-complex image analysis tasks often make the implementation of static and predefined processing rules a cumbersome effort. Machine-learning methods, instead, seek to use intrinsic data structure, as well as the expert annotations of biologists to infer models that can be used to solve versatile data analysis tasks. Here, we explain how machine-learning methods work and what needs to be considered for their successful application in cell biology. We outline how microscopy images can be converted into a data representation suitable for machine learning, and then introduce various state-of-the-art machine-learning algorithms, highlighting recent applications in image-based screening. Our Commentary aims to provide the biologist with a guide to the application of machine learning to microscopy assays and we therefore include extensive discussion on how to optimize experimental workflow as well as the data analysis pipeline.", "year": 2013, "referenceCount": 102, "citationCount": 280, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Biology", "Medicine"], "authors": [{"authorId": "2059204219", "name": "Christoph Sommer"}, {"authorId": "5811106", "name": "D. Gerlich"}]}, {"paperId": "941000ea62b7a7048b912c73a0adaeedc683b78b", "url": "https://www.semanticscholar.org/paper/941000ea62b7a7048b912c73a0adaeedc683b78b", "title": "Introduction to machine learning.", "abstract": null, "year": 2014, "referenceCount": 56, "citationCount": 126, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "1788636", "name": "Y. Bastanlar"}, {"authorId": "152540259", "name": "Mustafa Ozuysal"}]}, {"paperId": "84bb60b83f82ad847e19d96403ad0011abfc888f", "url": "https://www.semanticscholar.org/paper/84bb60b83f82ad847e19d96403ad0011abfc888f", "title": "The Boosting Approach to Machine Learning An Overview", "abstract": null, "year": 2003, "referenceCount": 86, "citationCount": 1965, "influentialCitationCount": 116, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1716301", "name": "R. Schapire"}]}, {"paperId": "49bdeb07b045dd77f0bfe2b44436608770235a23", "url": "https://www.semanticscholar.org/paper/49bdeb07b045dd77f0bfe2b44436608770235a23", "title": "Federated Learning: Challenges, Methods, and Future Directions", "abstract": "Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.", "year": 2019, "referenceCount": 154, "citationCount": 1598, "influentialCitationCount": 132, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "145530218", "name": "Tian Li"}, {"authorId": "2894821", "name": "Anit Kumar Sahu"}, {"authorId": "145532827", "name": "Ameet S. Talwalkar"}, {"authorId": "145260024", "name": "Virginia Smith"}]}, {"paperId": "73b51b02a061e2eae2eebe2ceae45872ea7d509d", "url": "https://www.semanticscholar.org/paper/73b51b02a061e2eae2eebe2ceae45872ea7d509d", "title": "A Survey on Machine-Learning Techniques in Cognitive Radios", "abstract": "In this survey paper, we characterize the learning problem in cognitive radios (CRs) and state the importance of artificial intelligence in achieving real cognitive communications systems. We review various learning problems that have been studied in the context of CRs classifying them under two main categories: Decision-making and feature classification. Decision-making is responsible for determining policies and decision rules for CRs while feature classification permits identifying and classifying different observation models. The learning algorithms encountered are categorized as either supervised or unsupervised algorithms. We describe in detail several challenging learning issues that arise in cognitive radio networks (CRNs), in particular in non-Markovian environments and decentralized networks, and present possible solution methods to address them. We discuss similarities and differences among the presented algorithms and identify the conditions under which each of the techniques may be applied.", "year": 2013, "referenceCount": 209, "citationCount": 449, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2849164", "name": "Mario Bkassiny"}, {"authorId": "50025121", "name": "Yang Li"}, {"authorId": "1682685", "name": "S. Jayaweera"}]}, {"paperId": "61017ac0c108f68c987a1fe3e4c2b6223ddd6f31", "url": "https://www.semanticscholar.org/paper/61017ac0c108f68c987a1fe3e4c2b6223ddd6f31", "title": "Machine learning classifiers and fMRI: A tutorial overview", "abstract": null, "year": 2009, "referenceCount": 51, "citationCount": 1521, "influentialCitationCount": 118, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "144637670", "name": "Francisco Pereira"}, {"authorId": "40975594", "name": "Tom Michael Mitchell"}, {"authorId": "46378362", "name": "M. Botvinick"}]}, {"paperId": "d480f90ec1d48309850c1b92b2053990a60522a8", "url": "https://www.semanticscholar.org/paper/d480f90ec1d48309850c1b92b2053990a60522a8", "title": "MLI: An API for Distributed Machine Learning", "abstract": "MLI is an Application Programming Interface designed to address the challenges of building Machine Learning algorithms in a distributed setting based on data-centric computing. Its primary goal is to simplify the development of high-performance, scalable, distributed algorithms. Our initial results show that, relative to existing systems, this interface can be used to build distributed implementations of a wide variety of common Machine Learning algorithms with minimal complexity and highly competitive performance and scalability.", "year": 2013, "referenceCount": 30, "citationCount": 194, "influentialCitationCount": 23, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "144752747", "name": "Evan R. Sparks"}, {"authorId": "145532827", "name": "Ameet S. Talwalkar"}, {"authorId": "145260024", "name": "Virginia Smith"}, {"authorId": "2983690", "name": "Jey Kottalam"}, {"authorId": "40201504", "name": "Xinghao Pan"}, {"authorId": "49988044", "name": "Joseph E. Gonzalez"}, {"authorId": "143666627", "name": "M. Franklin"}, {"authorId": "1694621", "name": "Michael I. Jordan"}, {"authorId": "1746961", "name": "Tim Kraska"}]}, {"paperId": "a19a69cdb137e83ba4b8d5c99d187b9f44bbc2d3", "url": "https://www.semanticscholar.org/paper/a19a69cdb137e83ba4b8d5c99d187b9f44bbc2d3", "title": "Learning scikit-learn: Machine Learning in Python", "abstract": "Experience the benefits of machine learning techniques by applying them to real-world problems using Python and the open source scikit-learn library Overview Use Python and scikit-learn to create intelligent applications Apply regression techniques to predict future behaviour and learn to cluster items in groups by their similarities Make use of classification techniques to perform image recognition and document classification In Detail Machine learning, the art of creating applications that learn from experience and data, has been around for many years. However, in the era of big data, huge amounts of information is being generated. This makes machine learning an unavoidable source of new data-based approximations for problem solving. With Learning scikit-learn: Machine Learning in Python, you will learn to incorporate machine learning in your applications. The book combines an introduction to some of the main concepts and methods in machine learning with practical, hands-on examples of real-world problems. Ranging from handwritten digit recognition to document classification, examples are solved step by step using Scikit-learn and Python. The book starts with a brief introduction to the core concepts of machine learning with a simple example. Then, using real-world applications and advanced features, it takes a deep dive into the various machine learning techniques. You will learn to evaluate your results and apply advanced techniques for preprocessing data. You will also be able to select the best set of features and the best methods for each problem. With Learning scikit-learn: Machine Learning in Python you will learn how to use the Python programming language and the scikit-learn library to build applications that learn from experience, applying the main concepts and techniques of machine learning. What you will learn from this book Set up scikit-learn inside your Python environment Classify objects (from documents to human faces and flower species) based on some of their features, using a variety of methods from Support Vector Machines to Nave Bayes Use Decision Trees to explain the main causes of certain phenomenon such as the Titanic passengers survival Predict house prices using regression techniques Display and analyse groups in your data using dimensionality reduction Make use of different tools to preprocess, extract, and select the learning features Select the best parameters for your models using model selection Improve the way you build your models using parallelization techniques Approach The book adopts a tutorial-based approach to introduce the user to Scikit-learn. Who this book is written for If you are a programmer who wants to explore machine learning and data-based methods to build intelligent applications and enhance your programming skills, this the book for you. No previous experience with machine-learning algorithms is required.", "year": 2013, "referenceCount": 0, "citationCount": 167, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2091354115", "name": "Ral Garreta"}, {"authorId": "2171196", "name": "Guillermo Moncecchi"}]}, {"paperId": "5fb8ba2e3967e079c57aa703bf216c168ea8104f", "url": "https://www.semanticscholar.org/paper/5fb8ba2e3967e079c57aa703bf216c168ea8104f", "title": "Model-based machine learning", "abstract": "Several decades of research in the field of machine learning have resulted in a multitude of different algorithms for solving a broad range of problems. To tackle a new application, a researcher typically tries to map their problem onto one of these existing methods, often influenced by their familiarity with specific algorithms and by the availability of corresponding software implementations. In this study, we describe an alternative methodology for applying machine learning, in which a bespoke solution is formulated for each new application. The solution is expressed through a compact modelling language, and the corresponding custom machine learning code is then generated automatically. This model-based approach offers several major advantages, including the opportunity to create highly tailored models for specific scenarios, as well as rapid prototyping and comparison of a range of alternative models. Furthermore, newcomers to the field of machine learning do not have to learn about the huge range of traditional methods, but instead can focus their attention on understanding a single modelling environment. In this study, we show how probabilistic graphical models, coupled with efficient inference algorithms, provide a very flexible foundation for model-based machine learning, and we outline a large-scale commercial application of this framework involving tens of millions of users. We also describe the concept of probabilistic programming as a powerful software environment for model-based machine learning, and we discuss a specific probabilistic programming language called Infer.NET, which has been widely used in practical applications.", "year": 2013, "referenceCount": 36, "citationCount": 168, "influentialCitationCount": 12, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "1792884", "name": "Charles M. Bishop"}]}, {"paperId": "a43e61f7900c64e7f3bf18ef7ff5770295149b37", "url": "https://www.semanticscholar.org/paper/a43e61f7900c64e7f3bf18ef7ff5770295149b37", "title": "Machine Learning, a Probabilistic Perspective", "abstract": "ISBN-13: 978-0262018029 The book also introduces the notion of a Bayesian likelihood function (p.228), which \u201cdiffers slightly from that in classical statistics.\u201d The only difference I can spot is in the interpretation: Both functions of (\u03b8, x) are numerically the same. Overall, the chapter on Bayesian inference does not spend much time on prior specification. There is a section on conjugate priors that does not mention picking the hyperparameters. While improper priors are introduced as limits of proper priors and as conveying \u201cthe least amount of information about [the parameters]\u201d (p.236), the difficulty in using improper priors for hypothesis testing is not mentioned. Both Chib\u2019s method and the Savage-Dickey density ratio are suggested for the approximation of marginal likelihoods.", "year": 2014, "referenceCount": 0, "citationCount": 187, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145155783", "name": "C. Robert"}]}, {"paperId": "93aa298b40bb3ec23c25239089284fdf61ded917", "url": "https://www.semanticscholar.org/paper/93aa298b40bb3ec23c25239089284fdf61ded917", "title": "Support vector machine learning for interdependent and structured output spaces", "abstract": "Learning general functional dependencies is one of the main goals in machine learning. Recent progress in kernel-based methods has focused on designing flexible and powerful input representations. This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces. We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs. The resulting optimization problem is solved efficiently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem. We demonstrate the versatility and effectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment.", "year": 2004, "referenceCount": 17, "citationCount": 1472, "influentialCitationCount": 319, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1765700", "name": "Ioannis Tsochantaridis"}, {"authorId": "143936663", "name": "Thomas Hofmann"}, {"authorId": "1680188", "name": "T. Joachims"}, {"authorId": "1783941", "name": "Y. Altun"}]}, {"paperId": "ea11efe27e029e391ea52609468353f98d9f946b", "url": "https://www.semanticscholar.org/paper/ea11efe27e029e391ea52609468353f98d9f946b", "title": "Machine learning on Big Data", "abstract": "Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research.", "year": 2013, "referenceCount": 26, "citationCount": 176, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3269316", "name": "Tyson Condie"}, {"authorId": "3040175", "name": "Paul Mineiro"}, {"authorId": "1763100", "name": "Neoklis Polyzotis"}, {"authorId": "2965406", "name": "Markus Weimer"}]}, {"paperId": "d2b7da2775b8a65034faaa5b1486e5062f827505", "url": "https://www.semanticscholar.org/paper/d2b7da2775b8a65034faaa5b1486e5062f827505", "title": "Optimization for Machine Learning", "abstract": "The interplay between optimization and machine learning is one of the most important developments in modern computational science. Optimization formulations and methods are proving to be vital in designing algorithms to extract essential knowledge from huge volumes of data. Machine learning, however, is not simply a consumer of optimization technology but a rapidly evolving field that is itself generating new optimization ideas. This book captures the state of the art of the interaction between optimization and machine learning in a way that is accessible to researchers in both fields.Optimization approaches have enjoyed prominence in machine learning because of their wide applicability and attractive theoretical properties. The increasing complexity, size, and variety of today's machine learning models call for the reassessment of existing assumptions. This book starts the process of reassessment. It describes the resurgence in novel contexts of established frameworks such as first-order methods, stochastic approximations, convex relaxations, interior-point methods, and proximal methods. It also devotes attention to newer themes such as regularized optimization, robust optimization, gradient and subgradient methods, splitting techniques, and second-order methods. Many of these techniques draw inspiration from other fields, including operations research, theoretical computer science, and subfields of optimization. The book will enrich the ongoing cross-fertilization between the machine learning community and these other fields, and within the broader optimization community.", "year": 2013, "referenceCount": 298, "citationCount": 163, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3072326", "name": "S. Sra"}, {"authorId": "2388416", "name": "S. Nowozin"}, {"authorId": "144731788", "name": "Stephen J. Wright"}]}, {"paperId": "c0f7fcc2e03be4395625b6757b17b8834632b952", "url": "https://www.semanticscholar.org/paper/c0f7fcc2e03be4395625b6757b17b8834632b952", "title": "Ensemble Machine Learning: Methods and Applications", "abstract": "It is common wisdom that gathering a variety of views and inputs improves the process of decision making, and, indeed, underpins a democratic society. Dubbed ensemble learning by researchers in computational intelligence and machine learning, it is known to improve a decision systems robustness and accuracy. Now, fresh developments are allowing researchers to unleash the power of ensemble learning in an increasing range of real-world applications. Ensemble learning algorithms such as boosting and random forest facilitate solutions to key computational issues such as face recognition and are now being applied in areas as diverse as object tracking and bioinformatics. Responding to a shortage of literature dedicated to the topic, this volume offers comprehensive coverage of state-of-the-art ensemble learning techniques, including the random forest skeleton tracking algorithm in the Xbox Kinect sensor, which bypasses the need for game controllers. At once a solid theoretical study and a practical guide, the volume is a windfall for researchers and practitioners alike.", "year": 2012, "referenceCount": 0, "citationCount": 562, "influentialCitationCount": 28, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2109292021", "name": "Cha Zhang"}, {"authorId": "2363386", "name": "Yunqian Ma"}]}]}