{"total": 5120627, "offset": 2700, "next": 2800, "data": [{"paperId": "d67019e2c610e5b1b0e3661bc1ccc5e0e93d2476", "url": "https://www.semanticscholar.org/paper/d67019e2c610e5b1b0e3661bc1ccc5e0e93d2476", "title": "Learning in Humans and Machines", "abstract": "Discusses the analysis, comparison and integration of computational approaches to learning and research on human learning. This book aims to provide the reader with an overview of the prolific research on learning throughout the disciplines. It also highlights the important research issues and methodologies.", "year": 1995, "referenceCount": 0, "citationCount": 95, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Psychology"], "authors": [{"authorId": "20779579", "name": "P. Reimann"}, {"authorId": "2926339", "name": "H. Spada"}]}, {"paperId": "9aee764d4c7d9d1361a3629be6a317c0e8c73d99", "url": "https://www.semanticscholar.org/paper/9aee764d4c7d9d1361a3629be6a317c0e8c73d99", "title": "Managing Diversity in Regression Ensembles", "abstract": "Ensembles are a widely used and effective technique in machine learning---their success is commonly attributed to the degree of disagreement, or 'diversity', within the ensemble. For ensembles where the individual estimators output crisp class labels, this 'diversity' is not well understood and remains an open research issue. For ensembles of regression estimators, the diversity can be exactly formulated in terms of the covariance between individual estimator outputs, and the optimum level is expressed in terms of a bias-variance-covariance trade-off. Despite this, most approaches to learning ensembles use heuristics to encourage the right degree of diversity. In this work we show how to explicitly control diversity through the error function. The first contribution of this paper is to show that by taking the combination mechanism for the ensemble into account we can derive an error function for each individual that balances ensemble diversity with individual accuracy. We show the relationship between this error function and an existing algorithm called negative correlation learning, which uses a heuristic penalty term added to the mean squared error function. It is demonstrated that these methods control the bias-variance-covariance trade-off systematically, and can be utilised with any estimator capable of minimising a quadratic error function, for example MLPs, or RBF networks. As a second contribution, we derive a strict upper bound on the coefficient of the penalty term, which holds for any estimator that can be cast in a generalised linear regression framework, with mild assumptions on the basis functions. Finally we present the results of an empirical study, showing significant improvements over simple ensemble learning, and finding that this technique is competitive with a variety of methods, including boosting, bagging, mixtures of experts, and Gaussian processes, on a number of tasks.", "year": 2005, "referenceCount": 28, "citationCount": 341, "influentialCitationCount": 32, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "145485821", "name": "Gavin Brown"}, {"authorId": "1688492", "name": "J. Wyatt"}, {"authorId": "4023505", "name": "P. Ti\u0148o"}]}, {"paperId": "31240cf20c338535aeb490c6b0eb55fc1fbab2af", "url": "https://www.semanticscholar.org/paper/31240cf20c338535aeb490c6b0eb55fc1fbab2af", "title": "Machine Learning in Mental Health", "abstract": "High prevalence of mental illness and the need for effective mental health care, combined with recent advances in AI, has led to an increase in explorations of how the field of machine learning (ML) can assist in the detection, diagnosis and treatment of mental health problems. ML techniques can potentially offer new routes for learning patterns of human behavior; identifying mental health symptoms and risk factors; developing predictions about disease progression; and personalizing and optimizing therapies. Despite the potential opportunities for using ML within mental health, this is an emerging research area, and the development of effective ML-enabled applications that are implementable in practice is bound up with an array of complex, interwoven challenges. Aiming to guide future research and identify new directions for advancing development in this important domain, this article presents an introduction to, and a systematic review of, current ML work regarding psycho-socially based mental health conditions from the computing and HCI literature. A quantitative synthesis and qualitative narrative review of 54 papers that were included in the analysis surfaced common trends, gaps, and challenges in this space. Discussing our findings, we (i) reflect on the current state-of-the-art of ML work for mental health, (ii) provide concrete suggestions for a stronger integration of human-centered and multi-disciplinary approaches in research and development, and (iii) invite more consideration of the potentially far-reaching personal, social, and ethical implications that ML models and interventions can have, if they are to find widespread, successful adoption in real-world mental health contexts.", "year": 2020, "referenceCount": 280, "citationCount": 77, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Psychology"], "authors": [{"authorId": "1944467", "name": "Anja Thieme"}, {"authorId": "145763736", "name": "D. Belgrave"}, {"authorId": "2659843", "name": "Gavin Doherty"}]}, {"paperId": "590fbc7b3b06416b72e23ef02e96ba5831977a3c", "url": "https://www.semanticscholar.org/paper/590fbc7b3b06416b72e23ef02e96ba5831977a3c", "title": "Cross-disciplinary perspectives on meta-learning for algorithm selection", "abstract": "The algorithm selection problem [Rice 1976] seeks to answer the question: Which algorithm is likely to perform best for my problem? Recognizing the problem as a learning task in the early 1990's, the machine learning community has developed the field of meta-learning, focused on learning about learning algorithm performance on classification problems. But there has been only limited generalization of these ideas beyond classification, and many related attempts have been made in other disciplines (such as AI and operations research) to tackle the algorithm selection problem in different ways, introducing different terminology, and overlooking the similarities of approaches. In this sense, there is much to be gained from a greater awareness of developments in meta-learning, and how these ideas can be generalized to learn about the behaviors of other (nonlearning) algorithms. In this article we present a unified framework for considering the algorithm selection problem as a learning problem, and use this framework to tie together the crossdisciplinary developments in tackling the algorithm selection problem. We discuss the generalization of meta-learning concepts to algorithms focused on tasks including sorting, forecasting, constraint satisfaction, and optimization, and the extension of these ideas to bioinformatics, cryptography, and other fields.", "year": 2009, "referenceCount": 119, "citationCount": 502, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1398371449", "name": "K. Smith\u2010Miles"}]}, {"paperId": "12244deb997152492d96c6246ec21b2b9804800d", "url": "https://www.semanticscholar.org/paper/12244deb997152492d96c6246ec21b2b9804800d", "title": "Text Detection and Character Recognition in Scene Images with Unsupervised Feature Learning", "abstract": "Reading text from photographs is a challenging problem that has received a significant amount of attention. Two key components of most systems are (i) text detection from images and (ii) character recognition, and many recent methods have been proposed to design better feature representations and models for both. In this paper, we apply methods recently developed in machine learning -- specifically, large-scale algorithms for learning the features automatically from unlabeled data -- and show that they allow us to construct highly effective classifiers for both detection and recognition to be used in a high accuracy end-to-end system.", "year": 2011, "referenceCount": 28, "citationCount": 407, "influentialCitationCount": 24, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144638694", "name": "Adam Coates"}, {"authorId": "37742741", "name": "Blake Carpenter"}, {"authorId": "2065131508", "name": "Carl Case"}, {"authorId": "145031342", "name": "S. Satheesh"}, {"authorId": "39086009", "name": "B. Suresh"}, {"authorId": "41154933", "name": "Tao Wang"}, {"authorId": "25629078", "name": "David J. Wu"}, {"authorId": "34699434", "name": "A. Ng"}]}, {"paperId": "4ce39a77a7347ca7fedce513dec361e7cb9fed02", "url": "https://www.semanticscholar.org/paper/4ce39a77a7347ca7fedce513dec361e7cb9fed02", "title": "Machine Learning of Inductive Bias", "abstract": null, "year": 1986, "referenceCount": 0, "citationCount": 77, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2195972", "name": "P. Utgoff"}]}, {"paperId": "a9fee459ed211f53bfadef22e3ab774d0e927358", "url": "https://www.semanticscholar.org/paper/a9fee459ed211f53bfadef22e3ab774d0e927358", "title": "Computing Semantic Relatedness Using Wikipedia-based Explicit Semantic Analysis", "abstract": "Computing semantic relatedness of natural language texts requires access to vast amounts of common-sense and domain-specific world knowledge. We propose Explicit Semantic Analysis (ESA), a novel method that represents the meaning of texts in a high-dimensional space of concepts derived from Wikipedia. We use machine learning techniques to explicitly represent the meaning of any text as a weighted vector of Wikipedia-based concepts. Assessing the relatedness of texts in this space amounts to comparing the corresponding vectors using conventional metrics (e.g., cosine). Compared with the previous state of the art, using ESA results in substantial improvements in correlation of computed relatedness scores with human judgments: from r = 0.56 to 0.75 for individual words and from r = 0.60 to 0.72 for texts. Importantly, due to the use of natural concepts, the ESA model is easy to explain to human users.", "year": 2007, "referenceCount": 48, "citationCount": 2353, "influentialCitationCount": 377, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1718798", "name": "E. Gabrilovich"}, {"authorId": "2309269", "name": "Shaul Markovitch"}]}, {"paperId": "bb56bc6676fb88d67a071fd482a349286e20b16d", "url": "https://www.semanticscholar.org/paper/bb56bc6676fb88d67a071fd482a349286e20b16d", "title": "A Survey of ReRAM-Based Architectures for Processing-In-Memory and Neural Networks", "abstract": "As data movement operations and power-budget become key bottlenecks in the design of computing systems, the interest in unconventional approaches such as processing-in-memory (PIM), machine learning (ML), and especially neural network (NN)-based accelerators has grown significantly. Resistive random access memory (ReRAM) is a promising technology for efficiently architecting PIM- and NN-based accelerators due to its capabilities to work as both: High-density/low-energy storage and in-memory computation/search engine. In this paper, we present a survey of techniques for designing ReRAM-based PIM and NN architectures. By classifying the techniques based on key parameters, we underscore their similarities and differences. This paper will be valuable for computer architects, chip designers and researchers in the area of machine learning.", "year": 2018, "referenceCount": 40, "citationCount": 90, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "38918006", "name": "Sparsh Mittal"}]}, {"paperId": "25d53b9e68cc5f9bb1c01287cfe05ed64cf38432", "url": "https://www.semanticscholar.org/paper/25d53b9e68cc5f9bb1c01287cfe05ed64cf38432", "title": "Regularized extreme learning machine for regression problems", "abstract": null, "year": 2011, "referenceCount": 19, "citationCount": 157, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1398184868", "name": "J. Mart\u00ednez-Mart\u00ednez"}, {"authorId": "1398184857", "name": "Pablo Escandell-Montero"}, {"authorId": "83227156", "name": "E. Soria-Olivas"}, {"authorId": "84306443", "name": "J. Mart\u00edn-Guerrero"}, {"authorId": "35119570", "name": "J. Benedito"}, {"authorId": "1396035413", "name": "J. G\u00f3mez-Sanch\u00eds"}]}, {"paperId": "c1a46d9a0972fb0ec0977d24a191f612e7401369", "url": "https://www.semanticscholar.org/paper/c1a46d9a0972fb0ec0977d24a191f612e7401369", "title": "Distributed Learning with Regularized Least Squares", "abstract": "We study distributed learning with the least squares regularization scheme in a reproducing kernel Hilbert space (RKHS). By a divide-and-conquer approach, the algorithm partitions a data set into disjoint data subsets, applies the least squares regularization scheme to each data subset to produce an output function, and then takes an average of the individual output functions as a final global estimator or predictor. We show with error bounds in expectation in both the $L^2$-metric and RKHS-metric that the global output function of this distributed learning is a good approximation to the algorithm processing the whole data in one single machine. Our error bounds are sharp and stated in a general setting without any eigenfunction assumption. The analysis is achieved by a novel second order decomposition of operator differences in our integral operator approach. Even for the classical least squares regularization scheme in the RKHS associated with a general kernel, we give the best learning rate in the literature.", "year": 2016, "referenceCount": 46, "citationCount": 140, "influentialCitationCount": 31, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "2432506", "name": "Shaobo Lin"}, {"authorId": "2116513495", "name": "Xin Guo"}, {"authorId": "1758237", "name": "Ding-Xuan Zhou"}]}, {"paperId": "1e0a41e48821d6111329d75dc63354aa8ecd241a", "url": "https://www.semanticscholar.org/paper/1e0a41e48821d6111329d75dc63354aa8ecd241a", "title": "Explanation-Based Generalization: A Unifying View", "abstract": null, "year": 1986, "referenceCount": 67, "citationCount": 368, "influentialCitationCount": 29, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "40975594", "name": "Tom Michael Mitchell"}, {"authorId": "50337526", "name": "R. Keller"}, {"authorId": "1403824951", "name": "S. Kedar-Cabelli"}]}, {"paperId": "93e4cb65cb5bfa568e57495c804c4c5e2324ccaf", "url": "https://www.semanticscholar.org/paper/93e4cb65cb5bfa568e57495c804c4c5e2324ccaf", "title": "DScribe: Library of Descriptors for Machine Learning in Materials Science", "abstract": null, "year": 2019, "referenceCount": 98, "citationCount": 255, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Physics", "Materials Science"], "authors": [{"authorId": "2603574", "name": "L. Himanen"}, {"authorId": "2007829129", "name": "M. J\u00e4ger"}, {"authorId": "95983512", "name": "Eiaki V. Morooka"}, {"authorId": "39166484", "name": "F. F. Canova"}, {"authorId": "51255118", "name": "Y. S. Ranawat"}, {"authorId": "2225189", "name": "D. Gao"}, {"authorId": "2529275", "name": "P. Rinke"}, {"authorId": "35851774", "name": "A. Foster"}]}, {"paperId": "e7d6c69fe45659e3698bd990d6a369e39bfb6b2f", "url": "https://www.semanticscholar.org/paper/e7d6c69fe45659e3698bd990d6a369e39bfb6b2f", "title": "Voltage Stability Prediction Using Active Machine Learning", "abstract": "An active machine learning technique for monitoring the voltage stability in transmission systems is presented. It has been shown that machine learning algorithms may be used to supplement the traditional simulation approach, but they suffer from the difficulties of online machine learning model update and offline training data preparation. We propose an active learning solution to enhance existing machine learning applications by actively interacting with the online prediction and offline training process. The technique identifies operating points where machine learning predictions based on power system measurements contradict with actual system conditions. By creating the training set around the identified operating points, it is possible to improve the capability of machine learning tools to predict future power system states. The technique also accelerates the offline training process by reducing the amount of simulations on a detailed power system model around operating points where correct predictions are made. Experiments show a significant advantage in relation to the training time, prediction time, and number of measurements that need to be queried to achieve high prediction accuracy.", "year": 2017, "referenceCount": 33, "citationCount": 71, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2279271", "name": "V. Malbasa"}, {"authorId": "46882254", "name": "Ce Zheng"}, {"authorId": "2527605", "name": "Po-Chen Chen"}, {"authorId": "47398218", "name": "T. Popovic"}, {"authorId": "2998246", "name": "M. Kezunovic"}]}, {"paperId": "d53cd4dc81a93f496c92864509de9c9c8ca4513e", "url": "https://www.semanticscholar.org/paper/d53cd4dc81a93f496c92864509de9c9c8ca4513e", "title": "Machine Learning Methods in the Environmental Sciences: Contents", "abstract": "Machine learning methods, having originated from computational intelligence (i.e. artificial intelligence), are now ubiquitous in the environmental sciences. This is the first single-authored textbook to give a unified treatment of machine learning methods and their applications in the environmental sciences. Machine learning methods began to infiltrate the environmental sciences in the 1990s. Today, thanks to their powerful nonlinear modelling capability, they are no longer an exotic fringe species, as they are heavily used in satellite data processing, in general circulation models (GCM), in weather and climate prediction, air quality forecasting, analysis and modelling of environmental data, oceanographic and hydrological forecasting, ecological modelling, and in the monitoring of snow, ice and forests, etc. End-of-chapter review questions are included, allowing readers to develop their problem-solving skills and monitor their understanding of the material presented. An appendix lists websites available for downloading computer code and data sources. A resources website is available containing datasets for exercises, and additional material to keep the book completely up-to-date. This book presents machine learning methods and their applications in the environmental sciences (including satellite remote sensing, atmospheric science, climate science, oceanography, hydrology and ecology), written at a level suitable for beginning graduate students and advanced undergraduates. It is also valuable for researchers and practitioners in environmental sciences interested in applying these new methods to their own work.", "year": 2009, "referenceCount": 1, "citationCount": 121, "influentialCitationCount": 5, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1781249", "name": "W. Hsieh"}]}, {"paperId": "59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "url": "https://www.semanticscholar.org/paper/59a916cdc943f0282908e6f3fa0360f4c5fb78d0", "title": "Stabilizing Transformers for Reinforcement Learning", "abstract": "Owing to their ability to both effectively integrate information over long time horizons and scale to massive amounts of data, self-attention architectures have recently shown breakthrough success in natural language processing (NLP), achieving state-of-the-art results in domains such as language modeling and machine translation. Harnessing the transformer's ability to process long time horizons of information could provide a similar performance boost in partially observable reinforcement learning (RL) domains, but the large-scale transformers used in NLP have yet to be successfully applied to the RL setting. In this work we demonstrate that the standard transformer architecture is difficult to optimize, which was previously observed in the supervised learning setting but becomes especially pronounced with RL objectives. We propose architectural modifications that substantially improve the stability and learning speed of the original Transformer and XL variant. The proposed architecture, the Gated Transformer-XL (GTrXL), surpasses LSTMs on challenging memory environments and achieves state-of-the-art results on the multi-task DMLab-30 benchmark suite, exceeding the performance of an external memory architecture. We show that the GTrXL, trained using the same losses, has stability and performance that consistently matches or exceeds a competitive LSTM baseline, including on more reactive tasks where memory is less critical. GTrXL offers an easy-to-train, simple-to-implement but substantially more expressive architectural alternative to the standard multi-layer LSTM ubiquitously used for RL agents in partially observable environments.", "year": 2019, "referenceCount": 57, "citationCount": 164, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3166516", "name": "Emilio Parisotto"}, {"authorId": "2107148568", "name": "H. F. Song"}, {"authorId": "34269227", "name": "Jack W. Rae"}, {"authorId": "1996134", "name": "Razvan Pascanu"}, {"authorId": "1854385", "name": "\u00c7aglar G\u00fcl\u00e7ehre"}, {"authorId": "35880964", "name": "Siddhant M. Jayakumar"}, {"authorId": "3093886", "name": "Max Jaderberg"}, {"authorId": "31713635", "name": "Raphael Lopez Kaufman"}, {"authorId": "31993415", "name": "Aidan Clark"}, {"authorId": "30155667", "name": "Seb Noury"}, {"authorId": "46378362", "name": "M. Botvinick"}, {"authorId": "2801204", "name": "N. Heess"}, {"authorId": "2315504", "name": "R. Hadsell"}]}, {"paperId": "595c811c70d2e6ea29ea8aabe201d7290e6ef23c", "url": "https://www.semanticscholar.org/paper/595c811c70d2e6ea29ea8aabe201d7290e6ef23c", "title": "Weakly Supervised Learning for Hedge Classification in Scientific Literature", "abstract": "We investigate automatic classification of speculative language (\u2018hedging\u2019), in biomedical text using weakly supervised machine learning. Our contributions include a precise description of the task with annotation guidelines, analysis and discussion, a probabilistic weakly supervised learning model, and experimental evaluation of the methods presented. We show that hedge classification is feasible using weakly supervised ML, and point toward avenues for future research.", "year": 2007, "referenceCount": 21, "citationCount": 207, "influentialCitationCount": 20, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2310842", "name": "Ben Medlock"}, {"authorId": "145693410", "name": "Ted Briscoe"}]}, {"paperId": "26a1094ea12e3ea1f734e1670e6ba0e96c6b4bcf", "url": "https://www.semanticscholar.org/paper/26a1094ea12e3ea1f734e1670e6ba0e96c6b4bcf", "title": "A DEEP LEARNING APPROACH TO", "abstract": "Wildfires are a serious disaster, which often cause severe damages to forests and plants. Without an early detection and suitable control action, a small wildfire could grow into a big and serious one. The problem is especially fatal at night, as firefighters in general miss the chance to detect the wildfires in the very first few hours. Low-light satellites, which take pictures at night, offer an opportunity to detect night fire timely. However, previous studies identify night fires based on threshold methods or conventional machine learning approaches, which are not robust and accurate enough. In this paper, we develop a new deep learning approach, which determines night fire locations by a pixel-level classification on low-light remote sensing image. Experimental results on VIIRS data demonstrate the superiority and effectiveness of the proposed method, which outperforms conventional threshold and machine learning approaches.", "year": 2021, "referenceCount": 12, "citationCount": 169, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2118461571", "name": "Yue Wang"}, {"authorId": "2072724646", "name": "Ye Ni"}, {"authorId": "48569885", "name": "Xutao Li"}, {"authorId": "144782498", "name": "Yunming Ye"}]}, {"paperId": "465d56d1f1874f76b2a1094d1a694d23c65d5242", "url": "https://www.semanticscholar.org/paper/465d56d1f1874f76b2a1094d1a694d23c65d5242", "title": "The promise of machine learning in cybersecurity", "abstract": "Over the last few years' machine learning has migrated from the laboratory to the forefront of operational systems. Amazon, Google and Facebook use machine learning every day to improve customer experiences, suggested purchases or connect people socially with new applications and facilitate personal connections. Machine learning's powerful capability is also there for cybersecurity. Cybersecurity is positioned to leverage machine learning to improve malware detection, triage events, recognize breaches and alert organizations to security issues. Machine learning can be used to identify advanced targeting and threats such as organization profiling, infrastructure vulnerabilities and potential interdependent vulnerabilities and exploits. Machine learning can significantly change the cybersecurity landscape. Malware by itself can represent as many as 3 million new samples an hour. Traditional malware detection and malware analysis is unable to pace with new attacks and variants. New attacks and sophisticated malware have been able to bypass network and end-point detection to deliver cyber-attacks at alarming rates. New techniques like machine learning must be leveraged to address the growing malware problem. This paper describes how machine learning can be used to detect and highlight advanced malware for cyber defense analysts. The results of our initial research and a discussion of future research to extend machine learning is presented.", "year": 2017, "referenceCount": 11, "citationCount": 56, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "40558000", "name": "James B. Fraley"}, {"authorId": "144403288", "name": "J. Cannady"}]}, {"paperId": "70f6937b6253db8209d8fd6a4115e766946f04c5", "url": "https://www.semanticscholar.org/paper/70f6937b6253db8209d8fd6a4115e766946f04c5", "title": "eDoctor: machine learning and the future of medicine", "abstract": "Machine learning (ML) is a burgeoning field of medicine with huge resources being applied to fuse computer science and statistics to medical problems. Proponents of ML extol its ability to deal with large, complex and disparate data, often found within medicine and feel that ML is the future for biomedical research, personalized medicine, computer\u2010aided diagnosis to significantly advance global health care. However, the concepts of ML are unfamiliar to many medical professionals and there is untapped potential in the use of ML as a research tool. In this article, we provide an overview of the theory behind ML, explore the common ML algorithms used in medicine including their pitfalls and discuss the potential future of ML in medicine.", "year": 2018, "referenceCount": 110, "citationCount": 181, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "26612400", "name": "G. Handelman"}, {"authorId": "6129704", "name": "H. Kok"}, {"authorId": "35333607", "name": "R. Chandra"}, {"authorId": "3144725", "name": "A. H. Razavi"}, {"authorId": "153692329", "name": "M. Lee"}, {"authorId": "40911580", "name": "H. Asadi"}]}, {"paperId": "11a9f7712b88f698bc062797872867b8b4e5f439", "url": "https://www.semanticscholar.org/paper/11a9f7712b88f698bc062797872867b8b4e5f439", "title": "Applying machine learning to agricultural data", "abstract": null, "year": 1995, "referenceCount": 35, "citationCount": 135, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Engineering"], "authors": [{"authorId": "1728867", "name": "R. McQueen"}, {"authorId": "2072119972", "name": "Stephen R. Garner"}, {"authorId": "1389909404", "name": "C. Nevill-Manning"}, {"authorId": "9419406", "name": "I. Witten"}]}, {"paperId": "f7a062bc0c39672c327df0042866dc328e700d2b", "url": "https://www.semanticscholar.org/paper/f7a062bc0c39672c327df0042866dc328e700d2b", "title": "Predicting weather forecast uncertainty with machine learning", "abstract": "Weather forecasts are inherently uncertain. Therefore, for many applications forecasts are only considered valuable if an uncertainty estimate can be assigned to them. Currently, the best method to provide a confidence estimate for individual forecasts is to produce an ensemble of numerical weather simulations, which is computationally very expensive. Here, we assess whether machine learning techniques can provide an alternative approach to predict the uncertainty of a weather forecast given the large\u2010scale atmospheric state at initialization. We propose a method based on deep learning with artificial convolutional neural networks that is trained on past weather forecasts. Given a new weather situation, it assigns a scalar value of confidence to medium\u2010range forecasts initialized from the said atmospheric state, indicating whether the predictability is higher or lower than usual for the time of the year. While our method has a lower skill than ensemble weather forecast models in predicting forecast uncertainty, it is computationally very efficient and outperforms a range of alternative methods that do not involve performing numerical forecasts. This shows that it is possible to use machine learning in order to estimate future forecast uncertainty from past forecasts. The main constraint in the performance of our method seems to be the number of past forecasts available for training the machine learning algorithm.", "year": 2018, "referenceCount": 26, "citationCount": 99, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "89677034", "name": "S. Scher"}, {"authorId": "8752529", "name": "G. Messori"}]}, {"paperId": "86ce004214845a1683d59b64c4363a067d342cac", "url": "https://www.semanticscholar.org/paper/86ce004214845a1683d59b64c4363a067d342cac", "title": "Machine Learning Methods for Estimating Heterogeneous Causal Effects\u2217", "abstract": "In this paper we study the problems of estimating heterogeneity in causal effects in experimental or observational studies and conducting inference about the magnitude of the differences in treatment effects across subsets of the population. In applications, our method provides a data-driven approach to determine which subpopulations have large or small treatment effects and to test hypotheses about the differences in these effects. For experiments, our method allows researchers to identify heterogeneity in treatment effects that was not specified in a pre-analysis plan, without concern about invalidating inference due to multiple testing. In most of the literature on supervised machine learning (e.g. regression trees, random forests, LASSO, etc.), the goal is to build a model of the relationship between a unit\u2019s attributes and an observed outcome. A prominent role in these methods is played by cross-validation which compares predictions to actual outcomes in test samples, in order to select the level of complexity of the model that provides the best predictive power. Our method is closely related, but it differs in that it is tailored for predicting causal effects of a treatment rather than a unit\u2019s outcome. The challenge is that the \u201cground truth\u201d for a causal effect is not observed for any individual unit: we observe the unit with the treatment, or without the treatment, but not both at the same time. Thus, it is not obvious how to use cross-validation to determine whether a causal effect has been accurately predicted. We propose several novel cross-validation criteria for this problem and demonstrate through simulations the conditions under which they perform better than standard methods for the problem of causal effects. We then apply the method to a large-scale field experiment re-ranking results on a search engine.", "year": 2015, "referenceCount": 42, "citationCount": 192, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": null, "authors": [{"authorId": "2631417", "name": "S. Athey"}, {"authorId": "47166531", "name": "G. Imbens"}]}, {"paperId": "a104f5056f066b5c29c8f1320e37535220b7ce6e", "url": "https://www.semanticscholar.org/paper/a104f5056f066b5c29c8f1320e37535220b7ce6e", "title": "Forecasting tourist arrivals with machine learning and internet search index", "abstract": "The queries entered into search engines register hundreds of millions of different searches by tourists, not only reflecting the trends of the searchers' preferences for travel products, but also offering a forecasting of their future travel behavior. This paper proposed a forecasting framework based on internet search index and machine learning to forecast tourist arrivals, and compared the forecasting performance of two different search engines data, Baidu and Google. The empirical results suggest that the proposed KELM models by fusing Baidu index and Google index can significantly improve the forecasting performance and outperform other benchmark models in terms of forecasting accuracy.", "year": 2017, "referenceCount": 52, "citationCount": 185, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "48904871", "name": "Shaolong Sun"}, {"authorId": "34203815", "name": "Shouyang Wang"}, {"authorId": "2023780929", "name": "Yunjie Wei"}, {"authorId": "35344980", "name": "X. Yang"}, {"authorId": "145690550", "name": "K. Tsui"}]}, {"paperId": "1a270a3e6a014943845660dc0630763deb6d4d09", "url": "https://www.semanticscholar.org/paper/1a270a3e6a014943845660dc0630763deb6d4d09", "title": "Prediction Models of Functional Outcomes for Individuals in the Clinical High-Risk State for Psychosis or With Recent-Onset Depression: A Multimodal, Multisite Machine Learning Analysis", "abstract": "Importance Social and occupational impairments contribute to the burden of psychosis and depression. There is a need for risk stratification tools to inform personalized functional-disability preventive strategies for individuals in at-risk and early phases of these illnesses. Objective To determine whether predictors associated with social and role functioning can be identified in patients in clinical high-risk (CHR) states for psychosis or with recent-onset depression (ROD) using clinical, imaging-based, and combined machine learning; assess the geographic, transdiagnostic, and prognostic generalizability of machine learning and compare it with human prognostication; and explore sequential prognosis encompassing clinical and combined machine learning. Design, Setting, and Participants This multisite naturalistic study followed up patients in CHR states, with ROD, and with recent-onset psychosis, and healthy control participants for 18 months in 7 academic early-recognition services in 5 European countries. Participants were recruited between February 2014 and May 2016, and data were analyzed from April 2017 to January 2018. ain Outcomes and Measures Performance and generalizability of prognostic models. Results A total of 116 individuals in CHR states (mean [SD] age, 24.0 [5.1] years; 58 [50.0%] female) and 120 patients with ROD (mean [SD] age, 26.1 [6.1] years; 65 [54.2%] female) were followed up for a mean (SD) of 329 (142) days. Machine learning predicted the 1-year social-functioning outcomes with a balanced accuracy of 76.9% of patients in CHR states and 66.2% of patients with ROD using clinical baseline data. Balanced accuracy in models using structural neuroimaging was 76.2% in patients in CHR states and 65.0% in patients with ROD, and in combined models, it was 82.7% for CHR states and 70.3% for ROD. Lower functioning before study entry was a transdiagnostic predictor. Medial prefrontal and temporo-parieto-occipital gray matter volume (GMV) reductions and cerebellar and dorsolateral prefrontal GMV increments had predictive value in the CHR group; reduced mediotemporal and increased prefrontal-perisylvian GMV had predictive value in patients with ROD. Poor prognoses were associated with increased risk of psychotic, depressive, and anxiety disorders at follow-up in patients in the CHR state but not ones with ROD. Machine learning outperformed expert prognostication. Adding neuroimaging machine learning to clinical machine learning provided a 1.9-fold increase of prognostic certainty in uncertain cases of patients in CHR states, and a 10.5-fold increase of prognostic certainty for patients with ROD. Conclusions and Relevance Precision medicine tools could augment effective therapeutic strategies aiming at the prevention of social functioning impairments in patients with CHR states or with ROD.", "year": 2018, "referenceCount": 130, "citationCount": 122, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "3214043", "name": "N. Koutsouleris"}, {"authorId": "1414119219", "name": "L. Kambeitz-Ilankovic"}, {"authorId": "1982479", "name": "S. Ruhrmann"}, {"authorId": "40892922", "name": "M. Rosen"}, {"authorId": "32098768", "name": "A. Ruef"}, {"authorId": "5672681", "name": "D. Dwyer"}, {"authorId": "5250359", "name": "M. Paolini"}, {"authorId": "15568397", "name": "Katharine Chisholm"}, {"authorId": "2876416", "name": "J. Kambeitz"}, {"authorId": "40900560", "name": "T. Haidl"}, {"authorId": "12462273", "name": "A. Schmidt"}, {"authorId": "40210909", "name": "J. Gillam"}, {"authorId": "1398034341", "name": "F. Schultze-Lutter"}, {"authorId": "2660554", "name": "P. Falkai"}, {"authorId": "145371637", "name": "M. Reiser"}, {"authorId": "146173036", "name": "A. Riecher-R\u00f6ssler"}, {"authorId": "4361455", "name": "R. Upthegrove"}, {"authorId": "34718106", "name": "J. Hietala"}, {"authorId": "6257052", "name": "R. Salokangas"}, {"authorId": "8770059", "name": "C. Pantelis"}, {"authorId": "2875471", "name": "E. Meisenzahl"}, {"authorId": "2086924", "name": "S. Wood"}, {"authorId": "2423864", "name": "D. Beque"}, {"authorId": "3110755", "name": "P. Brambilla"}, {"authorId": "48682353", "name": "S. Borgwardt"}]}, {"paperId": "8f7a7aea33c942e626832f014a831361b7fa39c7", "url": "https://www.semanticscholar.org/paper/8f7a7aea33c942e626832f014a831361b7fa39c7", "title": "PotentialNet for Molecular Property Prediction", "abstract": "The arc of drug discovery entails a multiparameter optimization problem spanning vast length scales. The key parameters range from solubility (angstroms) to protein\u2013ligand binding (nanometers) to in vivo toxicity (meters). Through feature learning\u2014instead of feature engineering\u2014deep neural networks promise to outperform both traditional physics-based and knowledge-based machine learning models for predicting molecular properties pertinent to drug discovery. To this end, we present the PotentialNet family of graph convolutions. These models are specifically designed for and achieve state-of-the-art performance for protein\u2013ligand binding affinity. We further validate these deep neural networks by setting new standards of performance in several ligand-based tasks. In parallel, we introduce a new metric, the Regression Enrichment Factor EF\u03c7(R), to measure the early enrichment of computational models for chemical data. Finally, we introduce a cross-validation strategy based on structural homology clustering that can more accurately measure model generalizability, which crucially distinguishes the aims of machine learning for drug discovery from standard machine learning tasks.", "year": 2018, "referenceCount": 60, "citationCount": 210, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "5932099", "name": "Evan N. Feinberg"}, {"authorId": "39460558", "name": "Debnil Sur"}, {"authorId": "9957625", "name": "Zhenqin Wu"}, {"authorId": "8751433", "name": "B. Husic"}, {"authorId": "80646261", "name": "Huanghao Mai"}, {"authorId": "2154902070", "name": "Yang Li"}, {"authorId": "51248807", "name": "Saisai Sun"}, {"authorId": "49500220", "name": "Jianyi Yang"}, {"authorId": "2378027", "name": "Bharath Ramsundar"}, {"authorId": "1806271", "name": "V. Pande"}]}, {"paperId": "78cd29d44f06f180af1b87c2f36be9a8492741f3", "url": "https://www.semanticscholar.org/paper/78cd29d44f06f180af1b87c2f36be9a8492741f3", "title": "Learning from ambiguously labeled examples", "abstract": null, "year": 2005, "referenceCount": 45, "citationCount": 164, "influentialCitationCount": 43, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1691955", "name": "E. H\u00fcllermeier"}, {"authorId": "49966445", "name": "J. Beringer"}]}, {"paperId": "18bc1d4271abe8dd6e16179cdb06524a4f396e16", "url": "https://www.semanticscholar.org/paper/18bc1d4271abe8dd6e16179cdb06524a4f396e16", "title": "Snorkel: Rapid Training Data Creation with Weak Supervision", "abstract": "Labeling training data is increasingly the largest bottleneck in deploying machine learning systems. We present Snorkel, a first-of-its-kind system that enables users to train state-of- the-art models without hand labeling any training data. Instead, users write labeling functions that express arbitrary heuristics, which can have unknown accuracies and correlations. Snorkel denoises their outputs without access to ground truth by incorporating the first end-to-end implementation of our recently proposed machine learning paradigm, data programming. We present a flexible interface layer for writing labeling functions based on our experience over the past year collaborating with companies, agencies, and research labs. In a user study, subject matter experts build models 2.8\u00d7 faster and increase predictive performance an average 45.5% versus seven hours of hand labeling. We study the modeling tradeoffs in this new setting and propose an optimizer for automating tradeoff decisions that gives up to 1.8\u00d7 speedup per pipeline execution. In two collaborations, with the U.S. Department of Veterans Affairs and the U.S. Food and Drug Administration, and on four open-source text and image data sets representative of other deployments, Snorkel provides 132% average improvements to predictive performance over prior heuristic approaches and comes within an average 3.60% of the predictive performance of large hand-curated training sets.", "year": 2017, "referenceCount": 68, "citationCount": 715, "influentialCitationCount": 120, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine", "Mathematics"], "authors": [{"authorId": "143711421", "name": "Alexander J. Ratner"}, {"authorId": "2870504", "name": "Stephen H. Bach"}, {"authorId": "33918804", "name": "Henry R. Ehrenberg"}, {"authorId": "31592365", "name": "Jason Alan Fries"}, {"authorId": "144766615", "name": "Sen Wu"}, {"authorId": "2114485554", "name": "C. R\u00e9"}]}, {"paperId": "29409efa04ac99ccf01d2a011d21d5d14e870000", "url": "https://www.semanticscholar.org/paper/29409efa04ac99ccf01d2a011d21d5d14e870000", "title": "Artificial intelligence to deep learning: machine intelligence approach for drug discovery", "abstract": null, "year": 2021, "referenceCount": 501, "citationCount": 99, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "1409846740", "name": "Rohan Gupta"}, {"authorId": "153610437", "name": "Devesh Srivastava"}, {"authorId": "2059118408", "name": "Mehar Sahu"}, {"authorId": "2072850683", "name": "Swati Tiwari"}, {"authorId": "2288195", "name": "R. K. Ambasta"}, {"authorId": "38183916", "name": "Pravir Kumar"}]}, {"paperId": "88996cf9195240f469e4270d514090e1e33e1966", "url": "https://www.semanticscholar.org/paper/88996cf9195240f469e4270d514090e1e33e1966", "title": "Learning and Selecting Features Jointly with Point-wise Gated Boltzmann Machines", "abstract": "Unsupervised feature learning has emerged as a promising tool in learning representations from unlabeled data. However, it is still challenging to learn useful high-level features when the data contains a significant amount of irrelevant patterns. Although feature selection can be used for such complex data, it may fail when we have to build a learning system from scratch (i.e., starting from the lack of useful raw features). To address this problem, we propose a point-wise gated Boltzmann machine, a unified generative model that combines feature learning and feature selection. Our model performs not only feature selection on learned high-level features (i.e., hidden units), but also dynamic feature selection on raw features (i.e., visible units) through a gating mechanism. For each example, the model can adaptively focus on a variable subset of visible nodes corresponding to the task-relevant patterns, while ignoring the visible units corresponding to the task-irrelevant patterns. In experiments, our method achieves improved performance over state-of-the-art in several visual recognition benchmarks.", "year": 2013, "referenceCount": 39, "citationCount": 93, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1729571", "name": "Kihyuk Sohn"}, {"authorId": "2110808972", "name": "Guanyu Zhou"}, {"authorId": "2109425498", "name": "Chansoo Lee"}, {"authorId": "1697141", "name": "Honglak Lee"}]}, {"paperId": "feaeda74182d7f9890a6ff5a1733ee21a288cbd3", "url": "https://www.semanticscholar.org/paper/feaeda74182d7f9890a6ff5a1733ee21a288cbd3", "title": "Electronic skins and machine learning for intelligent soft robots", "abstract": "Developments in e-skins and machine learning may achieve tactile sensing and proprioception for autonomous, deployable soft robots. Soft robots have garnered interest for real-world applications because of their intrinsic safety embedded at the material level. These robots use deformable materials capable of shape and behavioral changes and allow conformable physical contact for manipulation. Yet, with the introduction of soft and stretchable materials to robotic systems comes a myriad of challenges for sensor integration, including multimodal sensing capable of stretching, embedment of high-resolution but large-area sensor arrays, and sensor fusion with an increasing volume of data. This Review explores the emerging confluence of e-skins and machine learning, with a focus on how roboticists can combine recent developments from the two fields to build autonomous, deployable soft robots, integrated with capabilities for informative touch and proprioception to stand up to the challenges of real-world environments.", "year": 2020, "referenceCount": 145, "citationCount": 170, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "40030879", "name": "Benjamin Shih"}, {"authorId": "51051515", "name": "Dylan S. Shah"}, {"authorId": "1644316962", "name": "Jinxing Li"}, {"authorId": "3455927", "name": "T. G. Thuruthel"}, {"authorId": "1783778", "name": "Yong\u2010Lae Park"}, {"authorId": "34567297", "name": "F. Iida"}, {"authorId": "71995610", "name": "Z. Bao"}, {"authorId": "1400632409", "name": "Rebecca Kramer\u2010Bottiglio"}, {"authorId": "48724645", "name": "M. Tolley"}]}, {"paperId": "299686e8512822a2cf32979d2e7caa4dfac963e4", "url": "https://www.semanticscholar.org/paper/299686e8512822a2cf32979d2e7caa4dfac963e4", "title": "Learning to Identify Internet Sexual Predation", "abstract": "This work integrates communication theories and computer science algorithms to create a program that can detect the occurrence of sexual predation in an online social setting. Although much work has discussed social media in general, this particular aspect of online social interaction remains largely unexplored. In previous work we developed phrase-matching and rule-based approaches to classify and label lines of chat logs. In the current work we expand these techniques and use machine learning algorithms to classify posts. Our machine learning system leveraged the phrase-matching and rule-based systems to identify appropriate attributes for our supervised learning algorithms. Our machine learning experiments confirmed that the rules we developed are adequate to identify the coding rules. Neither decision trees nor instance-based learning algorithms were able to significantly improve upon the 68 percent accuracy we were able to achieve using the rule-based methods employed by a software program called ChatCoder 2, as described here.", "year": 2011, "referenceCount": 17, "citationCount": 112, "influentialCitationCount": 14, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2059822", "name": "India McGhee"}, {"authorId": "2164969", "name": "Jennifer Bayzick"}, {"authorId": "1713751", "name": "April Kontostathis"}, {"authorId": "38000101", "name": "Lynne Edwards"}, {"authorId": "38712049", "name": "Alexandra McBride"}, {"authorId": "48876583", "name": "E. Jakubowski"}]}, {"paperId": "15527b1313746b00a85b07cd838534849e7dd95e", "url": "https://www.semanticscholar.org/paper/15527b1313746b00a85b07cd838534849e7dd95e", "title": "Intrusion Detection System Using Bagging Ensemble Method of Machine Learning", "abstract": "Intrusion detection system is widely used to protect and reduce damage to information system. It protects virtual and physical computer networks against threats and vulnerabilities. Presently, machine learning techniques are widely extended to implement effective intrusion detection system. Neural network, statistical models, rule learning, and ensemble methods are some of the kinds of machine learning methods for intrusion detection. Among them, ensemble methods of machine learning are known for good performance in learning process. Investigation of appropriate ensemble method is essential for building effective intrusion detection system. In this paper, a novel intrusion detection technique based on ensemble method of machine learning is proposed. The Bagging method of ensemble with REPTree as base class is used to implement intrusion detection system. The relevant features from NSL_KDD dataset are selected to improve the classification accuracy and reduce the false positive rate. The performance of proposed ensemble method is evaluated in term of classification accuracy, model building time and False Positives. The experimental results show that the Bagging ensemble with REPTree base class exhibits highest classification accuracy. One advantage of using Bagging method is that it takes less time to build the model. The proposed ensemble method provides competitively low false positives compared with other machine learning techniques.", "year": 2015, "referenceCount": 14, "citationCount": 79, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145874577", "name": "D. Gaikwad"}, {"authorId": "2423345", "name": "R. Thool"}]}, {"paperId": "a4f9e7e695bba1ffb90b30752a40d5ee907dcb36", "url": "https://www.semanticscholar.org/paper/a4f9e7e695bba1ffb90b30752a40d5ee907dcb36", "title": "Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks", "abstract": "We identify label errors in the test sets of 10 of the most commonly-used computer vision, natural language, and audio datasets, and subsequently study the potential for these label errors to affect benchmark results. Errors in test sets are numerous and widespread: we estimate an average of at least 3.3% errors across the 10 datasets, where for example label errors comprise at least 6% of the ImageNet validation set. Putative label errors are identified using confident learning algorithms and then human-validated via crowdsourcing (51% of the algorithmically-flagged candidates are indeed erroneously labeled, on average across the datasets). Traditionally, machine learning practitioners choose which model to deploy based on test accuracy \u2014 our findings advise caution here, proposing that judging models over correctly labeled test sets may be more useful, especially for noisy real-world datasets. Surprisingly, we find that lower capacity models may be practically more useful than higher capacity models in real-world datasets with high proportions of erroneously labeled data. For example, on ImageNet with corrected labels: ResNet-18 outperforms ResNet-50 if the prevalence of originally mislabeled test examples increases by just 6%. On CIFAR-10 with corrected labels: VGG-11 outperforms VGG-19 if the prevalence of originally mislabeled test examples increases by just 5%. Test set errors across the 10 datasets can be viewed at https://labelerrors.com and all label errors can be reproduced by https://github.com/cleanlab/label-errors.", "year": 2021, "referenceCount": 56, "citationCount": 192, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "39972987", "name": "Curtis G. Northcutt"}, {"authorId": "38939786", "name": "Anish Athalye"}, {"authorId": "153430733", "name": "Jonas Mueller"}]}, {"paperId": "51cd23dee6f9cbd53e8dffc5c0976e19360be747", "url": "https://www.semanticscholar.org/paper/51cd23dee6f9cbd53e8dffc5c0976e19360be747", "title": "Active learning machine learns to create new quantum experiments", "abstract": "Significance Quantum experiments push the envelope of our understanding of fundamental concepts in quantum physics. Modern experiments have exhaustively probed the basic notions of quantum theory. Arguably, further breakthroughs require the tackling of complex quantum phenomena and consequently require complex experiments and involved techniques. The designing of such complex experiments is difficult and often clashes with human intuition. We present an autonomous learning model which learns to design such complex experiments, without relying on previous knowledge or often flawed intuition. Our system not only learns how to design desired experiments more efficiently than the best previous approaches, but in the process also discovers nontrivial experimental techniques. Our work demonstrates that learning machines can offer dramatic advances in how experiments are generated. How useful can machine learning be in a quantum laboratory? Here we raise the question of the potential of intelligent machines in the context of scientific research. A major motivation for the present work is the unknown reachability of various entanglement classes in quantum experiments. We investigate this question by using the projective simulation model, a physics-oriented approach to artificial intelligence. In our approach, the projective simulation system is challenged to design complex photonic quantum experiments that produce high-dimensional entangled multiphoton states, which are of high interest in modern quantum experiments. The artificial intelligence system learns to create a variety of entangled states and improves the efficiency of their realization. In the process, the system autonomously (re)discovers experimental techniques which are only now becoming standard in modern quantum optical experiments\u2014a trait which was not explicitly demanded from the system but emerged through the process of learning. Such features highlight the possibility that machines could have a significantly more creative role in future research.", "year": 2017, "referenceCount": 58, "citationCount": 201, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Physics", "Mathematics", "Medicine"], "authors": [{"authorId": "47610941", "name": "A. Melnikov"}, {"authorId": "1398691059", "name": "Hendrik Poulsen Nautrup"}, {"authorId": "5906965", "name": "Mario Krenn"}, {"authorId": "2878563", "name": "V. Dunjko"}, {"authorId": "2124867", "name": "M. Tiersch"}, {"authorId": "5385402", "name": "A. Zeilinger"}, {"authorId": "32534184", "name": "H. Briegel"}]}, {"paperId": "700dd2b620c12b06ba47225752b300c2c8d8c31f", "url": "https://www.semanticscholar.org/paper/700dd2b620c12b06ba47225752b300c2c8d8c31f", "title": "Learning to Discover Social Circles in Ego Networks", "abstract": "Our personal social networks are big and cluttered, and currently there is no good way to organize them. Social networking sites allow users to manually categorize their friends into social circles (e.g. 'circles' on Google+, and 'lists' on Facebook and Twitter), however they are laborious to construct and must be updated whenever a user's network grows. We define a novel machine learning task of identifying users' social circles. We pose the problem as a node clustering problem on a user's ego-network, a network of connections between her friends. We develop a model for detecting circles that combines network structure as well as user profile information. For each circle we learn its members and the circle-specific user profile similarity metric. Modeling node membership to multiple circles allows us to detect overlapping as well as hierarchically nested circles. Experiments show that our model accurately identifies circles on a diverse set of data from Facebook, Google+, and Twitter for all of which we obtain hand-labeled ground-truth.", "year": 2012, "referenceCount": 40, "citationCount": 1403, "influentialCitationCount": 146, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "35660011", "name": "Julian McAuley"}, {"authorId": "1702139", "name": "J. Leskovec"}]}, {"paperId": "5401637a14d6907bd9ca712cbf3bf0108bcd2b7a", "url": "https://www.semanticscholar.org/paper/5401637a14d6907bd9ca712cbf3bf0108bcd2b7a", "title": "How Machine Learning Will Transform Biomedicine", "abstract": null, "year": 2020, "referenceCount": 83, "citationCount": 137, "influentialCitationCount": 1, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Biology"], "authors": [{"authorId": "2718156", "name": "J. Goecks"}, {"authorId": "151506914", "name": "V. Jalili"}, {"authorId": "1947002", "name": "Laura M. Heiser"}, {"authorId": "144146923", "name": "J. Gray"}]}, {"paperId": "779e4492f1cf93fe9d92f58e70ee56003e3c5970", "url": "https://www.semanticscholar.org/paper/779e4492f1cf93fe9d92f58e70ee56003e3c5970", "title": "Big data and black-box medical algorithms", "abstract": "New machine-learning techniques entering medicine present challenges in validation, regulation, and integration into practice. New machine-learning techniques entering medicine present challenges in validation, regulation, and integration into practice.", "year": 2018, "referenceCount": 15, "citationCount": 89, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "40503754", "name": "W. Price"}]}, {"paperId": "3ccf5c97d89f0f5d6eb40c8feb2bcd387223e9c0", "url": "https://www.semanticscholar.org/paper/3ccf5c97d89f0f5d6eb40c8feb2bcd387223e9c0", "title": "Machine Learning Methods for Classifying Human Physical Activity from On-Body Accelerometers", "abstract": "The use of on-body wearable sensors is widespread in several academic and industrial domains. Of great interest are their applications in ambulatory monitoring and pervasive computing systems; here, some quantitative analysis of human motion and its automatic classification are the main computational tasks to be pursued. In this paper, we discuss how human physical activity can be classified using on-body accelerometers, with a major emphasis devoted to the computational algorithms employed for this purpose. In particular, we motivate our current interest for classifiers based on Hidden Markov Models (HMMs). An example is illustrated and discussed by analysing a dataset of accelerometer time series.", "year": 2010, "referenceCount": 60, "citationCount": 695, "influentialCitationCount": 40, "isOpenAccess": true, "fieldsOfStudy": ["Engineering", "Computer Science", "Medicine"], "authors": [{"authorId": "1758858", "name": "A. Mannini"}, {"authorId": "1688761", "name": "A. Sabatini"}]}, {"paperId": "30b24f45a0b5ddc4303a30ad2e3979a16b3f2b16", "url": "https://www.semanticscholar.org/paper/30b24f45a0b5ddc4303a30ad2e3979a16b3f2b16", "title": "Introduction to statistical relational learning", "abstract": "Handling inherent uncertainty and exploiting compositional structure are fundamental to understanding and designing large-scale systems. Statistical relational learning builds on ideas from probability theory and statistics to address uncertainty while incorporating tools from logic, databases and programming languages to represent structure. In Introduction to Statistical Relational Learning, leading researchers in this emerging area of machine learning describe current formalisms, models, and algorithms that enable effective and robust reasoning about richly structured systems and data. The early chapters provide tutorials for material used in later chapters, offering introductions to representation, inference and learning in graphical models, and logic. The book then describes object-oriented approaches, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models as well as logic-based formalisms including Bayesian logic programs, Markov logic, and stochastic logic programs. Later chapters discuss such topics as probabilistic models with unknown objects, relational dependency networks, reinforcement learning in relational domains, and information extraction. By presenting a variety of approaches, the book highlights commonalities and clarifies important differences among proposed approaches and, along the way, identifies important representational and algorithmic issues. Numerous applications are provided throughout.Lise Getoor is Assistant Professor in the Department of Computer Science at the University of Maryland. Ben Taskar is Assistant Professor in the Computer and Information Science Department at the University of Pennsylvania.", "year": 2007, "referenceCount": 11, "citationCount": 593, "influentialCitationCount": 42, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1746034", "name": "L. Getoor"}, {"authorId": "1685978", "name": "B. Taskar"}]}, {"paperId": "a22bc85367a6474a91fecea9dd20681451c6fd0d", "url": "https://www.semanticscholar.org/paper/a22bc85367a6474a91fecea9dd20681451c6fd0d", "title": "Applications of machine learning in animal behaviour studies", "abstract": null, "year": 2017, "referenceCount": 113, "citationCount": 249, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "24835813", "name": "J. J. Valletta"}, {"authorId": "3012349", "name": "C. Torney"}, {"authorId": "47792492", "name": "M. Kings"}, {"authorId": "144216799", "name": "A. Thornton"}, {"authorId": "5242799", "name": "J. Madden"}]}, {"paperId": "c0f17f99c44807762f2a386ac6579c364330e082", "url": "https://www.semanticscholar.org/paper/c0f17f99c44807762f2a386ac6579c364330e082", "title": "A Review on Deep Learning Techniques Applied to Semantic Segmentation", "abstract": "Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efficient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every field or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this field as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their significance in the field. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.", "year": 2017, "referenceCount": 118, "citationCount": 909, "influentialCitationCount": 44, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1397392435", "name": "Alberto Garcia-Garcia"}, {"authorId": "7540558", "name": "Sergio Orts"}, {"authorId": "152298373", "name": "Sergiu Oprea"}, {"authorId": "1409308132", "name": "Victor Villena-Martinez"}, {"authorId": "2117020529", "name": "J. G. Rodr\u00edguez"}]}, {"paperId": "9f6c28b20458f7f7de0989c2f8296d67162610f2", "url": "https://www.semanticscholar.org/paper/9f6c28b20458f7f7de0989c2f8296d67162610f2", "title": "Chinese Word Segmentation as Character Tagging", "abstract": "In this paper we report results of a supervised machine-learning approach to Chinese word segmentation. A maximum entropy tagger is trained on manually annotated data to automatically assign to Chinese characters, or hanzi, tags that indicate the position of a hanzi within a word. The tagged output is then converted into segmented text for evaluation. Preliminary results show that this approach is competitive against other supervised machine-learning segmenters reported in previous studies, achieving precision and recall rates of 95.01% and 94.94% respectively, trained on a 237K-word training set.", "year": 2003, "referenceCount": 20, "citationCount": 185, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1702849", "name": "Nianwen Xue"}]}, {"paperId": "c295674d0bd4e622cd2dd3a9e92d8dac67f3fa34", "url": "https://www.semanticscholar.org/paper/c295674d0bd4e622cd2dd3a9e92d8dac67f3fa34", "title": "Machine learning approaches for pathologic diagnosis", "abstract": null, "year": 2019, "referenceCount": 48, "citationCount": 64, "influentialCitationCount": 0, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "3025343", "name": "D. Komura"}, {"authorId": "3324584", "name": "S. Ishikawa"}]}, {"paperId": "402fe0cd8e168a21924eba9ac2afa660999b39e5", "url": "https://www.semanticscholar.org/paper/402fe0cd8e168a21924eba9ac2afa660999b39e5", "title": "Pitch accent prediction using ensemble machine learning", "abstract": "In this study, we applied ensemble machine learning to predict pitch accents. With decision tree as the baseline algorithm, two popular ensemble learning methods, bagging and boosting, were evaluated across different experiment conditions: using acoustic features only, using text-based features only; using both acoustic and text-based features. F0 related acoustic features are derived from underlying pitch targets. Models of four ToBI pitch accent types (High, Down-stepped high, Low, and Unaccented) are built at the syllable level. Results showed that in all experiments improved performance was achieved by ensemble learning. The best result was obtained in the third task, in which the overall correct rate increases from 84.26% to 87.17%.", "year": 2002, "referenceCount": 14, "citationCount": 93, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2105663", "name": "Xuejing Sun"}]}, {"paperId": "71709bfac702a5f87e79447c13fb71eb6b0cc913", "url": "https://www.semanticscholar.org/paper/71709bfac702a5f87e79447c13fb71eb6b0cc913", "title": "Development of machine learning models for diagnosis of glaucoma", "abstract": "The study aimed to develop machine learning models that have strong prediction power and interpretability for diagnosis of glaucoma based on retinal nerve fiber layer (RNFL) thickness and visual field (VF). We collected various candidate features from the examination of retinal nerve fiber layer (RNFL) thickness and visual field (VF). We also developed synthesized features from original features. We then selected the best features proper for classification (diagnosis) through feature evaluation. We used 100 cases of data as a test dataset and 399 cases of data as a training and validation dataset. To develop the glaucoma prediction model, we considered four machine learning algorithms: C5.0, random forest (RF), support vector machine (SVM), and k-nearest neighbor (KNN). We repeatedly composed a learning model using the training dataset and evaluated it by using the validation dataset. Finally, we got the best learning model that produces the highest validation accuracy. We analyzed quality of the models using several measures. The random forest model shows best performance and C5.0, SVM, and KNN models show similar accuracy. In the random forest model, the classification accuracy is 0.98, sensitivity is 0.983, specificity is 0.975, and AUC is 0.979. The developed prediction models show high accuracy, sensitivity, specificity, and AUC in classifying among glaucoma and healthy eyes. It will be used for predicting glaucoma against unknown examination records. Clinicians may reference the prediction results and be able to make better decisions. We may combine multiple learning models to increase prediction accuracy. The C5.0 model includes decision rules for prediction. It can be used to explain the reasons for specific predictions.", "year": 2017, "referenceCount": 31, "citationCount": 146, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2109709900", "name": "S. Kim"}, {"authorId": "88182610", "name": "K. Cho"}, {"authorId": "2121942865", "name": "Sejong Oh"}]}, {"paperId": "76d827e780e59962de02acd5b8bf6ad7ec2a316c", "url": "https://www.semanticscholar.org/paper/76d827e780e59962de02acd5b8bf6ad7ec2a316c", "title": "Evaluating machine learning models for engineering problems", "abstract": null, "year": 1999, "referenceCount": 38, "citationCount": 136, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Engineering", "Computer Science"], "authors": [{"authorId": "2870501", "name": "Y. Reich"}, {"authorId": "144118610", "name": "S. Barai"}]}, {"paperId": "45a710be199c8eb43f465c88fc4b343267c35d38", "url": "https://www.semanticscholar.org/paper/45a710be199c8eb43f465c88fc4b343267c35d38", "title": "Cascade Adversarial Machine Learning Regularized with a Unified Embedding", "abstract": "Injecting adversarial examples during training, known as adversarial training, can improve robustness against one-step attacks, but not for unknown iterative attacks. To address this challenge, we first show iteratively generated adversarial images easily transfer between networks trained with the same strategy. Inspired by this observation, we propose cascade adversarial training, which transfers the knowledge of the end results of adversarial training. We train a network from scratch by injecting iteratively generated adversarial images crafted from already defended networks in addition to one-step adversarial images from the network being trained. We also propose to utilize embedding space for both classification and low-level (pixel-level) similarity learning to ignore unknown pixel level perturbation. During training, we inject adversarial images without replacing their corresponding clean images and penalize the distance between the two embeddings (clean and adversarial). Experimental results show that cascade adversarial training together with our proposed low-level similarity learning efficiently enhances the robustness against iterative attacks, but at the expense of decreased robustness against one-step attacks. We show that combining those two techniques can also improve robustness under the worst case black box attack scenario.", "year": 2017, "referenceCount": 19, "citationCount": 90, "influentialCitationCount": 3, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "40191008", "name": "Taesik Na"}, {"authorId": "2813905", "name": "J. Ko"}, {"authorId": "144192725", "name": "S. Mukhopadhyay"}]}, {"paperId": "56b63f646939db212b8a1da008e3ee5d7fba5df5", "url": "https://www.semanticscholar.org/paper/56b63f646939db212b8a1da008e3ee5d7fba5df5", "title": "A Topology Layer for Machine Learning", "abstract": "Topology applied to real world data using persistent homology has started to find applications within machine learning, including deep learning. We present a differentiable topology layer that computes persistent homology based on level set filtrations and distance-bases filtrations. We present three novel applications: the topological layer can (i) serve as a regularizer directly on data or the weights of machine learning models, (ii) construct a loss on the output of a deep generative network to incorporate topological priors, and (iii) perform topological adversarial attacks on deep networks trained with persistence features. The code is publicly available and we hope its availability will facilitate the use of persistent homology in deep learning and other gradient based applications.", "year": 2019, "referenceCount": 43, "citationCount": 83, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "51910464", "name": "Rickard Br\u00fcel Gabrielsson"}, {"authorId": "2053022936", "name": "Bradley J. Nelson"}, {"authorId": "5856108", "name": "Anjan Dwaraknath"}, {"authorId": "1701872", "name": "P. Skraba"}, {"authorId": "1744254", "name": "L. Guibas"}, {"authorId": "40119133", "name": "G. Carlsson"}]}, {"paperId": "76bfc5f80030b24a6b2d744acfe9374f4a7e0445", "url": "https://www.semanticscholar.org/paper/76bfc5f80030b24a6b2d744acfe9374f4a7e0445", "title": "Empirical Bernstein stopping", "abstract": "Sampling is a popular way of scaling up machine learning algorithms to large datasets. The question often is how many samples are needed. Adaptive stopping algorithms monitor the performance in an online fashion and they can stop early, saving valuable resources. We consider problems where probabilistic guarantees are desired and demonstrate how recently-introduced empirical Bernstein bounds can be used to design stopping rules that are efficient. We provide upper bounds on the sample complexity of the new rules, as well as empirical results on model selection and boosting in the filtering setting.", "year": 2008, "referenceCount": 14, "citationCount": 200, "influentialCitationCount": 15, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "3255983", "name": "Volodymyr Mnih"}, {"authorId": "40868287", "name": "Csaba Szepesvari"}, {"authorId": "3015507", "name": "Jean-Yves Audibert"}]}, {"paperId": "ef9bbc83dea84df3711de01de56f2b7f91bae068", "url": "https://www.semanticscholar.org/paper/ef9bbc83dea84df3711de01de56f2b7f91bae068", "title": "Layer-Wise Relevance Propagation: An Overview", "abstract": null, "year": 2019, "referenceCount": 65, "citationCount": 301, "influentialCitationCount": 33, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144535526", "name": "G. Montavon"}, {"authorId": "2063967997", "name": "A. Binder"}, {"authorId": "3633358", "name": "S. Lapuschkin"}, {"authorId": "1699054", "name": "W. Samek"}, {"authorId": "145034054", "name": "K. M\u00fcller"}]}, {"paperId": "0be8038a05597c5e2e2d23d6ff20d3efdd4fc4d3", "url": "https://www.semanticscholar.org/paper/0be8038a05597c5e2e2d23d6ff20d3efdd4fc4d3", "title": "Stochastic Subgradient Methods", "abstract": "Stochastic subgradient methods play an important role in machine learning. We introduced the concepts of subgradient methods and stochastic subgradient methods in this project, discussed their convergence conditions as well as the strong and weak points against their competitors. We demonstrated the application of (stochastic) subgradient methods to machine learning with a running example of training support vector machines (SVM) throughout this report.", "year": 2007, "referenceCount": 17, "citationCount": 93, "influentialCitationCount": 11, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1843103", "name": "Stephen P. Boyd"}, {"authorId": "2289428", "name": "A. Mutapcic"}]}, {"paperId": "ba2621bf3811e80d74ef55439bafc1fbb48fd143", "url": "https://www.semanticscholar.org/paper/ba2621bf3811e80d74ef55439bafc1fbb48fd143", "title": "Robust Process Discovery with Artificial Negative Events", "abstract": "Process discovery is the automated construction of structured process models from information system event logs. Such event logs often contain positive examples only. Without negative examples, it is a challenge to strike the right balance between recall and specificity, and to deal with problems such as expressiveness, noise, incomplete event logs, or the inclusion of prior knowledge. In this paper, we present a configurable technique that deals with these challenges by representing process discovery as a multi-relational classification problem on event logs supplemented with Artificially Generated Negative Events (AGNEs). This problem formulation allows using learning algorithms and evaluation techniques that are well-know in the machine learning community. Moreover, it allows users to have a declarative control over the inductive bias and language bias.", "year": 2009, "referenceCount": 52, "citationCount": 185, "influentialCitationCount": 23, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3131370", "name": "Stijn Goedertier"}, {"authorId": "145147309", "name": "David Martens"}, {"authorId": "1790055", "name": "J. Vanthienen"}, {"authorId": "1720683", "name": "B. Baesens"}]}, {"paperId": "18c2d0b44a0c292ce76696bfe1dfd6839fe09ff9", "url": "https://www.semanticscholar.org/paper/18c2d0b44a0c292ce76696bfe1dfd6839fe09ff9", "title": "Data Lifecycle Challenges in Production Machine Learning", "abstract": "Machine learning has become an essential tool for gleaning knowledge from data and tackling a diverse set of computationally hard tasks. However, the accuracy of a machine learned model is deeply tied to the data that it is trained on. Designing and building robust processes and tools that make it easier to analyze, validate, and transform data that is fed into large-scale machine learning systems poses data management challenges. Drawn from our experience in developing data-centric infrastructure for a production machine learning platform at Google, we summarize some of the interesting research challenges that we encountered, and survey some of the relevant literature from the data management and machine learning communities. Specifically, we explore challenges in three main areas of focus - data understanding, data validation and cleaning, and data preparation. In each of these areas, we try to explore how different constraints are imposed on the solutions depending on where in the lifecycle of a model the problems are encountered and who encounters them.", "year": 2018, "referenceCount": 103, "citationCount": 96, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1763100", "name": "Neoklis Polyzotis"}, {"authorId": "1473253195", "name": "Sudip Roy"}, {"authorId": "3288247", "name": "Steven Euijong Whang"}, {"authorId": "8195063", "name": "Martin A. Zinkevich"}]}, {"paperId": "8ab66a80e12c794f1d733a5bf8d67606ab53ba6f", "url": "https://www.semanticscholar.org/paper/8ab66a80e12c794f1d733a5bf8d67606ab53ba6f", "title": "Multi-stage genetic fuzzy systems based on the iterative rule learning approach", "abstract": "Genetic algorithms (GAs) represent a class of adaptive search techniques inspired by natural evolution mechanisms. The search properties of GAs make \nthem suitable to be used in machine learning processes and for developing \nfuzzy systems, the so-called genetic \nfuzzy systems (GFSs). \n \nIn this contribution, we discuss genetics-based machine learning processes presenting the iterative rule learning approach, and a special kind of GFS, a multi-stage GFS based on the iterative rule learning approach, by learning from examples.", "year": 1997, "referenceCount": 40, "citationCount": 92, "influentialCitationCount": 8, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2149638027", "name": "A. G. Mu\u00f1oz"}, {"authorId": "120472586", "name": "F. Triguero"}]}, {"paperId": "08d0ea90b53aba0008d25811268fe46562cfb38c", "url": "https://www.semanticscholar.org/paper/08d0ea90b53aba0008d25811268fe46562cfb38c", "title": "On the quantitative analysis of deep belief networks", "abstract": "Deep Belief Networks (DBN's) are generative models that contain many layers of hidden variables. Efficient greedy algorithms for learning and approximate inference have allowed these models to be applied successfully in many application domains. The main building block of a DBN is a bipartite undirected graphical model called a restricted Boltzmann machine (RBM). Due to the presence of the partition function, model selection, complexity control, and exact maximum likelihood learning in RBM's are intractable. We show that Annealed Importance Sampling (AIS) can be used to efficiently estimate the partition function of an RBM, and we present a novel AIS scheme for comparing RBM's with different architectures. We further show how an AIS estimator, along with approximate inference, can be used to estimate a lower bound on the log-probability that a DBN model with multiple hidden layers assigns to the test data. This is, to our knowledge, the first step towards obtaining quantitative results that would allow us to directly assess the performance of Deep Belief Networks as generative models of data.", "year": 2008, "referenceCount": 17, "citationCount": 484, "influentialCitationCount": 86, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "145124475", "name": "R. Salakhutdinov"}, {"authorId": "145797336", "name": "Iain Murray"}]}, {"paperId": "9cd7f74f910619d90406464309b3c0e916d453ab", "url": "https://www.semanticscholar.org/paper/9cd7f74f910619d90406464309b3c0e916d453ab", "title": "Artificial intelligence in healthcare", "abstract": null, "year": 2018, "referenceCount": 164, "citationCount": 915, "influentialCitationCount": 27, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2150426303", "name": "Kun\u2010Hsing Yu"}, {"authorId": "143649421", "name": "Andrew Beam"}, {"authorId": "1740538", "name": "I. Kohane"}]}, {"paperId": "9531e81dba28c2239713f0428082796785884f73", "url": "https://www.semanticscholar.org/paper/9531e81dba28c2239713f0428082796785884f73", "title": "Malicious web content detection by machine learning", "abstract": null, "year": 2010, "referenceCount": 15, "citationCount": 136, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2149511350", "name": "Yung-Tsung Hou"}, {"authorId": "2112612979", "name": "Yimeng Chang"}, {"authorId": "40894914", "name": "Tsuhan Chen"}, {"authorId": "144470287", "name": "C. Laih"}, {"authorId": "66226414", "name": "Chia-Mei Chen"}]}, {"paperId": "472c809c28923c31da3e56c57d3846107fbace12", "url": "https://www.semanticscholar.org/paper/472c809c28923c31da3e56c57d3846107fbace12", "title": "Causal Interpretations of Black-Box Models", "abstract": "Abstract The fields of machine learning and causal inference have developed many concepts, tools, and theory that are potentially useful for each other. Through exploring the possibility of extracting causal interpretations from black-box machine-trained models, we briefly review the languages and concepts in causal inference that may be interesting to machine learning researchers. We start with the curious observation that Friedman\u2019s partial dependence plot has exactly the same formula as Pearl\u2019s back-door adjustment and discuss three requirements to make causal interpretations: a model with good predictive performance, some domain knowledge in the form of a causal diagram and suitable visualization tools. We provide several illustrative examples and find some interesting and potentially causal relations using visualization tools for black-box models.", "year": 2021, "referenceCount": 94, "citationCount": 197, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "49033211", "name": "Qingyuan Zhao"}, {"authorId": "1784682", "name": "T. Hastie"}]}, {"paperId": "4ff3eb9a99c7e2b491e5f91075df5c3abb0360ac", "url": "https://www.semanticscholar.org/paper/4ff3eb9a99c7e2b491e5f91075df5c3abb0360ac", "title": "Applications and limitations of machine learning in radiation oncology", "abstract": "Machine learning approaches to problem-solving are growing rapidly within healthcare, and radiation oncology is no exception. With the burgeoning interest in machine learning comes the significant risk of misaligned expectations as to what it can and cannot accomplish. This paper evaluates the role of machine learning and the problems it solves within the context of current clinical challenges in radiation oncology. The role of learning algorithms within the workflow for external beam radiation therapy are surveyed, considering simulation imaging, multimodal fusion, image segmentation, treatment planning, quality assurance, and treatment delivery and adaptation. For each aspect, the clinical challenges faced, the learning algorithms proposed, and the successes and limitations of various approaches are analyzed. It is observed that machine learning has largely thrived on reproducibly mimicking conventional human-driven solutions with more efficiency and consistency. On the other hand, since algorithms are generally trained using expert opinion as ground truth, machine learning is of limited utility where problems or ground truths are not well-defined, or if suitable measures of correctness are not available. As a result, machines may excel at replicating, automating and standardizing human behaviour on manual chores, meanwhile the conceptual clinical challenges relating to definition, evaluation, and judgement remain in the realm of human intelligence and insight.", "year": 2019, "referenceCount": 130, "citationCount": 72, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "123723354", "name": "Daniel Jarrett"}, {"authorId": "144034191", "name": "E. Stride"}, {"authorId": "143717899", "name": "K. Vallis"}, {"authorId": "2856658", "name": "M. Gooding"}]}, {"paperId": "771ca13f78a6cfda9ed99004a386e9e7e187bd34", "url": "https://www.semanticscholar.org/paper/771ca13f78a6cfda9ed99004a386e9e7e187bd34", "title": "Improved Automatic Keyword Extraction Given More Linguistic Knowledge", "abstract": "In this paper, experiments on automatic extraction of keywords from abstracts using a supervised machine learning algorithm are discussed. The main point of this paper is that by adding linguistic knowledge to the representation (such as syntactic features), rather than relying only on statistics (such as term frequency and n-grams), a better result is obtained as measured by keywords previously assigned by professional indexers. In more detail, extracting NP-chunks gives a better precision than n-grams, and by adding the PoS tag(s) assigned to the term as a feature, a dramatic improvement of the results is obtained, independent of the term selection approach applied.", "year": 2003, "referenceCount": 30, "citationCount": 921, "influentialCitationCount": 136, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "47571286", "name": "A. Hulth"}]}, {"paperId": "159630b16d937257966e360012a2852cea376881", "url": "https://www.semanticscholar.org/paper/159630b16d937257966e360012a2852cea376881", "title": "Deep Learning and Machine Learning in Hydrological Processes Climate Change and Earth Systems a Systematic Review", "abstract": null, "year": 2019, "referenceCount": 86, "citationCount": 66, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "96693599", "name": "S. Ardabili"}, {"authorId": "3081489", "name": "A. Mosavi"}, {"authorId": "145019138", "name": "Majid Dehghani"}, {"authorId": "1401945699", "name": "A. V\u00e1rkonyi-K\u00f3czy"}]}, {"paperId": "c63de99b9461b521d61c78c98d5ce6c59f50c959", "url": "https://www.semanticscholar.org/paper/c63de99b9461b521d61c78c98d5ce6c59f50c959", "title": "Machine\u2010learning scoring functions to improve structure\u2010based binding affinity prediction and virtual screening", "abstract": "Docking tools to predict whether and how a small molecule binds to a target can be applied if a structural model of such target is available. The reliability of docking depends, however, on the accuracy of the adopted scoring function (SF). Despite intense research over the years, improving the accuracy of SFs for structure\u2010based binding affinity prediction or virtual screening has proven to be a challenging task for any class of method. New SFs based on modern machine\u2010learning regression models, which do not impose a predetermined functional form and thus are able to exploit effectively much larger amounts of experimental data, have recently been introduced. These machine\u2010learning SFs have been shown to outperform a wide range of classical SFs at both binding affinity prediction and virtual screening. The emerging picture from these studies is that the classical approach of using linear regression with a small number of expert\u2010selected structural features can be strongly improved by a machine\u2010learning approach based on nonlinear regression allied with comprehensive data\u2010driven feature selection. Furthermore, the performance of classical SFs does not grow with larger training datasets and hence this performance gap is expected to widen as more training data becomes available in the future. Other topics covered in this review include predicting the reliability of a SF on a particular target class, generating synthetic data to improve predictive performance and modeling guidelines for SF development. WIREs Comput Mol Sci 2015, 5:405\u2013424. doi: 10.1002/wcms.1225", "year": 2015, "referenceCount": 114, "citationCount": 195, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2385968", "name": "Q. Ain"}, {"authorId": "51243506", "name": "Antoniya A. Aleksandrova"}, {"authorId": "47084155", "name": "Florian D. Roessler"}, {"authorId": "9998035", "name": "P. Ballester"}]}, {"paperId": "de725e21513df76f2f965d804920a40fa1f1cc59", "url": "https://www.semanticscholar.org/paper/de725e21513df76f2f965d804920a40fa1f1cc59", "title": "Prediction of Acute Kidney Injury after Liver Transplantation: Machine Learning Approaches vs. Logistic Regression Model", "abstract": "Acute kidney injury (AKI) after liver transplantation has been reported to be associated with increased mortality. Recently, machine learning approaches were reported to have better predictive ability than the classic statistical analysis. We compared the performance of machine learning approaches with that of logistic regression analysis to predict AKI after liver transplantation. We reviewed 1211 patients and preoperative and intraoperative anesthesia and surgery-related variables were obtained. The primary outcome was postoperative AKI defined by acute kidney injury network criteria. The following machine learning techniques were used: decision tree, random forest, gradient boosting machine, support vector machine, na\u00efve Bayes, multilayer perceptron, and deep belief networks. These techniques were compared with logistic regression analysis regarding the area under the receiver-operating characteristic curve (AUROC). AKI developed in 365 patients (30.1%). The performance in terms of AUROC was best in gradient boosting machine among all analyses to predict AKI of all stages (0.90, 95% confidence interval [CI] 0.86\u20130.93) or stage 2 or 3 AKI. The AUROC of logistic regression analysis was 0.61 (95% CI 0.56\u20130.66). Decision tree and random forest techniques showed moderate performance (AUROC 0.86 and 0.85, respectively). The AUROC of support the vector machine, na\u00efve Bayes, neural network, and deep belief network was smaller than that of the other models. In our comparison of seven machine learning approaches with logistic regression analysis, the gradient boosting machine showed the best performance with the highest AUROC. An internet-based risk estimator was developed based on our model of gradient boosting. However, prospective studies are required to validate our results.", "year": 2018, "referenceCount": 42, "citationCount": 101, "influentialCitationCount": 5, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "2110208828", "name": "Hyung\u2010Chul Lee"}, {"authorId": "51884393", "name": "S. Yoon"}, {"authorId": "67117330", "name": "Seong-Mi Yang"}, {"authorId": "47902458", "name": "W. Kim"}, {"authorId": "6681973", "name": "H. Ryu"}, {"authorId": "82299363", "name": "C. Jung"}, {"authorId": "145963649", "name": "K. Suh"}, {"authorId": "2145602748", "name": "Kook Hyun Lee"}]}, {"paperId": "84e24ab56820d89f554a1d8db51b3e5500623ce9", "url": "https://www.semanticscholar.org/paper/84e24ab56820d89f554a1d8db51b3e5500623ce9", "title": "Differential Evolution Extreme Learning Machine for the Classification of Hyperspectral Images", "abstract": "Recently, a new machine learning approach that is termed as the extreme learning machine (ELM) has been introduced in the literature. This approach is characterized by a unified formulation for regression, binary, and multiclass classification problems, and the related solution is given in an analytical compact form. In this letter, we propose an efficient classification method for hyperspectral images based on this machine learning approach. To address the model selection issue that is associated with the ELM, we develop an automatic-solution-based differential evolution (DE). This simple yet powerful evolutionary optimization algorithm uses cross-validation accuracy as a performance indicator for determining the optimal ELM parameters. Experimental results obtained from four benchmark hyperspectral data sets confirm the attractive properties of the proposed DE-ELM method in terms of classification accuracy and computation time.", "year": 2014, "referenceCount": 20, "citationCount": 128, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1795469", "name": "Y. Bazi"}, {"authorId": "1755194", "name": "N. Alajlan"}, {"authorId": "1774633", "name": "F. Melgani"}, {"authorId": "2186161", "name": "H. Alhichri"}, {"authorId": "2865182", "name": "S. Malek"}, {"authorId": "144127749", "name": "R. Yager"}]}, {"paperId": "27515c4d1c72184a6539136a020b77b38b7480dd", "url": "https://www.semanticscholar.org/paper/27515c4d1c72184a6539136a020b77b38b7480dd", "title": "Measuring Polarization in High-Dimensional Data: Method and Application to Congressional Speech", "abstract": "This paper studies trends in the partisanship of Congressional speech from 1873 to 2009. It defines partisanship to be the ease with which an observer could infer a congressperson\u00e2\u20ac\u2122s party from a fixed amount of speech, and estimates it using a structural choice model and methods from machine learning. This paper applies tools from structural estimation and machine learning to study the partisanship of language in the US Congress. [Working Paper 22423]", "year": 2016, "referenceCount": 172, "citationCount": 137, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Political Science"], "authors": [{"authorId": "8731644", "name": "M. Gentzkow"}, {"authorId": "122795272", "name": "Jesse M. Shapiro"}, {"authorId": "32407682", "name": "Matt Taddy"}]}, {"paperId": "685b27cf6dc891da649af035507b7b43b3b4b0b9", "url": "https://www.semanticscholar.org/paper/685b27cf6dc891da649af035507b7b43b3b4b0b9", "title": "Dynamic Backdoor Attacks Against Machine Learning Models", "abstract": "Machine learning (ML) has made tremendous progress during the past decade and is being adopted in various critical real-world applications. However, recent research has shown that ML models are vulnerable to multiple security and privacy attacks. In particular, backdoor attacks against ML models have recently raised a lot of awareness. A successful backdoor attack can cause severe consequences, such as allowing an adversary to bypass critical authentication systems. Current backdooring techniques rely on adding static triggers (with fixed patterns and locations) on ML model inputs which are prone to detection by the current backdoor detection mechanisms. In this paper, we propose the first class of dynamic backdooring techniques against deep neural networks (DNN), namely Random Backdoor, Backdoor Generating Network (BaN), and conditional Backdoor Generating Network (c-BaN). Triggers generated by our techniques can have random patterns and locations, which reduce the efficacy of the current backdoor detection mechanisms. In particular, BaN and c-BaN based on a novel generative network are the first two schemes that algorithmically generate triggers. Moreover, c-BaN is the first conditional backdooring technique that given a target label, it can generate a target-specific trigger. Both BaN and c-BaN are essentially a general framework which renders the adversary the flexibility for further customizing backdoor attacks. We extensively evaluate our techniques on three benchmark datasets: MNIST, CelebA, and CIFAR-10. Our techniques achieve almost perfect attack performance on back-doored data with a negligible utility loss. We further show that our techniques can bypass current state-of-the-art defense mechanisms against backdoor attacks, including ABS, Februus, MNTD, Neural Cleanse, and STRIP.", "year": 2020, "referenceCount": 68, "citationCount": 111, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "66697271", "name": "A. Salem"}, {"authorId": "2054749404", "name": "Rui Wen"}, {"authorId": "144588806", "name": "M. Backes"}, {"authorId": "2026855", "name": "Shiqing Ma"}, {"authorId": "2145954003", "name": "Yang Zhang"}]}, {"paperId": "b1e6716d068ee0d98aa213ad496ec189c10f9250", "url": "https://www.semanticscholar.org/paper/b1e6716d068ee0d98aa213ad496ec189c10f9250", "title": "Training individually fair ML models with sensitive subspace robustness", "abstract": "We propose an approach to training machine learning models that are fair in the sense that their performance is invariant under certain perturbations to the features. For example, the performance of a resume screening system should be invariant under changes to the name of the applicant. We formalize this intuitive notion of fairness by connecting it to the original notion of individual fairness put forth by Dwork et al and show that the proposed approach achieves this notion of fairness. We also demonstrate the effectiveness of the approach on two machine learning tasks that are susceptible to gender and racial biases.", "year": 2019, "referenceCount": 48, "citationCount": 71, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "8202372", "name": "Mikhail Yurochkin"}, {"authorId": "145340365", "name": "Amanda Bower"}, {"authorId": "3340442", "name": "Yuekai Sun"}]}, {"paperId": "07925910d45761d96269fc3bdfdc21b1d20d84ad", "url": "https://www.semanticscholar.org/paper/07925910d45761d96269fc3bdfdc21b1d20d84ad", "title": "Deep Learning without Poor Local Minima", "abstract": "In this paper, we prove a conjecture published in 1989 and also partially address an open problem announced at the Conference on Learning Theory (COLT) 2015. With no unrealistic assumption, we first prove the following statements for the squared loss function of deep linear neural networks with any depth and any widths: 1) the function is non-convex and non-concave, 2) every local minimum is a global minimum, 3) every critical point that is not a global minimum is a saddle point, and 4) there exist \"bad\" saddle points (where the Hessian has no negative eigenvalue) for the deeper networks (with more than three layers), whereas there is no bad saddle point for the shallow networks (with three layers). Moreover, for deep nonlinear neural networks, we prove the same four statements via a reduction to a deep linear model under the independence assumption adopted from recent work. As a result, we present an instance, for which we can answer the following question: how difficult is it to directly train a deep model in theory? It is more difficult than the classical machine learning models (because of the non-convexity), but not too difficult (because of the nonexistence of poor local minima). Furthermore, the mathematically proven existence of bad saddle points for deeper models would suggest a possible open problem. We note that even though we have advanced the theoretical foundations of deep learning and non-convex optimization, there is still a gap between theory and practice.", "year": 2016, "referenceCount": 27, "citationCount": 789, "influentialCitationCount": 82, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2324666", "name": "Kenji Kawaguchi"}]}, {"paperId": "40d44fad89f4c49cf898766b7808185ba4a5a1c9", "url": "https://www.semanticscholar.org/paper/40d44fad89f4c49cf898766b7808185ba4a5a1c9", "title": "Topic detection and tracking: event-based information organization", "abstract": "Topic Detection and Tracking: Event-based Information Organization brings together in one place state-of-the-art research in Topic Detection and Tracking (TDT). This collection of technical papers from leading researchers in the field not only provides several chapters devoted to the research program and its evaluation paradigm, but also presents the most current research results and describes some of the remaining open challenges. Topic Detection and Tracking: Event-based Information Organization is an excellent reference for researchers and practitioners in a variety of fields related to TDT, including information retrieval, automatic speech recognition, machine learning, and information extraction", "year": 2002, "referenceCount": 0, "citationCount": 914, "influentialCitationCount": 89, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144890574", "name": "James Allan"}]}, {"paperId": "c0be2ac2f45681f1852fc1d298af5dceb85834f4", "url": "https://www.semanticscholar.org/paper/c0be2ac2f45681f1852fc1d298af5dceb85834f4", "title": "Paraphrase-Driven Learning for Open Question Answering", "abstract": "We study question answering as a machine learning problem, and induce a function that maps open-domain questions to queries over a database of web extractions. Given a large, community-authored, question-paraphrase corpus, we demonstrate that it is possible to learn a semantic lexicon and linear ranking function without manually annotating questions. Our approach automatically generalizes a seed lexicon and includes a scalable, parallelized perceptron parameter estimation scheme. Experiments show that our approach more than quadruples the recall of the seed lexicon, with only an 8% loss in precision.", "year": 2013, "referenceCount": 31, "citationCount": 341, "influentialCitationCount": 48, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "38087946", "name": "Anthony Fader"}, {"authorId": "1982950", "name": "Luke Zettlemoyer"}, {"authorId": "1741101", "name": "Oren Etzioni"}]}, {"paperId": "98e6beeb5ea3fd3b18cb6ed13944cc1f65434f25", "url": "https://www.semanticscholar.org/paper/98e6beeb5ea3fd3b18cb6ed13944cc1f65434f25", "title": "Towards interactive Machine Learning (iML): Applying Ant Colony Algorithms to Solve the Traveling Salesman Problem with the Human-in-the-Loop Approach", "abstract": null, "year": 2016, "referenceCount": 44, "citationCount": 91, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1749801", "name": "Andreas Holzinger"}, {"authorId": "3446565", "name": "M. Plass"}, {"authorId": "3040735", "name": "K. Holzinger"}, {"authorId": "2767875", "name": "G. Cri\u015fan"}, {"authorId": "144202072", "name": "C. Pintea"}, {"authorId": "145940006", "name": "V. Palade"}]}, {"paperId": "de92552973ab73bb60759d02ab7f9eab6fc5ef83", "url": "https://www.semanticscholar.org/paper/de92552973ab73bb60759d02ab7f9eab6fc5ef83", "title": "An Empirical Study of Bugs in Machine Learning Systems", "abstract": "Many machine learning systems that include various data mining, information retrieval, and natural language processing code and libraries are used in real world applications. Search engines, internet advertising systems, product recommendation systems are sample users of these algorithm-intensive code and libraries. Machine learning code and toolkits have also been used in many recent studies on software mining and analytics that aim to automate various software engineering tasks. With the increasing number of important applications of machine learning systems, the reliability of such systems is also becoming increasingly important. A necessary step for ensuring reliability of such systems is to understand the features and characteristics of bugs occurred in the systems. A number of studies have investigated bugs and fixes in various software systems, but none focuses on machine learning systems. Machine learning systems are unique due to their algorithm-intensive nature and applications to potentially large-scale data, and thus deserve a special consideration. In this study, we fill the research gap by performing an empirical study on the bugs in machine learning systems. We analyze three systems, Apache Mahout, Lucene, and OpenNLP, which are data mining, information retrieval, and natural language processing tools respectively. We look into their bug databases and code repositories, analyze a sample set of bugs and corresponding fixes, and label the bugs into various categories. Our study finds that 22.6% of the bugs belong to the algorithm/method category, 15.6% of the bugs belong to the non-functional category, and 13% of the bugs belong to the assignment/initialization category. We also report the relationship between bug categories and bug severities, the time and effort needed to fix the bugs, and bug impacts. We highlight several bug categories that deserve attention in future research.", "year": 2012, "referenceCount": 41, "citationCount": 94, "influentialCitationCount": 10, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2121315", "name": "Ferdian Thung"}, {"authorId": "1390898759", "name": "Shaowei Wang"}, {"authorId": "143960553", "name": "D. Lo"}, {"authorId": "1680504", "name": "Lingxiao Jiang"}]}, {"paperId": "12d024a135eb689f77262a3b536a128497edef5e", "url": "https://www.semanticscholar.org/paper/12d024a135eb689f77262a3b536a128497edef5e", "title": "Weighted Online Sequential Extreme Learning Machine for Class Imbalance Learning", "abstract": null, "year": 2013, "referenceCount": 36, "citationCount": 107, "influentialCitationCount": 13, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3421228", "name": "Bilal Mirza"}, {"authorId": "145558868", "name": "Zhiping Lin"}, {"authorId": "143629972", "name": "K. Toh"}]}, {"paperId": "1d9277a91866a144469efb20aea06db3d3a38e0f", "url": "https://www.semanticscholar.org/paper/1d9277a91866a144469efb20aea06db3d3a38e0f", "title": "A comparative study of machine learning methods for authorship attribution", "abstract": "We compare and benchmark the performance of five classification methods, four of which are taken from the machine learning literature, in a classic authorship attribution problem involving the Federalist Papers. Cross-validation results are reported for each method, and each method is further employed in classifying the disputed papers and the few papers that are generally understood to be coauthored. These tests are performed using two separate feature sets: a \u2018\u2018raw\u2019\u2019 feature set containing all words and word bigrams that are common to all of the authors, and a second \u2018\u2018pre-processed\u2019\u2019 feature set derived by reducing the raw feature set to include only words meeting a minimum relative frequency threshold. Each of the methods tested performed well, but nearest shrunken centroids and regularized discriminant analysis had the best overall performances with 0/70 cross-validation errors. .................................................................................................................................................................................", "year": 2010, "referenceCount": 38, "citationCount": 183, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2967847", "name": "Matthew L. Jockers"}, {"authorId": "2113693105", "name": "D. Witten"}]}, {"paperId": "24f39f136246cee6f3ece602fef3fc1322c79199", "url": "https://www.semanticscholar.org/paper/24f39f136246cee6f3ece602fef3fc1322c79199", "title": "Machine Learning via Polyhedral Concave Minimization", "abstract": null, "year": 1996, "referenceCount": 31, "citationCount": 103, "influentialCitationCount": 9, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "1747026", "name": "O. Mangasarian"}]}, {"paperId": "0294bd2e6638c9a3619d4baaa63202a3c511dccc", "url": "https://www.semanticscholar.org/paper/0294bd2e6638c9a3619d4baaa63202a3c511dccc", "title": "SplitFed: When Federated Learning Meets Split Learning", "abstract": "Federated learning (FL) and split learning (SL) are two popular distributed machine learning approaches. Both follow a model-to-data scenario; clients train and test machine learning models without sharing raw data. SL provides better model privacy than FL due to the machine learning model architecture split between clients and the server. Moreover, the split model makes SL a better option for resource-constrained environments. However, SL performs slower than FL due to the relay-based training across multiple clients. In this regard, this paper presents a novel approach, named splitfed learning (SFL), that amalgamates the two approaches eliminating their inherent drawbacks, along with a refined architectural configuration incorporating differential privacy and PixelDP to enhance data privacy and model robustness. Our analysis and empirical results demonstrate that (pure) SFL provides similar test accuracy and communication efficiency as SL while significantly decreasing its computation time per global epoch than in SL for multiple clients. Furthermore, as in SL, its communication efficiency over FL improves with the number of clients. Besides, the performance of SFL with privacy and robustness measures is further evaluated under extended experimental settings.", "year": 2020, "referenceCount": 46, "citationCount": 93, "influentialCitationCount": 16, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145890639", "name": "Chandra Thapa"}, {"authorId": "2584232", "name": "Pathum Chamikara Mahawaga Arachchige"}, {"authorId": "1811469", "name": "S. \u00c7amtepe"}]}, {"paperId": "70485e56e5c1758c904d5dddcc4b5b77fadb713f", "url": "https://www.semanticscholar.org/paper/70485e56e5c1758c904d5dddcc4b5b77fadb713f", "title": "Machine learning models in breast cancer survival prediction.", "abstract": "BACKGROUND\nBreast cancer is one of the most common cancers with a high mortality rate among women. With the early diagnosis of breast cancer survival will increase from 56% to more than 86%. Therefore, an accurate and reliable system is necessary for the early diagnosis of this cancer. The proposed model is the combination of rules and different machine learning techniques. Machine learning models can help physicians to reduce the number of false decisions. They try to exploit patterns and relationships among a large number of cases and predict the outcome of a disease using historical cases stored in datasets.\n\n\nOBJECTIVE\nThe objective of this study is to propose a rule-based classification method with machine learning techniques for the prediction of different types of Breast cancer survival.\n\n\nMETHODS\nWe use a dataset with eight attributes that include the records of 900 patients in which 876 patients (97.3%) and 24 (2.7%) patients were females and males respectively. Naive Bayes (NB), Trees Random Forest (TRF), 1-Nearest Neighbor (1NN), AdaBoost (AD), Support Vector Machine (SVM), RBF Network (RBFN), and Multilayer Perceptron (MLP) machine learning techniques with 10-cross fold technique were used with the proposed model for the prediction of breast cancer survival. The performance of machine learning techniques were evaluated with accuracy, precision, sensitivity, specificity, and area under ROC curve.\n\n\nRESULTS\nOut of 900 patients, 803 patients and 97 patients were alive and dead, respectively. In this study, Trees Random Forest (TRF) technique showed better results in comparison to other techniques (NB, 1NN, AD, SVM and RBFN, MLP). The accuracy, sensitivity and the area under ROC curve of TRF are 96%, 96%, 93%, respectively. However, 1NN machine learning technique provided poor performance (accuracy 91%, sensitivity 91% and area under ROC curve 78%).\n\n\nCONCLUSIONS\nThis study demonstrates that Trees Random Forest model (TRF) which is a rule-based classification model was the best model with the highest level of accuracy. Therefore, this model is recommended as a useful tool for breast cancer survival prediction as well as medical decision making.", "year": 2016, "referenceCount": 41, "citationCount": 118, "influentialCitationCount": 1, "isOpenAccess": false, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "34400978", "name": "M. Montazeri"}, {"authorId": "1852627", "name": "Mohadeseh Montazeri"}, {"authorId": "6655114", "name": "M. Montazeri"}, {"authorId": "8462606", "name": "A. Beigzadeh"}]}, {"paperId": "7ac8f533a18f584387dd412a0a27feb9af1c5c93", "url": "https://www.semanticscholar.org/paper/7ac8f533a18f584387dd412a0a27feb9af1c5c93", "title": "A Systematic Review on Imbalanced Data Challenges in Machine Learning", "abstract": "In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.", "year": 2019, "referenceCount": 175, "citationCount": 174, "influentialCitationCount": 6, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2061225608", "name": "H. kaur"}, {"authorId": "2506803", "name": "H. Pannu"}, {"authorId": "2718975", "name": "A. Malhi"}]}, {"paperId": "02d49b4dbaf8c093034918a76648fea53961753d", "url": "https://www.semanticscholar.org/paper/02d49b4dbaf8c093034918a76648fea53961753d", "title": "Time-series forecasting with deep learning: a survey", "abstract": "Numerous deep learning architectures have been developed to accommodate the diversity of time-series datasets across different domains. In this article, we survey common encoder and decoder designs used in both one-step-ahead and multi-horizon time-series forecasting\u2014describing how temporal information is incorporated into predictions by each model. Next, we highlight recent developments in hybrid deep learning models, which combine well-studied statistical models with neural network components to improve pure methods in either category. Lastly, we outline some ways in which deep learning can also facilitate decision support with time-series data. This article is part of the theme issue \u2018Machine learning for weather and climate modelling\u2019.", "year": 2020, "referenceCount": 115, "citationCount": 240, "influentialCitationCount": 4, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science", "Medicine"], "authors": [{"authorId": "143845299", "name": "Bryan Lim"}, {"authorId": "8106073", "name": "S. Zohren"}]}, {"paperId": "bf807c251962a694499b29938bdc54e716ca2dda", "url": "https://www.semanticscholar.org/paper/bf807c251962a694499b29938bdc54e716ca2dda", "title": "Reinforcement learning improves behaviour from evaluative feedback", "abstract": null, "year": 2015, "referenceCount": 60, "citationCount": 238, "influentialCitationCount": 7, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "144885169", "name": "M. Littman"}]}, {"paperId": "eac1c5ee648bf35a8d67e3ed400c2b0f96af05a2", "url": "https://www.semanticscholar.org/paper/eac1c5ee648bf35a8d67e3ed400c2b0f96af05a2", "title": "A novel method to estimate model uncertainty using machine learning techniques", "abstract": "A novel method is presented for model uncertainty estimation using machine learning techniques and its application in rainfall runoff modeling. In this method, first, the probability distribution of the model error is estimated separately for different hydrological situations and second, the parameters characterizing this distribution are aggregated and used as output target values for building the training sets for the machine learning model. This latter model, being trained, encapsulates the information about the model error localized for different hydrological conditions in the past and is used to estimate the probability distribution of the model error for the new hydrological model runs. The M5 model tree is used as a machine learning model. The method is tested to estimate uncertainty of a conceptual rainfall runoff model of the Bagmati catchment in Nepal. In this paper the method is extended further to enable it to predict an approximation of the whole error distribution, and also the new results of comparing this method to other uncertainty estimation approaches are reported. It can be concluded that the method generates consistent, interpretable and improved model uncertainty estimates.", "year": 2009, "referenceCount": 45, "citationCount": 186, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Geology"], "authors": [{"authorId": "1895474", "name": "D. Solomatine"}, {"authorId": "2422170", "name": "D. Shrestha"}]}, {"paperId": "3b718eebc6f4469053dadb5737b67ee18b16722d", "url": "https://www.semanticscholar.org/paper/3b718eebc6f4469053dadb5737b67ee18b16722d", "title": "Beyond prediction: Using big data for policy problems", "abstract": "Machine-learning prediction methods have been extremely productive in applications ranging from medicine to allocating fire and health inspectors in cities. However, there are a number of gaps between making a prediction and making a decision, and underlying assumptions need to be understood in order to optimize data-driven decision-making.", "year": 2017, "referenceCount": 27, "citationCount": 344, "influentialCitationCount": 22, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "2631417", "name": "S. Athey"}]}, {"paperId": "20a078fd73959f01a0e666a475419e64ad756042", "url": "https://www.semanticscholar.org/paper/20a078fd73959f01a0e666a475419e64ad756042", "title": "Engineering problems in machine learning systems", "abstract": null, "year": 2019, "referenceCount": 79, "citationCount": 21, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "2065468400", "name": "Hiroshi Kuwajima"}, {"authorId": "1856205", "name": "Hirotoshi Yasuoka"}, {"authorId": "2066586857", "name": "Toshihiro Nakae"}]}, {"paperId": "98e9127a21f7ae4e657763d51319edeffa9a86b2", "url": "https://www.semanticscholar.org/paper/98e9127a21f7ae4e657763d51319edeffa9a86b2", "title": "Comparison of Instance Selection Algorithms II. Results and Comments", "abstract": null, "year": 2004, "referenceCount": 19, "citationCount": 113, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "3042992", "name": "M. Grochowski"}, {"authorId": "145340093", "name": "N. Jankowski"}]}, {"paperId": "ccd10aee3919a8fb1f0ea236d3d9b8557556db58", "url": "https://www.semanticscholar.org/paper/ccd10aee3919a8fb1f0ea236d3d9b8557556db58", "title": "Classifying sentiment in microblogs: is brevity an advantage?", "abstract": "Microblogs as a new textual domain offer a unique proposition for sentiment analysis. Their short document length suggests any sentiment they contain is compact and explicit. However, this short length coupled with their noisy nature can pose difficulties for standard machine learning document representations. In this work we examine the hypothesis that it is easier to classify the sentiment in these short form documents than in longer form documents. Surprisingly, we find classifying sentiment in microblogs easier than in blogs and make a number of observations pertaining to the challenge of supervised learning for sentiment analysis in microblogs.", "year": 2010, "referenceCount": 17, "citationCount": 379, "influentialCitationCount": 28, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "34661385", "name": "A. Bermingham"}, {"authorId": "1680223", "name": "A. Smeaton"}]}, {"paperId": "006cb500fd0b25200e12eb5a024756aea3d569ed", "url": "https://www.semanticscholar.org/paper/006cb500fd0b25200e12eb5a024756aea3d569ed", "title": "Learning in a Large Function Space: Privacy-Preserving Mechanisms for SVM Learning", "abstract": "The ubiquitous need for analyzing privacy-sensitive information\u2014including health records, personal communications, product ratings and social network data\u2014is driving significant interest in privacy-preserving data analysis across several research communities. This paper explores the release of Support Vector Machine (SVM) classifiers while preserving the privacy of training data. The SVM is a popular machine learning method that maps data to a high-dimensional feature space before learning a linear decision boundary. We present efficient mechanisms for finite-dimensional feature mappings and for (potentially infinite-dimensional) mappings with translation-invariant kernels. In the latter case, our mechanism borrows a technique from large-scale learning to learn in a finite-dimensional feature space whose inner-product uniformly approximates the desired feature space inner-product (the desired kernel) with high probability. Differential privacy is established using algorithmic stability, a property used in learning theory to bound generalization error. Utility\u2014when the private classifier is pointwise close to the non-private classifier with high probability\u2014is proven using smoothness of regularized empirical risk minimization with respect to small perturbations to the feature mapping. Finally we conclude with lower bounds on the differential privacy of any mechanism approximating the SVM.", "year": 2009, "referenceCount": 58, "citationCount": 263, "influentialCitationCount": 17, "isOpenAccess": true, "fieldsOfStudy": ["Mathematics", "Computer Science"], "authors": [{"authorId": "1868067", "name": "Benjamin I. P. Rubinstein"}, {"authorId": "1745169", "name": "P. Bartlett"}, {"authorId": "50055322", "name": "Ling Huang"}, {"authorId": "2703784", "name": "N. Taft"}]}, {"paperId": "b662aed0b78346b954f182dd0afb4e8ca40c29be", "url": "https://www.semanticscholar.org/paper/b662aed0b78346b954f182dd0afb4e8ca40c29be", "title": "Radiomics in Brain Tumor: Image Assessment, Quantitative Feature Descriptors, and Machine-Learning Approaches", "abstract": "SUMMARY: Radiomics describes a broad set of computational methods that extract quantitative features from radiographic images. The resulting features can be used to inform imaging diagnosis, prognosis, and therapy response in oncology. However, major challenges remain for methodologic developments to optimize feature extraction and provide rapid information flow in clinical settings. Equally important, to be clinically useful, predictive radiomic properties must be clearly linked to meaningful biologic characteristics and qualitative imaging properties familiar to radiologists. Here we use a cross-disciplinary approach to highlight studies in radiomics. We review brain tumor radiologic studies (eg, imaging interpretation) through computational models (eg, computer vision and machine learning) that provide novel clinical insights. We outline current quantitative image feature extraction and prediction strategies with different levels of available clinical classes for supporting clinical decision-making. We further discuss machine-learning challenges and data opportunities to advance radiomic studies.", "year": 2017, "referenceCount": 82, "citationCount": 217, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Medicine"], "authors": [{"authorId": "2107134630", "name": "M. Zhou"}, {"authorId": "2107426101", "name": "J. Scott"}, {"authorId": "2674604", "name": "B. Chaudhury"}, {"authorId": "2060787599", "name": "L. Hall"}, {"authorId": "153614023", "name": "D. Goldgof"}, {"authorId": "3596750", "name": "K. Yeom"}, {"authorId": "3804322", "name": "M. Iv"}, {"authorId": "2142465933", "name": "Y. Ou"}, {"authorId": "1401724111", "name": "Jayashree Kalpathy-Cramer"}, {"authorId": "1911671", "name": "S. Napel"}, {"authorId": "4579991", "name": "R. Gillies"}, {"authorId": "91249347", "name": "O. Gevaert"}, {"authorId": "1691326", "name": "R. Gatenby"}]}, {"paperId": "fde4bf50d48d54ba913d574c849566dc4f3d4fde", "url": "https://www.semanticscholar.org/paper/fde4bf50d48d54ba913d574c849566dc4f3d4fde", "title": "Fast Sparse Gaussian Process Methods: The Informative Vector Machine", "abstract": "We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on information-theoretic principles, previously suggested for active learning. Our goal is not only to learn d-sparse predictors (which can be evaluated in O(d) rather than O(n), d \u226a n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements. The scaling of our method is at most O(n \u00b7 d2), and in large real-world classification experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be significantly faster in training. In contrast to the SVM, our approximation produces estimates of predictive probabilities ('error bars'), allows for Bayesian model selection and is less complex in implementation.", "year": 2002, "referenceCount": 14, "citationCount": 567, "influentialCitationCount": 55, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "145306271", "name": "Neil D. Lawrence"}, {"authorId": "1680574", "name": "M. Seeger"}, {"authorId": "3234984", "name": "R. Herbrich"}]}, {"paperId": "6a028cc26d7eceada86e873a37e57a3e113e24af", "url": "https://www.semanticscholar.org/paper/6a028cc26d7eceada86e873a37e57a3e113e24af", "title": "Big Data in Public Health: Terminology, Machine Learning, and Privacy.", "abstract": "The digital world is generating data at a staggering and still increasing rate. While these \"big data\" have unlocked novel opportunities to understand public health, they hold still greater potential for research and practice. This review explores several key issues that have arisen around big data. First, we propose a taxonomy of sources of big data to clarify terminology and identify threads common across some subtypes of big data. Next, we consider common public health research and practice uses for big data, including surveillance, hypothesis-generating research, and causal inference, while exploring the role that machine learning may play in each use. We then consider the ethical implications of the big data revolution with particular emphasis on maintaining appropriate care for privacy in a world in which technology is rapidly changing social norms regarding the need for (and even the meaning of) privacy. Finally, we make suggestions regarding structuring teams and training to succeed in working with big data in research and practice.", "year": 2018, "referenceCount": 148, "citationCount": 186, "influentialCitationCount": 4, "isOpenAccess": false, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "2153669", "name": "S. Mooney"}, {"authorId": "2866128", "name": "V. Pejaver"}]}, {"paperId": "9179e740dad4ca4c183f7677b854e5b15f9a122f", "url": "https://www.semanticscholar.org/paper/9179e740dad4ca4c183f7677b854e5b15f9a122f", "title": "Generating Images with Perceptual Similarity Metrics based on Deep Networks", "abstract": "Image-generating machine learning models are typically trained with loss functions based on distance in the image space. This often leads to over-smoothed results. We propose a class of loss functions, which we call deep perceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of computing distances in the image space, we compute distances between image features extracted by deep neural networks. This metric better reflects perceptually similarity of images and thus leads to better results. We show three applications: autoencoder training, a modification of a variational autoencoder, and inversion of deep convolutional networks. In all cases, the generated images look sharp and resemble natural images.", "year": 2016, "referenceCount": 41, "citationCount": 912, "influentialCitationCount": 75, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2841331", "name": "A. Dosovitskiy"}, {"authorId": "1710872", "name": "T. Brox"}]}, {"paperId": "9070dd33f56c180cc7677cc16784bb2c6ba15294", "url": "https://www.semanticscholar.org/paper/9070dd33f56c180cc7677cc16784bb2c6ba15294", "title": "Enhancing robustness of machine learning systems via data transformations", "abstract": "We propose the use of data transformations as a defense against evasion attacks on ML classifiers. We present and investigate strategies for incorporating a variety of data transformations including dimensionality reduction via Principal Component Analysis to enhance the resilience of machine learning, targeting both the classification and the training phase. We empirically evaluate and demonstrate the feasibility of linear transformations of data as a defense mechanism against evasion attacks using multiple real-world datasets. Our key findings are that the defense is (i) effective against the best known evasion attacks from the literature, resulting in a two-fold increase in the resources required by a white-box adversary with knowledge of the defense for a successful attack, (ii) applicable across a range of ML classifiers, including Support Vector Machines and Deep Neural Networks, and (iii) generalizable to multiple application domains, including image classification and human activity classification.", "year": 2017, "referenceCount": 63, "citationCount": 179, "influentialCitationCount": 7, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "10754103", "name": "A. Bhagoji"}, {"authorId": "3007016", "name": "Daniel Cullina"}, {"authorId": "30175233", "name": "Chawin Sitawarin"}, {"authorId": "143615345", "name": "Prateek Mittal"}]}, {"paperId": "f6227e4c1caf47da99955b61253984bfbb0eddf8", "url": "https://www.semanticscholar.org/paper/f6227e4c1caf47da99955b61253984bfbb0eddf8", "title": "Benchmark Data Set for in Silico Prediction of Ames Mutagenicity", "abstract": "Up to now, publicly available data sets to build and evaluate Ames mutagenicity prediction tools have been very limited in terms of size and chemical space covered. In this report we describe a new unique public Ames mutagenicity data set comprising about 6500 nonconfidential compounds (available as SMILES strings and SDF) together with their biological activity. Three commercial tools (DEREK, MultiCASE, and an off-the-shelf Bayesian machine learner in Pipeline Pilot) are compared with four noncommercial machine learning implementations (Support Vector Machines, Random Forests, k-Nearest Neighbors, and Gaussian Processes) on the new benchmark data set.", "year": 2009, "referenceCount": 8, "citationCount": 241, "influentialCitationCount": 9, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "39960184", "name": "K. Hansen"}, {"authorId": "2459012", "name": "S. Mika"}, {"authorId": "34954622", "name": "T. Schroeter"}, {"authorId": "2079588955", "name": "A. Sutter"}, {"authorId": "14270207", "name": "A. T. Laak"}, {"authorId": "1390062673", "name": "T. Steger-Hartmann"}, {"authorId": "34305015", "name": "N. Heinrich"}, {"authorId": "145034054", "name": "K. M\u00fcller"}]}, {"paperId": "d6a250c3e01003240b309ed78f20551e41521896", "url": "https://www.semanticscholar.org/paper/d6a250c3e01003240b309ed78f20551e41521896", "title": "Layered Learning", "abstract": null, "year": 2000, "referenceCount": 29, "citationCount": 167, "influentialCitationCount": 13, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science"], "authors": [{"authorId": "144848112", "name": "P. Stone"}, {"authorId": "1956361", "name": "M. Veloso"}]}, {"paperId": "0e54e1d7ca6d795bb5e6bd9ad9291af46fbcaa72", "url": "https://www.semanticscholar.org/paper/0e54e1d7ca6d795bb5e6bd9ad9291af46fbcaa72", "title": "Trident: Efficient 4PC Framework for Privacy Preserving Machine Learning", "abstract": "Machine learning has started to be deployed in fields such as healthcare and finance, which propelled the need for and growth of privacy-preserving machine learning (PPML). We propose an actively secure four-party protocol (4PC), and a framework for PPML, showcasing its applications on four of the most widely-known machine learning algorithms -- Linear Regression, Logistic Regression, Neural Networks, and Convolutional Neural Networks. \nOur 4PC protocol tolerating at most one malicious corruption is practically efficient as compared to the existing works. We use the protocol to build an efficient mixed-world framework (Trident) to switch between the Arithmetic, Boolean, and Garbled worlds. Our framework operates in the offline-online paradigm over rings and is instantiated in an outsourced setting for machine learning. Also, we propose conversions especially relevant to privacy-preserving machine learning. \nThe highlights of our framework include using a minimal number of expensive circuits overall as compared to ABY3. This can be seen in our technique for truncation, which does not affect the online cost of multiplication and removes the need for any circuits in the offline phase. Our B2A conversion has an improvement of $\\mathbf{7} \\times$ in rounds and $\\mathbf{18} \\times$ in the communication complexity. In addition to these, all of the special conversions for machine learning, e.g. Secure Comparison, achieve constant round complexity. \nThe practicality of our framework is argued through improvements in the benchmarking of the aforementioned algorithms when compared with ABY3. All the protocols are implemented over a 64-bit ring in both LAN and WAN settings. Our improvements go up to $\\mathbf{187} \\times$ for the training phase and $\\mathbf{158} \\times$ for the prediction phase when observed over LAN and WAN.", "year": 2019, "referenceCount": 57, "citationCount": 92, "influentialCitationCount": 10, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "65831050", "name": "Rahul Rachuri"}, {"authorId": "153456203", "name": "Ajith Suresh"}]}, {"paperId": "d395c7b8d43faaa37d69506cad18eb6ec58e26d7", "url": "https://www.semanticscholar.org/paper/d395c7b8d43faaa37d69506cad18eb6ec58e26d7", "title": "A novel method for protein secondary structure prediction using dual\u2010layer SVM and profiles", "abstract": "A high\u2010performance method was developed for protein secondary structure prediction based on the dual\u2010layer support vector machine (SVM) and position\u2010specific scoring matrices (PSSMs). SVM is a new machine learning technology that has been successfully applied in solving problems in the field of bioinformatics. The SVM's performance is usually better than that of traditional machine learning approaches. The performance was further improved by combining PSSM profiles with the SVM analysis. The PSSMs were generated from PSI\u2010BLAST profiles, which contain important evolution information. The final prediction results were generated from the second SVM layer output. On the CB513 data set, the three\u2010state overall per\u2010residue accuracy, Q3, reached 75.2%, while segment overlap (SOV) accuracy increased to 80.0%. On the CB396 data set, the Q3 of our method reached 74.0% and the SOV reached 78.1%. A web server utilizing the method has been constructed and is available at http://www.bioinfo.tsinghua.edu.cn/pmsvm. Proteins 2004;00:000\u2013000. \u00a9 2004 Wiley\u2010Liss, Inc.", "year": 2004, "referenceCount": 30, "citationCount": 195, "influentialCitationCount": 12, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Medicine"], "authors": [{"authorId": "50115727", "name": "Jian Guo"}, {"authorId": "2108276437", "name": "Hu Chen"}, {"authorId": "2300991", "name": "Zhirong Sun"}, {"authorId": "2153417", "name": "Yuanlie Lin"}]}, {"paperId": "037e7b04a88c4979ef6ac91dd8c0b71f627ec625", "url": "https://www.semanticscholar.org/paper/037e7b04a88c4979ef6ac91dd8c0b71f627ec625", "title": "Racial categories in machine learning", "abstract": "Controversies around race and machine learning have sparked debate among computer scientists over how to design machine learning systems that guarantee fairness. These debates rarely engage with how racial identity is embedded in our social experience, making for sociological and psychological complexity. This complexity challenges the paradigm of considering fairness to be a formal property of supervised learning with respect to protected personal attributes. Racial identity is not simply a personal subjective quality. For people labeled \"Black\" it is an ascribed political category that has consequences for social differentiation embedded in systemic patterns of social inequality achieved through both social and spatial segregation. In the United States, racial classification can best be understood as a system of inherently unequal status categories that places whites as the most privileged category while signifying the Negro/black category as stigmatized. Social stigma is reinforced through the unequal distribution of societal rewards and goods along racial lines that is reinforced by state, corporate, and civic institutions and practices. This creates a dilemma for society and designers: be blind to racial group disparities and thereby reify racialized social inequality by no longer measuring systemic inequality, or be conscious of racial categories in a way that itself reifies race. We propose a third option. By preceding group fairness interventions with unsupervised learning to dynamically detect patterns of segregation, machine learning systems can mitigate the root cause of social disparities, social segregation and stratification, without further anchoring status categories of disadvantage.", "year": 2018, "referenceCount": 56, "citationCount": 69, "influentialCitationCount": 2, "isOpenAccess": true, "fieldsOfStudy": ["Computer Science", "Mathematics", "Sociology"], "authors": [{"authorId": "2862008", "name": "Sebastian Benthall"}, {"authorId": "40387211", "name": "Bruce D. Haynes"}]}, {"paperId": "0d678ce457ad13e0d13a96cd502cc9da0ae95dcd", "url": "https://www.semanticscholar.org/paper/0d678ce457ad13e0d13a96cd502cc9da0ae95dcd", "title": "Experimental Machine Learning of Quantum States.", "abstract": "Quantum information technologies provide promising applications in communication and computation, while machine learning has become a powerful technique for extracting meaningful structures in \"big data.\" A crossover between quantum information and machine learning represents a new interdisciplinary area stimulating progress in both fields. Traditionally, a quantum state is characterized by quantum-state tomography, which is a resource-consuming process when scaled up. Here we experimentally demonstrate a machine-learning approach to construct a quantum-state classifier for identifying the separability of quantum states. We show that it is possible to experimentally train an artificial neural network to efficiently learn and classify quantum states, without the need of obtaining the full information of the states. We also show how adding a hidden layer of neurons to the neural network can significantly boost the performance of the state classifier. These results shed new light on how classification of quantum states can be achieved with limited resources, and represent a step towards machine-learning-based applications in quantum information processing.", "year": 2017, "referenceCount": 47, "citationCount": 93, "influentialCitationCount": 0, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Physics", "Computer Science"], "authors": [{"authorId": "2111014047", "name": "Jun Gao"}, {"authorId": "6891618", "name": "Lu-Feng Qiao"}, {"authorId": "66183707", "name": "Zhi-Qiang Jiao"}, {"authorId": "2109387083", "name": "Yue-Chi Ma"}, {"authorId": "50989843", "name": "Cheng-Qiu Hu"}, {"authorId": "51012274", "name": "Ruo-Jing Ren"}, {"authorId": "8026905", "name": "Ai-Lin Yang"}, {"authorId": "2109238434", "name": "Hao Tang"}, {"authorId": "145666876", "name": "M. Yung"}, {"authorId": "3398360", "name": "Xian-min Jin"}]}, {"paperId": "ca513657a09369be8cec83fda6a5948e744c78a6", "url": "https://www.semanticscholar.org/paper/ca513657a09369be8cec83fda6a5948e744c78a6", "title": "Scaling Distributed Machine Learning with In-Network Aggregation", "abstract": "Training complex machine learning models in parallel is an increasingly important workload. We accelerate distributed parallel training by designing a communication primitive that uses a programmable switch dataplane to execute a key step of the training process. Our approach, SwitchML, reduces the volume of exchanged data by aggregating the model updates from multiple workers in the network. We co-design the switch processing with the end-host protocols and ML frameworks to provide a robust, efficient solution that speeds up training by up to 300%, and at least by 20% for a number of real-world benchmark models.", "year": 2019, "referenceCount": 103, "citationCount": 177, "influentialCitationCount": 18, "isOpenAccess": false, "fieldsOfStudy": ["Computer Science", "Mathematics"], "authors": [{"authorId": "2239912", "name": "Amedeo Sapio"}, {"authorId": "1709876", "name": "M. Canini"}, {"authorId": "46192768", "name": "Chen-Yu Ho"}, {"authorId": "144107689", "name": "J. Nelson"}, {"authorId": "2000187", "name": "Panos Kalnis"}, {"authorId": "33742176", "name": "Changhoon Kim"}, {"authorId": "144695691", "name": "A. Krishnamurthy"}, {"authorId": "1865725", "name": "M. Moshref"}, {"authorId": "2883709", "name": "Dan R. K. Ports"}, {"authorId": "2662221", "name": "Peter Richt\u00e1rik"}]}, {"paperId": "e8547557eeea9c9a334edfc4bfa4bbe3774e24d5", "url": "https://www.semanticscholar.org/paper/e8547557eeea9c9a334edfc4bfa4bbe3774e24d5", "title": "Machine learning and data science in soft materials engineering", "abstract": "In many branches of materials science it is now routine to generate data sets of such large size and dimensionality that conventional methods of analysis fail. Paradigms and tools from data science and machine learning can provide scalable approaches to identify and extract trends and patterns within voluminous data sets, perform guided traversals of high-dimensional phase spaces, and furnish data-driven strategies for inverse materials design. This topical review provides an accessible introduction to machine learning tools in the context of soft and biological materials by \u2018de-jargonizing\u2019 data science terminology, presenting a taxonomy of machine learning techniques, and surveying the mathematical underpinnings and software implementations of popular tools, including principal component analysis, independent component analysis, diffusion maps, support vector machines, and relative entropy. We present illustrative examples of machine learning applications in soft matter, including inverse design of self-assembling materials, nonlinear learning of protein folding landscapes, high-throughput antimicrobial peptide design, and data-driven materials design engines. We close with an outlook on the challenges and opportunities for the field.", "year": 2018, "referenceCount": 286, "citationCount": 91, "influentialCitationCount": 2, "isOpenAccess": false, "fieldsOfStudy": ["Physics", "Medicine"], "authors": [{"authorId": "2424441", "name": "Andrew L. Ferguson"}]}, {"paperId": "e32a2519b59d62cff6cb8136ee242dc3754ed57b", "url": "https://www.semanticscholar.org/paper/e32a2519b59d62cff6cb8136ee242dc3754ed57b", "title": "Second opinion needed: communicating uncertainty in medical machine learning", "abstract": null, "year": 2021, "referenceCount": 82, "citationCount": 90, "influentialCitationCount": 3, "isOpenAccess": true, "fieldsOfStudy": ["Medicine", "Computer Science"], "authors": [{"authorId": "17850015", "name": "Benjamin Kompa"}, {"authorId": "144108062", "name": "Jasper Snoek"}, {"authorId": "1507094362", "name": "A. Beam"}]}]}