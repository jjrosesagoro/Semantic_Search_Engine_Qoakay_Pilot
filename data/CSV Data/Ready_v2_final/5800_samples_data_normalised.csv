paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,fieldsOfStudy/1,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,fieldsOfStudy/2,fieldsOfStudy/3,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,authors/23/authorId,authors/23/name,authors/24/authorId,authors/24/name,authors/25/authorId,authors/25/name,authors/26/authorId,authors/26/name,authors/27/authorId,authors/27/name,authors/28/authorId,authors/28/name,authors/29/authorId,authors/29/name,authors/30/authorId,authors/30/name,authors/31/authorId,authors/31/name,authors/32/authorId,authors/32/name,authors/33/authorId,authors/33/name
e6d207231dfbaf75383cc5f889bba8f4db00ee4f,https://www.semanticscholar.org/paper/e6d207231dfbaf75383cc5f889bba8f4db00ee4f,"Comprehensive Survey on Machine Learning in Vehicular Network: Technology, Applications and Challenges","Towards future intelligent vehicular network, the machine learning as the promising artificial intelligence tool is widely researched to intelligentize communication and networking functions. In this paper, we provide a comprehensive survey on various machine learning techniques applied to both communication and network parts in vehicular network. To benefit reading, we first give a preliminary on communication technologies and machine learning technologies in vehicular network. Then, we detailedly describe the challenges of conventional techniques in vehicular network and corresponding machine learning based solutions. Finally, we present several open issues and emphasize potential directions that are worthy of research for the future intelligent vehicular network.",2021,0,37,1,False,Computer Science,19282835,Fengxiao Tang,152877793.0,Bomin Mao,145842185.0,N. Kato,152593447.0,Guan Gui,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d67b47aa0e7866e3e253544a9b214c040f852ea3,https://www.semanticscholar.org/paper/d67b47aa0e7866e3e253544a9b214c040f852ea3,Evaluating the Performance of Machine Learning Techniques in the Classification of Wisconsin Breast Cancer,"Breast cancer is a considerable problem among the women and causes death around the world. This disease can be detected by distinguishing malignant and benign tumors. Hence, doctors require trustworthy diagnosing process in order to differentiate between malignant and benign tumors. Therefore, the automation of this process is required to recognize tumors. Numerous research works have tried to apply the algorithms of machine learning for classifying breast cancer and it was proven by many researchers that machine learning algorithms act preferable in the diagnosing process. In this paper, three machine-learning algorithms (Support Vector Machine, K-nearest neighbors, and Decision tree) have been used and the performance of these classifiers has been compared in order to detect which classifier works better in the classification of breast cancer. Furthermore, the dataset of Wisconsin Breast Cancer (Diagnostic) has been used in this study. The main aim of this work is to make comparison among several classifiers and find the best classifier which gives better accuracy. The outcomes of this study have revealed that quadratic support vector machine grants the largest accuracy of (98.1%) with lowest false discovery rates. The experiments of this study have been carried out and managed in Matlab which has a special toolbox for machine learning algorithms.",2018,26,50,1,False,,51992035,O. I. Obaid,7349492.0,M. Mohammed,2640028.0,Mohd Khanapi Abd. Ghani,36795542.0,S. Mostafa,2169753056.0,Fahad Taha,2169746981.0,AL-Dhief,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dd73f130092b0ab309334516df07e86e964e9de4,https://www.semanticscholar.org/paper/dd73f130092b0ab309334516df07e86e964e9de4,Experiments in Meta-level Learning with Ilp,"When considering new datasets for analysis with machine learning algorithms, we encounter the problem of choosing the algorithm which is best suited for the task at hand. The aim of meta-level learning is to relate the performance of diierent machine learning algorithms to the characteristics of the dataset. The relation is induced on the basis of empirical data about the performance of machine learning algorithms on the diierent datasets. In the paper, an Inductive Logic Programming (ILP) framework for meta-level learning is presented. The performance of three machine learning algorithms (the tree learning system C4.5, the rule learning system CN2 and the k-NN nearest neighbour classiier) were measured on twenty datasets from the UCI repository in order to obtain the dataset for meta-learning. The results of applying ILP on this meta-learning problem are presented and discussed.",1999,10,41,0,False,,2103786841,Ljup Co Todorovski,2052861106.0,So D Sa,2105454905.0,Zeroski,2060897885.0,Si,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ac31f81456137da8c603847d7d6cedc339c51168,https://www.semanticscholar.org/paper/ac31f81456137da8c603847d7d6cedc339c51168,"Gravity Spy: integrating advanced LIGO detector characterization, machine learning, and citizen science","With the first direct detection of gravitational waves, the advanced laser interferometer gravitational-wave observatory (LIGO) has initiated a new field of astronomy by providing an alternative means of sensing the universe. The extreme sensitivity required to make such detections is achieved through exquisite isolation of all sensitive components of LIGO from non-gravitational-wave disturbances. Nonetheless, LIGO is still susceptible to a variety of instrumental and environmental sources of noise that contaminate the data. Of particular concern are noise features known as glitches, which are transient and non-Gaussian in their nature, and occur at a high enough rate so that accidental coincidence between the two LIGO detectors is non-negligible. Glitches come in a wide range of time-frequency-amplitude morphologies, with new morphologies appearing as the detector evolves. Since they can obscure or mimic true gravitational-wave signals, a robust characterization of glitches is paramount in the effort to achieve the gravitational-wave detection rates that are predicted by the design sensitivity of LIGO. This proves a daunting task for members of the LIGO Scientific Collaboration alone due to the sheer amount of data. In this paper we describe an innovative project that combines crowdsourcing with machine learning to aid in the challenging task of categorizing all of the glitches recorded by the LIGO detectors. Through the Zooniverse platform, we engage and recruit volunteers from the public to categorize images of time-frequency representations of glitches into pre-identified morphological classes and to discover new classes that appear as the detectors evolve. In addition, machine learning algorithms are used to categorize images after being trained on human-classified examples of the morphological classes. Leveraging the strengths of both classification methods, we create a combined method with the aim of improving the efficiency and accuracy of each individual classifier. The resulting classification and characterization should help LIGO scientists to identify causes of glitches and subsequently eliminate them from the data or the detector entirely, thereby improving the rate and accuracy of gravitational-wave observations. We demonstrate these methods using a small subset of data from LIGO’s first observing run.",2016,64,201,9,True,Physics,13322962,M. Zevin,39507823.0,S. Coughlin,3185424.0,S. Bahaadini,1962615.0,E. Besler,2116548.0,N. Rohani,2072563951.0,S. Allen,Medicine,49448026.0,M. Cabero,1716974.0,Kevin Crowston,144842935.0,A. Katsaggelos,38489633.0,S. Larson,2110897462.0,T. K. Lee,34769917.0,C. Lintott,1383461830.0,T. Littenberg,87451944.0,A. Lundgren,2064431404.0,C. Østerlund,,J R Smith,3021092.0,L. Trouille,4013201.0,V. Kalogera,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ccd64c17c811d0d60672ac1a4a4bbb222debfa5d,https://www.semanticscholar.org/paper/ccd64c17c811d0d60672ac1a4a4bbb222debfa5d,The Management of Context-Sensitive Features: A Review of Strategies,"In this paper, we review five heuristic strategies for handling context- sensitive features in supervised machine learning from examples. We discuss two methods for recovering lost (implicit) contextual information. We mention some evidence that hybrid strategies can have a synergetic effect. We then show how the work of several machine learning researchers fits into this framework. While we do not claim that these strategies exhaust the possibilities, it appears that the framework includes all of the techniques that can be found in the published literature on context-sensitive learning.",2002,25,70,3,False,Computer Science,1689647,Peter D. Turney,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3003e9e965957ab262212635f313cdaf6ded13ed,https://www.semanticscholar.org/paper/3003e9e965957ab262212635f313cdaf6ded13ed,Machine Learning Energies of 2 Million Elpasolite (ABC_{2}D_{6}) Crystals.,"Elpasolite is the predominant quaternary crystal structure (AlNaK_{2}F_{6} prototype) reported in the Inorganic Crystal Structure Database. We develop a machine learning model to calculate density functional theory quality formation energies of all ∼2×10^{6} pristine ABC_{2}D_{6} elpasolite crystals that can be made up from main-group elements (up to bismuth). Our model's accuracy can be improved systematically, reaching a mean absolute error of 0.1  eV/atom for a training set consisting of 10×10^{3} crystals. Important bonding trends are revealed: fluoride is best suited to fit the coordination of the D site, which lowers the formation energy whereas the opposite is found for carbon. The bonding contribution of the elements A and B is very small on average. Low formation energies result from A and B being late elements from group II, C being a late (group I) element, and D being fluoride. Out of 2×10^{6} crystals, 90 unique structures are predicted to be on the convex hull-among which is NFAl_{2}Ca_{6}, with a peculiar stoichiometry and a negative atomic oxidation state for Al.",2015,45,231,0,True,Physics,145483118,Felix A Faber,13174355.0,Alexander Hans Gustav Lindmaa,7847508.0,O. A. von Lilienfeld,145399646.0,R. Armiento,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,Materials Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6227e6923797c00ad3bd89b39643ee05faccb422,https://www.semanticscholar.org/paper/6227e6923797c00ad3bd89b39643ee05faccb422,Federated Learning in Mobile Edge Networks: A Comprehensive Survey,"In recent years, mobile devices are equipped with increasingly advanced sensing and computing capabilities. Coupled with advancements in Deep Learning (DL), this opens up countless possibilities for meaningful applications, e.g., for medical purposes and in vehicular networks. Traditional cloud-based Machine Learning (ML) approaches require the data to be centralized in a cloud server or data center. However, this results in critical issues related to unacceptable latency and communication inefficiency. To this end, Mobile Edge Computing (MEC) has been proposed to bring intelligence closer to the edge, where data is produced. However, conventional enabling technologies for ML at mobile edge networks still require personal data to be shared with external parties, e.g., edge servers. Recently, in light of increasingly stringent data privacy legislations and growing privacy concerns, the concept of Federated Learning (FL) has been introduced. In FL, end devices use their local data to train an ML model required by the server. The end devices then send the model updates rather than raw data to the server for aggregation. FL can serve as an enabling technology in mobile edge networks since it enables the collaborative training of an ML model and also enables DL for mobile edge network optimization. However, in a large-scale and complex mobile edge network, heterogeneous devices with varying constraints are involved. This raises challenges of communication costs, resource allocation, and privacy and security in the implementation of FL at scale. In this survey, we begin with an introduction to the background and fundamentals of FL. Then, we highlight the aforementioned challenges of FL implementation and review existing solutions. Furthermore, we present the applications of FL for mobile edge network optimization. Finally, we discuss the important challenges and future research directions in FL.",2019,222,713,48,True,Computer Science,1753717562,Wei Yang Bryan Lim,3046954.0,Nguyen Cong Luong,2233724.0,D. Hoang,2878072.0,Yutao Jiao,144791622.0,Ying-Chang Liang,153096457.0,Qiang Yang,Engineering,1713586.0,D. Niyato,1679209.0,C. Miao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7cad19a569461df23761f59d97bc7b9efa709832,https://www.semanticscholar.org/paper/7cad19a569461df23761f59d97bc7b9efa709832,Towards Automated Machine Learning: Evaluation and Comparison of AutoML Approaches and Tools,"There has been considerable growth and interest in industrial applications of machine learning (ML) in recent years. ML engineers, as a consequence, are in high demand across the industry, yet improving the efficiency of ML engineers remains a fundamental challenge. Automated machine learning (AutoML) has emerged as a way to save time and effort on repetitive tasks in ML pipelines, such as data pre-processing, feature engineering, model selection, hyperparameter optimization, and prediction result analysis. In this paper, we investigate the current state of AutoML tools aiming to automate these tasks. We conduct various evaluations of the tools on many datasets, in different data segments, to examine their performance, and compare their advantages and disadvantages on different test cases.",2019,17,102,9,True,Computer Science,4543607,A. Truong,145008132.0,Austin Walters,8606417.0,Jeremy Goodsitt,4634403.0,Keegan E. Hines,8954363.0,C. B. Bruss,2068373997.0,R. Farivar,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aee1e402d5a2fe7c3096f5406bb8088ba587565c,https://www.semanticscholar.org/paper/aee1e402d5a2fe7c3096f5406bb8088ba587565c,Using supervised machine learning on large-scale online forums to classify course-related Facebook messages in predicting learning achievement within the personal learning environment,"ABSTRACT This paper demonstrated the use of the supervised Machine Learning (ML) for text classification to predict students’ final course grades in a hybrid Advanced Statistics course and exhibited the potential of using ML classified messages to identify students at risk of course failure. We built three classification models with training data of 76,936 posts from two large online forums and applied the models to classify messages into statistics-related and non-statistics-related posts in a private Facebook group. Three ML algorithms were compared in terms of classification effectiveness and congruency with human coding. Students with more messages endorsed by two or more ML algorithms as statistics-related had higher final course grades. Students who failed the course also had significantly fewer messages endorsed by all three ML algorithms than those who passed. Results suggest that ML can be used for identifying students in need of support within the personal learning environment and for quality control of the large-scale educational data.",2018,59,52,2,False,Computer Science,47876037,Jiun-Yu Wu,25219613.0,Yi-Cheng Hsiao,40373696.0,Mei-Wen Nian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a17bbef16253a0da824d528e5027ce77c986d10b,https://www.semanticscholar.org/paper/a17bbef16253a0da824d528e5027ce77c986d10b,Estimation of effective temperatures in quantum annealers for sampling applications: A case study with possible applications in deep learning,"An increase in the efficiency of sampling from Boltzmann distributions would have a significant impact on deep learning and other machine-learning applications. Recently, quantum annealers have been proposed as a potential candidate to speed up this task, but several limitations still bar these state-of-the-art technologies from being used effectively. One of the main limitations is that, while the device may indeed sample from a Boltzmann-like distribution, quantum dynamical arguments suggest it will do so with an {\it instance-dependent} effective temperature, different from its physical temperature. Unless this unknown temperature can be unveiled, it might not be possible to effectively use a quantum annealer for Boltzmann sampling. In this work, we propose a strategy to overcome this challenge with a simple effective-temperature estimation algorithm. We provide a systematic study assessing the impact of the effective temperatures in the learning of a special class of a restricted Boltzmann machine embedded on quantum hardware, which can serve as a building block for deep-learning architectures. We also provide a comparison to $k$-step contrastive divergence (CD-$k$) with $k$ up to 100. Although assuming a suitable fixed effective temperature also allows us to outperform one step contrastive divergence (CD-1), only when using an instance-dependent effective temperature do we find a performance close to that of CD-100 for the case studied here.",2015,27,153,10,True,Physics,3468759,M. Benedetti,1402789590.0,John Realpe-G'omez,144637418.0,R. Biswas,1402938096.0,A. Perdomo-Ortiz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2a124978220b2214929d6e6c6cee0a4598d8f3d1,https://www.semanticscholar.org/paper/2a124978220b2214929d6e6c6cee0a4598d8f3d1,Learning in Implicit Generative Models,"Generative adversarial networks (GANs) provide an algorithmic framework for constructing generative models with several appealing properties: they do not require a likelihood function to be specified, only a generating procedure; they provide samples that are sharp and compelling; and they allow us to harness our knowledge of building highly accurate neural network classifiers. Here, we develop our understanding of GANs with the aim of forming a rich view of this growing area of machine learning---to build connections to the diverse set of statistical thinking on this topic, of which much can be gained by a mutual exchange of ideas. We frame GANs within the wider landscape of algorithms for learning in implicit generative models--models that only specify a stochastic procedure with which to generate data--and relate these ideas to modelling problems in related fields, such as econometrics and approximate Bayesian computation. We develop likelihood-free inference methods and highlight hypothesis testing as a principle for learning in implicit generative models, using which we are able to derive the objective function used by GANs, and many other related objectives. The testing viewpoint directs our focus to the general problem of density ratio estimation. There are four approaches for density ratio estimation, one of which is a solution using classifiers to distinguish real from generated data. Other approaches such as divergence minimisation and moment matching have also been explored in the GAN literature, and we synthesise these views to form an understanding in terms of the relationships between them and the wider literature, highlighting avenues for future exploration and cross-pollination.",2016,59,327,13,False,Mathematics,14594344,S. Mohamed,40627523.0,Balaji Lakshminarayanan,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d302b0aad742a4242f929926ebcd57a530143410,https://www.semanticscholar.org/paper/d302b0aad742a4242f929926ebcd57a530143410,Modern Machine Learning Techniques and Their Applications in Cartoon Animation Research,"The integration of machine learning techniques and cartoon animation research is fast becoming a hot topic. This book helps readers learn the latest machine learning techniques, including patch alignment framework; spectral clustering, graph cuts, and convex relaxation; ensemble manifold learning; multiple kernel learning; multiview subspace learning; and multiview distance metric learning. It then presents the applications of these modern machine learning techniques in cartoon animation research. With these techniques, users can efficiently utilize the cartoon materials to generate animations in areas such as virtual reality, video games, animation films, and sport simulations",2013,0,35,0,False,Computer Science,2117883981,Jun Yu,143719920.0,D. Tao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76d9ab5822fce4d1eca85f9e816242dc632d88f4,https://www.semanticscholar.org/paper/76d9ab5822fce4d1eca85f9e816242dc632d88f4,Real-Time Machine Learning: The Missing Pieces,"Machine learning applications are increasingly deployed not only to serve predictions using static models, but also as tightly-integrated components of feedback loops involving dynamic, real-time decision making. These applications pose a new set of requirements, none of which are difficult to achieve in isolation, but the combination of which creates a challenge for existing distributed execution frameworks: computation with millisecond latency at high throughput, adaptive construction of arbitrary task graphs, and execution of heterogeneous kernels over diverse sets of resources. We assert that a new distributed execution framework is needed for such ML applications and propose a candidate approach with a proof-of-concept architecture that achieves a 63x performance improvement over a state-of-the-art execution framework for a representative application.",2017,22,52,4,False,Computer Science,34994156,Robert Nishihara,29912342.0,Philipp Moritz,2117867.0,Stephanie Wang,144312193.0,Alexey Tumanov,2058356165.0,William Paul,1389954462.0,Johann Schleier-Smith,,3393220.0,Richard Liaw,1694621.0,Michael I. Jordan,144467753.0,I. Stoica,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7fdc9264cf59d2736071791c6afce162c2cd743b,https://www.semanticscholar.org/paper/7fdc9264cf59d2736071791c6afce162c2cd743b,Book Review: Building online learning communities: Effective strategies for the virtual classroom,"List of Exhibits. Preface to the Second Edition. Acknowledgments. The Authors. PART ONE: The Learning Community in Online Learning. One: When Teaching and Learning Leave the Classroom. Online Issues and Concerns. Students Online. Making the Transition and Establishing Presence. The Search for Knowledge and Meaning in the Online Classroom. Putting the Pieces Together. New Approaches, New Skills. Implications. Two: Recontextualizing Community. The Importance of Community. Community Online. The Element of Social Presence. Coalescence and Belonging Online. Recontextualizing Community. Community in the Virtual Classroom. Participation and Desired Outcomes in the Online Classroom. Three: The Human Side of Online Learning. The Need for Human Contact. Connectedness and Coalescence. Shared Responsibility, Rules, and Norms. Roles and Participation. Shadow Issues: The Issues We Simply Don't Want to Face. Other Psychological Issues. Ritual as the Psychological Expression of Community. Spiritual Issues. Culture and Language Issues. Vulnerability, Ethics, and Privacy. Final Thoughts. Four: Practical Considerations in Online Learning. About Time. Group Size. Cost and Other Administrative Issues. Online Security. Five: Managing the Relationship to Technology. The Relationship of Person to Machine. Technology as a Facilitative Tool. Excuse Us, We Are Now Experiencing Technical Difficulties. Six: Moving Teaching and Learning Online. Effective Teaching and Learning in the Online Classroom. Roles and Functions of the Instructor in the Online Classroom. The Role of the Learner in the Learning Process. The Hybrid Course and Online Community. Moving to Specifics. PART TWO: TEACHING AND LEARNING IN THE VIRTUAL LEARNING COMMUNITY. Seven: Building Foundations. Creating an Effective Course Design. Constructing the Online Course Site. If You Build It, Will They Come? Final Thoughts. Guiding Questions to Assist in Building an Effective Course Syllabus. Evaluating an Effective Online Course. Eight: Promoting Collaborative Learning. Formulating a Shared Goal for Learning. Problems, Interests, and Experiences as Springboards for Learning. Dialogue as Inquiry. Encouraging Expansive Questioning. Sharing Responsibility for Facilitation. Promoting Feedback. Intergroup and Other Forms of Collaboration. Final Thoughts. Guiding Questions to Promote Collaborative Learning. Nine: Transformative Learning. The Process of Transformative Learning in the Online Classroom. Learning About Learning Through the Use of Technology. Creating Opportunities to Encourage Reflection on the Differences. Learning About Technology by Using It. Encouraging Questions and Comments About the Technology. Self-Reflection. Final Thoughts: We Are the Experts When It Comes to Our Own Learning. Guiding Questions to Promote Transformative Learning. Ten: Student Assessment and Course Evaluation. Assessment and Evaluation Basics. Student Performance. Course Evaluation. Program Evaluation. Final Thoughts. Questions to Consider in Student, Course, and Program Evaluation. Eleven: Lessons Learned and a Look Ahead. The Six Essential Elements. The Essence of Online Learning: Community. Unresolved Issues and Unanswered Questions. Lessons Learned and a Look to the Future. Extending Community Beyond the Classroom. Implications for Instructor Training. APPENDIX A: Examples of Course Syllabi. APPENDIX B: Glossary of Terms Used in Online Learning. APPENDIX C: Internet Resources for Distance Education. References. Index.",2007,0,531,58,False,Computer Science,2233115,R. Palloff,144073756.0,K. Pratt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2c40e6439fd283cf960cb9a753a018adc7ab0ad5,https://www.semanticscholar.org/paper/2c40e6439fd283cf960cb9a753a018adc7ab0ad5,Data Mining and Statistics for Decision Making,"Data mining is the process of automatically searching large volumes of data for models and patterns using computational techniques from statistics, machine learning and information theory; it is the ideal tool for such an extraction of knowledge. Data mining is usually associated with a business or an organization's need to identify trends and profiles, allowing, for example, retailers to discover patterns on which to base marketing objectives. This book looks at both classical and recent techniques of data mining, such as clustering, discriminant analysis, logistic regression, generalized linear models, regularized regression, PLS regression, decision trees, neural networks, support vector machines, Vapnik theory, naive Bayesian classifier, ensemble learning and detection of association rules. They are discussed along with illustrative examples throughout the book to explain the theory of these methods, as well as their strengths and limitations. Key Features: * Presents a comprehensive introduction to all techniques used in data mining and statistical learning, from classical to latest techniques. * Starts from basic principles up to advanced concepts. * Includes many step-by-step examples with the main software (R, SAS, IBM SPSS) as well as a thorough discussion and comparison of those software. * Gives practical tips for data mining implementation to solve real world problems. * Looks at a range of tools and applications, such as association rules, web mining and text mining, with a special focus on credit scoring. * Supported by an accompanying website hosting datasets and user analysis. Statisticians and business intelligence analysts, students as well as computer science, biology, marketing and financial risk professionals in both commercial and government organizations across all business and industry sectors will benefit from this book.",2011,0,324,28,False,Computer Science,69329748,Stphane Tuffry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4dc2ab5d60dcc2e5a2e0655e5ddcc6b124f03f11,https://www.semanticscholar.org/paper/4dc2ab5d60dcc2e5a2e0655e5ddcc6b124f03f11,Staleness-Aware Async-SGD for Distributed Deep Learning,"Deep neural networks have been shown to achieve state-of-the-art performance in several machine learning tasks. Stochastic Gradient Descent (SGD) is the preferred optimization algorithm for training these networks and asynchronous SGD (ASGD) has been widely adopted for accelerating the training of large-scale deep networks in a distributed computing environment. However, in practice it is quite challenging to tune the training hyperparameters (such as learning rate) when using ASGD so as achieve convergence and linear speedup, since the stability of the optimization algorithm is strongly influenced by the asynchronous nature of parameter updates. In this paper, we propose a variant of the ASGD algorithm in which the learning rate is modulated according to the gradient staleness and provide theoretical guarantees for convergence of this algorithm. Experimental verification is performed on commonly-used image classification benchmarks: CIFAR10 and Imagenet to demonstrate the superior effectiveness of the proposed approach, compared to SSGD (Synchronous SGD) and the conventional ASGD algorithm.",2015,31,210,34,False,Computer Science,31765881,Wei Zhang,2116011472.0,Suyog Gupta,2922996.0,Xiangru Lian,40478933.0,Ji Liu,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
402f850dff86fb601d34b2841e6083ac0f928edd,https://www.semanticscholar.org/paper/402f850dff86fb601d34b2841e6083ac0f928edd,SCNN: An accelerator for compressed-sparse convolutional neural networks,"Convolutional Neural Networks (CNNs) have emerged as a fundamental technology for machine learning. High performance and extreme energy efficiency are critical for deployments of CNNs, especially in mobile platforms such as autonomous vehicles, cameras, and electronic personal assistants. This paper introduces the Sparse CNN (SCNN) accelerator architecture, which improves performance and energy efficiency by exploiting the zero-valued weights that stem from network pruning during training and zero-valued activations that arise from the common ReLU operator. Specifically, SCNN employs a novel dataflow that enables maintaining the sparse weights and activations in a compressed encoding, which eliminates unnecessary data transfers and reduces storage requirements. Furthermore, the SCNN dataflow facilitates efficient delivery of those weights and activations to a multiplier array, where they are extensively reused; product accumulation is performed in a novel accumulator array. On contemporary neural networks, SCNN can improve both performance and energy by a factor of 2.7× and 2.3×, respectively, over a comparably provisioned dense CNN accelerator.",2017,32,794,119,False,Computer Science,1790421,A. Parashar,1998820.0,Minsoo Rhu,3374545.0,Anurag Mukkara,2274681.0,A. Puglielli,3172075.0,Rangharajan Venkatesan,2125244.0,Brucek Khailany,,1775477.0,J. Emer,1715863.0,S. Keckler,80724002.0,W. Dally,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f56425ec56586dcfd2694ab83643e9e76f314e91,https://www.semanticscholar.org/paper/f56425ec56586dcfd2694ab83643e9e76f314e91,50 Years of Data Science,"ABSTRACT More than 50 years ago, John Tukey called for a reformation of academic statistics. In “The Future of Data Analysis,” he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or “data analysis.” Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name “data science” for this envisioned field. A recent and growing phenomenon has been the emergence of “data science” programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a $100M “Data Science Initiative” that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as “cultural appropriation.” This article reviews some ingredients of the current “data science moment,” including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for “scaling up” to “big data.” This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere “scaling up,” but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are “learning from data,” and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today’s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.",2017,78,462,36,True,Engineering,1709392,D. Donoho,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9cdd742261c9f07887354622f79ade8226d625c7,https://www.semanticscholar.org/paper/9cdd742261c9f07887354622f79ade8226d625c7,DeepEar: robust smartphone audio sensing in unconstrained acoustic environments using deep learning,"Microphones are remarkably powerful sensors of human behavior and context. However, audio sensing is highly susceptible to wild fluctuations in accuracy when used in diverse acoustic environments (such as, bedrooms, vehicles, or cafes), that users encounter on a daily basis. Towards addressing this challenge, we turn to the field of deep learning; an area of machine learning that has radically changed related audio modeling domains like speech recognition. In this paper, we present DeepEar -- the first mobile audio sensing framework built from coupled Deep Neural Networks (DNNs) that simultaneously perform common audio sensing tasks. We train DeepEar with a large-scale dataset including unlabeled data from 168 place visits. The resulting learned model, involving 2.3M parameters, enables DeepEar to significantly increase inference robustness to background noise beyond conventional approaches present in mobile devices. Finally, we show DeepEar is feasible for smartphones by building a cloud-free DSP-based prototype that runs continuously, using only 6% of the smartphone's battery daily.",2015,83,318,15,False,Computer Science,144948031,N. Lane,1737522.0,Petko Georgiev,1994899.0,Lorena Qendro,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c3de2985843fa0387554cb120333848140939eee,https://www.semanticscholar.org/paper/c3de2985843fa0387554cb120333848140939eee,Integrating Plausibility Checks and Machine Learning for Misbehavior Detection in VANET,"The safety and efficiency of vehicular communications rely on the correctness of the data exchanged between vehicles. In this paper we address the issue of detecting and classifying location spoofing misbehavior using the VeReMi dataset. We propose a framework for a system that uses plausibility checks as a feature vector for machine learning models, used to detect and classify misbehavior. Using KNN and SVM, our results show we can improve the overall detection precision of the plausibility checks used in the feature vectors by over 20%, while maintaining a recall within 5%. We have also proven once a misbehavior has been detected it is possible to classify different types of known misbehavior's. Classifying the misbehavior types allows for more accurate and specific action steps to counteract the attacks, hence improving the ability to recover safety and security in the system.",2018,16,60,10,False,Computer Science,66904445,Steven So,32704690.0,Prinkle Sharma,1817032.0,J. Petit,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c709e8f2d6c66e68003a0db22c60d35715293b9f,https://www.semanticscholar.org/paper/c709e8f2d6c66e68003a0db22c60d35715293b9f,Extending the search for new resonances with machine learning,"The oldest and most robust technique to search for new particles is to look for ``bumps'' in invariant mass spectra over smoothly falling backgrounds. We present a new extension of the bump hunt that naturally benefits from modern machine learning algorithms while remaining model agnostic. This approach is based on the classification without labels (CWoLa) method where the invariant mass is used to create two potentially mixed samples, one with little or no signal and one with a potential resonance. Additional features that are uncorrelated with the invariant mass can be used for training the classifier. Given the lack of new physics signals at the Large Hadron Collider (LHC), such model-agnostic approaches are critical for ensuring full coverage to fully exploit the rich datasets from the LHC experiments. In addition to illustrating how the new method works in simple test cases, we demonstrate the power of the extended bump hunt on a realistic all-hadronic resonance search in a channel that would not be covered with existing techniques.",2019,82,91,4,True,Physics,153639309,J. Collins,28203888.0,K. Howe,3085579.0,B. Nachman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bc01a1a27b3a2f154d2a8cc9032f6ea957c6723b,https://www.semanticscholar.org/paper/bc01a1a27b3a2f154d2a8cc9032f6ea957c6723b,"Harnessing the Expertise of 70, 000 Human Editors: Knowledge-Based Feature Generation for Text Categorization","Most existing methods for text categorization employ induction algorithms that use the words appearing in the training documents as features. While they perform well in many categorization tasks, these methods are inherently limited when faced with more complicated tasks where external knowledge is essential. Recently, there have been efforts to augment these basic features with external knowledge, including semi-supervised learning and transfer learning. In this work, we present a new framework for automatic acquisition of world knowledge and methods for incorporating it into the text categorization process. Our approach enhances machine learning algorithms with features generated from domain-specific and common-sense knowledge. This knowledge is represented by ontologies that contain hundreds of thousands of concepts, further enriched through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts that augment the bag of words used in simple supervised learning. Feature generation is accomplished through contextual analysis of document text, thus implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses two significant problems in natural language processing---synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the training documents alone. We applied our methodology using the Open Directory Project, the largest existing Web directory built by over 70,000 human editors. Experimental results over a range of data sets confirm improved performance compared to the bag of words document representation.",2007,116,85,4,False,Computer Science,1718798,E. Gabrilovich,2309269.0,Shaul Markovitch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0d69ef2ecaae3151b1bda6b044aa9815645698be,https://www.semanticscholar.org/paper/0d69ef2ecaae3151b1bda6b044aa9815645698be,Applying Novel Resampling Strategies To Software Defect Prediction,"Due to the tremendous complexity and sophistication of software, improving software reliability is an enormously difficult task. We study the software defect prediction problem, which focuses on predicting which modules will experience a failure during operation. Numerous studies have applied machine learning to software defect prediction; however, skewness in defect-prediction datasets usually undermines the learning algorithms. The resulting classifiers will often never predict the faulty minority class. This problem is well known in machine learning and is often referred to as learning from unbalanced datasets. We examine stratification, a widely used technique for learning unbalanced data that has received little attention in software defect prediction. Our experiments are focused on the SMOTE technique, which is a method of over-sampling minority-class examples. Our goal is to determine if SMOTE can improve recognition of defect-prone modules, and at what cost. Our experiments demonstrate that after SMOTE resampling, we have a more balanced classification. We found an improvement of at least 23% in the average geometric mean classification accuracy on four benchmark datasets.",2007,30,126,4,False,Computer Science,2520605,L. Pelayo,144091556.0,S. Dick,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8efe2e730344e9df401854981bf368019b4084af,https://www.semanticscholar.org/paper/8efe2e730344e9df401854981bf368019b4084af,Recognition of Electromyographic Signals Using Cascaded Kernel Learning Machine,"Electromyographic (EMG) signals recognition is a complex pattern recognition problem due to its property of large variations in signals and features. This paper proposes a novel EMG classifier called cascaded kernel learning machine (CKLM) to achieve the goal of high-accuracy EMG recognition. First, the EMG signals are acquired by three surface electrodes placed on three different muscles. Second, EMG features are extracted by autoregressive model (ARM) and EMG histogram. After the feature extraction, the CKLM is performed to classify the features. CKLM is composed of two different kinds of kernel learning machines: generalized discriminant analysis (GDA) algorithm and support vector machine (SVM). By using GDA, both the goals of the dimensionality reduction of input features and the selection of discriminating features, named kernel FisherEMG, can be reached. Then, SVM combined with one-against-one strategy is executed to classify the kernel FisherEMG. By cascading SVM with GDA, the input features will be nonlinearly mapped twice by radial-basis function (RBF). As a result, a linear optimal separating hyperplane can be found with the largest margin of separation between each pair of postures' classes in the implicit dot product feature space. In addition, we develop a digital signal processor (DSP)-based EMG classification system for the control of a multi-degrees-of-freedom prosthetic hand for the practical implementation. Based on the clinical experiments, the results show that the proposed CKLM is superior to other frequently used methods, such as k-nearest neighbor algorithm, multilayer neural network, and SVM. The best EMG recognition rate 93.54% is obtained by CKLM.",2007,33,104,8,False,Computer Science,47909860,Yi-Hung Liu,1734312.0,Han-Pang Huang,50985940.0,C.H. Weng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8,https://www.semanticscholar.org/paper/8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8,Learning-based view synthesis for light field cameras,"With the introduction of consumer light field cameras, light field imaging has recently become widespread. However, there is an inherent trade-off between the angular and spatial resolution, and thus, these cameras often sparsely sample in either spatial or angular domain. In this paper, we use machine learning to mitigate this trade-off. Specifically, we propose a novel learning-based approach to synthesize new views from a sparse set of input views. We build upon existing view synthesis techniques and break down the process into disparity and color estimation components. We use two sequential convolutional neural networks to model these two components and train both networks simultaneously by minimizing the error between the synthesized and ground truth images. We show the performance of our approach using only four corner sub-aperture views from the light fields captured by the Lytro Illum camera. Experimental results show that our approach synthesizes high-quality images that are superior to the state-of-the-art techniques on a variety of challenging real-world scenes. We believe our method could potentially decrease the required angular resolution of consumer light field cameras, which allows their spatial resolution to increase.",2016,54,491,105,True,Computer Science,1717070,N. Kalantari,2155389841.0,Tingxian Wang,1752236.0,R. Ramamoorthi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7f5271c79af7ea6806770c8febf441b55dcfd554,https://www.semanticscholar.org/paper/7f5271c79af7ea6806770c8febf441b55dcfd554,"Rethinking Drug Repositioning and Development with Artificial Intelligence, Machine Learning, and Omics.","Pharmaceutical industry and the art and science of drug development are sorely in need of novel transformative technologies in the current age of digital health and artificial intelligence (AI). Often described as game-changing technologies, AI and machine learning algorithms have slowly but surely begun to revolutionize pharmaceutical industry and drug development over the past 5 years. In this expert review, we describe the most frequently used machine learning algorithms in drug development pipelines and the -omics databases well poised to support machine learning and drug discovery. Subsequently, we analyze the emerging new computational approaches to drug discovery and the in silico pipelines for drug repositioning and the synergies among -omics system sciences, AI and machine learning. As with system sciences, AI and machine learning embody a system scale and Big Data driven vision for drug discovery and development. We conclude with a future outlook on the ways in which machine learning approaches can be implemented to buttress and expedite drug discovery and precision medicine. As AI and machine learning are rapidly entering pharmaceutical industry and the art and science of drug development, we need to critically examine the attendant prospects and challenges to benefit patients and public health.",2019,74,37,0,True,Medicine,1387833466,M. Koromina,1387833483.0,Maria-Theodora Pandi,2727213.0,G. Patrinos,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d02ce9e37a3fd647d2ac1c7e5e1580240260e05d,https://www.semanticscholar.org/paper/d02ce9e37a3fd647d2ac1c7e5e1580240260e05d,Machine and deep learning for sport-specific movement recognition: a systematic review of model development and performance,"ABSTRACT Objective assessment of an athlete’s performance is of importance in elite sports to facilitate detailed analysis. The implementation of automated detection and recognition of sport-specific movements overcomes the limitations associated with manual performance analysis methods. The object of this study was to systematically review the literature on machine and deep learning for sport-specific movement recognition using inertial measurement unit (IMU) and, or computer vision data inputs. A search of multiple databases was undertaken. Included studies must have investigated a sport-specific movement and analysed via machine or deep learning methods for model development. A total of 52 studies met the inclusion and exclusion criteria. Data pre-processing, processing, model development and evaluation methods varied across the studies. Model development for movement recognition were predominantly undertaken using supervised classification approaches. A kernel form of the Support Vector Machine algorithm was used in 53% of IMU and 50% of vision-based studies. Twelve studies used a deep learning method as a form of Convolutional Neural Network algorithm and one study also adopted a Long Short Term Memory architecture in their model. The adaptation of experimental set-up, data pre-processing, and model development methods are best considered in relation to the characteristics of the targeted sports movement(s).",2018,185,117,9,True,Medicine,30419764,Emily E. Cust,8003145.0,Alice J. Sweeting,46952322.0,K. Ball,52152859.0,S. Robertson,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56ef935e32386256d3fc57c409ac6a8d7af1ca2e,https://www.semanticscholar.org/paper/56ef935e32386256d3fc57c409ac6a8d7af1ca2e,An enhanced WiFi indoor localization system based on machine learning,"The Global Navigation Satellite Systems (GNSS) suffer from accuracy deterioration and outages in dense urban canyons and are almost unavailable for indoor environments. Nowadays, developing indoor positioning systems has become an attractive research topic due to the increasing demands on ubiquitous positioning. WiFi technology has been studied for many years to provide indoor positioning services. The WiFi indoor localization systems based on machine learning approach are widely used in the literature. These systems attempt to find the perfect match between the user fingerprint and pre-defined set of grid points on the radio map. However, Fingerprints are duplicated from available Access Points (APs) and interference, which increase number of matched patterns with the user's fingerprint. In this research, the Principle Component Analysis (PCA) is utilized to improve the performance and to reduce the computation cost of the WiFi indoor localization systems based on machine learning approach. All proposed methods were developed and physically realized on Android-based smart phone using the IEEE 802.11 WLANs. The experimental setup was conducted in a real indoor environment in both static and dynamic modes. The performance of the proposed method was tested using K-Nearest Neighbors, Decision Tree, Random Forest and Support Vector Machine classifiers. The results show that the performance of the proposed method outperforms other indoor localization reported in the literature. The computation time was reduced by 70% when using Random Forest classifier in the static mode and by 33% when using KNN in the dynamic mode.",2016,25,84,10,False,Engineering,7566339,Ahmed H. Salamah,49640813.0,M. Tamazin,145844806.0,M. Sharkas,145386145.0,M. Khedr,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a61a3fe4a35ebc27ba77db57e8eb6b5a59f58cf0,https://www.semanticscholar.org/paper/a61a3fe4a35ebc27ba77db57e8eb6b5a59f58cf0,Diagnostic Accuracy of a Machine-Learning Approach to Coronary Computed Tomographic Angiography–Based Fractional Flow Reserve: Result From the MACHINE Consortium,"Background: Coronary computed tomographic angiography (CTA) is a reliable modality to detect coronary artery disease. However, CTA generally overestimates stenosis severity compared with invasive angiography, and angiographic stenosis does not necessarily imply hemodynamic relevance when fractional flow reserve (FFR) is used as reference. CTA-based FFR (CT-FFR), using computational fluid dynamics (CFD), improves the correlation with invasive FFR results but is computationally demanding. More recently, a new machine-learning (ML) CT-FFR algorithm has been developed based on a deep learning model, which can be performed on a regular workstation. In this large multicenter cohort, the diagnostic performance ML-based CT-FFR was compared with CTA and CFD-based CT-FFR for detection of functionally obstructive coronary artery disease. Methods and Results: At 5 centers in Europe, Asia, and the United States, 351 patients, including 525 vessels with invasive FFR comparison, were included. ML-based and CFD-based CT-FFR were performed on the CTA data, and diagnostic performance was evaluated using invasive FFR as reference. Correlation between ML-based and CFD-based CT-FFR was excellent (R=0.997). ML-based (area under curve, 0.84) and CFD-based CT-FFR (0.84) outperformed visual CTA (0.69; P<0.0001). On a per-vessel basis, diagnostic accuracy improved from 58% (95% confidence interval, 54%–63%) by CTA to 78% (75%–82%) by ML-based CT-FFR. The per-patient accuracy improved from 71% (66%–76%) by CTA to 85% (81%–89%) by adding ML-based CT-FFR as 62 of 85 (73%) false-positive CTA results could be correctly reclassified by adding ML-based CT-FFR. Conclusions: On-site CT-FFR based on ML improves the performance of CTA by correctly reclassifying hemodynamically nonsignificant stenosis and performs equally well as CFD-based CT-FFR.",2018,48,198,5,True,Medicine,35845763,A. Coenen,40698117.0,Young-Hak Kim,36842653.0,M. Kruk,34419657.0,C. Tesche,52214986.0,J. de Geer,6606745.0,A. Kurata,,2074193162.0,Marisa L Lubbers,46779183.0,J. Daemen,3100263.0,L. Itu,2648533.0,S. Rapaka,46756618.0,Puneet S. Sharma,2698289.0,C. Schwemmer,48522189.0,A. Persson,3924618.0,U. Schoepf,4274356.0,C. Kȩpka,115291289.0,Dong Hyun Yang,145703411.0,K. Nieman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c18abfbabd3e878e9df45305c4f08203d4bf8790,https://www.semanticscholar.org/paper/c18abfbabd3e878e9df45305c4f08203d4bf8790,Comparison of Selected Machine Learning Algorithms for Industrial Electrical Tomography,"The main goal of this work was to compare the selected machine learning methods with the classic deterministic method in the industrial field of electrical impedance tomography. The research focused on the development and comparison of algorithms and models for the analysis and reconstruction of data using electrical tomography. The novelty was the use of original machine learning algorithms. Their characteristic feature is the use of many separately trained subsystems, each of which generates a single pixel of the output image. Artificial Neural Network (ANN), LARS and Elastic net methods were used to solve the inverse problem. These algorithms have been modified by a corresponding increase in equations (multiply) for electrical impedance tomography using the finite element method grid. The Gauss-Newton method was used as a reference to machine learning methods. The algorithms were trained using learning data obtained through computer simulation based on real models. The results of the experiments showed that in the considered cases the best quality of reconstructions was achieved by ANN. At the same time, ANN was the slowest in terms of both the training process and the speed of image generation. Other machine learning methods were comparable with the deterministic Gauss-Newton method and with each other.",2019,77,55,2,False,Computer Science,31030949,T. Rymarczyk,2017552.0,G. Kłosowski,143862941.0,E. Kozłowski,73499247.0,P. Tchorzewski,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4d16a47fb6708704b155855045c9e5d2ea380bb0,https://www.semanticscholar.org/paper/4d16a47fb6708704b155855045c9e5d2ea380bb0,Sentiment Analysis in Czech Social Media Using Supervised Machine Learning,"This article provides an in-depth research of machine learning methods for sentiment analysis of Czech social media. Whereas in English, Chinese, or Spanish this field has a long history and evaluation datasets for various domains are widely available, in case of Czech language there has not yet been any systematical research conducted. We tackle this issue and establish a common ground for further research by providing a large humanannotated Czech social media corpus. Furthermore, we evaluate state-of-the-art supervised machine learning methods for sentiment analysis. We explore different pre-processing techniques and employ various features and classifiers. Moreover, in addition to our newly created social media dataset, we also report results on other widely popular domains, such as movie and product reviews. We believe that this article will not only extend the current sentiment analysis research to another family of languages, but will also encourage competition which potentially leads to the production of high-end commercial solutions.",2013,41,82,2,False,Computer Science,2572366,Ivan Habernal,3398330.0,T. Ptácek,3292561.0,J. Steinberger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2186650898f1ec8abaa26f0e4a17b4a5a6fee2f7,https://www.semanticscholar.org/paper/2186650898f1ec8abaa26f0e4a17b4a5a6fee2f7,ProQ3D: improved model quality assessments using deep learning,"Summary: Protein quality assessment is a long‐standing problem in bioinformatics. For more than a decade we have developed state‐of‐art predictors by carefully selecting and optimising inputs to a machine learning method. The correlation has increased from 0.60 in ProQ to 0.81 in ProQ2 and 0.85 in ProQ3 mainly by adding a large set of carefully tuned descriptions of a protein. Here, we show that a substantial improvement can be obtained using exactly the same inputs as in ProQ2 or ProQ3 but replacing the support vector machine by a deep neural network. This improves the Pearson correlation to 0.90 (0.85 using ProQ2 input features). Availability and Implementation: ProQ3D is freely available both as a webserver and a stand‐alone program at http://proq3.bioinfo.se/ Contact: arne@bioinfo.se Supplementary information: Supplementary data are available at Bioinformatics online.",2016,29,132,12,True,Computer Science,3396593,Karolis Uziela,29763957.0,D. Hurtado,38705724.0,N. Shu,40107817.0,B. Wallner,2471717.0,A. Elofsson,,,Chemistry,,,,,,,,,,,,,,,,,,,,,,,,,Biology,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57e18ad4f97b34dead51336ea992844f1ce4fee2,https://www.semanticscholar.org/paper/57e18ad4f97b34dead51336ea992844f1ce4fee2,Analysis of Spectrum Occupancy Using Machine Learning Algorithms,"In this paper, we analyze the spectrum occupancy in cognitive radio networks (CRNs) using different machine learning techniques. Both supervised techniques [naive Bayesian classifier (NBC), decision trees (DT), support vector machine (SVM), linear regression (LR)] and unsupervised algorithms [hidden Markov model (HMM)] are studied to find the best technique with the highest classification accuracy (CA). A detailed comparison of the supervised and unsupervised algorithms in terms of the computational time and the CA is performed. The classified occupancy status is further utilized to evaluate the blocking probability of secondary user for future time slots, which can be used by system designers to define spectrum-allocation and spectrum-sharing policies. Numerical results show that SVM is the best algorithm among all the supervised and unsupervised classifiers. Based on this, we proposed a new SVM algorithm by combining it with a firefly algorithm (FFA), which is shown to outperform all the other algorithms.",2015,36,81,3,True,Computer Science,3134954,F. Azmat,1809404.0,Yunfei Chen,31900038.0,N. Stocks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4cd7d43de8ec59b50d44828ea6964599155bf93a,https://www.semanticscholar.org/paper/4cd7d43de8ec59b50d44828ea6964599155bf93a,Toward a Semiautomatic Machine Learning Retrieval of Biophysical Parameters,"Biophysical parameters such as leaf chlorophyll content (LCC) and leaf area index (LAI) are standard vegetation products that can be retrieved from Earth observation imagery. This paper introduces a new machine learning regression algorithms (MLRAs) toolbox into the scientific Automated Radiative Transfer Models Operator (ARTMO) software package. ARTMO facilitates retrieval of biophysical parameters from remote observations in a MATLAB graphical user interface (GUI) environment. The MLRA toolbox enables analyzing the predictive power of various MLRAs in a semiautomatic and systematic manner, and applying a selected MLRA to multispectral or hyperspectral imagery for mapping applications. It contains both linear and nonlinear state-of-the-art regression algorithms, in particular linear feature extraction via principal component regression (PCR), partial least squares regression (PLSR), decision trees (DTs), neural networks (NNs), kernel ridge regression (KRR), and Gaussian processes regression (GPR). The performance of multiple implemented regression strategies has been evaluated against the SPARC dataset (Barrax, Spain) and simulated Sentinel-2 (8 bands), CHRIS (62 bands) and HyMap (125 bands) observations. In general, nonlinear regression algorithms (NN, KRR, and GPR) outperformed linear techniques (PCR and PLSR) in terms of accuracy, bias, and robustness. Most robust results along gradients of training/validation partitioning and noise variance were obtained by KRR while GPR delivered most accurate estimations. We applied a GPR model to a hyperspectral HyMap flightline to map LCC and LAI. We exploited the associated uncertainty intervals to gain insight in the per-pixel performance of the model.",2014,59,93,4,False,Computer Science,33311787,J. Caicedo,2069785.0,J. Verrelst,1397420485.0,J. Muñoz-Marí,144394874.0,J. Moreno,1397959153.0,G. Camps-Valls,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f08102c12927a9d36cbe66994d64aca41ba7411,https://www.semanticscholar.org/paper/5f08102c12927a9d36cbe66994d64aca41ba7411,Bitcoin price prediction using machine learning,"In this paper, we attempt to predict the Bitcoin price accurately taking into consideration various parameters that affect the Bitcoin value. For the first phase of our investigation, we aim to understand and identify daily trends in the Bitcoin market while gaining insight into optimal features surrounding Bitcoin price. Our data set consists of various features relating to the Bitcoin price and payment network over the course of five years, recorded daily. For the second phase of our investigation, using the available information, we will predict the sign of the daily price change with highest possible accuracy.",2018,4,63,2,False,Computer Science,86932793,S. Velankar,40797102.0,Sakshi Valecha,40795443.0,Shreya Maji,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6830899ac1fad20cb2a22f6719558fe03542168a,https://www.semanticscholar.org/paper/6830899ac1fad20cb2a22f6719558fe03542168a,Analysis of Android malware detection performance using machine learning classifiers,"As mobile devices have supported various services and contents, much personal information such as private SMS messages, bank account information, etc. is scattered in mobile devices. Thus, attackers extend the attack range not only to the existing environment of PC and Internet, but also to the mobile device. Previous studies evaluated the malware detection performance of machine learning classifiers through collecting and analyzing event, system call, and log information generated in Android mobile devices. However, monitoring of unnecessary features without understanding Android architecture and malware characteristics generates resource consumption overhead of Android devices and low ratio of malware detection. In this paper, we propose new feature sets which solve the problem of previous studies in mobile malware detection and analyze the malware detection performance of machine learning classifiers.",2013,13,81,5,False,Computer Science,1986701,Hyo-Sik Ham,2628554.0,Mi-Jung Choi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5baa3e00d66bc42db7e3908f0b70875cff9d0193,https://www.semanticscholar.org/paper/5baa3e00d66bc42db7e3908f0b70875cff9d0193,What is being transferred in transfer learning?,"One desired capability for machines is the ability to transfer their knowledge of one domain to another where data is (usually) scarce. Despite ample adaptation of transfer learning in various deep learning applications, we yet do not understand what enables a successful transfer and which part of the network is responsible for that. In this paper, we provide new tools and analyses to address these fundamental questions. Through a series of analyses on transferring to block-shuffled images, we separate the effect of feature reuse from learning low-level statistics of data and show that some benefit of transfer learning comes from the latter. We present that when training from pre-trained weights, the model stays in the same basin in the loss landscape and different instances of such model are similar in feature space and close in parameter space.",2020,47,186,22,False,Computer Science,3007442,Behnam Neyshabur,2812848.0,Hanie Sedghi,151505981.0,Chiyuan Zhang,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94b0e8e97c19ad0977d26e3e355d3ae09ad49365,https://www.semanticscholar.org/paper/94b0e8e97c19ad0977d26e3e355d3ae09ad49365,Conditional Restricted Boltzmann Machines for Structured Output Prediction,"Conditional Restricted Boltzmann Machines (CRBMs) are rich probabilistic models that have recently been applied to a wide range of problems, including collaborative filtering, classification, and modeling motion capture data. While much progress has been made in training non-conditional RBMs, these algorithms are not applicable to conditional models and there has been almost no work on training and generating predictions from conditional RBMs for structured output problems. We first argue that standard Contrastive Divergence-based learning may not be suitable for training CRBMs. We then identify two distinct types of structured output prediction problems and propose an improved learning algorithm for each. The first problem type is one where the output space has arbitrary structure but the set of likely output configurations is relatively small, such as in multi-label classification. The second problem is one where the output space is arbitrarily structured but where the output space variability is much greater, such as in image denoising or pixel labeling. We show that the new learning algorithms can work much better than Contrastive Divergence on both types of problems.",2011,27,120,15,False,Computer Science,3255983,Volodymyr Mnih,1777528.0,H. Larochelle,1695689.0,Geoffrey E. Hinton,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a065f40bac876a41ffc66577efaf8c935a0944e9,https://www.semanticscholar.org/paper/a065f40bac876a41ffc66577efaf8c935a0944e9,Modeling electronic quantum transport with machine learning,"We present a machine learning approach to solve electronic quantum transport equations of one-dimensional nanostructures. The transmission coefficients of disordered systems were computed to provide training and test data sets to the machine. The system's representation encodes energetic as well as geometrical information to characterize similarities between disordered configurations, while the Euclidean norm is used as a measure of similarity. Errors for out-of-sample predictions systematically decrease with training set size, enabling the accurate and fast prediction of new transmission coefficients. The remarkable performance of our model to capture the complexity of interference phenomena lends further support to its viability in dealing with transport problems of undulatory nature.",2014,27,52,0,True,Physics,1398945311,A. Lopez-Bezanilla,11615881.0,O. A. V. Lilienfeld,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b44ef382fbe639a51ae66a08bbce5c4e485f74a5,https://www.semanticscholar.org/paper/b44ef382fbe639a51ae66a08bbce5c4e485f74a5,New machine learning method for image-based diagnosis of COVID-19,"COVID-19 is a worldwide epidemic, as announced by the World Health Organization (WHO) in March 2020. Machine learning (ML) methods can play vital roles in identifying COVID-19 patients by visually analyzing their chest x-ray images. In this paper, a new ML-method proposed to classify the chest x-ray images into two classes, COVID-19 patient or non-COVID-19 person. The features extracted from the chest x-ray images using new Fractional Multichannel Exponent Moments (FrMEMs). A parallel multi-core computational framework utilized to accelerate the computational process. Then, a modified Manta-Ray Foraging Optimization based on differential evolution used to select the most significant features. The proposed method evaluated using two COVID-19 x-ray datasets. The proposed method achieved accuracy rates of 96.09% and 98.09% for the first and second datasets, respectively.",2020,47,211,10,True,Computer Science,144211237,M. A. Elaziz,2409960.0,K. Hosny,2056674529.0,Ahmad Salah,145004101.0,M. M. Darwish,66845023.0,Songfeng Lu,2728640.0,A. Sahlol,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f2b18264de28827a061fe9e22c437d1f616fdb4a,https://www.semanticscholar.org/paper/f2b18264de28827a061fe9e22c437d1f616fdb4a,Learning question classifiers: the role of semantic information,"To respond correctly to a free form factual question given a large collection of text data, one needs to understand the question to a level that allows determining some of the constraints the question imposes on a possible answer. These constraints may include a semantic classification of the sought after answer and may even suggest using different strategies when looking for and verifying a candidate answer. This work presents a machine learning approach to question classification. Guided by a layered semantic hierarchy of answer types, we develop a hierarchical classifier that classifies questions into fine-grained classes. This work also performs a systematic study of the use of semantic information sources in natural language classification tasks. It is shown that, in the context of question classification, augmenting the input of the classifier with appropriate semantic category information results in significant improvements to classification accuracy. We show accurate results on a large collection of free-form questions used in TREC 10 and 11.",2005,27,288,39,False,Computer Science,2153901204,Xin Li,144590225.0,D. Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b096b715fae0c215a14b98a024dc8be216a121bd,https://www.semanticscholar.org/paper/b096b715fae0c215a14b98a024dc8be216a121bd,Neural Networks for Multi-Instance Learning,"Multi-instance learning originates from the investigation on drug activity prediction, where the task is to predict whether an unseen molecule could be used to make some drug. Such a problem is difficult because a molecule may have many alternative shapes with low energy, yet only one of those shapes may be responsible for the qualification of the molecule to make the drug. Because of its unique characteristics and extensive existence, multi-instance learning is regarded as a new machine learning framework parallel to supervised learning, unsupervised learning, and reinforcement learning. In this paper, an open problem of this area is addressed. That is, a popular neural network algorithm is adapted for multi-instance learning through employing a specific error function. Experiments show that the adapted algorithm achieves good result on the drug activity prediction data.",2002,30,125,13,False,Computer Science,145624000,Zhi-Hua Zhou,3039887.0,Min-Ling Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3d73e21af71bde8dc7984bd72f7077fb691b2523,https://www.semanticscholar.org/paper/3d73e21af71bde8dc7984bd72f7077fb691b2523,FATE: An Industrial Grade Platform for Collaborative Learning With Data Protection,"Collaborative and federated learning has become an emerging solution to many industrial applications where data values from different sites are exploit jointly with privacy protection. We introduce FATE, an industrial-grade project that supports enterprises and institutions to build machine learning models collaboratively at large-scale in a distributed manner. FATE supports a variety of secure computation protocols and machine learning algorithms, and features out-of-box usability with end-to-end building modules and visualization tools. Documentations are available at https://github.com/FederatedAI/FATE. Case studies and other information are available at https://www.fedai.org.",2021,19,26,0,False,Computer Science,1614034792,Yang Liu,2072650627.0,Tao Fan,11573257.0,Tianjian Chen,144217477.0,Qian Xu,152290618.0,Qiang Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
db615940f79830760d823adb4db9e5391f7777a3,https://www.semanticscholar.org/paper/db615940f79830760d823adb4db9e5391f7777a3,Sparse Coding on Symmetric Positive Definite Manifolds Using Bregman Divergences,"This paper introduces sparse coding and dictionary learning for symmetric positive definite (SPD) matrices, which are often used in machine learning, computer vision, and related areas. Unlike traditional sparse coding schemes that work in vector spaces, in this paper, we discuss how SPD matrices can be described by sparse combination of dictionary atoms, where the atoms are also SPD matrices. We propose to seek sparse coding by embedding the space of SPD matrices into the Hilbert spaces through two types of the Bregman matrix divergences. This not only leads to an efficient way of performing sparse coding but also an online and iterative scheme for dictionary learning. We apply the proposed methods to several computer vision tasks where images are represented by region covariance matrices. Our proposed algorithms outperform state-of-the-art methods on a wide range of classification tasks, including face recognition, action recognition, material classification, and texture categorization.",2014,71,75,9,True,Computer Science,1686714,M. Harandi,143750012.0,R. Hartley,144367279.0,B. Lovell,144228552.0,C. Sanderson,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e02bc29aa007d0f4dcfe98e89776c66a991c458d,https://www.semanticscholar.org/paper/e02bc29aa007d0f4dcfe98e89776c66a991c458d,Non-negative low rank and sparse graph for semi-supervised learning,"Constructing a good graph to represent data structures is critical for many important machine learning tasks such as clustering and classification. This paper proposes a novel non-negative low-rank and sparse (NNLRS) graph for semi-supervised learning. The weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph can capture both the global mixture of subspaces structure (by the low rankness) and the locally linear structure (by the sparseness) of the data, hence is both generative and discriminative. We demonstrate the effectiveness of NNLRS-graph in semi-supervised classification and discriminative analysis. Extensive experiments testify to the significant advantages of NNLRS-graph over graphs obtained through conventional means.",2012,26,301,31,True,Mathematics,1734743,Liansheng Zhuang,2345388.0,Haoyuan Gao,33383055.0,Zhouchen Lin,2146275501.0,Yi Ma,2155051858.0,Xin Zhang,1708598.0,Nenghai Yu,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
05e39bbaa5bf77919cccabc32fe6b2f03a342dbe,https://www.semanticscholar.org/paper/05e39bbaa5bf77919cccabc32fe6b2f03a342dbe,Dropout Inference in Bayesian Neural Networks with Alpha-divergences,"To obtain uncertainty estimates with real-world Bayesian deep learning models, practical inference approximations are needed. Dropout variational inference (VI) for example has been used for machine vision and medical applications, but VI can severely underestimates model uncertainty. Alpha-divergences are alternative divergences to VI's KL objective, which are able to avoid VI's uncertainty underestimation. But these are hard to use in practice: existing techniques can only use Gaussian approximating distributions, and require existing models to be changed radically, thus are of limited use for practitioners. We propose a reparametrisation of the alpha-divergence objectives, deriving a simple inference technique which, together with dropout, can be easily implemented with existing models by simply changing the loss of the model. We demonstrate improved uncertainty estimates and accuracy compared to VI in dropout networks. We study our model's epistemic uncertainty far away from the data using adversarial images, showing that these can be distinguished from non-adversarial images by examining our model's uncertainty.",2017,54,163,22,False,Computer Science,2672661,Yingzhen Li,2681954.0,Y. Gal,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
87a18efaeb18776dff93597124d67e216da3ac48,https://www.semanticscholar.org/paper/87a18efaeb18776dff93597124d67e216da3ac48,Hippocampal Shape Analysis of Alzheimer Disease Based on Machine Learning Methods,"BACKGROUND AND PURPOSE: Alzheimer disease (AD) is a neurodegenerative disease characterized by progressive dementia. The hippocampus is particularly vulnerable to damage at the very earliest stages of AD. This article seeks to evaluate critical AD-associated regional changes in the hippocampus using machine learning methods. MATERIALS AND METHODS: High-resolution MR images were acquired from 19 patients with AD and 20 age- and sex-matched healthy control subjects. Regional changes of bilateral hippocampi were characterized using computational anatomic mapping methods. A feature selection method for support vector machine and leave-1-out cross-validation was introduced to determine regional shape differences that minimized the error rate in the datasets. RESULTS: Patients with AD showed significant deformations in the CA1 region of bilateral hippocampi, as well as the subiculum of the left hippocampus. There were also some changes in the CA2–4 subregions of the left hippocampus among patients with AD. Moreover, the left hippocampal surface showed greater variations than the right compared with those in healthy control subjects. The accuracies of leave-1-out cross-validation and 3-fold cross-validation experiments for assessing the reliability of these subregions were more than 80% in bilateral hippocampi. CONCLUSION: Subtle and spatially complex deformation patterns of hippocampus between patients with AD and healthy control subjects can be detected by machine learning methods.",2007,51,125,3,True,Medicine,33125653,S. Li,1686093.0,F. Shi,49551728.0,F. Pu,1502862234.0,X. Li,40570474.0,T. Jiang,2114078962.0,S. Xie,,119917444.0,Y. Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d17c57f8bdfd1f66312ad144e974bbb32a2ed14c,https://www.semanticscholar.org/paper/d17c57f8bdfd1f66312ad144e974bbb32a2ed14c,"Democrats, republicans and starbucks afficionados: user classification in twitter","More and more technologies are taking advantage of the explosion of social media (Web search, content recommendation services, marketing, ad targeting, etc.). This paper focuses on the problem of automatically constructing user profiles, which can significantly benefit such technologies. We describe a general and robust machine learning framework for large-scale classification of social media users according to dimensions of interest. We report encouraging experimental results on 3 tasks with different characteristics: political affiliation detection, ethnicity identification and detecting affinity for a particular business.",2011,26,338,28,False,Computer Science,145375801,M. Pennacchiotti,41192561.0,A. Popescu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a92696ea6d6e88b727bc5f0ea2eefd78aa4ea6c5,https://www.semanticscholar.org/paper/a92696ea6d6e88b727bc5f0ea2eefd78aa4ea6c5,Online detection of freezing of gait with smartphones and machine learning techniques,"Freezing of gait (FoG) is a common gait deficit in advanced Parkinson's disease (PD). FoG events are associated with falls, interfere with daily life activities and impair quality of life. FoG is often resistant to pharmacologic treatment; therefore effective non-pharmacologic assistance is needed. We propose a wearable assistant, composed of a smartphone and wearable accelerometers, for online detection of FoG. The system is based on machine learning techniques for automatic detection of FoG episodes. When FoG is detected, the assistant provides rhythmic auditory cueing or vibrotactile feedback that stimulates the patient to resume walking. We tested our solution on more than 8h of recorded lab data from PD patients that experience FoG in daily life. We characterize the system performance on user-dependent and user-independent experiments, with respect to different machine learning algorithms, sensor placement and preprocessing window size. The final system was able to detect FoG events with an average sensitivity and specificity of more than 95%, and mean detection latency of 0.34s in user-dependent settings.",2012,37,193,27,True,Computer Science,1791423,Sinziana Mazilu,1778390.0,M. Hardegger,2535234.0,Zack Z. Zhu,1703539.0,D. Roggen,144119654.0,G. Tröster,1843554.0,M. Plotnik,,7766661.0,Jeffrey M. Hausdorff,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f366e7b30c507c9c3acdd19173fa9db7368f1831,https://www.semanticscholar.org/paper/f366e7b30c507c9c3acdd19173fa9db7368f1831,"Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence","From the Publisher: Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. John H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and isDirector of the University of Michigan/Santa Fe Institute Advanced Research Program.",1992,40,12019,482,False,Computer Science,144404817,J. Holland,,,,,,,,,,,Engineering,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3f6f0d06004dde20483c191455e351844de0769d,https://www.semanticscholar.org/paper/3f6f0d06004dde20483c191455e351844de0769d,Positive Semidefinite Metric Learning Using Boosting-like Algorithms,"The success of many machine learning and pattern recognition methods relies heavily upon the identification of an appropriate distance metric on the input data. It is often beneficial to learn such a metric from the input training data, instead of using a default one such as the Euclidean distance. In this work, we propose a boosting-based technique, termed BOOSTMETRIC, for learning a quadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance metric requires enforcing the constraint that the matrix parameter to the metric remains positive semidefinite. Semidefinite programming is often used to enforce this constraint, but does not scale well and is not easy to implement. BOOSTMETRIC is instead based on the observation that any positive semidefinite matrix can be decomposed into a linear combination of trace-one rank-one matrices. BOOSTMETRIC thus uses rank-one positive semidefinite matrices as weak learners within an efficient and scalable boosting-based learning process. The resulting methods are easy to implement, efficient, and can accommodate various types of constraints. We extend traditional boosting algorithms in that its weak learner is a positive semidefinite matrix with trace and rank being one rather than a classifier or regressor. Experiments on various data sets demonstrate that the proposed algorithms compare favorably to those state-of-the-art methods in terms of classification accuracy and running time.",2011,55,83,7,False,Mathematics,1780381,Chunhua Shen,1752839.0,Junae Kim,36547165.0,Lei Wang,5546141.0,A. V. Hengel,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d468396ab05a1ee98e92e3b8232d47708092af09,https://www.semanticscholar.org/paper/d468396ab05a1ee98e92e3b8232d47708092af09,Persistent Homology Machine Learning for Fingerprint Classification,"The fingerprint classification problem is to sort fingerprints into predetermined groups, such as arch, loop, and whorl. It was asserted in the literature that minutiae points, which are commonly used for fingerprint matching, are not useful for classification. We show that, to the contrary, near state-of-the-art classification accuracy rates can be achieved when applying topological data analysis (TDA) to 3-dimensional point clouds of oriented minutiae points. We also apply TDA to fingerprint ink-roll images, which yields a lower accuracy rate but still shows promise; moreover, combining the two approaches outperforms each one individually. These methods use supervised learning applied to persistent homology and allow us to explore feature selection on barcodes, an important topic at the interface between TDA and machine learning. We test our classification algorithms on the NIST fingerprint database SD-27.",2017,24,23,0,True,Computer Science,2640058,Noah Giansiracusa,2855899.0,Robert S. Giansiracusa,145016678.0,Chul Moon,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0da2c627f416d44caceeec27ded90d864342aaff,https://www.semanticscholar.org/paper/0da2c627f416d44caceeec27ded90d864342aaff,Adaptive neuro-fuzzy intrusion detection systems,"The intrusion detection system architecture commonly used in commercial and research systems have a number of problems that limit their configurability, scalability or efficiency. In this paper, two machine-learning paradigms, artificial neural networks and fuzzy inference system, are used to design an intrusion detection system. SNORT is used to perform real time traffic analysis and packet logging on IP network during the training phase of the system. Then a signature pattern database is constructed using protocol analysis and neuro-fuzzy learning method. Using 1998 DARPA Intrusion Detection Evaluation Data and TCP dump raw data, the experiments are deployed and discussed.",2004,23,172,6,True,Computer Science,50472765,Sampada Chavan,49173386.0,Khusbu Shah,97485809.0,Nehal K. Dave,2183326.0,S. Mukherjee,145731499.0,A. Abraham,50456492.0,S. Sanyal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433,https://www.semanticscholar.org/paper/f2f72cfb48d15d4d2bd1e91a92e7f3ac8635d433,Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing,"Open-text semantic parsers are designed to interpret any statement in natural language by inferring a corresponding meaning representation (MR – a formal representation of its sense). Unfortunately, large scale systems cannot be easily machine-learned due to a lack of directly supervised data. We propose a method that learns to assign MRs to a wide range of text (using a dictionary of more than 70,000 words mapped to more than 40,000 entities) thanks to a training scheme that combines learning from knowledge bases (e.g. WordNet) with learning from raw text. The model jointly learns representations of words, entities and MRs via a multi-task training process operating on these diverse sources of data. Hence, the system ends up providing methods for knowledge acquisition and wordsense disambiguation within the context of semantic parsing in a single elegant framework. Experiments on these various tasks indicate the promise of the approach.",2012,39,345,25,False,Computer Science,1713934,Antoine Bordes,3119801.0,Xavier Glorot,145183709.0,J. Weston,1751762.0,Yoshua Bengio,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8eba56788a15441e0c6b8b470698a5c8126adc45,https://www.semanticscholar.org/paper/8eba56788a15441e0c6b8b470698a5c8126adc45,"Study and Observation of the Variation of Accuracies of KNN, SVM, LMNN, ENN Algorithms on Eleven Different Datasets from UCI Machine Learning Repository","Machine learning qualifies computers to assimilate with data, without being solely programmed [1, 2]. Machine learning can be classified as supervised and unsupervised learning. In supervised learning, computers learn an objective that portrays an input to an output hinged on training input-output pairs [3]. Most efficient and widely used supervised learning algorithms are K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Large Margin Nearest Neighbor (LMNN), and Extended Nearest Neighbor (ENN). The main contribution of this paper is to implement these elegant learning algorithms on eleven different datasets from the UCI machine learning repository to observe the variation of accuracies for each of the algorithms on all datasets. Analyzing the accuracy of the algorithms will give us a brief idea about the relationship of the machine learning algorithms and the data dimensionality. All the algorithms are developed in Matlab. Upon such accuracy observation, the comparison can be built among KNN, SVM, LMNN, and ENN regarding their performances on each dataset.",2018,32,34,1,True,Computer Science,2109254441,Mohammad Mahmudur Rahman Khan,51449344.0,Rezoana Bente Arif,71752773.0,M. Siddique,80496351.0,Mahjabin Rahman Oishe,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81b6783ae6ce1882dc00b73146aaf8946b1b71be,https://www.semanticscholar.org/paper/81b6783ae6ce1882dc00b73146aaf8946b1b71be,Machine Learning at Microsoft with ML.NET,"Machine Learning is transitioning from an art and science into a technology available to every developer. In the near future, every application on every platform will incorporate trained models to encode data-based decisions that would be impossible for developers to author. This presents a significant engineering challenge, since currently data science and modeling are largely decoupled from standard software development processes. This separation makes incorporating machine learning capabilities inside applications unnecessarily costly and difficult, and furthermore discourage developers from embracing ML in first place. In this paper we present ML.NET, a framework developed at Microsoft over the last decade in response to the challenge of making it easy to ship machine learning models in large software applications. We present its architecture, and illuminate the application demands that shaped it. Specifically, we introduce DataView, the core data abstraction of ML.NET which allows it to capture full predictive pipelines efficiently and consistently across training and inference lifecycles. We close the paper with a surprisingly favorable performance study of ML.NET compared to more recent entrants, and a discussion of some lessons learned.",2019,28,50,3,True,Computer Science,2144094395,Zeeshan Ahmed,1961237.0,S. Amizadeh,47695762.0,M. Bilenko,46464440.0,Rogan Carr,40429042.0,Wei-Sheng Chin,2077137972.0,Yael Dekel,Mathematics,2098180941.0,Xavier Dupre,1389623540.0,Vadim Eksarevskiy,1389623565.0,Eric Erhardt,1389623551.0,Costin Eseanu,1389623553.0,Senja Filipi,2436568.0,Tom Finley,2054713176.0,Abhishek Goswami,2070458766.0,Monte L. Hoover,2065974288.0,Scott Inglis,2192580.0,Matteo Interlandi,67301176.0,S. Katzenberger,1389623559.0,Najeeb Kazmi,,,2135405691.0,Gleb Krivosheev,2105238610.0,Pete Luferenko,1389623537.0,Ivan Matantsev,3035003.0,Sergiy Matusevych,2072909915.0,S. Moradi,1389623503.0,Gani Nazirov,2233861.0,Justin Ormont,2271928.0,Gal Oshri,51152502.0,Artidoro Pagnoni,2065336399.0,Jignesh Parmar,2068306945.0,Prabhat Roy,2112398343.0,Sarthak Shah,1388651232.0,Mohammad Zeeshan Siddiqui,2965406.0,Markus Weimer,2886622.0,S. Zahirazami,2139103184.0,Yiwen Zhu
966ce7b2567280088ee1d5816cee9e06d12fa19d,https://www.semanticscholar.org/paper/966ce7b2567280088ee1d5816cee9e06d12fa19d,Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG,"Recent research suggests that electrophysiological changes develop minutes to hours before the actual clinical onset in focal epileptic seizures. Seizure prediction is a major field of neurological research, enabled by statistical analysis methods applied to features derived from intracranial Electroencephalographic (EEG) recordings of brain activity. However, no reliable seizure prediction method is ready for clinical applications. In this study, we use modern machine learning techniques to predict seizures from a number of features proposed in the literature. We concentrate on aggregated features that encode the relationship between pairs of EEG channels, such as cross-correlation, nonlinear interdependence, difference of Lyapunov exponents and wavelet analysis-based synchrony such as phase locking. We compare L1-regularized logistic regression, convolutional networks, and support vector machines. Results are reported on the standard Freiburg EEG dataset which contains data from 21 patients suffering from medically intractable focal epilepsy. For each patient, at least one method predicts 100% of the seizures on average 60 minutes before the onset, with no false alarm. Possible future applications include implantable devices capable of warning the patient of an upcoming seizure as well as implanted drug-delivery devices.",2008,30,162,4,False,Computer Science,144705062,Piotr Wojciech Mirowski,1688882.0,Yann LeCun,2505629.0,D. Madhavan,2305833.0,R. Kuzniecky,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84b7729299a2c4efecf88b5b0467ca29ba5e77b3,https://www.semanticscholar.org/paper/84b7729299a2c4efecf88b5b0467ca29ba5e77b3,Deep learning versus traditional machine learning methods for aggregated energy demand prediction,"In this paper the more advanced, in comparison with traditional machine learning approaches, deep learning methods are explored with the purpose of accurately predicting the aggregated energy consumption. Despite the fact that a wide range of machine learning methods have been applied to probabilistic energy prediction, the deep learning ones certainly represent the state-of-the-art artificial intelligence methods with remarkable success in a spectrum of practical applications. In particular, the use of Multi Layer Perceptrons, recently enhanced with deep learning capabilities, is proposed. Furthermore, its performance is compared with the most commonly used machine learning methods, such as Support Vector Machines, Gaussian Processes, Regression Trees, Ensemble Boosting and Linear Regression. The analysis of the day-ahead energy prediction demonstrates that different prediction methods present significantly different levels of accuracy in the case of a challenging dataset that comprises an interesting mix of consumers, wind and solar generation. The results show that Multi Layer Perceptrons outperform all the eight methods used as a benchmark in this study.",2017,35,51,2,False,Computer Science,1790542,N. Paterakis,146634864.0,Elena Mocanu,1970654.0,M. Gibescu,50257911.0,Bart Stappers,35360436.0,Walter van Alst,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94d33955e1d6c11402aa65105fcd2d9a46418870,https://www.semanticscholar.org/paper/94d33955e1d6c11402aa65105fcd2d9a46418870,"A Topological ""Reading"" Lesson: Classification of MNIST using TDA","We present a way to use Topological Data Analysis (TDA) for machine learning tasks on grayscale images. We apply persistent homology to generate a wide range of topological features using a point cloud obtained from an image, its natural grayscale filtration, and different filtrations defined on the binarized image. We show that this topological machine learning pipeline can be used as a highly relevant dimensionality reduction by applying it to the MNIST digits dataset. We conduct a feature selection and study their correlations while providing an intuitive interpretation of their importance, which is relevant in both machine learning and TDA. Finally, we show that we can classify digit images while reducing the size of the feature set by a factor 5 compared to the grayscale pixel value features and maintain similar accuracy.",2019,19,27,9,True,Computer Science,1379498044,A. Garin,102217200.0,Guillaume Tauzin,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2ce99492e164adc03641c62df765e635b0968bca,https://www.semanticscholar.org/paper/2ce99492e164adc03641c62df765e635b0968bca,Personalized Explanation for Machine Learning: a Conceptualization,"Explanation in machine learning and related fields such as artificial intelligence aims at making machine learning models and their decisions understandable to humans. Existing work suggests that personalizing explanations might help to improve understandability. In this work, we derive a conceptualization of personalized explanation by defining and structuring the problem based on prior work on machine learning explanation, personalization (in machine learning) and concepts and techniques from other domains such as privacy and knowledge elicitation. We perform a categorization of explainee data used in the process of personalization as well as describing means to collect this data. We also identify three key explanation properties that are amendable to personalization: complexity, decision information and presentation. We also enhance existing work on explanation by introducing additional desiderata and measures to quantify the quality of personalized explanations.",2019,75,42,8,False,Computer Science,66695718,J. Schneider,9557173.0,J. Handali,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52289cccda6b9109f4a3d19ffc3f111114ef820b,https://www.semanticscholar.org/paper/52289cccda6b9109f4a3d19ffc3f111114ef820b,Application of neural networks and other machine learning algorithms to DNA sequence analysis,"In this article we report initial, quantitative results on application of simple neutral networks, and simple machine learning methods, to two problems in DNA sequence analysis. The two problems we consider are: (1) determination of whether procaryotic and eucaryotic DNA sequences segments are translated to protein. An accuracy of 99.4% is reported for procaryotic DNA (E. coli) and 98.4% for eucaryotic DNA (H. Sapiens genes known to be expressed in liver); (2) determination of whether eucaryotic DNA sequence segments containing the dinucleotides ''AG'' or ''GT'' are transcribed to RNA splice junctions. Accuracy of 91.2% was achieved on intron/exon splice junctions (acceptor sites) and 92.8% on exon/intron splice junctions (donor sites). The solution of these two problems, by use of information processing algorithms operating on unannotated base sequences and without recourse to biological laboratory work, is relevant to the Human Genome Project. A variety of neural network, machine learning, and information theoretic algorithms are used. The accuracies obtained exceed those of previous investigations for which quantitative results are available in the literature. They result from an ongoing program of research that applies machine learning algorithms to the problem of determining biological function of DNA sequences. Some predictions of possible new genesmore » using these methods are listed -- although a complete survey of the H. sapiens and E. coli sections of GenBank will be given elsewhere. 36 refs., 6 figs., 6 tabs.« less",1988,0,92,4,True,Biology,2020074,A. Lapedes,50672341.0,C. Barnes,1763036.0,C. Burks,2542113.0,R. Farber,2182166.0,K. Sirotkin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
69dbd0f1e4d7d804dea0be176fd3adc2c7cd8bb3,https://www.semanticscholar.org/paper/69dbd0f1e4d7d804dea0be176fd3adc2c7cd8bb3,"Big Data Analytics, Machine Learning, and Artificial Intelligence in Next-Generation Wireless Networks","The next-generation wireless networks are evolving into very complex systems because of the very diversified service requirements, heterogeneity in applications, devices, and networks. The network operators need to make the best use of the available resources, for example, power, spectrum, as well as infrastructures. Traditional networking approaches, i.e., reactive, centrally-managed, one-size-fits-all approaches, and conventional data analysis tools that have limited capability (space and time) are not competent anymore and cannot satisfy and serve that future complex networks regarding operation and optimization cost effectively. A novel paradigm of proactive, self-aware, self-adaptive, and predictive networking is much needed. The network operators have access to large amounts of data, especially from the network and the subscribers. Systematic exploitation of the big data dramatically helps in making the system smart, intelligent, and facilitates efficient as well as cost-effective operation and optimization. We envision data-driven next-generation wireless networks, where the network operators employ advanced data analytics, machine learning (ML), and artificial intelligence. We discuss the data sources and strong drivers for the adoption of the data analytics, and the role of ML, artificial intelligence in making the system intelligent regarding being self-aware, self-adaptive, proactive and prescriptive. A set of network design and optimization schemes are presented concerning data analytics. This paper concludes with a discussion of challenges and the benefits of adopting big data analytics, ML, and artificial intelligence in the next-generation communication systems.",2017,31,227,8,False,Computer Science,2109751,M. G. Kibria,145025159.0,K. Nguyen,1707891.0,G. Villardi,3278294.0,Ou Zhao,1889421.0,K. Ishizu,32987476.0,F. Kojima,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9538759763d4039036f621baf82567d43b00518c,https://www.semanticscholar.org/paper/9538759763d4039036f621baf82567d43b00518c,Distributed Box-Constrained Quadratic Optimization for Dual Linear SVM,"Training machine learning models sometimes needs to be done on large amounts of data that exceed the capacity of a single machine, motivating recent works on developing algorithms that train in a distributed fashion. This paper proposes an efficient box-constrained quadratic optimization algorithm for distributedly training linear support vector machines (SVMs) with large data. Our key technical contribution is an analytical solution to the problem of computing the optimal step size at each iteration, using an efficient method that requires only O(1) communication cost to ensure fast convergence. With this optimal step size, our approach is superior to other methods by possessing global linear convergence, or, equivalently, O(log(1/e)) iteration complexity for an e-accurate solution, for distributedly solving the non-strongly-convex linear SVM dual problem. Experiments also show that our method is significantly faster than state-of-the-art distributed linear SVM algorithms including DSVM-AVE, DisDCA and TRON.",2015,37,50,4,False,Computer Science,37376821,Ching-pei Lee,144590225.0,D. Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b1fa66caf75d5c77449930beba864378f4c959ce,https://www.semanticscholar.org/paper/b1fa66caf75d5c77449930beba864378f4c959ce,Rafiki: Machine Learning as an Analytics Service System,"Big data analytics is gaining massive momentum in the last few years. Applying machine learning models to big data has become an implicit requirement or an expectation for most analysis tasks, especially on high-stakes applications.Typical applications include sentiment analysis against reviews for analyzing on-line products, image classification in food logging applications for monitoring user's daily intake and stock movement prediction. Extending traditional database systems to support the above analysis is intriguing but challenging. First, it is almost impossible to implement all machine learning models in the database engines. Second, expertise knowledge is required to optimize the training and inference procedures in terms of efficiency and effectiveness, which imposes heavy burden on the system users. In this paper, we develop and present a system, called Rafiki, to provide the training and inference service of machine learning models, and facilitate complex analytics on top of cloud platforms. Rafiki provides distributed hyper-parameter tuning for the training service, and online ensemble modeling for the inference service which trades off between latency and accuracy. Experimental results confirm the efficiency, effectiveness, scalability and usability of Rafiki.",2018,43,74,6,False,Computer Science,47825100,Wei Wang,2151484843.0,Sheng Wang,2504016.0,Jinyang Gao,1793178.0,Meihui Zhang,46965289.0,Gang Chen,3082766.0,Teck Khim Ng,,1693070.0,B. Ooi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4d9a5db16bc818de736e9c64f53705c3530e7369,https://www.semanticscholar.org/paper/4d9a5db16bc818de736e9c64f53705c3530e7369,Computational Analysis of Behavior.,"In this review, we discuss the emerging field of computational behavioral analysis-the use of modern methods from computer science and engineering to quantitatively measure animal behavior. We discuss aspects of experiment design important to both obtaining biologically relevant behavioral data and enabling the use of machine vision and learning techniques for automation. These two goals are often in conflict. Restraining or restricting the environment of the animal can simplify automatic behavior quantification, but it can also degrade the quality or alter important aspects of behavior. To enable biologists to design experiments to obtain better behavioral measurements, and computer scientists to pinpoint fruitful directions for algorithm improvement, we review known effects of artificial manipulation of the animal on behavior. We also review machine vision and learning techniques for tracking, feature extraction, automated behavior classification, and automated behavior discovery, the assumptions they make, and the types of data they work best with.",2016,150,148,10,False,Computer Science,144649110,S. Egnor,2424812.0,K. Branson,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
758b1d823ac975720e6e81e375cd4432009e5bca,https://www.semanticscholar.org/paper/758b1d823ac975720e6e81e375cd4432009e5bca,Convex Neural Networks,"Convexity has recently received a lot of attention in the machine learning community, and the lack of convexity has been seen as a major disadvantage of many learning algorithms, such as multi-layer artificial neural networks. We show that training multi-layer neural networks in which the number of hidden units is learned can be viewed as a convex optimization problem. This problem involves an infinite number of variables, but can be solved by incrementally inserting a hidden unit at a time, each time finding a linear classifier that minimizes a weighted sum of errors.",2005,18,171,6,False,Computer Science,1751762,Yoshua Bengio,7245737.0,Nicolas Le Roux,145467703.0,Pascal Vincent,2460212.0,Olivier Delalleau,144683424.0,P. Marcotte,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2946bf642907677363a04c60762c74d815574885,https://www.semanticscholar.org/paper/2946bf642907677363a04c60762c74d815574885,Stochastic Optimization of Sorting Networks via Continuous Relaxations,"Sorting input objects is an important step in many machine learning pipelines. However, the sorting operator is non-differentiable with respect to its inputs, which prohibits end-to-end gradient-based optimization. In this work, we propose NeuralSort, a general-purpose continuous relaxation of the output of the sorting operator from permutation matrices to the set of unimodal row-stochastic matrices, where every row sums to one and has a distinct arg max. This relaxation permits straight-through optimization of any computational graph involve a sorting operation. Further, we use this relaxation to enable gradient-based stochastic optimization over the combinatorially large space of permutations by deriving a reparameterized gradient estimator for the Plackett-Luce family of distributions over permutations. We demonstrate the usefulness of our framework on three tasks that require learning semantic orderings of high-dimensional objects, including a fully differentiable, parameterized extension of the k-nearest neighbors algorithm.",2019,38,95,24,False,Computer Science,1954250,Aditya Grover,2113762219.0,Eric Wang,40576688.0,Aaron Zweig,2490652.0,S. Ermon,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
949598d27a95ae0723e3a1907c69be9bf12fc2ce,https://www.semanticscholar.org/paper/949598d27a95ae0723e3a1907c69be9bf12fc2ce,6G White Paper on Machine Learning in Wireless Communication Networks,"The focus of this white paper is on machine learning (ML) in wireless communications. 6G wireless communication networks will be the backbone of the digital transformation of societies by providing ubiquitous, reliable, and near-instant wireless connectivity for humans and machines. Recent advances in ML research has led enable a wide range of novel technologies such as self-driving vehicles and voice assistants. Such innovation is possible as a result of the availability of advanced ML models, large datasets, and high computational power. On the other hand, the ever-increasing demand for connectivity will require a lot of innovation in 6G wireless networks, and ML tools will play a major role in solving problems in the wireless domain. In this paper, we provide an overview of the vision of how ML will impact the wireless communication systems. We first give an overview of the ML methods that have the highest potential to be used in wireless networks. Then, we discuss the problems that can be solved by using ML in various layers of the network such as the physical layer, medium access layer, and application layer. Zero-touch optimization of wireless networks using ML is another interesting aspect that is discussed in this paper. Finally, at the end of each section, important research questions that the section aims to answer are presented.",2020,49,85,2,False,Computer Science,2555406,Samad Ali,145412074.0,W. Saad,144310950.0,Nandana Rajatheva,1791254.0,Kapseok Chang,46577771.0,Daniel Steinbach,3434086.0,Benjamin Sliwa,Engineering,1744664.0,C. Wietfeld,48295463.0,Kai Mei,1986317.0,Hamid Shiri,48546175.0,H. Zepernick,1885035.0,T. Chu,2074278854.0,Ijaz Ahmad,1901264.0,J. Huusko,2481788.0,Jaakko Suutala,1661213398.0,Shubhangi Bhadauria,3196184.0,V. Bhatia,39074694.0,R. Mitra,3228686.0,Saidhiraj Amuru,Mathematics,,51387503.0,R. Abbas,9150396.0,Baohua Shao,28842841.0,M. Capobianco,49568499.0,Guanghui Yu,2002057.0,Maëlick Claes,1765944.0,Teemu Karvonen,2888344.0,Mingzhe Chen,1757365.0,Maksym A. Girnyk,46727017.0,Hassan Malik,,,,,,,,,,,,,,
