paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,fieldsOfStudy/1,fieldsOfStudy/2,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,fieldsOfStudy/3,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name
b1448f55029e007b1ba04bb3b64d7d571ed5bf58,https://www.semanticscholar.org/paper/b1448f55029e007b1ba04bb3b64d7d571ed5bf58,Bias-Variance Analysis of Support Vector Machines for the Development of SVM-Based Ensemble Methods,"Bias-variance analysis provides a tool to study learning algorithms and can be used to properly design ensemble methods well tuned to the properties of a specific base learner. Indeed the effectiveness of ensemble methods critically depends on accuracy, diversity and learning characteristics of base learners. We present an extended experimental analysis of bias-variance decomposition of the error in Support Vector Machines (SVMs), considering Gaussian, polynomial and dot product kernels. A characterization of the error decomposition is provided, by means of the analysis of the relationships between bias, variance, kernel type and its parameters, offering insights into the way SVMs learn. The results show that the expected trade-off between bias and variance is sometimes observed, but more complex relationships can be detected, especially in Gaussian and polynomial kernels. We show that the bias-variance decomposition offers a rationale to develop ensemble methods using SVMs as base learners, and we outline two directions for developing SVM ensembles, exploiting the SVM bias characteristics and the bias-variance dependence on the kernel param",2004,51,254,20,False,Computer Science,37659088,G. Valentini,144299726.0,Thomas G. Dietterich,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b0ebf91b31c0d491af6f269d1e3c9a9a9b6d4cd8,https://www.semanticscholar.org/paper/b0ebf91b31c0d491af6f269d1e3c9a9a9b6d4cd8,Deep Convolutional Neural Networks for Raman Spectrum Recognition: A Unified Solution,"Machine learning methods have found many applications in Raman spectroscopy, especially for the identification of chemical species. However, almost all of these methods require non-trivial preprocessing such as baseline correction and/or PCA as an essential step. Here we describe our unified solution for the identification of chemical species in which a convolutional neural network is trained to automatically identify substances according to their Raman spectrum without the need for preprocessing. We evaluated our approach using the RRUFF spectral database, comprising mineral sample data. Superior classification performance is demonstrated compared with other frequently used machine learning algorithms including the popular support vector machine method.",2017,40,191,13,True,Computer Science,2144149279,Jinchao Liu,1700737.0,Margarita Osadchy,Mathematics,Medicine,144915866.0,L. Ashton,145373668.0,Michael Foster,2490634.0,C. Solomon,3354810.0,S. Gibson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e9fd1a7ae0322d417ab2d32017e373dd50efc063,https://www.semanticscholar.org/paper/e9fd1a7ae0322d417ab2d32017e373dd50efc063,A comparison of two learning algorithms for text categorization,"This paper examines the use of inductive learning to categorize natural language documents into predeened content categories. Categorization of text is of increasing importance in information retrieval and natural language processing systems. Previous research on automated text categorization has mixed machine learning and knowledge engineering methods, making it diicult to draw conclusions about the performance of particular methods. In this paper we present empirical results on the performance of a Bayesian classiier and a decision tree learning algorithm on two text categorization data sets. We nd that both algorithms achieve reasonable performance and allow controlled tradeoos between false positives and false negatives. The stepwise feature selection in the decision tree algorithm is particularly eeective in dealing with the large feature sets common in text categorization. However, even this algorithm is aided by an initial preeltering of features, connrming the results found by Almuallim and Dietterich on artiicial data sets. We also demonstrate the impact of the time-varying nature of category deenitions.",1994,25,751,42,False,Computer Science,35153517,D. Lewis,2697855.0,M. Ringuette,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1b4c906704cd125adf5c9a974e16c56e49925bf3,https://www.semanticscholar.org/paper/1b4c906704cd125adf5c9a974e16c56e49925bf3,Variational Relevance Vector Machines,"The Support Vector Machine (SVM) of Vapnik (1998) has become widely established as one of the leading approaches to pattern recognition and machine learning. It expresses predictions in terms of a linear combination of kernel functions centred on a subset of the training data, known as support vectors. Despite its widespread success, the SVM suffers from some important limitations, one of the most significant being that it makes point predictions rather than generating predictive distributions. Recently Tipping (1999) has formulated the Relevance Vector Machine (RVM), a probabilistic model whose functional form is equivalent to the SVM. It achieves comparable recognition accuracy to the SVM, yet provides a full predictive distribution, and also requires substantially fewer kernel functions. The original treatment of the RVM relied on the use of type II maximum likelihood (the `evidence framework') to provide point estimates of the hyperparameters which govern model sparsity. In this paper we show how the RVM can be formulated and solved within a completely Bayesian paradigm through the use of variational inference, thereby giving a posterior distribution over both parameters and hyperparameters. We demonstrate the practicality and performance of the variational RVM using both synthetic and real world examples.",2000,16,394,53,False,Computer Science,1792884,Charles M. Bishop,2831141.0,Michael E. Tipping,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6df333b6e4dc95a19fb5dcfa49dbd3ac11db967b,https://www.semanticscholar.org/paper/6df333b6e4dc95a19fb5dcfa49dbd3ac11db967b,Empirical Methods in Information Extraction,"This article surveys the use of empirical, machine-learning methods for a particular natural language-understanding task-information extraction. The author presents a generic architecture for information-extraction systems and then surveys the learning algorithms that have been developed to address the problems of accuracy, portability, and knowledge acquisition for each component of the architecture.",1997,47,295,6,False,Computer Science,1748501,Claire Cardie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29cedf9f9edd5179aa2e78654a7b81c9da45f0d0,https://www.semanticscholar.org/paper/29cedf9f9edd5179aa2e78654a7b81c9da45f0d0,Learning and optimization using the clonal selection principle,"The clonal selection principle is used to explain the basic features of an adaptive immune response to an antigenic stimulus. It establishes the idea that only those cells that recognize the antigens (Ag's) are selected to proliferate. The selected cells are subject to an affinity maturation process, which improves their affinity to the selective Ag's. This paper proposes a computational implementation of the clonal selection principle that explicitly takes into account the affinity maturation of the immune response. The general algorithm, named CLONALG, is derived primarily to perform machine learning and pattern recognition tasks, and then it is adapted to solve optimization problems, emphasizing multimodal and combinatorial optimization. Two versions of the algorithm are derived, their computational cost per iteration is presented, and a sensitivity analysis in relation to the user-defined parameters is given. CLONALG is also contrasted with evolutionary algorithms. Several benchmark problems are considered to evaluate the performance of CLONALG and it is also compared to a niching method for multimodal function optimization.",2002,61,2279,208,False,Computer Science,145390561,L. Castro,7359553.0,F. V. Zuben,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
256db9dba1978f004a67c86ffc321563b1aee79a,https://www.semanticscholar.org/paper/256db9dba1978f004a67c86ffc321563b1aee79a,Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges,"Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the “Rashomon set” of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.1",2021,346,145,8,False,Computer Science,48395540,C. Rudin,,Chaofan Chen,Mathematics,,2143786389.0,Zhi Chen,2146285954.0,Haiyang Huang,151489878.0,Lesia Semenova,1750932565.0,Chudi Zhong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70,https://www.semanticscholar.org/paper/30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70,Exploiting Unintended Feature Leakage in Collaborative Learning,"Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates. We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points -- for example, specific locations -- in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier. We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses.",2018,70,724,74,True,Computer Science,145557680,Luca Melis,3469125.0,Congzheng Song,,,1728207.0,Emiliano De Cristofaro,1723945.0,Vitaly Shmatikov,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c940a2144b1e5cc89bbeb9003b5f3541e50fc9e1,https://www.semanticscholar.org/paper/c940a2144b1e5cc89bbeb9003b5f3541e50fc9e1,"eXpose: A Character-Level Convolutional Neural Network with Embeddings For Detecting Malicious URLs, File Paths and Registry Keys","For years security machine learning research has promised to obviate the need for signature based detection by automatically learning to detect indicators of attack. Unfortunately, this vision hasn't come to fruition: in fact, developing and maintaining today's security machine learning systems can require engineering resources that are comparable to that of signature-based detection systems, due in part to the need to develop and continuously tune the ""features"" these machine learning systems look at as attacks evolve. Deep learning, a subfield of machine learning, promises to change this by operating on raw input signals and automating the process of feature design and extraction. In this paper we propose the eXpose neural network, which uses a deep learning approach we have developed to take generic, raw short character strings as input (a common case for security inputs, which include artifacts like potentially malicious URLs, file paths, named pipes, named mutexes, and registry keys), and learns to simultaneously extract features and classify using character-level embeddings and convolutional neural network. In addition to completely automating the feature design and extraction process, eXpose outperforms manual feature extraction based baselines on all of the intrusion detection problems we tested it on, yielding a 5%-10% detection rate gain at 0.1% false positive rate compared to these baselines.",2017,35,159,25,False,Computer Science,39617543,Joshua Saxe,2040708537.0,Konstantin Berlin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7e152e587fbc73b5bd23048c71c1b36c569416c5,https://www.semanticscholar.org/paper/7e152e587fbc73b5bd23048c71c1b36c569416c5,EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models,"This paper describes EMBER: a labeled benchmark dataset for training machine learning models to statically detect malicious Windows portable executable files. The dataset includes features extracted from 1.1M binary files: 900K training samples (300K malicious, 300K benign, 300K unlabeled) and 200K test samples (100K malicious, 100K benign). To accompany the dataset, we also release open source code for extracting features from additional binaries so that additional sample features can be appended to the dataset. This dataset fills a void in the information security machine learning community: a benign/malicious dataset that is large, open and general enough to cover several interesting use cases. We enumerate several use cases that we considered when structuring the dataset. Additionally, we demonstrate one use case wherein we compare a baseline gradient boosted decision tree model trained using LightGBM with default settings to MalConv, a recently published end-to-end (featureless) deep learning model for malware detection. Results show that even without hyper-parameter optimization, the baseline EMBER model outperforms MalConv. The authors hope that the dataset, code and baseline model provided by EMBER will help invigorate machine learning research for malware detection, in much the same way that benchmark datasets have advanced computer vision research.",2018,31,222,61,False,Computer Science,2639880,H. Anderson,153379407.0,P. Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bfbdf36d50066c39dedf688150d63ba4b84d7e52,https://www.semanticscholar.org/paper/bfbdf36d50066c39dedf688150d63ba4b84d7e52,DroidDetector: Android Malware Characterization and Detection Using Deep Learning,"Smartphones and mobile tablets are rapidly becoming indispensable in daily life. Android has been the most popular mobile operating system since 2012. However, owing to the open nature of Android, countless malwares are hidden in a large number of benign apps in Android markets that seriously threaten Android security. Deep learning is a new area of machine learning research that has gained increasing attention in artificial intelligence. In this study, we propose to associate the features from the static analysis with features from dynamic analysis of Android apps and characterize malware using deep learning techniques. We implement an online deep-learning-based Android malware detection engine (DroidDetector) that can automatically detect whether an app is a malware or not. With thousands of Android apps, we thoroughly test DroidDetector and perform an indepth analysis on the features that deep learning essentially exploits to characterize malware. The results show that deep learning is suitable for characterizing Android malware and especially effective with the availability of more training data. DroidDetector can achieve 96.76% detection accuracy, which outperforms traditional machine learning techniques. An evaluation of ten popular anti-virus softwares demonstrates the urgency of advancing our capabilities in Android malware detection.",2016,34,316,15,True,Engineering,2970223,Zhenlong Yuan,2115728499.0,Yongqiang Lu,,,2564865.0,Y. Xue,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b8e49216e5b4a017342b0be5f6fbbd79e690a1c7,https://www.semanticscholar.org/paper/b8e49216e5b4a017342b0be5f6fbbd79e690a1c7,Optimal auctions through deep learning,"Designing an incentive compatible auction that maximizes expected revenue is an intricate task. The single-item case was resolved in a seminal piece of work by Myerson in 1981. Even after 30--40 years of intense research, the problem remains unsolved for settings with two or more items. We overview recent research results that show how tools from deep learning are shaping up to become a powerful tool for the automated design of near-optimal auctions auctions. In this approach, an auction is modeled as a multilayer neural network, with optimal auction design framed as a constrained learning problem that can be addressed with standard machine learning pipelines. Through this approach, it is possible to recover to a high degree of accuracy essentially all known analytically derived solutions for multi-item settings and obtain novel mechanisms for settings in which the optimal mechanism is unknown.",2017,111,147,28,True,Computer Science,3086323,Paul Dütting,2113906856.0,Zhe Feng,,,1727387.0,H. Narasimhan,30907562.0,D. Parkes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ec4f1eb6d2f38879792419e90ab3821460bc90f7,https://www.semanticscholar.org/paper/ec4f1eb6d2f38879792419e90ab3821460bc90f7,Empirical assessment of machine learning based software defect prediction techniques,"The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems perform as specified and not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models; such as stepwise multi-linear regression models and multivariate models, and machine learning approaches, such as artificial neural networks, instance-based reasoning, Bayesian-belief networks, decision trees, and rule inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper; we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of IR and instance-based learning along with the consistency-based subset evaluation technique provides a relatively better consistency in accuracy prediction compared to other models. The results also show that ""size"" and ""complexity"" metrics are not sufficient for accurately predicting real-time software defects.",2005,25,263,12,False,Computer Science,2313270,Venkata U. B. Challagulla,1788188.0,F. Bastani,,,9082943.0,I. Yen,1762814.0,R. Paul,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7184ed59dde95f27f45c0ec64ccdf01878baa7e2,https://www.semanticscholar.org/paper/7184ed59dde95f27f45c0ec64ccdf01878baa7e2,Galaxy Zoo: reproducing galaxy morphologies via machine learning★,"We present morphological classifications obtained using machine learning for objects in the Sloan Digital Sky Survey DR6 that have been classified by Galaxy Zoo into three classes, namely early types, spirals and point sources/artefacts. An artificial neural network is trained on a subset of objects classified by the human eye, and we test whether the machine-learning algorithm can reproduce the human classifications for the rest of the sample. We find that the success of the neural network in matching the human classifications depends crucially on the set of input parameters chosen for the machine-learning algorithm. The colours and parameters associated with profile fitting are reasonable in separating the objects into three classes. However, these results are considerably improved when adding adaptive shape parameters as well as concentration and texture. The adaptive moments, concentration and texture parameters alone cannot distinguish between early type galaxies and the point sources/artefacts. Using a set of 12 parameters, the neural network is able to reproduce the human classifications to better than 90 per cent for all three morphological classes. We find that using a training set that is incomplete in magnitude does not degrade our results given our particular choice of the input parameters to the network. We conclude that it is promising to use machine-learning algorithms to perform morphological classification for the next generation of wide-field imaging surveys and that the Galaxy Zoo catalogue provides an invaluable training set for such purposes.",2009,34,161,15,True,Physics,32608670,M. Banerji,103135769.0,O. Lahav,,,34769917.0,C. Lintott,4373369.0,F. Abdalla,6552704.0,K. Schawinski,3297934.0,S. Bamford,34647376.0,D. Andreescu,144442878.0,P. Murray,2873960.0,M. Raddick,102304245.0,A. Slosar,7934073.0,A. Szalay,2111204168.0,D. Thomas,144979911.0,J. vandenBerg,,,,,,,,,,,,,,,,,,,,,
21c76cc8ebfb9c112c2594ce490b47e458b50e31,https://www.semanticscholar.org/paper/21c76cc8ebfb9c112c2594ce490b47e458b50e31,American Sign Language Recognition Using Leap Motion Sensor,"In this paper, we present an American Sign Language recognition system using a compact and affordable 3D motion sensor. The palm-sized Leap Motion sensor provides a much more portable and economical solution than Cyblerglove or Microsoft kinect used in existing studies. We apply k-nearest neighbor and support vector machine to classify the 26 letters of the English alphabet in American Sign Language using the derived features from the sensory data. The experiment result shows that the highest average classification rate of 72.78% and 79.83% was achieved by k-nearest neighbor and support vector machine respectively. We also provide detailed discussions on the parameter setting in machine learning methods and accuracy of specific alphabet letters in this paper.",2014,5,170,20,False,Computer Science,2061766,C. Chuan,15529331.0,Eric Regina,,,3215225.0,Caroline Guardino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
01b24de15cf337c55b9866c4b534596ca3d93abe,https://www.semanticscholar.org/paper/01b24de15cf337c55b9866c4b534596ca3d93abe,Geometric diffusions as a tool for harmonic analysis and structure definition of data: diffusion maps.,"We provide a framework for structural multiscale geometric organization of graphs and subsets of R(n). We use diffusion semigroups to generate multiscale geometries in order to organize and represent complex structures. We show that appropriately selected eigenfunctions or scaling functions of Markov matrices, which describe local transitions, lead to macroscopic descriptions at different scales. The process of iterating or diffusing the Markov matrix is seen as a generalization of some aspects of the Newtonian paradigm, in which local infinitesimal transitions of a system lead to global macroscopic descriptions by integration. We provide a unified view of ideas from data analysis, machine learning, and numerical analysis.",2005,25,1433,66,True,Computer Science,1780112,R. Coifman,37805393.0,S. Lafon,Medicine,,2107734495.0,A. B. Lee,34207023.0,M. Maggioni,1786884.0,B. Nadler,49818480.0,F. Warner,1698824.0,S. Zucker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
761d8b21b078c7b9bb876583fee38ec369be2efe,https://www.semanticscholar.org/paper/761d8b21b078c7b9bb876583fee38ec369be2efe,Rule-based Machine Learning Methods for Functional Prediction,"We describe a machine learning method for predicting the value of a real-valued function, given the values of multiple input variables. The method induces solutions from samples in the form of ordered disjunctive normal form (DNF) decision rules. A central objective of the method and representation is the induction of compact, easily interpretable solutions. This rule-based decision model can be extended to search efficiently for similar cases prior to approximating function values. Experimental results on real-world data demonstrate that the new techniques are competitive with existing machine learning and statistical methods and can sometimes yield superior regression performance.",1995,31,179,12,True,Computer Science,145700185,S. Weiss,1726727.0,N. Indurkhya,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f7f2d6450d50ee11d3c5827ca1997daafef0a8fb,https://www.semanticscholar.org/paper/f7f2d6450d50ee11d3c5827ca1997daafef0a8fb,Applications of Machine Learning in Real-Life Digital Health Interventions: Review of the Literature,"Background Machine learning has attracted considerable research interest toward developing smart digital health interventions. These interventions have the potential to revolutionize health care and lead to substantial outcomes for patients and medical professionals. Objective Our objective was to review the literature on applications of machine learning in real-life digital health interventions, aiming to improve the understanding of researchers, clinicians, engineers, and policy makers in developing robust and impactful data-driven interventions in the health care domain. Methods We searched the PubMed and Scopus bibliographic databases with terms related to machine learning, to identify real-life studies of digital health interventions incorporating machine learning algorithms. We grouped those interventions according to their target (ie, target condition), study design, number of enrolled participants, follow-up duration, primary outcome and whether this had been statistically significant, machine learning algorithms used in the intervention, and outcome of the algorithms (eg, prediction). Results Our literature search identified 8 interventions incorporating machine learning in a real-life research setting, of which 3 (37%) were evaluated in a randomized controlled trial and 5 (63%) in a pilot or experimental single-group study. The interventions targeted depression prediction and management, speech recognition for people with speech disabilities, self-efficacy for weight loss, detection of changes in biopsychosocial condition of patients with multiple morbidity, stress management, treatment of phantom limb pain, smoking cessation, and personalized nutrition based on glycemic response. The average number of enrolled participants in the studies was 71 (range 8-214), and the average follow-up study duration was 69 days (range 3-180). Of the 8 interventions, 6 (75%) showed statistical significance (at the P=.05 level) in health outcomes. Conclusions This review found that digital health interventions incorporating machine learning algorithms in real-life studies can be useful and effective. Given the low number of studies identified in this review and that they did not follow a rigorous machine learning evaluation methodology, we urge the research community to conduct further studies in intervention settings following evaluation principles and demonstrating the potential of machine learning in clinical practice.",2019,57,115,1,True,Medicine,39427767,Andreas K Triantafyllidis,2151583.0,A. Tsanas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
210b2a60c77d9f34f3a78a3214e4732e7413728e,https://www.semanticscholar.org/paper/210b2a60c77d9f34f3a78a3214e4732e7413728e,Machine learning in genome‐wide association studies,"Recently, genome‐wide association studies have substantially expanded our knowledge about genetic variants that influence the susceptibility to complex diseases. Although standard statistical tests for each single‐nucleotide polymorphism (SNP) separately are able to capture main genetic effects, different approaches are necessary to identify SNPs that influence disease risk jointly or in complex interactions. Experimental and simulated genome‐wide SNP data provided by the Genetic Analysis Workshop 16 afforded an opportunity to analyze the applicability and benefit of several machine learning methods. Penalized regression, ensemble methods, and network analyses resulted in several new findings while known and simulated genetic risk variants were also identified. In conclusion, machine learning approaches are promising complements to standard single‐and multi‐SNP analysis methods for understanding the overall genetic architecture of complex human diseases. However, because they are not optimized for genome‐wide SNP data, improved implementations and new variable selection procedures are required. Genet. Epidemiol. 33 (Suppl. 1):S51–S57, 2009. © 2009 Wiley‐Liss, Inc.",2009,61,136,11,True,Biology,3073224,S. Szymczak,1839708.0,J. Biernacka,Medicine,,2505364.0,H. Cordell,102050270.0,O. González-Recio,1825863.0,I. König,48212763.0,Heping Zhang,40586355.0,Yan V. Sun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
594c60b58590b9eda5be787a25974a8b34ec6c17,https://www.semanticscholar.org/paper/594c60b58590b9eda5be787a25974a8b34ec6c17,Machine learning based hyperspectral image analysis: A survey,"Hyperspectral sensors enable the study of the chemical properties of scene materials remotely for the purpose of identification, detection, and chemical composition analysis of objects in the environment. Hence, hyperspectral images captured from earth observing satellites and aircraft have been increasingly important in agriculture, environmental monitoring, urban planning, mining, and defense. Machine learning algorithms due to their outstanding predictive power have become a key tool for modern hyperspectral image analysis. Therefore, a solid understanding of machine learning techniques have become essential for remote sensing researchers and practitioners. This paper reviews and compares recent machine learning-based hyperspectral image analysis methods published in literature. We organize the methods by the image analysis task and by the type of machine learning algorithm, and present a two-way mapping between the image analysis tasks and the types of machine learning algorithms that can be applied to them. The paper is comprehensive in coverage of both hyperspectral image analysis tasks and machine learning algorithms. The image analysis tasks considered are land cover classification, target detection, unmixing, and physical parameter estimation. The machine learning algorithms covered are Gaussian models, linear regression, logistic regression, support vector machines, Gaussian mixture model, latent linear models, sparse linear models, Gaussian mixture models, ensemble learning, directed graphical models, undirected graphical models, clustering, Gaussian processes, Dirichlet processes, and deep learning. We also discuss the open challenges in the field of hyperspectral image analysis and explore possible future directions.",2018,352,77,1,False,Computer Science,7372271,Utsav B. Gewali,2763808.0,S. Monteiro,Engineering,,1733172.0,E. Saber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d42f875d9580de703a29c9b6c05cd535a41976dc,https://www.semanticscholar.org/paper/d42f875d9580de703a29c9b6c05cd535a41976dc,Statistical Reinforcement Learning - Modern Machine Learning Approaches,"Reinforcement learning (RL) is a framework for decision making in unknown environments based on a large amount of data. Several practical RL applications for business intelligence, plant control, and game players have been successfully explored in recent years. Providing an accessible introduction to the field, this book covers model-based and model-free approaches, policy iteration, and policy search methods. It presents illustrative examples and state-of-the-art results, including dimensionality reduction in RL and risk-sensitive RLm. The book provides a bridge between RL and data mining and machine learning research.",2015,0,37,2,False,Computer Science,67154907,Masashi Sugiyama,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6117239f75255bc281051b0b5876102f820b337f,https://www.semanticscholar.org/paper/6117239f75255bc281051b0b5876102f820b337f,Could Machine Learning Break the Convection Parameterization Deadlock?,"Representing unresolved moist convection in coarse‐scale climate models remains one of the main bottlenecks of current climate simulations. Many of the biases present with parameterized convection are strongly reduced when convection is explicitly resolved (i.e., in cloud resolving models at high spatial resolution approximately a kilometer or so). We here present a novel approach to convective parameterization based on machine learning, using an aquaplanet with prescribed sea surface temperatures as a proof of concept. A deep neural network is trained with a superparameterized version of a climate model in which convection is resolved by thousands of embedded 2‐D cloud resolving models. The machine learning representation of convection, which we call the Cloud Brain (CBRAIN), can skillfully predict many of the convective heating, moistening, and radiative features of superparameterization that are most important to climate simulation, although an unintended side effect is to reduce some of the superparameterization's inherent variance. Since as few as three months' high‐frequency global training data prove sufficient to provide this skill, the approach presented here opens up a new possibility for a future class of convection parameterizations in climate models that are built “top‐down,” that is, by learning salient features of convection from unusually explicit simulations.",2018,166,242,15,True,Computer Science,15572823,P. Gentine,119659025.0,M. Pritchard,,,41151821.0,S. Rasp,3535135.0,G. Reinaudi,107581222.0,G. Yacalis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b32852abb9e55424f2dfadefa4da74cbe194059c,https://www.semanticscholar.org/paper/b32852abb9e55424f2dfadefa4da74cbe194059c,ROC Graphs: Notes and Practical Considerations for Data Mining Researchers,"Receiver Operating Characteristics (ROC) graphs are a useful technique for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been increasingly adopted in the machine learning and data mining research communities. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. This article serves both as a tutorial introduction to ROC graphs and as a practical guide for using them in research.",2003,34,766,86,False,Computer Science,145421658,Tom Fawcett,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14ecec7a0541c00537441d4561b7c7673bfcaf70,https://www.semanticscholar.org/paper/14ecec7a0541c00537441d4561b7c7673bfcaf70,Distance Metric Learning: A Comprehensive Survey,"Many machine learning algorithms, such as K Nearest Neighbor (KNN), heavily rely on the distance metric for the input data patterns. Distance Metric learning is to learn a distance metric for the input space of data from a given collection of pair of similar/dissimilar points that preserves the distance relation among the training data. In recent years, many studies have demonstrated, both empirically and theoretically, that a learned metric can significantly improve the performance in classification, clustering and retrieval tasks. This paper surveys the field of distance metric learning from a principle perspective, and includes a broad selection of recent work. In particular, distance metric learning is reviewed under different learning conditions: supervised learning versus unsupervised learning, learning in a global sense versus in a local sense; and the distance matrix based on linear kernel versus nonlinear kernel. In addition, this paper discusses a number of techniques that is central to distance metric learning, including convex programming, positive semi-definite programming, kernel learning, dimension reduction, K Nearest Neighbor, large margin classification, and graph-based approaches.",2006,52,637,29,False,,46554639,Liu Yang,144723884.0,Rong Jin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95745f70f8bb68db0d73c09c29fe964ee48b5460,https://www.semanticscholar.org/paper/95745f70f8bb68db0d73c09c29fe964ee48b5460,"Causal learning mechanisms in very young children: two-, three-, and four-year-olds infer causal relations from patterns of variation and covariation.","Three studies investigated whether young children make accurate causal inferences on the basis of patterns of variation and covariation. Children were presented with a new causal relation by means of a machine called the ""blicket detector."" Some objects, but not others, made the machine light up and play music. In the first 2 experiments, children were told that ""blickets make the machine go"" and were then asked to identify which objects were ""blickets."" Two-, 3-, and 4-year-old children were shown various patterns of variation and covariation between two different objects and the activation of the machine. All 3 age groups took this information into account in their causal judgments about which objects were blickets. In a 3rd experiment, 3- and 4-year-old children used the information when they were asked to make the machine stop. These results are related to Bayes-net causal graphical models of causal learning.",2001,84,421,18,True,Medicine,2222423,A. Gopnik,2124398.0,D. Sobel,Psychology,,144877155.0,L. Schulz,3058012.0,C. Glymour,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b97047c4dc75cbe8d6fc5cb3dd5a81d36458892d,https://www.semanticscholar.org/paper/b97047c4dc75cbe8d6fc5cb3dd5a81d36458892d,APPLIED FEDERATED LEARNING: IMPROVING GOOGLE KEYBOARD QUERY SUGGESTIONS,"Federated learning is a distributed form of machine learning where both the training data and model training are decentralized. In this paper, we use federated learning in a commercial, global-scale setting to train, evaluate and deploy a model to improve virtual keyboard search suggestion quality without direct access to the underlying user data. We describe our observations in federated training, compare metrics to live deployments, and present resulting quality increases. In whole, we demonstrate how federated learning can be applied endto-end to both improve user experiences and enhance user privacy.",2018,20,335,21,False,Computer Science,2122814996,Timothy Yang,144339350.0,Galen Andrew,Mathematics,,153086296.0,Hubert Eichner,2595960.0,Haicheng Sun,2157335981.0,Wei Li,2139798966.0,Nicholas Kong,1878835.0,D. Ramage,51940742.0,F. Beaufays,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2e6c570d277b0b4edd48e2054d5cede4c6bbb50f,https://www.semanticscholar.org/paper/2e6c570d277b0b4edd48e2054d5cede4c6bbb50f,Machine learning in acoustics: Theory and applications.,"Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning (ML), including deep learning, in the field of acoustics. ML is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, ML is data-driven. Given sufficient training data, ML can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, ML can discover models describing complex acoustic phenomena such as human speech and reverberation. ML in acoustics is rapidly developing with compelling results and significant future promise. We first introduce ML, then highlight ML developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes.",2019,291,138,2,True,Engineering,48293266,Michael J. Bianco,1929240.0,P. Gerstoft,Computer Science,Physics,50690309.0,James Traer,15018343.0,Emma Ozanich,35154087.0,M. Roch,1774548.0,S. Gannot,2262533.0,C. Deledalle,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
448d13aae6ed21411d28887c550663973893f70c,https://www.semanticscholar.org/paper/448d13aae6ed21411d28887c550663973893f70c,Machine Learning in Healthcare: A Review,"Machine Learning is modern and highly sophisticated technological applications became a huge trend in the industry. Machine Learning is Omni present and is widely used in various applications. It is playing a vital role in many fields like finance, Medical science and in security. Machine learning is used to discover patterns from medical data sources and provide excellent capabilities to predict diseases. In this paper, we review various machine learning algorithms used for developing efficient decision support for healthcare applications. This paper helps in reducing the research gap for building efficient decision support system for medical applications.",2018,35,82,3,False,Computer Science,9339569,K. Shailaja,51451321.0,B. Seetharamulu,,,144959450.0,M. Jabbar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3a62d3759631153ff135184202792977fbdd265b,https://www.semanticscholar.org/paper/3a62d3759631153ff135184202792977fbdd265b,Learning And Soft Computing Support Vector Machines Neural Networks And Fuzzy Logic Models,"Thank you for reading learning and soft computing support vector machines neural networks and fuzzy logic models. As you may know, people have search hundreds times for their chosen books like this learning and soft computing support vector machines neural networks and fuzzy logic models, but end up in malicious downloads. Rather than enjoying a good book with a cup of coffee in the afternoon, instead they juggled with some infectious bugs inside their computer.",2016,0,186,10,False,Computer Science,52615285,D. Eichel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
652537f9d1c0f41b185fecd0f218a0e37729474f,https://www.semanticscholar.org/paper/652537f9d1c0f41b185fecd0f218a0e37729474f,Comparison deep learning method to traditional methods using for network intrusion detection,"Recently, deep learning has gained prominence due to the potential it portends for machine learning. For this reason, deep learning techniques have been applied in many fields, such as recognizing some kinds of patterns or classification. Intrusion detection analyses got data from monitoring security events to get situation assessment of network. Lots of traditional machine learning method has been put forward to intrusion detection, but it is necessary to improvement the detection performance and accuracy. This paper discusses different methods which were used to classify network traffic. We decided to use different methods on open data set and did experiment with these methods to find out a best way to intrusion detection.",2016,11,162,9,False,Computer Science,2057587951,Bo Dong,2108224931.0,Xue Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ffd42963b10315d79fce48e8aa8e185e9a109152,https://www.semanticscholar.org/paper/ffd42963b10315d79fce48e8aa8e185e9a109152,Evaluating Different Machine Learning Methods for Upscaling Evapotranspiration from Flux Towers to the Regional Scale,"Evapotranspiration (ET) is a vital variable for land‐atmosphere interactions that links surface energy balance, water, and carbon cycles. The in situ techniques can measure ET accurately but the observations have limited spatial and temporal coverage. Modeling approaches have been used to estimate ET at broad spatial and temporal scales, while accurately simulating ET at regional scales remains a major challenge. In this study, we upscale ET from eddy covariance flux tower sites to the regional scale with machine learning algorithms. Five machine learning algorithms are employed for ET upscaling including artificial neural network, Cubist, deep belief network, random forest, and support vector machine. The machine learning methods are trained and tested at 36 flux towers sites (65 site years) across the Heihe River Basin and are then applied to estimate ET for each grid cell (1 km × 1 km) within the watershed and for each day over the period 2012–2016. The artificial neural network, Cubist, random forest, and support vector machine algorithms have almost identical performance in estimating ET and have slightly lower root‐mean‐square error than deep belief network at the site scale. The random forest algorithm has slightly lower relative uncertainty at the regional scale than other methods based on three‐cornered hat method. Additionally, the machine learning methods perform better over densely vegetated conditions than barren land or sparsely vegetated conditions. The regional ET generated from the machine learning approaches captured the spatial and temporal patterns of ET at the regional scale.",2018,82,104,2,True,Environmental Science,8739781,Tongren Xu,49694840.0,Zhixia Guo,,,83386822.0,Shaomin Liu,2167426766.0,Xinlei He,113243901.0,Yangfanyu Meng,50070098.0,Ziwei Xu,40684078.0,Youlong Xia,2786708.0,Jingfeng Xiao,104755339.0,Y. Zhang,48521450.0,Yanfei Ma,2634361.0,Lisheng Song,,,,,,,,,,,,,,,,,,,,,,,,,
5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b,https://www.semanticscholar.org/paper/5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b,Measuring Compositional Generalization: A Comprehensive Method on Realistic Data,"State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings.",2019,73,153,30,False,Computer Science,51027911,Daniel Keysers,3094520.0,Nathanael Schärli,Mathematics,,1471909492.0,Nathan Scales,2836674.0,Hylke Buisman,2362932.0,Daniel Furrer,1471005695.0,S. Kashubin,1470531643.0,Nikola Momchev,1470524352.0,Danila Sinopalnikov,3140227.0,Lukasz Stafiniak,1470473803.0,Tibor Tihon,3045792.0,D. Tsarkov,2118450238.0,Xiao Wang,2807540.0,Marc van Zee,,1698617.0,O. Bousquet,,,,,,,,,,,,,,,,,,
8948bea1e2436e51316f131170923cb5b7d870db,https://www.semanticscholar.org/paper/8948bea1e2436e51316f131170923cb5b7d870db,Learning with Hierarchical-Deep Models,"We introduce HD (or “Hierarchical-Deep”) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.",2013,51,213,12,True,Computer Science,145124475,R. Salakhutdinov,1763295.0,J. Tenenbaum,Medicine,,143805211.0,A. Torralba,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
977d7f2cbcfe06812c2591e8bc28e6c6d01ee9a6,https://www.semanticscholar.org/paper/977d7f2cbcfe06812c2591e8bc28e6c6d01ee9a6,Machine Learning for Survival Analysis: A Survey,"Accurately predicting the time of occurrence of an event of interest is a critical problem in longitudinal data analysis. One of the main challenges in this context is the presence of instances whose event outcomes become unobservable after a certain time point or when some instances do not experience any event during the monitoring period. Such a phenomenon is called censoring which can be effectively handled using survival analysis techniques. Traditionally, statistical approaches have been widely developed in the literature to overcome this censoring issue. In addition, many machine learning algorithms are adapted to effectively handle survival data and tackle other challenging problems that arise in real-world data. In this survey, we provide a comprehensive and structured review of the representative statistical methods along with the machine learning techniques used in survival analysis and provide a detailed taxonomy of the existing methods. We also discuss several topics that are closely related to survival analysis and illustrate several successful applications in various real-world application domains. We hope that this paper will provide a more thorough understanding of the recent advances in survival analysis and offer some guidelines on applying these approaches to solve new problems that arise in applications with censored data.",2017,102,138,14,False,Computer Science,144442051,Ping Wang,2152885669.0,Yan Li,,,144417522.0,C. Reddy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d1800b8c7ea7cda4248eccad995b242b8e403ce0,https://www.semanticscholar.org/paper/d1800b8c7ea7cda4248eccad995b242b8e403ce0,Coadaptive Brain–Machine Interface via Reinforcement Learning,"This paper introduces and demonstrates a novel brain-machine interface (BMI) architecture based on the concepts of reinforcement learning (RL), coadaptation, and shaping. RL allows the BMI control algorithm to learn to complete tasks from interactions with the environment, rather than an explicit training signal. Coadaption enables continuous, synergistic adaptation between the BMI control algorithm and BMI user working in changing environments. Shaping is designed to reduce the learning curve for BMI users attempting to control a prosthetic. Here, we present the theory and in vivo experimental paradigm to illustrate how this BMI learns to complete a reaching task using a prosthetic arm in a 3-D workspace based on the user's neuronal activity. This semisupervised learning framework does not require user movements. We quantify BMI performance in closed-loop brain control over six to ten days for three rats as a function of increasing task difficulty. All three subjects coadapted with their BMI control algorithms to control the prosthetic significantly above chance at each level of difficulty.",2009,61,156,12,False,Computer Science,46851752,J. DiGiovanna,2538494.0,B. Mahmoudi,Medicine,,144371682.0,J. Fortes,143961030.0,J. Príncipe,34732826.0,Justin C. Sanchez,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6cd7a47bbba11a994cd8e68ee5eae2fcb0033054,https://www.semanticscholar.org/paper/6cd7a47bbba11a994cd8e68ee5eae2fcb0033054,Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?,"Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have relied upon massive amounts of human annotated training data. This time consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for the training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor-based classification problems like those that appear in self-driving cars. The source code and data to train and validate the networks described in this paper are made available for researchers.",2016,24,402,59,True,Computer Science,1389944402,M. Johnson-Roberson,116731556.0,Charlie Barto,,,2067925945.0,Rounak Mehta,2057436877.0,S. N. Sridhar,2748006.0,Karl Rosaen,145386932.0,R. Vasudevan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95da1bff50185494bd747bead09958f2e34bf50a,https://www.semanticscholar.org/paper/95da1bff50185494bd747bead09958f2e34bf50a,Types of Cost in Inductive Concept Learning,"Inductive concept learning is the task of learning to assign cases to a discrete set of classes. In real-world applications of concept learning, there are many different types of cost involved. The majority of the machine learning literature ignores all types of cost (unless accuracy is interpreted as a type of cost measure). A few papers have investigated the cost of misclassification errors. Very few papers have examined the many other types of cost. In this paper, we attempt to create a taxonomy of the different types of cost that are involved in inductive concept learning. This taxonomy may help to organize the literature on cost-sensitive learning. We hope that it will inspire researchers to investigate all types of cost in inductive concept learning in more depth.",2002,28,400,14,False,Computer Science,1689647,Peter D. Turney,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86cff4d050beb90fed2e1ceac8940c8221b120aa,https://www.semanticscholar.org/paper/86cff4d050beb90fed2e1ceac8940c8221b120aa,Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer,"Computers are being used more and more in all aspects of our lives and, programmed correctly, they are more accurate and precise than humans can ever be. Here, however, the myth of the superiority of artificial intelligence is examined and dispelled. The authors, one a philosopher and the other a computer scientist, argue that even highly advanced systems only correspond to the very early stages of human learning and that there are many human skills that computers will never be able to emulate. The mind will always be superior to the machine. To illustrate their point, they set forth a model documenting five distinct levels - novice, advanced beginner, competent, proficient and expert - through which human beings pass in acquiring and mastering a skill. The two final stages require a degree of intuitive intelligence far beyond the most ambitious projects being planned for the future. The authors acknowledge the huge progress made by computers and the massive advantages to be gained from using them, but they stress that their value can only lie in their use as aids, never as substitutes for the human mind.",1987,0,3586,235,False,Computer Science,3333658,H. Dreyfus,2547681.0,S. Dreyfus,Psychology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b10e4deadf978d8fd6eec97ff18888629f4261ab,https://www.semanticscholar.org/paper/b10e4deadf978d8fd6eec97ff18888629f4261ab,The Information Content of Forward-Looking Statements in Corporate Filings—A Naïve Bayesian Machine Learning Approach,"ABSTRACT This paper examines the information content of the forward-looking statements (FLS) in the Management Discussion and Analysis section (MD&A) of 10-K and 10-Q filings using a Naive Bayesian machine learning algorithm. I find that firms with better current performance, lower accruals, smaller size, lower market-to-book ratio, less return volatility, lower MD&A Fog index, and longer history tend to have more positive FLSs. The average tone of the FLS is positively associated with future earnings even after controlling for other determinants of future performance. The results also show that, despite increased regulations aimed at strengthening MD&A disclosures, there is no systematic change in the information content of MD&As over time. In addition, the tone in MD&As seems to mitigate the mispricing of accruals. When managers ""warn"" about the future performance implications of accruals (i.e., the MD&A tone is positive (negative) when accruals are negative (positive)), accruals are not associated with future returns. The tone measures based on three commonly used dictionaries (Diction, General Inquirer, and the Linguistic Inquiry and Word Count) do not positively predict future performance. This result suggests that these dictionaries might not work well for analyzing corporate filings. Copyright (c), University of Chicago on behalf of the Accounting Research Center, 2010.",2010,63,772,161,False,Economics,2146312811,Feng Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
17409ae85c237983dc22a5e4750d8054e4b6edc9,https://www.semanticscholar.org/paper/17409ae85c237983dc22a5e4750d8054e4b6edc9,Estimating individual treatment effect: generalization bounds and algorithms,"There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a ""balanced"" representation such that the induced treated and control distributions look similar. We give a novel, simple and intuitive generalization-error bound showing that the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.",2016,79,589,190,False,Mathematics,2304764,Uri Shalit,144602383.0,Fredrik D. Johansson,Computer Science,,1746662.0,D. Sontag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eca05441703a2913b45130d7c33ea51090cb5e3d,https://www.semanticscholar.org/paper/eca05441703a2913b45130d7c33ea51090cb5e3d,CANTINA+: A Feature-Rich Machine Learning Framework for Detecting Phishing Web Sites,"Phishing is a plague in cyberspace. Typically, phish detection methods either use human-verified URL blacklists or exploit Web page features via machine learning techniques. However, the former is frail in terms of new phish, and the latter suffers from the scarcity of effective features and the high false positive rate (FP). To alleviate those problems, we propose a layered anti-phishing solution that aims at (1) exploiting the expressiveness of a rich set of features with machine learning to achieve a high true positive rate (TP) on novel phish, and (2) limiting the FP to a low level via filtering algorithms.Specifically, we proposed CANTINA+, the most comprehensive feature-based approach in the literature including eight novel features, which exploits the HTML Document Object Model (DOM), search engines and third party services with machine learning techniques to detect phish. Moreover, we designed two filters to help reduce FP and achieve runtime speedup. The first is a near-duplicate phish detector that uses hashing to catch highly similar phish. The second is a login form filter, which directly classifies Web pages with no identified login form as legitimate.We extensively evaluated CANTINA+ with two methods on a diverse spectrum of corpora with 8118 phish and 4883 legitimate Web pages. In the randomized evaluation, CANTINA+ achieved over 92% TP on unique testing phish and over 99% TP on near-duplicate testing phish, and about 0.4% FP with 10% training phish. In the time-based evaluation, CANTINA+ also achieved over 92% TP on unique testing phish, over 99% TP on near-duplicate testing phish, and about 1.4% FP under 20% training phish with a two-week sliding window. Capable of achieving 0.4% FP and over 92% TP, our CANTINA+ has been demonstrated to be a competitive anti-phishing solution.",2011,36,429,34,False,Computer Science,145353524,Guang Xiang,2110688724.0,Jason I. Hong,,,35959897.0,C. Rosé,1699751.0,L. Cranor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24a3043e89c18efcb7c4baace5998522449e144b,https://www.semanticscholar.org/paper/24a3043e89c18efcb7c4baace5998522449e144b,Plant Disease Detection Using Machine Learning,"Crop diseases are a noteworthy risk to sustenance security, however their quick distinguishing proof stays troublesome in numerous parts of the world because of the non attendance of the important foundation. Emergence of accurate techniques in the field of leaf-based image classification has shown impressive results. This paper makes use of Random Forest in identifying between healthy and diseased leaf from the data sets created. Our proposed paper includes various phases of implementation namely dataset creation, feature extraction, training the classifier and classification. The created datasets of diseased and healthy leaves are collectively trained under Random Forest to classify the diseased and healthy images. For extracting features of an image we use Histogram of an Oriented Gradient (HOG). Overall, using machine learning to train the large data sets available publicly gives us a clear way to detect the disease present in plants in a colossal scale.",2018,19,136,5,False,Computer Science,51141201,Shima Ramesh Maniyath,51197607.0,Vinod P V,,,51202601.0,N. M,51186469.0,P. R.,1400796361.0,P. N,51197979.0,S. N,51183853.0,R. Hebbar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4e8d226bf69d78ee11cafc216486428102fa90cf,https://www.semanticscholar.org/paper/4e8d226bf69d78ee11cafc216486428102fa90cf,A Progressive Batching L-BFGS Method for Machine Learning,"The standard L-BFGS method relies on gradient approximations that are not dominated by noise, so that search directions are descent directions, the line search is reliable, and quasi-Newton updating yields useful quadratic models of the objective function. All of this appears to call for a full batch approach, but since small batch sizes give rise to faster algorithms with better generalization properties, L-BFGS is currently not considered an algorithm of choice for large-scale machine learning applications. One need not, however, choose between the two extremes represented by the full batch or highly stochastic regimes, and may instead follow a progressive batching approach in which the sample size increases during the course of the optimization. In this paper, we present a new version of the L-BFGS algorithm that combines three basic components - progressive batching, a stochastic line search, and stable quasi-Newton updating - and that performs well on training logistic regression and deep neural networks. We provide supporting convergence theory for the method.",2018,58,87,14,False,Mathematics,16235213,Raghu Bollapragada,2205699.0,D. Mudigere,Computer Science,,2784955.0,J. Nocedal,3311352.0,H. Shi,144669504.0,P. T. P. Tang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ba4cf6046d420af0ae86e2f4b587a8d50d219be3,https://www.semanticscholar.org/paper/ba4cf6046d420af0ae86e2f4b587a8d50d219be3,Measuring Compositionality in Representation Learning,"Many machine learning algorithms represent input data with vector embeddings or discrete codes. When inputs exhibit compositional structure (e.g. objects built from parts or procedures from subroutines), it is natural to ask whether this compositional structure is reflected in the the inputs' learned representations. While the assessment of compositionality in languages has received significant attention in linguistics and adjacent fields, the machine learning literature lacks general-purpose tools for producing graded measurements of compositional structure in more general (e.g. vector-valued) representation spaces. We describe a procedure for evaluating compositionality by measuring how well the true representation-producing model can be approximated by a model that explicitly composes a collection of inferred representational primitives. We use the procedure to provide formal and empirical characterizations of compositional structure in a variety of settings, exploring the relationship between compositionality and learning dynamics, human judgments, representational similarity, and generalization.",2019,55,90,15,False,Mathematics,2112400,Jacob Andreas,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07581e49aff7231159c9405195872d3a154733be,https://www.semanticscholar.org/paper/07581e49aff7231159c9405195872d3a154733be,Clinical Text Data in Machine Learning: Systematic Review,"Background Clinical narratives represent the main form of communication within health care, providing a personalized account of patient history and assessments, and offering rich information for clinical decision making. Natural language processing (NLP) has repeatedly demonstrated its feasibility to unlock evidence buried in clinical narratives. Machine learning can facilitate rapid development of NLP tools by leveraging large amounts of text data. Objective The main aim of this study was to provide systematic evidence on the properties of text data used to train machine learning approaches to clinical NLP. We also investigated the types of NLP tasks that have been supported by machine learning and how they can be applied in clinical practice. Methods Our methodology was based on the guidelines for performing systematic reviews. In August 2018, we used PubMed, a multifaceted interface, to perform a literature search against MEDLINE. We identified 110 relevant studies and extracted information about text data used to support machine learning, NLP tasks supported, and their clinical applications. The data properties considered included their size, provenance, collection methods, annotation, and any relevant statistics. Results The majority of datasets used to train machine learning models included only hundreds or thousands of documents. Only 10 studies used tens of thousands of documents, with a handful of studies utilizing more. Relatively small datasets were utilized for training even when much larger datasets were available. The main reason for such poor data utilization is the annotation bottleneck faced by supervised machine learning algorithms. Active learning was explored to iteratively sample a subset of data for manual annotation as a strategy for minimizing the annotation effort while maximizing the predictive performance of the model. Supervised learning was successfully used where clinical codes integrated with free-text notes into electronic health records were utilized as class labels. Similarly, distant supervision was used to utilize an existing knowledge base to automatically annotate raw text. Where manual annotation was unavoidable, crowdsourcing was explored, but it remains unsuitable because of the sensitive nature of data considered. Besides the small volume, training data were typically sourced from a small number of institutions, thus offering no hard evidence about the transferability of machine learning models. The majority of studies focused on text classification. Most commonly, the classification results were used to support phenotyping, prognosis, care improvement, resource management, and surveillance. Conclusions We identified the data annotation bottleneck as one of the key obstacles to machine learning approaches in clinical NLP. Active learning and distant supervision were explored as a way of saving the annotation efforts. Future research in this field would benefit from alternatives such as data augmentation and transfer learning, or unsupervised learning, which do not require data annotation.",2020,150,101,4,True,Computer Science,1750238,I. Spasić,2144507.0,G. Nenadic,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0f2ab8e03a32a9e2c5dbd6bdfe28d74fb59eb7eb,https://www.semanticscholar.org/paper/0f2ab8e03a32a9e2c5dbd6bdfe28d74fb59eb7eb,Gestalt: integrated support for implementation and analysis in machine learning,"We present Gestalt, a development environment designed to support the process of applying machine learning. While traditional programming environments focus on source code, we explicitly support both code and data. Gestalt allows developers to implement a classification pipeline, analyze data as it moves through that pipeline, and easily transition between implementation and analysis. An experiment shows this significantly improves the ability of developers to find and fix bugs in machine learning systems. Our discussion of Gestalt and our experimental observations provide new insight into general-purpose support for the machine learning process.",2010,21,112,10,False,Computer Science,39699737,Kayur Patel,1949091.0,Naomi Bancroft,,,2311676.0,S. Drucker,145504534.0,J. Fogarty,1441987875.0,Amy J. Ko,9522307.0,J. Landay,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a07b43d2a911ebd2a5f72dd0e01f94f4478a220c,https://www.semanticscholar.org/paper/a07b43d2a911ebd2a5f72dd0e01f94f4478a220c,Combining a large sentiment lexicon and machine learning for subjectivity classification,"Most previous work on subjectivity/sentiment classification bases on either machine learning techniques (such as SVM, Maximum Entropy, Naive Bayes, etc.) or general sentiment lexicons. This paper presents a novel approach to combine a large sentiment lexicon and machine learning techniques for opinion analysis: 1) a large sentiment lexicon is automatically adjusted according to training data; 2) machine learning techniques are used to learn models on training data; 3) the results given by machine learning classifiers and the supervised lexicon-based classifier are combined to get better results. The experiments with the NTCIR data show that our approach significantly outperforms the baselines on subjectivity classification, i.e. the adjusted large sentiment lexicon shows good performance and its combination with machine learning techniques shows further improvement.",2010,24,39,1,False,Computer Science,1391185385,Bin Lu,2847676.0,Benjamin Ka-Yin T'sou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d1a262d97c7bd3411f3c0a69756ad0c8bcda37eb,https://www.semanticscholar.org/paper/d1a262d97c7bd3411f3c0a69756ad0c8bcda37eb,Co-Tracking Using Semi-Supervised Support Vector Machines,"This paper treats tracking as a foreground/background classification problem and proposes an online semi- supervised learning framework. Initialized with a small number of labeled samples, semi-supervised learning treats each new sample as unlabeled data. Classification of new data and updating of the classifier are achieved simultaneously in a co-training framework. The object is represented using independent features and an online support vector machine (SVM) is built for each feature. The predictions from different features are fused by combining the confidence map from each classifier using a classifier weighting method which creates a final classifier that performs better than any classifier based on a single feature. The semi-supervised learning approach then uses the output of the combined confidence map to generate new samples and update the SVMs online. With this approach, the tracker gains increasing knowledge of the object and background and continually improves itself over time. Compared to other discriminative trackers, the online semi-supervised learning approach improves each individual classifier using the information from other features, thus leading to a more robust tracker. Experiments show that this framework performs better than state-of-the-art tracking algorithms on challenging sequences.",2007,25,284,24,False,Computer Science,2053846614,Feng Tang,7207299.0,Shane Brennan,,,2110560544.0,Qi Zhao,145492205.0,Hai Tao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
db3e4b11a569fe17908417351678525f6304e7b7,https://www.semanticscholar.org/paper/db3e4b11a569fe17908417351678525f6304e7b7,Resource-efficient Machine Learning in 2 KB RAM for the Internet of Things,"This paper develops a novel tree-based algorithm, called Bonsai, for efficient prediction on IoT devices - such as those based on the Arduino Uno board having an 8 bit ATmega328P microcontroller operating at 16 MHz with no native floating point support, 2 KB RAM and 32 KB read-only flash. Bonsai maintains prediction accuracy while minimizing model size and prediction costs by: (a) developing a tree model which learns a single, shallow, sparse tree with powerful nodes; (b) sparsely projecting all data into a low-dimensional space in which the tree is learnt; and (c) jointly learning all tree and projection parameters. Experimental results on multiple benchmark datasets demonstrate that Bonsai can make predictions in milliseconds even on slow microcontrollers, can fit in KB of memory, has lower battery consumption than all other algorithms while achieving prediction accuracies that can be as much as 30% higher than state-of-the-art methods for resource-efficient machine learning. Bonsai is also shown to generalize to other resource constrained settings beyond IoT by generating significantly better search results as compared to Bing's L3 ranker when the model size is restricted to 300 bytes. Bonsai's code can be downloaded from (BonsaiCode).",2017,57,177,21,False,Computer Science,2026843558,Ashish Kumar,2601821.0,Saurabh Goyal,,,145859952.0,M. Varma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
265644f1b6740ca34bfbe9762b90b33021adde62,https://www.semanticscholar.org/paper/265644f1b6740ca34bfbe9762b90b33021adde62,Deep Learning in Medical Imaging: General Overview,"The artificial neural network (ANN)–a machine learning technique inspired by the human neuronal synapse system–was introduced in the 1950s. However, the ANN was previously limited in its ability to solve actual problems, due to the vanishing gradient and overfitting problems with training of deep architecture, lack of computing power, and primarily the absence of sufficient data to train the computer system. Interest in this concept has lately resurfaced, due to the availability of big data, enhanced computing power with the current graphics processing units, and novel algorithms to train the deep neural network. Recent studies on this technology suggest its potentially to perform better than humans in some visual and auditory recognition tasks, which may portend its applications in medicine and healthcare, especially in medical imaging, in the foreseeable future. This review article offers perspectives on the history, development, and applications of deep learning technology, particularly regarding its applications in medical imaging.",2017,99,690,11,True,Medicine,120704132,June-Goo Lee,2052576935.0,Sanghoon Jun,,,2116632761.0,Younghoon Cho,46901084.0,Hyunna Lee,38628528.0,G. Kim,46844846.0,J. Seo,145979410.0,Namkug Kim,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6ee716bc6bb11c5857794e7723aeb1c55c7d6b66,https://www.semanticscholar.org/paper/6ee716bc6bb11c5857794e7723aeb1c55c7d6b66,Regulating by Robot: Administrative Decision Making in the Machine-Learning Era,"Machine-learning algorithms are transforming large segments of the economy as they fuel innovation in search engines, self-driving cars, product marketing, and medical imaging, among many other technologies. As machine learning’s use expands across all facets of society, anxiety has emerged about the intrusion of algorithmic machines into facets of life previously dependent on human judgment. Alarm bells sounding over the diffusion of artificial intelligence throughout the private sector only portend greater anxiety about digital robots replacing humans in the governmental sphere. A few administrative agencies have already begun to adopt this technology, while others have clear potential in the near term to use algorithms to shape official decisions over both rulemaking and adjudication. It is no longer fanciful to envision a future in which government agencies could effectively make law by robot, a prospect that understandably conjures up dystopian images of individuals surrendering their liberty to the control of computerized overlords. Should society be alarmed by governmental use of machine-learning applications? We examine this question by considering whether the use of robotic decision tools by government agencies can pass muster under core, time-honored doctrines of administrative and constitutional law. At first glance, the idea of algorithmic regulation might appear to offend one or more traditional doctrines, such as the nondelegation doctrine, procedural due process, equal protection, or principles of reason-giving and transparency. We conclude, however, that when machine-learning technology is properly understood, its use by government agencies can comfortably fit within these conventional legal parameters. We recognize, of course, that the legality of regulation by robot is only one criterion by which its use should be assessed. Agencies should not apply algorithms cavalierly, even if doing so might not run afoul of the law; in some cases, safeguards may be needed for machine learning to satisfy broader, good-governance aspirations. Yet, in contrast with the emerging alarmism, we resist any categorical dismissal of a future administrative state in which algorithmic automation guides, and even at times makes, key decisions. Instead, we urge that governmental reliance on machine learning should be approached with measured optimism about the potential benefits such technology can offer society by making government smarter and its decisions more efficient and just.",2017,59,165,2,False,Engineering,1740052,C. Coglianese,2081973974.0,David Lehr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8221ed66d16b608653393757eaf443187ffe60a0,https://www.semanticscholar.org/paper/8221ed66d16b608653393757eaf443187ffe60a0,A Machine Learning Approach to Building Domain-Specific Search Engines,"Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This paper proposes the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific search engines. We describe new research in reinforcement learning, text classification and information extraction that enables efficient spidering, populates topic hierarchies, and identifies informative text segments. Using these techniques, we have built a demonstration system: a search engine for computer science research papers available at www.cora.justrcsettrch.com.",1999,19,211,11,False,Computer Science,143753639,A. McCallum,145172877.0,K. Nigam,,,35211659.0,Jason D. M. Rennie,2544946.0,K. Seymore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d70cbaf8d9163d9c27a2635b2b764e4ebf400871,https://www.semanticscholar.org/paper/d70cbaf8d9163d9c27a2635b2b764e4ebf400871,Quantum support vector machine for big feature and big data classification,"Supervised machine learning is the classification of new data based on already classified training examples. In this work, we show that the support vector machine, an optimized binary classifier, can be implemented on a quantum computer, with complexity logarithmic in the size of the vectors and the number of training examples. In cases where classical sampling algorithms require polynomial time, an exponential speedup is obtained. At the core of this quantum big data algorithm is a nonsparse matrix exponentiation technique for efficiently performing a matrix inversion of the training data inner-product (kernel) matrix.",2013,63,453,23,True,Computer Science,3157522,P. Rebentrost,145233982.0,M. Mohseni,Physics,Medicine,145762777.0,S. Lloyd,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7eb733c8ac1b3d1dd8b50e066ddae10769e3b46e,https://www.semanticscholar.org/paper/7eb733c8ac1b3d1dd8b50e066ddae10769e3b46e,CrypTen: Secure Multi-Party Computation Meets Machine Learning,"Secure multi-party computation (MPC) allows parties to perform computations on data while keeping that data private. This capability has great potential for machine-learning applications: it facilitates training of machine-learning models on private data sets owned by different parties, evaluation of one party’s private model using another party’s private data, etc. Although a range of studies implement machine-learning models via secure MPC, such implementations are not yet mainstream. Adoption of secure MPC is hampered by the absence of ﬂexible software frameworks that “speak the language” of machine-learning researchers and engineers. To foster adoption of secure MPC in machine learning, we present C RYP T EN : a software framework that exposes popular secure MPC primitives via abstractions that are common in modern machine-learning frameworks, such as tensor computations, automatic differentiation, and modular neural networks. This paper describes the design of C RYP T EN and measure its performance on state-of-the-art models for text classiﬁcation, speech recognition, and image classiﬁcation. Our benchmarks show that C RYP T EN ’s GPU support and high-performance communication between (an arbitrary number of) parties allows it to perform efﬁcient private evaluation of modern machine-learning models under a semi-honest threat model. For example, two parties using C RYP T EN can securely predict phonemes in speech recordings using Wav2Letter [18] faster than real-time. We hope that C RYP T EN will spur adoption of secure MPC in the machine-learning community.",2021,80,77,18,False,Computer Science,2713842,Brian Knott,2262405.0,Shobha Venkataraman,,,144479015.0,Awni Y. Hannun,2264597.0,Shubho Sengupta,3407874.0,Mark Ibrahim,1803520.0,L. V. D. Maaten,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
07b5093aace8e485e7d23b83edb6351618138127,https://www.semanticscholar.org/paper/07b5093aace8e485e7d23b83edb6351618138127,Does Distributionally Robust Supervised Learning Give Robust Classifiers?,"Distributionally Robust Supervised Learning (DRSL) is necessary for building reliable machine learning systems. When machine learning is deployed in the real world, its performance can be significantly degraded because test data may follow a different distribution from training data. DRSL with f-divergences explicitly considers the worst-case distribution shift by minimizing the adversarially reweighted training loss. In this paper, we analyze this DRSL, focusing on the classification scenario. Since the DRSL is explicitly formulated for a distribution shift scenario, we naturally expect it to give a robust classifier that can aggressively handle shifted distributions. However, surprisingly, we prove that the DRSL just ends up giving a classifier that exactly fits the given training distribution, which is too pessimistic. This pessimism comes from two sources: the particular losses used in classification and the fact that the variety of distributions to which the DRSL tries to be robust is too wide. Motivated by our analysis, we propose simple DRSL that overcomes this pessimism and empirically demonstrate its effectiveness.",2016,37,161,22,False,Computer Science,48594758,Weihua Hu,47537639.0,Gang Niu,,,73355331.0,Issei Sato,67154907.0,Masashi Sugiyama,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
055e2b142026cadd9ebb7b740e1641d6fafa962b,https://www.semanticscholar.org/paper/055e2b142026cadd9ebb7b740e1641d6fafa962b,Machine Unlearning,"Once users have shared their data online, it is generally difficult for them to revoke access and ask for the data to be deleted. Machine learning (ML) exacerbates this problem because any model trained with said data may have memorized it, putting users at risk of a successful privacy attack exposing their information. Yet, having models unlearn is notoriously difficult.We introduce SISA training, a framework that expedites the unlearning process by strategically limiting the influence of a data point in the training procedure. While our framework is applicable to any learning algorithm, it is designed to achieve the largest improvements for stateful algorithms like stochastic gradient descent for deep neural networks. SISA training reduces the computational overhead associated with unlearning, even in the worst-case setting where unlearning requests are made uniformly across the training set. In some cases, the service provider may have a prior on the distribution of unlearning requests that will be issued by users. We may take this prior into account to partition and order data accordingly, and further decrease overhead from unlearning.Our evaluation spans several datasets from different domains, with corresponding motivations for unlearning. Under no distributional assumptions, for simple learning tasks, we observe that SISA training improves time to unlearn points from the Purchase dataset by 4.63×, and 2.45× for the SVHN dataset, over retraining from scratch. SISA training also provides a speed-up of 1.36× in retraining for complex learning tasks such as ImageNet classification; aided by transfer learning, this results in a small degradation in accuracy. Our work contributes to practical data governance in machine unlearning.",2019,65,103,21,False,Computer Science,1452678444,Lucas Bourtoule,143754359.0,Varun Chandrasekaran,,,1415982317.0,Christopher A. Choquette-Choo,120074583.0,Hengrui Jia,1452679273.0,Adelin Travers,23696685.0,Baiwu Zhang,47412202.0,D. Lie,1967156.0,Nicolas Papernot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a850b1dcc10f413918d4d6810980031851d8c4dc,https://www.semanticscholar.org/paper/a850b1dcc10f413918d4d6810980031851d8c4dc,Fuzzy Restricted Boltzmann Machine for the Enhancement of Deep Learning,"In recent years, deep learning caves out a research wave in machine learning. With outstanding performance, more and more applications of deep learning in pattern recognition, image recognition, speech recognition, and video processing have been developed. Restricted Boltzmann machine (RBM) plays an important role in current deep learning techniques, as most of existing deep networks are based on or related to it. For regular RBM, the relationships between visible units and hidden units are restricted to be constants. This restriction will certainly downgrade the representation capability of the RBM. To avoid this flaw and enhance deep learning capability, the fuzzy restricted Boltzmann machine (FRBM) and its learning algorithm are proposed in this paper, in which the parameters governing the model are replaced by fuzzy numbers. This way, the original RBM becomes a special case in the FRBM, when there is no fuzziness in the FRBM model. In the process of learning FRBM, the fuzzy free energy function is defuzzified before the probability is defined. The experimental results based on bar-and-stripe benchmark inpainting and MNIST handwritten digits classification problems show that the representation capability of FRBM model is significantly better than the traditional RBM. Additionally, the FRBM also reveals better robustness property compared with RBM when the training data are contaminated by noises.",2015,39,166,10,False,Computer Science,47978588,C. L. P. Chen,47423401.0,Chun-Yang Zhang,,,2118171924.0,Long Chen,48082259.0,Min Gan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3614e6b9313b0093bda33b719c28708637237323,https://www.semanticscholar.org/paper/3614e6b9313b0093bda33b719c28708637237323,A Comparison of Supervised Machine Learning Techniques for Predicting Short-Term In-Hospital Length of Stay among Diabetic Patients,"Diabetes is a life-altering medical condition that affects millions of people and results in many hospitalizations per year. Consequently, predicting the length of stay of in-hospital diabetic patients has become increasingly important for staffing and resource planning. Although statistical methods have been used to predict length of stay in hospitalized patients, many powerful machine learning techniques have not yet been explored. In this paper, we compare and discuss the performance of various supervised machine learning algorithms (i.e., Multiple linear regression, support vector machines, multi-task learning, and random forests) for predicting long versus short-term length of stay of hospitalized diabetic patients.",2014,26,51,5,False,Computer Science,38569173,A. Morton,1492038511.0,Eman N. Marzban,,,46599451.0,G. Giannoulis,27875247.0,Ayush Patel,2154233.0,R. Aparasu,1706204.0,I. Kakadiaris,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3abcf9ba64f21fdcab8237104a78beb11afe28b2,https://www.semanticscholar.org/paper/3abcf9ba64f21fdcab8237104a78beb11afe28b2,Machine Learning for Cognitive Network Management,"Over the last decade, a significant amount of effort has been invested on architecting agile and adaptive management solutions in support of autonomic, self-managing networks. Autonomic networking calls for automated decisions for management actions. This can be realized through a set of pre-defined network management policies engineered from human expert knowledge. However, engineering sufficiently accurate knowledge considering the high complexity of today's networking environment is a difficult task. This has been a particularly limiting factor in the practical deployment of autonomic systems. ML is a powerful technique for extracting knowledge from data. However, there has been little evidence of its application in realizing practical management solutions for autonomic networks. Recent advances in network softwarization and programmability through SDN and NFV, the proliferation of new sources of data, and the availability of lowcost and seemingly infinite storage and compute resource from the cloud are paving the way for the adoption of ML to realize cognitive network management in support of autonomic networking. This article is intended to stimulate thought and foster discussion on how to defeat the bottlenecks that are limiting the wide deployment of autonomic systems, and the role that ML can play in this regard.",2018,17,154,6,False,Computer Science,144517577,Sara Ayoubi,2367393.0,Noura Limam,,,10297273.0,M. A. Salahuddin,2618286.0,Nashid Shahriar,1715494.0,R. Boutaba,2585060.0,Felipe Estrada Solano,2832428.0,O. Rendón,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
96357dcc485fe021035cb1b287eb258ec3e56482,https://www.semanticscholar.org/paper/96357dcc485fe021035cb1b287eb258ec3e56482,Landslide prediction from machine learning,"Predicting where and when landslides are likely to occur in a specific region of interest remains a key challenge in natural hazards research and mitigation. While the basic mechanics of slope‐failure initiation and runout can be cast into physical and numerical models, a scarcity of sufficiently detailed and real‐time measurements of soil, rock‐mass and groundwater conditions prohibits accurate landslide forecasting. Researchers are therefore increasingly exploring multivariate data analysis techniques from the fields of data mining or machine learning in order to approximate future occurrences of landslides from past distribution patterns. This work has elucidated patterns of spatial susceptibility, but temporal forecasts have remained largely empirical. Most machine learning techniques achieve overall success rates of 75–95 percent. Whilst this may seem very promising, issues remain with data input quality, potential overfitting and commensurate inadequate choice of prediction models, inadvertent inclusion of redundant or noise variables, and technical limits to predicting only certain types and sizes of landslides. Simpler models provide only slightly inferior predictions to more complex models, and should guide the way for a more widespread application of data mining in regional landslide prediction. This approach should especially be communicated to planners and decision makers. Future research may want to develop: (1) further best‐practice guidelines for model selection; (2) predictions of occurrence and runout of large slope failures at the regional scale; and (3) temporal forecasts of landslides.",2014,2,86,3,False,Geology,6929558,O. Korup,32562787.0,A. Stolle,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6169aadcb008f550bd634057ee31fcbfbed3e65b,https://www.semanticscholar.org/paper/6169aadcb008f550bd634057ee31fcbfbed3e65b,Machine learning for interatomic potential models.,"The use of supervised machine learning to develop fast and accurate interatomic potential models is transforming molecular and materials research by greatly accelerating atomic-scale simulations with little loss of accuracy. Three years ago, Jörg Behler published a perspective in this journal providing an overview of some of the leading methods in this field. In this perspective, we provide an updated discussion of recent developments, emerging trends, and promising areas for future research in this field. We include in this discussion an overview of three emerging approaches to developing machine-learned interatomic potential models that have not been extensively discussed in existing reviews: moment tensor potentials, message-passing networks, and symbolic regression.",2020,153,133,0,True,Medicine,46199341,Tim Mueller,143831235.0,Alberto Hernandez,Computer Science,,32272204.0,Chuhong Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
006b577653e0e91e1cfd37c32c6d1cfb198a730e,https://www.semanticscholar.org/paper/006b577653e0e91e1cfd37c32c6d1cfb198a730e,Partially Supervised Classification of Text Documents,"We investigate the following problem: Given a set of documents of a particular topic or class P , and a large set M of mixed documents that contains documents from class P and other types of documents, identify the documents from class P in M . The key feature of this problem is that there is no labeled nonP document, which makes traditional machine learning techniques inapplicable, as they all need labeled documents of both classes. We call this problem partially supervised classification. In this paper, we show that this problem can be posed as a constrained optimization problem and that under appropriate conditions, solutions to the constrained optimization problem will give good solutions to the partially supervised classification problem. We present a novel technique to solve the problem and demonstrate the effectiveness of the technique through extensive experimentation.",2002,34,579,60,False,Computer Science,145321667,B. Liu,1740222.0,Wee Sun Lee,,,144019071.0,Philip S. Yu,39952499.0,Xiaoli Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291,https://www.semanticscholar.org/paper/6f803c1729ed818ef6a5ee28cf23b3c6ca9e4291,Advancing Biosensors with Machine Learning.,"Chemometrics play a critical role in biosensors-based detection, analysis, and diagnosis. Nowadays, as a branch of artificial intelligence (AI), machine learning (ML) have achieved impressive advances. However, novel advanced ML methods, especially deep learning, which is famous for image analysis, facial recognition, and speech recognition, has remained relatively elusive to the biosensor community. Herein, how ML can be beneficial to biosensors is systematically discussed. The advantages and drawbacks of most popular ML algorithms are summarized on the basis of sensing data analysis. Specially, deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN) are emphasized. Diverse ML-assisted electrochemical biosensors, wearable electronics, SERS and other spectra-based biosensors, fluorescence biosensors and colorimetric biosensors are comprehensively discussed. Furthermore, biosensor networks and multibiosensor data fusion are introduced. This review will nicely bridge ML with biosensors, and greatly expand chemometrics for detection, analysis, and diagnosis.",2020,151,93,1,False,Medicine,11555660,Feiyun Cui,51315458.0,Yun Yue,Computer Science,,2153913604.0,Yi Zhang,7969330.0,Ziming Zhang,2107209242.0,H. S. Zhou,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81f40a75802dcff2278f24c22205952b0b330285,https://www.semanticscholar.org/paper/81f40a75802dcff2278f24c22205952b0b330285,Power Utility Nontechnical Loss Analysis With Extreme Learning Machine Method,"This paper presents a new approach to nontechnical loss (NTL) analysis for utilities using the modern computational technique extreme learning machine (ELM). Nontechnical losses represent a significant proportion of electricity losses in both developing and developed countries. The ELM-based approach presented here uses customer load-profile information to expose abnormal behavior that is known to be highly correlated with NTL activities. This approach provides a method of data mining for this purpose, and it involves extracting patterns of customer behavior from historical kWh consumption data. The results yield classification classes that are used to reveal whether any significant behavior that emerges is due to irregularities in consumption. In this paper, ELM and online sequential-ELM (OS-ELM) algorithms are both used to achieve an improved classification performance and to increase accuracy of results. A comparison of this approach with other classification techniques, such as the support vector machine (SVM) algorithm, is also undertaken and the ELM performance and accuracy in NTL analysis is shown to be superior.",2008,28,323,7,False,Engineering,123743835,A. Nizar,144402926.0,Z. Dong,,,51267860.0,Y. Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3e7f5455e0ed81de16f9327ffc12093ec8245cf7,https://www.semanticscholar.org/paper/3e7f5455e0ed81de16f9327ffc12093ec8245cf7,Multiview Privileged Support Vector Machines,"Multiview learning (MVL), by exploiting the complementary information among multiple feature sets, can improve the performance of many existing learning tasks. Support vector machine (SVM)-based models have been frequently used for MVL. A typical SVM-based MVL model is SVM-2K, which extends SVM for MVL by using the distance minimization version of kernel canonical correlation analysis. However, SVM-2K cannot fully unleash the power of the complementary information among different feature views. Recently, a framework of learning using privileged information (LUPI) has been proposed to model data with complementary information. Motivated by LUPI, we propose a new multiview privileged SVM model, multi-view privileged SVM model (PSVM-2V), for MVL. This brings a new perspective that extends LUPI to MVL. The optimization of PSVM-2V can be solved by the classical quadratic programming solver. We theoretically analyze the performance of PSVM-2V from the viewpoints of the consensus principle, the generalization error bound, and the SVM-2K learning model. Experimental results on 95 binary data sets demonstrate the effectiveness of the proposed method.",2018,49,73,4,False,Computer Science,48252042,Jingjing Tang,143790318.0,Ying-jie Tian,Medicine,,2151332283.0,Peng Zhang,87180246.0,Xiaohui Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b5d086119d31272a2fa3efdf4dcd9222e071c723,https://www.semanticscholar.org/paper/b5d086119d31272a2fa3efdf4dcd9222e071c723,Regroup: interactive machine learning for on-demand group creation in social networks,"We present ReGroup, a novel end-user interactive machine learning system for helping people create custom, on demand groups in online social networks. As a person adds members to a group, ReGroup iteratively learns a probabilistic model of group membership specific to that group. ReGroup then uses its currently learned model to suggest additional members and group characteristics for filtering. Our evaluation shows that ReGroup is effective for helping people create large and varied groups, whereas traditional methods (searching by name or selecting from an alphabetical list) are better suited for small groups whose members can be easily recalled by name. By facilitating on demand group creation, ReGroup can enable in-context sharing and potentially encourage better online privacy practices. In addition, applying interactive machine learning to social network group creation introduces several challenges for designing effective end-user interaction with machine learning. We identify these challenges and discuss how we address them in ReGroup.",2012,58,155,19,False,Computer Science,1719124,Saleema Amershi,145504534.0,J. Fogarty,,,1780531.0,Daniel S. Weld,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3ff2ba8bd2658817c780b450028040ba78a10681,https://www.semanticscholar.org/paper/3ff2ba8bd2658817c780b450028040ba78a10681,Hardware for machine learning: Challenges and opportunities,"Machine learning plays a critical role in extracting meaningful information out of the zetabytes of sensor data collected every day. For some applications, the goal is to analyze and understand the data to identify trends (e.g., surveillance, portable/wearable electronics); in other applications, the goal is to take immediate action based the data (e.g., robotics/drones, self-driving cars, smart Internet of Things). For many of these applications, local embedded processing near the sensor is preferred over the cloud due to privacy or latency concerns, or hmitations in the communication bandwidth. However, at the sensor there are often stringent constraints on energy consumption and cost in addition to throughput and accuracy requirements. Furthermore, flexibility is often required such that the processing can be adapted for different applications or environments (e.g., update the weights and model in the classifier). In many applications, machine learning often involves transforming the input data into a higher dimensional space, which, along with programmable weights, increases data movement and consequently energy consumption. In this paper, we will discuss how these challenges can be addressed at various levels of hardware design ranging from architecture, hardware-friendly algorithms, mixed-signal circuits, and advanced technologies (including memories and sensors).",2016,84,137,10,True,Computer Science,1691305,V. Sze,50579876.0,Yu-hsin Chen,,,1399426866.0,Joel Einer,2071741.0,Amr Suleiman,48805472.0,Zhengdong Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94187ef33e34af2cdb42502083c6f9b4c3f5ba6b,https://www.semanticscholar.org/paper/94187ef33e34af2cdb42502083c6f9b4c3f5ba6b,Practical Black-Box Attacks against Deep Learning Systems using Adversarial Examples,"Advances in deep learning have led to the broad adoption of Deep Neural Networks (DNNs) to a range of important machine learning problems, e.g., guiding autonomous vehicles, speech recognition, malware detection. Yet, machine learning models, including DNNs, were shown to be vulnerable to adversarial samples-subtly (and often humanly indistinguishably) modified malicious inputs crafted to compromise the integrity of their outputs. Adversarial examples thus enable adversaries to manipulate system behaviors. Potential attacks include attempts to control the behavior of vehicles, have spam content identified as legitimate content, or have malware identified as legitimate software. Adversarial examples are known to transfer from one model to another, even if the second model has a different architecture or was trained on a different set. We introduce the first practical demonstration that this cross-model transfer phenomenon enables attackers to control a remotely hosted DNN with no access to the model, its parameters, or its training data. In our demonstration, we only assume that the adversary can observe outputs from the target DNN given inputs chosen by the adversary. We introduce the attack strategy of fitting a substitute model to the input-output pairs in this manner, then crafting adversarial examples based on this auxiliary model. We evaluate the approach on existing DNN datasets and real-world settings. In one experiment, we force a DNN supported by MetaMind (one of the online APIs for DNN classifiers) to mis-classify inputs at a rate of 84.24%. We conclude with experiments exploring why adversarial samples transfer between DNNs, and a discussion on the applicability of our attack when targeting machine learning algorithms distinct from DNNs.",2016,47,442,46,False,Computer Science,1967156,Nicolas Papernot,144061974.0,P. Mcdaniel,,,153440022.0,Ian J. Goodfellow,1680133.0,S. Jha,144643812.0,Z. B. Celik,144231976.0,A. Swami,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cc9cd080b16405267fbfa8b28e027ca62c873b5e,https://www.semanticscholar.org/paper/cc9cd080b16405267fbfa8b28e027ca62c873b5e,An iterative learning control method with application for CNC machine tools,"A PID (proportional, integral, and derivative) iterative learning controller is proposed for precise tracking control of industrial robots and CNC (computer numerical control) machine tools performing repetitive tasks. The convergence of the output error by the proposed learning controller is guaranteed under a certain condition even when system parameters are not known exactly and periodic disturbances exist. In actual implementation, the distance difference between the desired path and the actual machined path, which is one of the most significant factors in the evaluation of control performance of industrial robots and CNC machine tools, is reduced in machining a circle with depth on the aluminum workpiece as the proposed learning algorithm repeats. Experimental results demonstrate that the proposed PID learning controller can improve machining accuracy when the CNC machine tool performs repetitive tasks in machining.<<ETX>>",1993,10,103,4,False,Engineering,2109397772,D. Kim,2153591169.0,S. Kim,Biology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95d8ab48f213e01f33c3af0b34a0cc0e4fba9349,https://www.semanticscholar.org/paper/95d8ab48f213e01f33c3af0b34a0cc0e4fba9349,"Drug-target interaction prediction: databases, web servers and computational models","Identification of drug-target interactions is an important process in drug discovery. Although high-throughput screening and other biological assays are becoming available, experimental methods for drug-target interaction identification remain to be extremely costly, time-consuming and challenging even nowadays. Therefore, various computational models have been developed to predict potential drug-target associations on a large scale. In this review, databases and web servers involved in drug-target identification and drug discovery are summarized. In addition, we mainly introduced some state-of-the-art computational models for drug-target interactions prediction, including network-based method, machine learning-based method and so on. Specially, for the machine learning-based method, much attention was paid to supervised and semi-supervised models, which have essential difference in the adoption of negative samples. Although significant improvements for drug-target interaction prediction have been obtained by many effective computational models, both network-based and machine learning-based methods have their disadvantages, respectively. Furthermore, we discuss the future directions of the network-based drug discovery and network approach for personalized drug discovery based on personalized medicine, genome sequencing, tumor clone-based network and cancer hallmark-based network. Finally, we discussed the new evaluation validation framework and the formulation of drug-target interactions prediction problem by more realistic regression formulation based on quantitative bioactivity data.",2016,89,361,8,True,Computer Science,48283613,Xing Chen,7590116.0,C. Yan,Medicine,,2130057502.0,Xiaotian Zhang,2115462781.0,Xu Zhang,152130996.0,Feng Dai,2111611501.0,Jian Yin,1699819.0,Yongdong Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
65d3e7fa7b452611aa729ac789d4373d6ee505b0,https://www.semanticscholar.org/paper/65d3e7fa7b452611aa729ac789d4373d6ee505b0,fastMRI: An Open Dataset and Benchmarks for Accelerated MRI,"Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background.",2018,63,402,65,False,Computer Science,3105120,Jure Zbontar,3597472.0,F. Knoll,Engineering,Physics,8401284.0,Anuroop Sriram,2954796.0,Matthew Muckley,145219594.0,M. Bruno,34597877.0,Aaron Defazio,48674611.0,Marc Parente,2376144.0,Krzysztof J Geras,51983841.0,Joe Katsnelson,2382287.0,H. Chandarana,2476328.0,Zizhao Zhang,3325894.0,M. Drozdzal,144290131.0,Adriana Romero,Mathematics,2066127975.0,Michael G. Rabbat,145467703.0,Pascal Vincent,2064937515.0,James Pinkerton,2111247556.0,Duo Wang,6584461.0,N. Yakubova,2057049036.0,Erich Owens,1699161.0,C. L. Zitnick,5677770.0,M. Recht,2827060.0,D. Sodickson,2376478.0,Y. Lui
d4632690af6cb5522f6895586c16cb741e0757c5,https://www.semanticscholar.org/paper/d4632690af6cb5522f6895586c16cb741e0757c5,The Pyramid Match Kernel: Efficient Learning with Sets of Features,"In numerous domains it is useful to represent a single example by the set of the local features or parts that comprise it. However, this representation poses a challenge to many conventional machine learning techniques, since sets may vary in cardinality and elements lack a meaningful ordering. Kernel methods can learn complex functions, but a kernel over unordered set inputs must somehow solve for correspondences---generally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function called the pyramid match that measures partial match similarity in time linear in the number of features. The pyramid match maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in order to find implicit correspondences based on the finest resolution histogram cell where a matched pair first appears. We show the pyramid match yields a Mercer kernel, and we prove bounds on its error relative to the optimal partial matching cost. We demonstrate our algorithm on both classification and regression tasks, including object recognition, 3-D human pose inference, and time of publication estimation for documents, and we show that the proposed method is accurate and significantly more efficient than current approaches.",2007,69,385,46,False,Computer Science,1794409,K. Grauman,1753210.0,Trevor Darrell,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36652428740cd30d245d55889f01a7fb04a91c93,https://www.semanticscholar.org/paper/36652428740cd30d245d55889f01a7fb04a91c93,Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning,"Many interesting problems in machine learning are being revisited with new deep learning tools. For graph-based semi-supervised learning, a recent important development is graph convolutional networks (GCNs), which nicely integrate local vertex features and graph topology in the convolutional layers. Although the GCN model compares favorably with other state-of-the-art methods, its mechanisms are not clear and it still requires considerable amount of labeled data for validation and model selection. In this paper, we develop deeper insights into the GCN model and address its fundamental limits. First, we show that the graph convolution of the GCN model is actually a special form of Laplacian smoothing, which is the key reason why GCNs work, but it also brings potential concerns of over-smoothing with many convolutional layers. Second, to overcome the limits of the GCN model with shallow architectures, we propose both co-training and self-training approaches to train GCNs. Our approaches significantly improve GCNs in learning with very few labels, and exempt them from requiring additional labels for validation. Extensive experiments on benchmarks have verified our theory and proposals.",2018,33,1387,151,True,Computer Science,35692225,Qimai Li,40592359.0,Zhichao Han,Mathematics,,19195265.0,Xiao-Ming Wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
