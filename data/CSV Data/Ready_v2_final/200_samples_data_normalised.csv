paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/1,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,fieldsOfStudy/2,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,fieldsOfStudy/3,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name
a9cbbef8f4426329d0687025b34287c35bdd8b38,https://www.semanticscholar.org/paper/a9cbbef8f4426329d0687025b34287c35bdd8b38,Machine learning and the physical sciences,"Machine learning (ML) encompasses a broad range of algorithms and modeling tools used for a vast array of data processing tasks, which has entered most scientific disciplines in recent years. This article reviews in a selective way the recent research on the interface between machine learning and the physical sciences. This includes conceptual developments in ML motivated by physical insights, applications of machine learning techniques to several domains in physics, and cross fertilization between the two fields. After giving a basic notion of machine learning methods and principles, examples are described of how statistical physics is used to understand methods in ML. This review then describes applications of ML methods in particle physics and cosmology, quantum many-body physics, quantum computing, and chemical and material physics. Research and development into novel computing architectures aimed at accelerating ML are also highlighted. Each of the sections describe recent successes as well as domain-specific methodology and challenges.",2019,429,819,17,True,Physics,50666189,G. Carleo,119628938.0,I. Cirac,11638962.0,K. Cranmer,1742040.0,L. Daudet,3048564.0,M. Schuld,1777660.0,Naftali Tishby,1445956232.0,Leslie Vogt-Maranto,2065813820.0,Lenka Zdeborov'a,,,,,,,,,,,,,,,,,,,,,
6bc43977fb11cceed0b9aa55b23c6dd29dd9a132,https://www.semanticscholar.org/paper/6bc43977fb11cceed0b9aa55b23c6dd29dd9a132,Correlation-based Feature Selection for Machine Learning,"A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate correlation measure and a heuristic search strategy. CFS was evaluated by experiments on artificial and natural datasets. Three machine learning algorithms were used: C4.5 (a decision tree learner), IB1 (an instance based learner), and naive Bayes. Experiments on artificial datasets showed that CFS quickly identifies and screens irrelevant, redundant, and noisy features, and identifies relevant features as long as their relevance does not strongly depend on other features. On natural domains, CFS typically eliminated well over half the features. In most cases, classification accuracy using the reduced feature set equaled or bettered accuracy using the complete feature set. Feature selection degraded machine learning performance in cases where some features were eliminated which were highly predictive of very small areas of the instance space. Further experiments compared CFS with a wrapper—a well known approach to feature selection that employs the target learning algorithm to evaluate feature sets. In many cases CFS gave comparable results to the wrapper, and in general, outperformed the wrapper on small datasets. CFS executes many times faster than the wrapper, which allows it to scale to larger datasets. Two methods of extending CFS to handle feature interaction are presented and experimentally evaluated. The first considers pairs of features and the second incorporates iii feature weights calculated by the RELIEF algorithm. Experiments on artificial domains showed that both methods were able to identify interacting features. On natural domains, the pairwise method gave more reliable results than using weights provided by RELIEF.",2003,111,3636,443,False,Computer Science,118860642,M. Hall,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21dfbc88b21b27fe8a245ab1df98edd45f655ae7,https://www.semanticscholar.org/paper/21dfbc88b21b27fe8a245ab1df98edd45f655ae7,Machine Learning in Medicine,"Machine Learning in Medicine In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. The...",2019,0,702,9,False,Medicine,8638650,A. Rajkomar,2056947059.0,Jeffrey Dean,1740538.0,I. Kohane,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
9583ac53a19cdf0db81fef6eb0b63e66adbe2324,https://www.semanticscholar.org/paper/9583ac53a19cdf0db81fef6eb0b63e66adbe2324,Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent,"We study the resilience to Byzantine failures of distributed implementations of Stochastic Gradient Descent (SGD). So far, distributed machine learning frameworks have largely ignored the possibility of failures, especially arbitrary (i.e., Byzantine) ones. Causes of failures include software bugs, network asynchrony, biases in local datasets, as well as attackers trying to compromise the entire system. Assuming a set of n workers, up to f being Byzantine, we ask how resilient can SGD be, without limiting the dimension, nor the size of the parameter space. We first show that no gradient aggregation rule based on a linear combination of the vectors proposed by the workers (i.e, current approaches) tolerates a single Byzantine failure. We then formulate a resilience property of the aggregation rule capturing the basic requirements to guarantee convergence despite f Byzantine workers. We propose Krum, an aggregation rule that satisfies our resilience property, which we argue is the first provably Byzantine-resilient algorithm for distributed SGD. We also report on experimental evaluations of Krum.",2017,34,649,209,False,Computer Science,3094352,P. Blanchard,9623412.0,El Mahdi El Mhamdi,1727558.0,R. Guerraoui,1718150.0,J. Stainer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46c266b3d1274dacd7fce27ee8cb4d587f087a58,https://www.semanticscholar.org/paper/46c266b3d1274dacd7fce27ee8cb4d587f087a58,Machine Learning Interpretability: A Survey on Methods and Metrics,"Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.",2019,147,534,24,True,Computer Science,33791144,D. V. Carvalho,35153466.0,E. M. Pereira,3698192.0,Jaime S. Cardoso,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57fdd4d1b69e7640c54eef4e8fbba2beb6449019,https://www.semanticscholar.org/paper/57fdd4d1b69e7640c54eef4e8fbba2beb6449019,"Definitions, methods, and applications in interpretable machine learning","Significance The recent surge in interpretability research has led to confusion on numerous fronts. In particular, it is unclear what it means to be interpretable and how to select, evaluate, or even discuss methods for producing interpretations of machine-learning models. We aim to clarify these concerns by defining interpretable machine learning and constructing a unifying framework for existing methods which highlights the underappreciated role played by human audiences. Within this framework, methods are organized into 2 classes: model based and post hoc. To provide guidance in selecting and evaluating interpretation methods, we introduce 3 desiderata: predictive accuracy, descriptive accuracy, and relevancy. Using our framework, we review existing work, grounded in real-world studies which exemplify our desiderata, and suggest directions for future work. Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.",2019,113,562,14,True,Computer Science,144585578,W. James Murdoch,145229121.0,Chandan Singh,19225295.0,Karl Kumbier,1405625449.0,R. Abbasi-Asl,2116415778.0,Bin Yu,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
638e41912f314c74436205aa8d332dca963ab1dc,https://www.semanticscholar.org/paper/638e41912f314c74436205aa8d332dca963ab1dc,Parameterized quantum circuits as machine learning models,"Hybrid quantum–classical systems make it possible to utilize existing quantum computers to their fullest extent. Within this framework, parameterized quantum circuits can be regarded as machine learning models with remarkable expressive power. This Review presents the components of these models and discusses their application to a variety of data-driven tasks, such as supervised learning and generative modeling. With an increasing number of experimental demonstrations carried out on actual quantum hardware and with software being actively developed, this rapidly growing field is poised to have a broad spectrum of real-world applications.",2019,182,361,21,False,Physics,3468759,M. Benedetti,39853731.0,Erika Lloyd,2071662750.0,Stefan H. Sack,103837672.0,Mattia Fiorentini,,,,,,,,,Computer Science,,,,,,,Mathematics,,,,,,,,,,,,,
ec6200bdcc23b79a71555962cde50306c4029f1a,https://www.semanticscholar.org/paper/ec6200bdcc23b79a71555962cde50306c4029f1a,Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization,"Hyperparameters are important for machine learning algorithms since they directly control the behaviors of training algorithms and have a significant effect on the performance of machine learning models. Several techniques have been developed and successfully applied for certain application domains. However, this work demands professional knowledge and expert experience. And sometimes it has to resort to the brute-force search. Therefore, if an efficient hyperparameter optimization algorithm can be developed to optimize any given machine learning method, it will greatly improve the efficiency of machine learning. In this paper, we consider building the relationship between the performance of the machine learning models and their hyperparameters by Gaussian processes. In this way, the hyperparameter tuning problem can be abstracted as an optimization problem and Bayesian optimization is used to solve the problem. Bayesian optimization is based on the Bayesian theorem. It sets a prior over the optimization function and gathers the information from the previous sample to update the posterior of the optimization function. A utility function selects the next sample point to maximize the optimization function. Several experiments were conducted on standard test datasets. Experiment results show that the proposed method can find the best hyperparameters for the widely used machine learning models, such as the random forest algorithm and the neural networks, even multi-grained cascade forest under the consideration of time cost.",2019,31,323,17,False,Computer Science,153171583,Jia Wu,2109243152.0,Xiuyun Chen,1682058.0,H. Zhang,2068236437.0,Li-Dong Xiong,1878461.0,Hang Lei,48136123.0,S. Deng,,,,,,,,,,,,,,,,,,,,,,,,,
d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c,https://www.semanticscholar.org/paper/d294d5246e0dd8ed8bd9ec9d24a01fd4ece4fb3c,A Detailed Investigation and Analysis of Using Machine Learning Techniques for Intrusion Detection,"Intrusion detection is one of the important security problems in todays cyber world. A significant number of techniques have been developed which are based on machine learning approaches. However, they are not very successful in identifying all types of intrusions. In this paper, a detailed investigation and analysis of various machine learning techniques have been carried out for finding the cause of problems associated with various machine learning techniques in detecting intrusive activities. Attack classification and mapping of the attack features is provided corresponding to each attack. Issues which are related to detecting low-frequency attacks using network attack dataset are also discussed and viable methods are suggested for improvement. Machine learning techniques have been analyzed and compared in terms of their detection capability for detecting the various category of attacks. Limitations associated with each category of them are also discussed. Various data mining tools for machine learning have also been included in the paper. At the end, future directions are provided for attack detection using machine learning techniques.",2019,184,288,21,False,Computer Science,4268597,P. Mishra,1693037.0,V. Varadharajan,1707996.0,U. Tupakula,2371703.0,E. Pilli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f,https://www.semanticscholar.org/paper/a42e380e1b8aafecb3b1e338a8a9a579c6a5a40f,A Survey of Machine Learning Techniques Applied to Software Defined Networking (SDN): Research Issues and Challenges,"In recent years, with the rapid development of current Internet and mobile communication technologies, the infrastructure, devices and resources in networking systems are becoming more complex and heterogeneous. In order to efficiently organize, manage, maintain and optimize networking systems, more intelligence needs to be deployed. However, due to the inherently distributed feature of traditional networks, machine learning techniques are hard to be applied and deployed to control and operate networks. Software defined networking (SDN) brings us new chances to provide intelligence inside the networks. The capabilities of SDN (e.g., logically centralized control, global view of the network, software-based traffic analysis, and dynamic updating of forwarding rules) make it easier to apply machine learning techniques. In this paper, we provide a comprehensive survey on the literature involving machine learning algorithms applied to SDN. First, the related works and background knowledge are introduced. Then, we present an overview of machine learning algorithms. In addition, we review how machine learning algorithms are applied in the realm of SDN, from the perspective of traffic classification, routing optimization, quality of service/quality of experience prediction, resource management and security. Finally, challenges and broader perspectives are discussed.",2019,255,284,14,False,Computer Science,153741316,Jun-feng Xie,1696615.0,F. Yu,102628601.0,Tao Huang,144814372.0,Renchao Xie,2119611603.0,Jiang Liu,3334549.0,Chen-meng Wang,2117417872.0,Yunjie Liu,,,,,,,,,,,,,,,,,,,,,,,
ac644a74a0ebc8cfbe1b0af8120004909828d283,https://www.semanticscholar.org/paper/ac644a74a0ebc8cfbe1b0af8120004909828d283,Adversarial attacks on medical machine learning,"Emerging vulnerabilities demand new conversations With public and academic attention increasingly focused on the new role of machine learning in the health information economy, an unusual and no-longer-esoteric category of vulnerabilities in machine-learning systems could prove important. These vulnerabilities allow a small, carefully designed change in how inputs are presented to a system to completely alter its output, causing it to confidently arrive at manifestly wrong conclusions. These advanced techniques to subvert otherwise-reliable machine-learning systems—so-called adversarial attacks—have, to date, been of interest primarily to computer science researchers (1). However, the landscape of often-competing interests within health care, and billions of dollars at stake in systems' outputs, implies considerable problems. We outline motivations that various players in the health care system may have to use adversarial attacks and begin a discussion of what to do about them. Far from discouraging continued innovation with medical machine learning, we call for active engagement of medical, technical, legal, and ethical experts in pursuit of efficient, broadly available, and effective health care that machine learning will enable.",2019,9,437,7,False,Computer Science,50478054,S. G. Finlayson,2066570629.0,John Bowers,35553861.0,Joichi Ito,46714697.0,J. Zittrain,143649421.0,Andrew Beam,1740538.0,I. Kohane,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
fbf9812f29156024ec693b4633a21303eead309d,https://www.semanticscholar.org/paper/fbf9812f29156024ec693b4633a21303eead309d,Machine learning algorithm validation with a limited sample size,"Advances in neuroimaging, genomic, motion tracking, eye-tracking and many other technology-based data collection methods have led to a torrent of high dimensional datasets, which commonly have a small number of samples because of the intrinsic high cost of data collection involving human participants. High dimensional data with a small number of samples is of critical importance for identifying biomarkers and conducting feasibility and pilot work, however it can lead to biased machine learning (ML) performance estimates. Our review of studies which have applied ML to predict autistic from non-autistic individuals showed that small sample size is associated with higher reported classification accuracy. Thus, we have investigated whether this bias could be caused by the use of validation methods which do not sufficiently control overfitting. Our simulations show that K-fold Cross-Validation (CV) produces strongly biased performance estimates with small sample sizes, and the bias is still evident with sample size of 1000. Nested CV and train/test split approaches produce robust and unbiased performance estimates regardless of sample size. We also show that feature selection if performed on pooled training and testing data is contributing to bias considerably more than parameter tuning. In addition, the contribution to bias by data dimensionality, hyper-parameter space and number of CV folds was explored, and validation methods were compared with discriminable data. The results suggest how to design robust testing methodologies when working with small datasets and how to interpret the results of other studies based on what validation method was used.",2019,33,382,7,True,Medicine,8452323,A. Vabalas,2283643.0,E. Gowen,2910758.0,E. Poliakoff,1807736.0,A. Casson,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
97f4a6f87f258053f2677504647696f1803c6794,https://www.semanticscholar.org/paper/97f4a6f87f258053f2677504647696f1803c6794,How to Read Articles That Use Machine Learning: Users' Guides to the Medical Literature.,"In recent years, many new clinical diagnostic tools have been developed using complicated machine learning methods. Irrespective of how a diagnostic tool is derived, it must be evaluated using a 3-step process of deriving, validating, and establishing the clinical effectiveness of the tool. Machine learning-based tools should also be assessed for the type of machine learning model used and its appropriateness for the input data type and data set size. Machine learning models also generally have additional prespecified settings called hyperparameters, which must be tuned on a data set independent of the validation set. On the validation set, the outcome against which the model is evaluated is termed the reference standard. The rigor of the reference standard must be assessed, such as against a universally accepted gold standard or expert grading.",2019,36,237,9,False,Medicine,2118113191,Yun Liu,1406206167.0,Po-Hsuan Cameron Chen,2058373914.0,Jonathan Krause,49506408.0,L. Peng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b5461f9c5d65e87561e00848921ee797902dae14,https://www.semanticscholar.org/paper/b5461f9c5d65e87561e00848921ee797902dae14,Causality for Machine Learning,"Graphical causal inference as pioneered by Judea Pearl arose from research on artiﬁcial intelligence (AI), and for a long time had little connection to the ﬁeld of machine learning. This article discusses where links have been and should be established, introducing key concepts along the way. It argues that the hard open problems of machine learning and AI are intrinsically related to causality, and explains how the ﬁeld is beginning to understand them.",2019,134,236,16,True,Computer Science,4080509,B. Scholkopf,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
236dfdeb4511754cf71ba220ac569b11973502cd,https://www.semanticscholar.org/paper/236dfdeb4511754cf71ba220ac569b11973502cd,Machine Learning and Deep Learning Methods for Intrusion Detection Systems: A Survey,"Networks play important roles in modern life, and cyber security has become a vital research area. An intrusion detection system (IDS) which is an important cyber security technique, monitors the state of software and hardware running in the network. Despite decades of development, existing IDSs still face challenges in improving the detection accuracy, reducing the false alarm rate and detecting unknown attacks. To solve the above problems, many researchers have focused on developing IDSs that capitalize on machine learning methods. Machine learning methods can automatically discover the essential differences between normal data and abnormal data with high accuracy. In addition, machine learning methods have strong generalizability, so they are also able to detect unknown attacks. Deep learning is a branch of machine learning, whose performance is remarkable and has become a research hotspot. This survey proposes a taxonomy of IDS that takes data objects as the main dimension to classify and summarize machine learning-based and deep learning-based IDS literature. We believe that this type of taxonomy framework is fit for cyber security researchers. The survey first clarifies the concept and taxonomy of IDSs. Then, the machine learning algorithms frequently used in IDSs, metrics, and benchmark datasets are introduced. Next, combined with the representative literature, we take the proposed taxonomic system as a baseline and explain how to solve key IDS issues with machine learning and deep learning techniques. Finally, challenges and future developments are discussed by reviewing recent representative studies.",2019,97,236,11,True,Engineering,2145593249,Hongyu Liu,2055226664.0,Bo Lang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dab261b25ff8ccd2c9144a5cb3a46b39ac0ac4bd,https://www.semanticscholar.org/paper/dab261b25ff8ccd2c9144a5cb3a46b39ac0ac4bd,Troubling Trends in Machine Learning Scholarship,"Flawed scholarship threatens to mislead the public and stymie future research by compromising ML’s intellectual foundations. Indeed, many of these problems have recurred cyclically throughout the history of AI and, more broadly, in scientific research. In 1976, Drew McDermott chastised the AI community for abandoning self-discipline, warning prophetically that ""if we can’t criticize ourselves, someone else will save us the trouble."" The current strength of machine learning owes to a large body of rigorous research to date, both theoretical and empirical. By promoting clear scientific thinking and communication, our community can sustain the trust and investment it currently enjoys.",2018,89,222,8,True,Computer Science,32219137,Zachary Chase Lipton,5164568.0,J. Steinhardt,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
18aaf8664bbae17a7d20bcb422c36e5d52201aa5,https://www.semanticscholar.org/paper/18aaf8664bbae17a7d20bcb422c36e5d52201aa5,Machine learning-assisted directed protein evolution with combinatorial libraries,"Significance Proteins often function poorly when used outside their natural contexts; directed evolution can be used to engineer them to be more efficient in new roles. We propose that the expense of experimentally testing a large number of protein variants can be decreased and the outcome can be improved by incorporating machine learning with directed evolution. Simulations on an empirical fitness landscape demonstrate that the expected performance improvement is greater with this approach. Machine learning-assisted directed evolution from a single parent produced enzyme variants that selectively synthesize the enantiomeric products of a new-to-nature chemical transformation. By exploring multiple mutations simultaneously, machine learning efficiently navigates large regions of sequence space to identify improved proteins and also produces diverse solutions to engineering problems. To reduce experimental effort associated with directed protein evolution and to explore the sequence space encoded by mutating multiple positions simultaneously, we incorporate machine learning into the directed evolution workflow. Combinatorial sequence space can be quite expensive to sample experimentally, but machine-learning models trained on tested variants provide a fast method for testing sequence space computationally. We validated this approach on a large published empirical fitness landscape for human GB1 binding protein, demonstrating that machine learning-guided directed evolution finds variants with higher fitness than those found by other directed evolution approaches. We then provide an example application in evolving an enzyme to produce each of the two possible product enantiomers (i.e., stereodivergence) of a new-to-nature carbene Si–H insertion reaction. The approach predicted libraries enriched in functional enzymes and fixed seven mutations in two rounds of evolution to identify variants for selective catalysis with 93% and 79% ee (enantiomeric excess). By greatly increasing throughput with in silico modeling, machine learning enhances the quality and diversity of sequence solutions for a protein engineering problem.",2019,53,233,5,True,Biology,51125091,Zachary Wu,145934550.0,S. Kan,144475958.0,Russell D. Lewis,8641455.0,Bruce J. Wittmann,2795724.0,F. Arnold,,,,,,,Computer Science,,,,,,,Medicine,,,,,Chemistry,,,,,,,,
8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8,https://www.semanticscholar.org/paper/8b27e2fafbe24cf9ce24f308a7e746489ff0dfb8,Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification,"Summary: State‐of‐the‐art light and electron microscopes are capable of acquiring large image datasets, but quantitatively evaluating the data often involves manually annotating structures of interest. This process is time‐consuming and often a major bottleneck in the evaluation pipeline. To overcome this problem, we have introduced the Trainable Weka Segmentation (TWS), a machine learning tool that leverages a limited number of manual annotations in order to train a classifier and segment the remaining data automatically. In addition, TWS can provide unsupervised segmentation learning schemes (clustering) and can be customized to employ user‐designed image features or classifiers. Availability and Implementation: TWS is distributed as open‐source software as part of the Fiji image processing distribution of ImageJ at http://imagej.net/Trainable_Weka_Segmentation. Contact: ignacio.arganda@ehu.eus Supplementary information: Supplementary data are available at Bioinformatics online.",2017,8,1051,50,True,Computer Science,1398461214,Ignacio Arganda-Carreras,2129065.0,V. Kaynig,1680265.0,C. Rueden,2504157.0,K. Eliceiri,3032174.0,Johannes E. Schindelin,145844120.0,A. Cardona,144924970.0,H. Seung,,,Medicine,,,,,,,,,,,,,,,,,,,,
3784b73a1f392160523400ec0309191c0a96d86f,https://www.semanticscholar.org/paper/3784b73a1f392160523400ec0309191c0a96d86f,MLlib: Machine Learning in Apache Spark,"Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.",2015,34,1567,171,False,Computer Science,39309572,Xiangrui Meng,2086593199.0,Joseph K. Bradley,2065287033.0,Burak Yavuz,144752747.0,Evan R. Sparks,2697906.0,S. Venkataraman,2536434.0,Davies Liu,2114973651.0,Jeremy Freeman,2064759911.0,D. B. Tsai,Mathematics,2089931559.0,Manish Amde,2060860697.0,Sean Owen,40413768.0,Doris Xin,,2066641.0,Reynold Xin,143666627.0,M. Franklin,,5985064.0,R. Zadeh,143834867.0,M. Zaharia,145532827.0,Ameet S. Talwalkar,,
b3ea2d9c8e5ea3b87ace121f0bece71565abc187,https://www.semanticscholar.org/paper/b3ea2d9c8e5ea3b87ace121f0bece71565abc187,Quantifying the Carbon Emissions of Machine Learning,"From an environmental standpoint, there are a few crucial aspects of training a neural network that have a major impact on the quantity of carbon that it emits. These factors include: the location of the server used for training and the energy grid that it uses, the length of the training procedure, and even the make and model of hardware on which the training takes place. In order to approximate these emissions, we present our Machine Learning Emissions Calculator, a tool for our community to better understand the environmental impact of training ML models. We accompany this tool with an explanation of the factors cited above, as well as concrete actions that individual practitioners and organizations can take to mitigate their carbon emissions.",2019,24,216,16,False,Computer Science,8651990,Alexandre Lacoste,2993731.0,A. Luccioni,97574153.0,V. Schmidt,2526021.0,Thomas Dandres,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62ccd99a65bfc7c735ae1f33b75b107665de95df,https://www.semanticscholar.org/paper/62ccd99a65bfc7c735ae1f33b75b107665de95df,Federated Machine Learning,"Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.",2019,75,773,16,False,Computer Science,152290618,Qiang Yang,40457423.0,Yang Liu,11573257.0,Tianjian Chen,8230559.0,Yongxin Tong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d0ab11de3077490c80a08abd0fb8827bac84c454,https://www.semanticscholar.org/paper/d0ab11de3077490c80a08abd0fb8827bac84c454,MoleculeNet: A Benchmark for Molecular Machine Learning,"Molecular machine learning has been maturing rapidly over the last few years. Improved methods and the presence of larger datasets have enabled machine learning algorithms to make increasingly accurate predictions about molecular properties. However, algorithmic progress has been limited due to the lack of a standard benchmark to compare the efficacy of proposed methods; most new algorithms are benchmarked on different datasets making it challenging to gauge the quality of proposed methods. This work introduces MoleculeNet, a large scale benchmark for molecular machine learning. MoleculeNet curates multiple public datasets, establishes metrics for evaluation, and offers high quality open-source implementations of multiple previously proposed molecular featurization and learning algorithms (released as part of the DeepChem open source library). MoleculeNet benchmarks demonstrate that learnable representations are powerful tools for molecular machine learning and broadly offer the best performance. However, this result comes with caveats. Learnable representations still struggle to deal with complex tasks under data scarcity and highly imbalanced classification. For quantum mechanical and biophysical datasets, the use of physics-aware featurizations can be more important than choice of particular learning algorithm.",2017,36,787,154,False,Computer Science,9957625,Zhenqin Wu,2378027.0,Bharath Ramsundar,5932099.0,Evan N. Feinberg,145986494.0,Joseph Gomes,9959840.0,Caleb Geniesse,5929246.0,Aneesh S. Pappu,40867019.0,K. Leswing,1806271.0,V. Pande,,,,,,,,,,,,,,,,,,,,,
6e23398447a022fb9495c44fa80e9de593a574bc,https://www.semanticscholar.org/paper/6e23398447a022fb9495c44fa80e9de593a574bc,Machine Learning in Agriculture: A Review,"Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.",2018,117,878,19,True,Medicine,2752858,Konstantinos G. Liakos,3375011.0,P. Busato,3201660.0,D. Moshou,145802955.0,S. Pearson,2345652.0,D. Bochtis,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
5c7e5248d9eb7f373f10277410bf8506160907ea,https://www.semanticscholar.org/paper/5c7e5248d9eb7f373f10277410bf8506160907ea,All-optical machine learning using diffractive deep neural networks,"All-optical deep learning Deep learning uses multilayered artificial neural networks to learn digitally from large datasets. It then performs advanced identification and classification tasks. To date, these multilayered neural networks have been implemented on a computer. Lin et al. demonstrate all-optical machine learning that uses passive optical components that can be patterned and fabricated with 3D-printing. Their hardware approach comprises stacked layers of diffractive optical elements analogous to an artificial neural network that can be trained to execute complex functions at the speed of light. Science, this issue p. 1004 All-optical deep learning can be implemented with 3D-printed passive optical components. Deep learning has been transforming our ability to execute advanced inference tasks using computers. Here we introduce a physical mechanism to perform machine learning by demonstrating an all-optical diffractive deep neural network (D2NN) architecture that can implement various functions following the deep learning–based design of passive diffractive layers that work collectively. We created 3D-printed D2NNs that implement classification of images of handwritten digits and fashion products, as well as the function of an imaging lens at a terahertz spectrum. Our all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can execute; will find applications in all-optical image analysis, feature detection, and object classification; and will also enable new camera designs and optical components that perform distinctive tasks using D2NNs.",2018,52,741,37,True,Computer Science,143746845,Xing Lin,48156295.0,Y. Rivenson,3913651.0,N. T. Yardimci,4901769.0,Muhammed Veli,5602194.0,Yilin Luo,2146359.0,M. Jarrahi,2660014.0,A. Ozcan,,,Physics,,,,,,,Medicine,,,,,,,,,,,,,
88a97c8ef539589c55a6fe869c243792e470d6a3,https://www.semanticscholar.org/paper/88a97c8ef539589c55a6fe869c243792e470d6a3,Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective,"Machine learning sits at the core of many essential products and services at Facebook. This paper describes the hardware and software infrastructure that supports machine learning at global scale. Facebook's machine learning workloads are extremely diverse: services require many different types of models in practice. This diversity has implications at all layers in the system stack. In addition, a sizable fraction of all data stored at Facebook flows through machine learning pipelines, presenting significant challenges in delivering data to high-performance distributed training flows. Computational requirements are also intense, leveraging both GPU and CPU platforms for training and abundant CPU capacity for real-time inference. Addressing these and other emerging challenges continues to require diverse efforts that span machine learning algorithms, software, and hardware design.",2018,19,409,38,False,Computer Science,1775500,Kim M. Hazelwood,145583374.0,Sarah Bird,1896817.0,D. Brooks,2127604.0,Soumith Chintala,40863835.0,Utku Diril,40858378.0,Dmytro Dzhulgakov,2133743548.0,Mohamed Fawzy,33920592.0,Bill Jia,,39978391.0,Yangqing Jia,10774798.0,Aditya Kalro,2057766961.0,James Law,,2110234018.0,Kevin Lee,2159321510.0,Jason Lu,,34837514.0,P. Noordhuis,1711231.0,M. Smelyanskiy,2068237821.0,Liang Xiong,2108429236.0,Xiaodong Wang
efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695,https://www.semanticscholar.org/paper/efd7b7aafeb83b8a8d6fd90a35d6fb6a62f5f695,Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning,"As machine learning becomes widely used for automated decisions, attackers have strong incentives to manipulate the results and models generated by machine learning algorithms. In this paper, we perform the first systematic study of poisoning attacks and their countermeasures for linear regression models. In poisoning attacks, attackers deliberately influence the training data to manipulate the results of a predictive model. We propose a theoretically-grounded optimization framework specifically designed for linear regression and demonstrate its effectiveness on a range of datasets and models. We also introduce a fast statistical attack that requires limited knowledge of the training process. Finally, we design a new principled defense method that is highly resilient against all poisoning attacks. We provide formal guarantees about its convergence and an upper bound on the effect of poisoning attacks when the defense is deployed. We evaluate extensively our attacks and defenses on three realistic datasets from health care, loan assessment, and real estate domains.",2018,56,434,35,True,Computer Science,40844378,Matthew Jagielski,3046437.0,Alina Oprea,1684175.0,B. Biggio,2118484076.0,Chang Liu,1398550766.0,C. Nita-Rotaru,2165247199.0,Bo Li,,,,,,,,,,,,,,,,,,,,,,,,,
960ba564e9e598d864dff38d2f3d0bad1b319ead,https://www.semanticscholar.org/paper/960ba564e9e598d864dff38d2f3d0bad1b319ead,A Survey of Machine Learning for Big Code and Naturalness,"Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.",2017,215,551,32,True,Computer Science,3216345,Miltiadis Allamanis,1757975.0,Earl T. Barr,1730296.0,Premkumar T. Devanbu,37210858.0,Charles Sutton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b9518627db25f05930e931f56497602363a75491,https://www.semanticscholar.org/paper/b9518627db25f05930e931f56497602363a75491,"Interpretable machine learning: definitions, methods, and applications","M learning (ML) has recently received considerable attention for its ability to accurately predict a wide variety of complex phenomena. However, there is a growing realization that, in addition to predictions, ML models are capable of producing knowledge about domain relationships contained in data, often referred to as interpretations. These interpretations have found uses both in their own right, e.g. medicine (1), policy-making (2), and science (3, 4), as well as in auditing the predictions themselves in response to issues such as regulatory pressure (5) and fairness (6). In the absence of a well-formed definition of interpretability, a broad range of methods with a correspondingly broad range of outputs (e.g. visualizations, natural language, mathematical equations) have been labeled as interpretation. This has led to considerable confusion about the notion of interpretability. In particular, it is unclear what it means to interpret something, what common threads exist among disparate methods, and how to select an interpretation method for a particular problem/audience. In this paper, we attempt to address these concerns. To do so, we first define interpretability in the context of machine learning and place it within a generic data science life cycle. This allows us to distinguish between two main classes of interpretation methods: model-based∗ and post hoc. We then introduce the Predictive, Descriptive, Relevant (PDR) framework, consisting of three desiderata for evaluating and constructing interpretations: predictive accuracy, descriptive",2019,94,317,10,True,Mathematics,144585578,W. James Murdoch,145229121.0,Chandan Singh,19225295.0,Karl Kumbier,1405625449.0,R. Abbasi-Asl,144923779.0,Bin Yu,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
05d20fda297c9afb347214bd1693bd049674e0c6,https://www.semanticscholar.org/paper/05d20fda297c9afb347214bd1693bd049674e0c6,Machine Learning for the Geosciences: Challenges and Opportunities,"Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML)—that has been widely successful in commercial domains—offers immense potential to contribute to problems in geosciences. However, geoscience applications introduce novel challenges for ML due to combinations of geoscience properties encountered in every problem, requiring novel research in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their common properties. We then describe some of the common categories of geoscience problems where machine learning can play a role, discussing the challenges faced by existing ML methods and opportunities for novel ML research. We conclude by discussing some of the cross-cutting research themes in machine learning that are applicable across several geoscience problems, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.",2017,128,201,6,True,Computer Science,2548167,A. Karpatne,1405321572.0,I. Ebert‐Uphoff,1753019.0,S. Ravela,30160005.0,H. Babaie,2107978833.0,Vipin Kumar,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
e9239469aba4bccf3e36d1c27894721e8dbefc44,https://www.semanticscholar.org/paper/e9239469aba4bccf3e36d1c27894721e8dbefc44,Foundations of Machine Learning,"This graduate-level textbook introduces fundamental concepts and methods in machine learning. It describes several important modern algorithms, provides the theoretical underpinnings of these algorithms, and illustrates key aspects for their application. The authors aim to present novel theoretical tools and concepts while giving concise proofs even for relatively advanced topics. Foundations of Machine Learning fills the need for a general textbook that also offers theoretical details and an emphasis on proofs. Certain topics that are often treated with insufficient attention are discussed in more detail here; for example, entire chapters are devoted to regression, multi-class classification, and ranking. The first three chapters lay the theoretical foundation for what follows, but each remaining chapter is mostly self-contained. The appendix offers a concise probability review, a short introduction to convex optimization, tools for concentration bounds, and several basic properties of matrices and norms used in the book. The book is intended for graduate students and researchers in machine learning, statistics, and related areas; it can be used either as a textbook or as a reference text for a research seminar.",2012,231,2512,306,False,Computer Science,81080659,M. Mohri,2435268.0,Afshin Rostamizadeh,145532827.0,Ameet S. Talwalkar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eed9fa4483cab37eacd59db0fac4b1441431ee85,https://www.semanticscholar.org/paper/eed9fa4483cab37eacd59db0fac4b1441431ee85,Tensor Decomposition for Signal Processing and Machine Learning,"Tensors or <italic>multiway arrays</italic> are functions of three or more indices <inline-formula> <tex-math notation=""LaTeX"">$(i,j,k,\ldots)$</tex-math></inline-formula>—similar to matrices (two-way arrays), which are functions of two indices <inline-formula><tex-math notation=""LaTeX"">$(r,c)$</tex-math></inline-formula> for (row, column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining, and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth <italic>and depth</italic> that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some background in applied optimization is useful but not strictly required. The material covered includes tensor rank and rank decomposition; basic tensor factorization models and their relationships and properties (including fairly good coverage of identifiability); broad coverage of algorithms ranging from alternating optimization to stochastic gradient; statistical performance analysis; and applications ranging from source separation to collaborative filtering, mixture and topic modeling, classification, and multilinear subspace learning.",2016,165,969,67,False,Computer Science,73776482,N. Sidiropoulos,2217213.0,L. Lathauwer,144406546.0,Xiao Fu,2349460.0,Kejun Huang,3000659.0,E. Papalexakis,1702392.0,C. Faloutsos,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
9d75cc322a4e06d0a3a868cb91b04219a289c12c,https://www.semanticscholar.org/paper/9d75cc322a4e06d0a3a868cb91b04219a289c12c,Machine Learning: An Applied Econometric Approach,"Machines are increasingly doing ""intelligent"" things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.",2017,252,982,66,True,Computer Science,2062143,S. Mullainathan,47281276.0,Jann Spiess,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
033f25ad905ef2ed32a8331cf38b83953ff15922,https://www.semanticscholar.org/paper/033f25ad905ef2ed32a8331cf38b83953ff15922,A Review of Relational Machine Learning for Knowledge Graphs,"Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be “trained” on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive data sets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's knowledge vault project as an example of such combination.",2015,156,1218,121,False,Computer Science,1729762,Maximilian Nickel,1702318.0,K. Murphy,1700754.0,Volker Tresp,1718798.0,E. Gabrilovich,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
4f2baff3195b6fc43a38e3e869496dab9fe9dbc3,https://www.semanticscholar.org/paper/4f2baff3195b6fc43a38e3e869496dab9fe9dbc3,Delayed Impact of Fair Machine Learning,"Static classification has been the predominant focus of the study of fairness in machine learning. While most models do not consider how decisions change populations over time, it is conventional wisdom that fairness criteria promote the long-term well-being of groups they aim to protect. This work studies the interaction of static fairness criteria with temporal indicators of well-being. We show a simple one-step feedback model in which common criteria do not generally promote improvement over time, and may in fact cause harm. Our results highlight the importance of temporal modeling in the evaluation of fairness criteria, suggesting a range of new challenges and trade-offs.",2018,34,312,26,True,Computer Science,1748108610,Lydia T. Liu,1491339790.0,Sarah Dean,144322309.0,Esther Rolf,3385674.0,Max Simchowitz,1775622.0,Moritz Hardt,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
78aa018ee7d52360e15d103390ea1cdb3a0beb41,https://www.semanticscholar.org/paper/78aa018ee7d52360e15d103390ea1cdb3a0beb41,Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples,"Many machine learning models are vulnerable to adversarial examples: inputs that are specially crafted to cause a machine learning model to produce an incorrect output. Adversarial examples that affect one model often affect another model, even if the two models have different architectures or were trained on different training sets, so long as both models were trained to perform the same task. An attacker may therefore train their own substitute model, craft adversarial examples against the substitute, and transfer them to a victim model, with very little information about the victim. Recent work has further developed a technique that uses the victim model as an oracle to label a synthetic training set for the substitute, so the attacker need not even collect a training set to mount the attack. We extend these recent techniques using reservoir sampling to greatly enhance the efficiency of the training procedure for the substitute model. We introduce new transferability attacks between previously unexplored (substitute, victim) pairs of machine learning model classes, most notably SVMs and decision trees. We demonstrate our attacks on two commercial machine learning classification systems from Amazon (96.19% misclassification rate) and Google (88.94%) using only 800 queries of the victim model, thereby showing that existing machine learning approaches are in general vulnerable to systematic black-box attacks regardless of their structure.",2016,34,1277,103,False,Computer Science,1967156,Nicolas Papernot,144061974.0,P. Mcdaniel,153440022.0,Ian J. Goodfellow,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7c63a6e6d3b31b14ae4236bfbd574ea37cab18a7,https://www.semanticscholar.org/paper/7c63a6e6d3b31b14ae4236bfbd574ea37cab18a7,Choosing Prediction Over Explanation in Psychology: Lessons From Machine Learning,"Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology’s near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.",2017,117,887,50,True,Psychology,2075675,T. Yarkoni,48804181.0,Jacob Westfall,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
2aadb938af2f77a6ad9321ff873c1c9b9a579fcb,https://www.semanticscholar.org/paper/2aadb938af2f77a6ad9321ff873c1c9b9a579fcb,A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection,"Cyber security is that the body of technologies, processes and practices designed to safeguard networks, computers, programs and knowledge from attack, harm or unauthorized access. During a computing context, the term security implies cyber security. This survey paper describes a targeted literature survey of machine learning (ML) and data processing (DM) strategies for cyber analytics in support of intrusion detection. This paper focuses totally on cyber intrusion detection as it applies to wired networks. With a wired network, associate oppose must experience many layers of defense at firewalls and operative systems, or gain physical access to the network. The quality of ML/DM algorithms is addressed, discussion of challenges for victimization ML/DM for cyber security is conferred, and some recommendations on once to use a given methodology area unit provided.",2017,13,851,70,False,Engineering,100818765,Lalu Banoth,70392354.0,M. S. Teja,2102149819.0,M. Saicharan,143612469.0,N. Chandra,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0359bba5112d472206d82ddb29947f2d634bb0cc,https://www.semanticscholar.org/paper/0359bba5112d472206d82ddb29947f2d634bb0cc,Introduction to machine learning,"The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. In order to present a unified treatment of machine learning problems and solutions, it discusses many methods from different fields, including statistics, pattern recognition, neural networks, artificial intelligence, signal processing, control, and data mining. All learning algorithms are explained so that the student can easily move from the equations in the book to a computer program. The text covers such topics as supervised learning, Bayesian decision theory, parametric methods, multivariate methods, multilayer perceptrons, local models, hidden Markov models, assessing and comparing classification algorithms, and reinforcement learning. New to the second edition are chapters on kernel machines, graphical models, and Bayesian estimation; expanded coverage of statistical tests in a chapter on design and analysis of machine learning experiments; case studies available on the Web (with downloadable results for instructors); and many additional exercises. All chapters have been revised and updated. Introduction to Machine Learning can be used by advanced undergraduates and graduate students who have completed courses in computer programming, probability, calculus, and linear algebra. It will also be of interest to engineers in the field who are concerned with the application of machine learning methods. Adaptive Computation and Machine Learning series",2004,19,3330,275,False,Computer Science,1691898,Ethem Alpaydin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c5c3fa019574988c479474c32f34debecd12e8d1,https://www.semanticscholar.org/paper/c5c3fa019574988c479474c32f34debecd12e8d1,Procedural Content Generation via Machine Learning (PCGML),"This survey explores procedural content generation via machine learning (PCGML), defined as the generation of game content using machine learning models trained on existing content. As the importance of PCG for game development increases, researchers explore new avenues for generating high-quality content with or without human involvement; this paper addresses the relatively new paradigm of using machine learning (in contrast with search-based, solver-based, and constructive methods). We focus on what is most often considered functional game content, such as platformer levels, game maps, interactive fiction stories, and cards in collectible card games, as opposed to cosmetic content, such as sprites and sound effects. In addition to using PCG for autonomous generation, cocreativity, mixed-initiative design, and compression, PCGML is suited for repair, critique, and content analysis because of its focus on modeling existing content. We discuss various data sources and representations that affect the generated content. Multiple PCGML methods are covered, including neural networks: long short-term memory networks, autoencoders, and deep convolutional networks; Markov models: $n$-grams and multi-dimensional Markov chains; clustering; and matrix factorization. Finally, we discuss open problems in PCGML, including learning from small data sets, lack of training data, multilayered learning, style-transfer, parameter tuning, and PCG as a game mechanic.",2017,112,254,35,True,Computer Science,3375548,A. Summerville,29929346.0,Sam Snodgrass,144599741.0,Matthew J. Guzdial,1757823.0,Christoffer Holmgård,48630276.0,Amy K. Hoover,2232368.0,Aaron Isaksen,3431050.0,Andy Nealen,1810053.0,J. Togelius,,,,,,,,,,,,,,,,,,,,,
59d9318f07331ec15e54fe2a4218bc4a5c247a38,https://www.semanticscholar.org/paper/59d9318f07331ec15e54fe2a4218bc4a5c247a38,Foolbox: A Python toolbox to benchmark the robustness of machine learning models,"Even todays most advanced machine learning models are easily fooled by almost imperceptible perturbations of their inputs. Foolbox is a new Python package to generate such adversarial perturbations and to quantify and compare the robustness of machine learning models. It is build around the idea that the most comparable robustness measure is the minimum perturbation needed to craft an adversarial example. To this end, Foolbox provides reference implementations of most published adversarial attack methods alongside some new ones, all of which perform internal hyperparameter tuning to find the minimum adversarial perturbation. Additionally, Foolbox interfaces with most popular deep learning frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows different adversarial criteria such as targeted misclassification and top-k misclassification as well as different distance measures. The code is licensed under the MIT license and is openly available at https://github.com/bethgelab/foolbox. The most up-to-date documentation can be found at http://foolbox.readthedocs.io. In 2013, Szegedy et al. demonstrated that minimal perturbations, often almost imperceptible to humans, can have devastating effects on machine predictions. These so-called adversarial perturbations thus demonstrate a striking difference between human and machine perception. As a result, adversarial perturbations have been subject to many Equal contribution Centre for Integrative Neuroscience, University of Tübingen, Germany Bernstein Center for Computational Neuroscience, Tübingen, Germany International Max Planck Research School for Intelligent Systems, Tübingen, Germany Max Planck Institute for Biological Cybernetics, Tübingen, Germany Institute for Theoretical Physics, University of Tübingen, Germany. Correspondence to: Jonas Rauber <jonas.rauber@bethgelab.org>. Reliable Machine Learning in the Wild Workshop, 34 th International Conference on Machine Learning, Sydney, Australia, 2017. studies concerning the generation of such perturbations and strategies to protect machine learning models such as deep neural networks against them. A practical definition of the robustness R of a model, first used by Szegedy et al. (2013), is the average size of the minimum adversarial perturbation ρ(x) across many samples x, R = 〈ρ(x)〉 x where (1) ρ(x) = min δ d(x,x+ δ) s.t. x+ δ is adversarial (2) and d(·) is some distance measure. Unfortunately, finding the global minimum adversarial perturbation is close to impossible in any practical setting, and we thus employ heuristic attacks to find a suitable approximation. Such heuristics, however, can fail, in which case we could easily be mislead to believe that a model is robust (Brendel & Bethge, 2017). Our best strategy is thus to employ as many attacks as possible, and to use the minimal perturbation found across all attacks as an approximation to the true global minimum. At the moment, however, such a strategy is severely obstructed by two problems: first, the code for most known attack methods is either not available at all, or only available for one particular deep learning framework. Second, implementations of the same attack often differ in many details and are thus not directly comparable. Foolbox improves upon the existing Python package cleverhans by Papernot et al. (2016b) in three important aspects: 1. It interfaces with most popular machine learning frameworks such as PyTorch, Keras, TensorFlow, Theano, Lasagne and MXNet and provides a straight forward way to add support for other frameworks, 2. it provides reference implementations for more than 15 adversarial attacks with a simple and consistent API, and 3. it supports many different criteria for adversarial examples, including custom ones. This technical report is structured as follows: In section 1 we provide an overview over Foolbox and demonstrate Foolbox: A Python toolbox to benchmark the robustness of machine learning models how to benchmark a model and report the result. In section 2 we describe the adversarial attack methods that are implemented in Foolbox and explain the internal hyperparameter tuning.",2017,11,354,49,False,,19237612,Jonas Rauber,40634590.0,Wieland Brendel,1731199.0,M. Bethge,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
be1496e9620089b377ef631692478f5034ee95b8,https://www.semanticscholar.org/paper/be1496e9620089b377ef631692478f5034ee95b8,Machine learning applications in epilepsy,"Machine learning leverages statistical and computer science principles to develop algorithms capable of improving performance through interpretation of data rather than through explicit instructions. Alongside widespread use in image recognition, language processing, and data mining, machine learning techniques have received increasing attention in medical applications, ranging from automated imaging analysis to disease forecasting. This review examines the parallel progress made in epilepsy, highlighting applications in automated seizure detection from electroencephalography (EEG), video, and kinetic data, automated imaging analysis and pre‐surgical planning, prediction of medication response, and prediction of medical and surgical outcomes using a wide variety of data sources. A brief overview of commonly used machine learning approaches, as well as challenges in further application of machine learning techniques in epilepsy, is also presented. With increasing computational capabilities, availability of effective machine learning algorithms, and accumulation of larger datasets, clinicians and researchers will increasingly benefit from familiarity with these techniques and the significant progress already made in their application in epilepsy.",2019,114,137,3,False,Medicine,48487599,B. Abbasi,2423726.0,D. Goldenholz,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
175e37bca3762b3a52c6a0e153060b98a251d061,https://www.semanticscholar.org/paper/175e37bca3762b3a52c6a0e153060b98a251d061,Inverse molecular design using machine learning: Generative models for matter engineering,"The discovery of new materials can bring enormous societal and technological progress. In this context, exploring completely the large space of potential materials is computationally intractable. Here, we review methods for achieving inverse design, which aims to discover tailored materials from the starting point of a particular desired functionality. Recent advances from the rapidly growing field of artificial intelligence, mostly from the subfield of machine learning, have resulted in a fertile exchange of ideas, where approaches to inverse molecular design are being proposed and employed at a rapid pace. Among these, deep generative models have been applied to numerous classes of materials: rational design of prospective drugs, synthetic routes to organic compounds, and optimization of photovoltaics and redox flow batteries, as well as a variety of other solid-state materials.",2018,93,839,12,False,Medicine,1380248978,Benjamín Sánchez-Lengeling,1380248954.0,Alán Aspuru-Guzik,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
3f22c9462f8e588ce4210a304133e2265f41d913,https://www.semanticscholar.org/paper/3f22c9462f8e588ce4210a304133e2265f41d913,Artificial Intelligence and Machine Learning in Pathology: The Present Landscape of Supervised Methods,"Increased interest in the opportunities provided by artificial intelligence and machine learning has spawned a new field of health-care research. The new tools under development are targeting many aspects of medical practice, including changes to the practice of pathology and laboratory medicine. Optimal design in these powerful tools requires cross-disciplinary literacy, including basic knowledge and understanding of critical concepts that have traditionally been unfamiliar to pathologists and laboratorians. This review provides definitions and basic knowledge of machine learning categories (supervised, unsupervised, and reinforcement learning), introduces the underlying concept of the bias-variance trade-off as an important foundation in supervised machine learning, and discusses approaches to the supervised machine learning study design along with an overview and description of common supervised machine learning algorithms (linear regression, logistic regression, Naive Bayes, k-nearest neighbor, support vector machine, random forest, convolutional neural networks).",2019,76,125,0,True,Medicine,31682040,H. Rashidi,144026292.0,N. Tran,83007327.0,Elham Vali Betts,5788528.0,L. Howell,2072877937.0,Ralph Green,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c,https://www.semanticscholar.org/paper/1ecc2bd0bc6ffa0a2f466a058589c20593e3e57c,The Marginal Value of Adaptive Gradient Methods in Machine Learning,"Adaptive optimization methods, which perform local optimization with a metric constructed from the history of iterates, are becoming increasingly popular for training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We show that for simple overparameterized problems, adaptive methods often find drastically different solutions than gradient descent (GD) or stochastic gradient descent (SGD). We construct an illustrative binary classification problem where the data is linearly separable, GD and SGD achieve zero test error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to half. We additionally study the empirical generalization capability of adaptive methods on several state-of-the-art deep learning models. We observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance. These results suggest that practitioners should reconsider the use of adaptive methods to train neural networks.",2017,26,784,80,False,Computer Science,144102853,Ashia C. Wilson,40458654.0,R. Roelofs,144872294.0,Mitchell Stern,1706280.0,Nathan Srebro,9229182.0,B. Recht,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea,https://www.semanticscholar.org/paper/efca2a32ce9c7a808c2c3efcc2c3dac032dfc8ea,Big Data and Machine Learning in Health Care.,"Nearly all aspects of modern life are in some way being changed by big data and machine learning. Netflix knows what movies people like to watch and Google knows what people want to know based on their search histories. Indeed, Google has recently begun to replace much of its existing non–machine learning technology with machine learning algorithms, and there is great optimism that these techniques can provide similar improvements across many sectors. It isnosurprisethenthatmedicineisawashwithclaims of revolution from the application of machine learning to big health care data. Recent examples have demonstrated that big data and machine learning can create algorithms that perform on par with human physicians.1 Though machine learning and big data may seem mysterious at first, they are in fact deeply related to traditional statistical models that are recognizable to most clinicians. It is our hope that elucidating these connections will demystify these techniques and provide a set of reasonable expectations for the role of machine learning and big data in health care. Machine learning was originally described as a program that learns to perform a task or make a decision automatically from data, rather than having the behavior explicitlyprogrammed.However,thisdefinitionisverybroad and could cover nearly any form of data-driven approach. For instance, consider the Framingham cardiovascular risk score,whichassignspointstovariousfactorsandproduces a number that predicts 10-year cardiovascular risk. Should this be considered an example of machine learning? The answer might obviously seem to be no. Closer inspection oftheFraminghamriskscorerevealsthattheanswermight not be as obvious as it first seems. The score was originally created2 by fitting a proportional hazards model to data frommorethan5300patients,andsothe“rule”wasinfact learnedentirelyfromdata.Designatingariskscoreasamachine learning algorithm might seem a strange notion, but this example reveals the uncertain nature of the original definition of machine learning. It is perhaps more useful to imagine an algorithm as existing along a continuum between fully human-guided vs fully machine-guided data analysis. To understand the degree to which a predictive or diagnostic algorithm can said to be an instance of machine learning requires understanding how much of its structure or parameters were predetermined by humans. The trade-off between human specificationofapredictivealgorithm’spropertiesvslearning those properties from data is what is known as the machine learning spectrum. Returning to the Framingham study, to create the original risk score statisticians and clinical experts worked together to make many important decisions, such as which variables to include in the model, therelationshipbetweenthedependentandindependent variables, and variable transformations and interactions. Since considerable human effort was used to define these properties, it would place low on the machine learning spectrum (#19 in the Figure and Supplement). Many evidence-based clinical practices are based on a statistical model of this sort, and so many clinical decisions in fact exist on the machine learning spectrum (middle left of Figure). On the extreme low end of the machine learning spectrum would be heuristics and rules of thumb that do not directly involve the use of any rules or models explicitly derived from data (bottom left of Figure). Suppose a new cardiovascular risk score is created that includes possible extensions to the original model. For example, it could be that risk factors should not be added but instead should be multiplied or divided, or perhaps a particularly important risk factor should square the entire score if it is present. Moreover, if it is not known in advance which variables will be important, but thousands of individual measurements have been collected, how should a good model be identified from among the infinite possibilities? This is precisely what a machine learning algorithm attempts to do. As humans impose fewer assumptions on the algorithm, it moves further up the machine learning spectrum. However, there is never a specific threshold wherein a model suddenly becomes “machine learning”; rather, all of these approaches exist along a continuum, determined by how many human assumptions are placed onto the algorithm. An example of an approach high on the machine learning spectrum has recently emerged in the form of so-called deep learning models. Deep learning models are stunningly complex networks of artificial neurons that were designed expressly to create accurate models directly from raw data. Researchers recently demonstrated a deep learning algorithm capable of detecting diabetic retinopathy (#4 in the Figure, top center) from retinal photographs at a sensitivity equal to or greater than that of ophthalmologists.1 This model learned the diagnosis procedure directly from the raw pixels of the images with no human intervention outside of a team of ophthalmologists who annotated each image with the correct diagnosis. Because they are able to learn the task with little human instruction or prior assumptions, these deep learning algorithms rank very high on the machine learning spectrum (Figure, light blue circles). Though they require less human guidance, deep learning algorithms for image recognition require enormous amounts of data to capture the full complexity, variety, and nuance inherent to real-world images. Consequently, these algorithms often require hundreds of thousands of examples to extract the salient image features that are correlated with the outcome of interest. Higher placement on the machine learning spectrum does not imply superiority, because different tasks require different levels of human involvement. While algorithms high on the spectrum are often very flexible and can learn many tasks, they are often uninterpretable VIEWPOINT",2018,3,789,10,False,Medicine,143649421,Andrew Beam,1740538.0,I. Kohane,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39361b3507c9f8b0a97780568b645f80a208d78a,https://www.semanticscholar.org/paper/39361b3507c9f8b0a97780568b645f80a208d78a,Machine Learning and Deep Learning Methods for Cybersecurity,"With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide suggestions for research directions.",2018,84,467,22,False,Computer Science,2067672128,Yang Xin,2069277364.0,Lingshuang Kong,2118357790.0,Zhi Liu,49069825.0,Yuling Chen,121704135.0,Yanmiao Li,96519515.0,Hongliang Zhu,49594896.0,Mingcheng Gao,2149274.0,Haixia Hou,,2108713951.0,Chunhua Wang,,,,,,,,,,,,,,,,,,
ab0a6b82c359ce6d4c2425080ffee632cb46fced,https://www.semanticscholar.org/paper/ab0a6b82c359ce6d4c2425080ffee632cb46fced,MoleculeNet: a benchmark for molecular machine learning† †Electronic supplementary information (ESI) available. See DOI: 10.1039/c7sc02664a,"A large scale benchmark for molecular machine learning consisting of multiple public datasets, metrics, featurizations and learning algorithms.",2017,121,457,21,True,Computer Science,9957625,Zhenqin Wu,2378027.0,Bharath Ramsundar,5932099.0,Evan N. Feinberg,145986494.0,Joseph Gomes,9959840.0,Caleb Geniesse,5929246.0,Aneesh S. Pappu,40867019.0,K. Leswing,1806271.0,V. Pande,Physics,,,,,,,Mathematics,,,,,Medicine,,,,,,,,
eef183687fab4d762a381f2e80e357e08e923f0a,https://www.semanticscholar.org/paper/eef183687fab4d762a381f2e80e357e08e923f0a,"Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning","The correct use of model evaluation, model selection, and algorithm selection techniques is vital in academic machine learning research as well as in many industrial settings. This article reviews different techniques that can be used for each of these three subtasks and discusses the main advantages and disadvantages of each technique with references to theoretical and empirical studies. Further, recommendations are given to encourage best yet feasible practices in research and applications of machine learning. Common methods such as the holdout method for model evaluation and selection are covered, which are not recommended when working with small datasets. Different flavors of the bootstrap technique are introduced for estimating the uncertainty of performance estimates, as an alternative to confidence intervals via normal approximation if bootstrapping is computationally feasible. Common cross-validation techniques such as leave-one-out cross-validation and k-fold cross-validation are reviewed, the bias-variance trade-off for choosing k is discussed, and practical tips for the optimal choice of k are given based on empirical evidence. Different statistical tests for algorithm comparisons are presented, and strategies for dealing with multiple comparisons such as omnibus tests and multiple-comparison corrections are discussed. Finally, alternative methods for algorithm selection, such as the combined F-test 5x2 cross-validation and nested cross-validation, are recommended for comparing machine learning algorithms when datasets are small.",2018,35,392,17,False,Computer Science,2562040,S. Raschka,,,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
d5125164c7fec457d1442cce807a3436841715d0,https://www.semanticscholar.org/paper/d5125164c7fec457d1442cce807a3436841715d0,Machine Learning Approaches for Clinical Psychology and Psychiatry.,"Machine learning approaches for clinical psychology and psychiatry explicitly focus on learning statistical functions from multidimensional data sets to make generalizable predictions about individuals. The goal of this review is to provide an accessible understanding of why this approach is important for future practice given its potential to augment decisions associated with the diagnosis, prognosis, and treatment of people suffering from mental illness using clinical and biological data. To this end, the limitations of current statistical paradigms in mental health research are critiqued, and an introduction is provided to critical machine learning methods used in clinical studies. A selective literature review is then presented aiming to reinforce the usefulness of machine learning methods and provide evidence of their potential. In the context of promising initial results, the current limitations of machine learning approaches are addressed, and considerations for future clinical translation are outlined.",2018,0,362,13,False,Medicine,5672681,D. Dwyer,2660554.0,P. Falkai,3214043.0,N. Koutsouleris,,,,,,,,,,,Psychology,,,,,,,,,,,,,,,,,,,,
5939ac3b5a9d64d8371ee179751351d7698637df,https://www.semanticscholar.org/paper/5939ac3b5a9d64d8371ee179751351d7698637df,Using Machine Learning to Advance Personality Assessment and Theory,"Machine learning has led to important advances in society. One of the most exciting applications of machine learning in psychological science has been the development of assessment tools that can powerfully predict human behavior and personality traits. Thus far, machine learning approaches to personality assessment have focused on the associations between social media and other digital records with established personality measures. The goal of this article is to expand the potential of machine learning approaches to personality assessment by embedding it in a more comprehensive construct validation framework. We review recent applications of machine learning to personality assessment, place machine learning research in the broader context of fundamental principles of construct validation, and provide recommendations for how to use machine learning to advance our understanding of personality.",2019,68,117,1,True,Medicine,5199283,W. Bleidorn,2066036.0,C. Hopwood,,,,,,,,,,,,,Psychology,,,,,,,,,,,,,,,,,,,,
5327bb691a1c63791a06de2d3f0478e47785add5,https://www.semanticscholar.org/paper/5327bb691a1c63791a06de2d3f0478e47785add5,Predicting Diabetes Mellitus With Machine Learning Techniques,"Diabetes mellitus is a chronic disease characterized by hyperglycemia. It may cause many complications. According to the growing morbidity in recent years, in 2040, the world’s diabetic patients will reach 642 million, which means that one of the ten adults in the future is suffering from diabetes. There is no doubt that this alarming figure needs great attention. With the rapid development of machine learning, machine learning has been applied to many aspects of medical health. In this study, we used decision tree, random forest and neural network to predict diabetes mellitus. The dataset is the hospital physical examination data in Luzhou, China. It contains 14 attributes. In this study, five-fold cross validation was used to examine the models. In order to verity the universal applicability of the methods, we chose some methods that have the better performance to conduct independent test experiments. We randomly selected 68994 healthy people and diabetic patients’ data, respectively as training set. Due to the data unbalance, we randomly extracted 5 times data. And the result is the average of these five experiments. In this study, we used principal component analysis (PCA) and minimum redundancy maximum relevance (mRMR) to reduce the dimensionality. The results showed that prediction with random forest could reach the highest accuracy (ACC = 0.8084) when all the attributes were used.",2018,74,356,13,True,Medicine,144268946,Q. Zou,26953868.0,Kaiyang Qu,2112602289.0,Ya-ling Luo,2053677281.0,Dehui Yin,144250293.0,Y. Ju,144256490.0,Hua Tang,,,,,,,,,,,,,,,,,,,,,,,,,
0f5476c9629f8093e8ba8c6a41868415c6a7f2f1,https://www.semanticscholar.org/paper/0f5476c9629f8093e8ba8c6a41868415c6a7f2f1,Stealing Hyperparameters in Machine Learning,"Hyperparameters are critical in machine learning, as different hyperparameters often result in models with significantly different performance. Hyperparameters may be deemed confidential because of their commercial value and the confidentiality of the proprietary algorithms that the learner uses to learn them. In this work, we propose attacks on stealing the hyperparameters that are learned by a learner. We call our attacks hyperparameter stealing attacks. Our attacks are applicable to a variety of popular machine learning algorithms such as ridge regression, logistic regression, support vector machine, and neural network. We evaluate the effectiveness of our attacks both theoretically and empirically. For instance, we evaluate our attacks on Amazon Machine Learning. Our results demonstrate that our attacks can accurately steal hyperparameters. We also study countermeasures. Our results highlight the need for new defenses against our hyperparameter stealing attacks for certain machine learning algorithms.",2018,53,312,15,True,Computer Science,1789625,Binghui Wang,144516687.0,N. Gong,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
7d065e649e3bfc7d6d36166f50eab37b8404eae0,https://www.semanticscholar.org/paper/7d065e649e3bfc7d6d36166f50eab37b8404eae0,Interpretable Machine Learning in Healthcare,"This tutorial extensively covers the definitions, nuances, challenges, and requirements for the design of interpretable and explainable machine learning models and systems in healthcare. We discuss many uses in which interpretable machine learning models are needed in healthcare and how they should be deployed. Additionally, we explore the landscape of recent advances to address the challenges model interpretability in healthcare and also describe how one would go about choosing the right interpretable machine learnig algorithm for a given problem in healthcare.",2018,46,304,13,False,Computer Science,145919340,M. Ahmad,1752398.0,A. Teredesai,36979326.0,C. Eckert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29524f145db94cab2336da99f157e869d805dead,https://www.semanticscholar.org/paper/29524f145db94cab2336da99f157e869d805dead,SoK: Security and Privacy in Machine Learning,"Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive—new systems and models are being deployed in every domain imaginable, leading to widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date.We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. In particular, it is apparent that constructing a theoretical understanding of the sensitivity of modern ML algorithms to the data they analyze, à la PAC theory, will foster a science of security and privacy in ML.",2018,134,324,24,False,Computer Science,1967156,Nicolas Papernot,144061974.0,P. Mcdaniel,2370629.0,Arunesh Sinha,1796536.0,Michael P. Wellman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2a944564c2466883ec14a6f6ef461f0e34d21b38,https://www.semanticscholar.org/paper/2a944564c2466883ec14a6f6ef461f0e34d21b38,Fairness in Machine Learning: Lessons from Political Philosophy,"What does it mean for a machine learning model to be `fair', in terms which can be operationalised? Should fairness consist of ensuring everyone has an equal probability of obtaining some benefit, or should we aim instead to minimise the harms to the least advantaged? Can the relevant ideal be determined by reference to some alternative state of affairs in which a particular social pattern of discrimination does not exist? Various definitions proposed in recent literature make different assumptions about what terms like discrimination and fairness mean and how they can be defined in mathematical terms. Questions of discrimination, egalitarianism and justice are of significant interest to moral and political philosophers, who have expended significant efforts in formalising and defending these central concepts. It is therefore unsurprising that attempts to formalise `fairness' in machine learning contain echoes of these old philosophical debates. This paper draws on existing work in moral and political philosophy in order to elucidate emerging debates about fair machine learning.",2017,42,280,25,False,Sociology,144147883,R. Binns,,,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,
0cc6dbfd929bc816d507527993f55f9b4e88615d,https://www.semanticscholar.org/paper/0cc6dbfd929bc816d507527993f55f9b4e88615d,Machine learning & artificial intelligence in the quantum domain: a review of recent progress,"Quantum information technologies, on the one hand, and intelligent learning systems, on the other, are both emergent technologies that are likely to have a transformative impact on our society in the future. The respective underlying fields of basic research—quantum information versus machine learning (ML) and artificial intelligence (AI)—have their own specific questions and challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question of the extent to which these fields can indeed learn and benefit from each other. Quantum ML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently we have witnessed significant breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups for ML problems, critical in our ‘big data’ world. Conversely, ML already permeates many cutting-edge technologies and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been (theoretically) demonstrated for interactive learning tasks, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement—exploring what ML/AI can do for quantum physics and vice versa—researchers have also broached the fundamental issue of quantum generalizations of learning and AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is fully described by quantum mechanics. In this review, we describe the main ideas, recent developments and progress in a broad spectrum of research investigating ML and AI in the quantum domain.",2017,375,507,7,True,Physics,2878563,V. Dunjko,32534184.0,H. Briegel,,,,,,,,,,,,,Computer Science,,,,,,,Medicine,,,,,,,,,,,,,
8285e1b5536ce11d55462ae757f61c75ec6773c6,https://www.semanticscholar.org/paper/8285e1b5536ce11d55462ae757f61c75ec6773c6,The Frontiers of Fairness in Machine Learning,"The last few years have seen an explosion of academic and popular interest in algorithmic fairness. Despite this interest and the volume and velocity of work that has been produced recently, the fundamental science of fairness in machine learning is still in a nascent state. In March 2018, we convened a group of experts as part of a CCC visioning workshop to assess the state of the field, and distill the most promising research directions going forward. This report summarizes the findings of that workshop. Along the way, it surveys recent theoretical work in the field and points towards promising directions for research.",2018,64,276,16,False,Computer Science,2082393,A. Chouldechova,1682008.0,Aaron Roth,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,
d4de528645fdfc6d954364a8e6eeeed9480ccfa2,https://www.semanticscholar.org/paper/d4de528645fdfc6d954364a8e6eeeed9480ccfa2,"Machine Learning for Networking: Workflow, Advances and Opportunities","Recently, machine learning has been used in every possible field to leverage its amazing power. For a long time, the networking and distributed computing system is the key infrastructure to provide efficient computational resources for machine learning. Networking itself can also benefit from this promising technology. This article focuses on the application of MLN, which can not only help solve the intractable old network questions but also stimulate new network applications. In this article, we summarize the basic workflow to explain how to apply machine learning technology in the networking domain. Then we provide a selective survey of the latest representative advances with explanations of their design principles and benefits. These advances are divided into several network design objectives and the detailed information of how they perform in each step of MLN workflow is presented. Finally, we shed light on the new opportunities in networking design and community building of this new inter-discipline. Our goal is to provide a broad research guideline on networking with machine learning to help motivate researchers to develop innovative algorithms, standards and frameworks.",2017,18,278,12,True,Computer Science,2109018752,Mowei Wang,143905357.0,Yong Cui,2153687403.0,Xin Wang,1994540.0,Shihan Xiao,1727978.0,Junchen Jiang,,,,,,,,,,,,,,,,,,,,,,,,,,,
8d7238eea00059deb446b6309bcae2901c966049,https://www.semanticscholar.org/paper/8d7238eea00059deb446b6309bcae2901c966049,"Predicting the Future - Big Data, Machine Learning, and Clinical Medicine.","The algorithms of machine learning, which can sift through vast numbers of variables looking for combinations that reliably predict outcomes, will improve prognosis, displace much of the work of radiologists and anatomical pathologists, and improve diagnostic accuracy.",2016,8,1509,25,True,Medicine,3797258,Z. Obermeyer,39714312.0,E. Emanuel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
920e561cee4fd4888212ed127d51aa09c02be6c3,https://www.semanticscholar.org/paper/920e561cee4fd4888212ed127d51aa09c02be6c3,Advances in Financial Machine Learning,"Machine learning (ML) is changing virtually every aspect of our lives. Today ML algorithms accomplish tasks that until recently only expert humans could perform. As it relates to finance, this is the most exciting time to adopt a disruptive technology that will transform how everyone invests for generations. Readers will learn how to structure Big data in a way that is amenable to ML algorithms; how to conduct research with ML algorithms on that data; how to use supercomputing methods; how to backtest your discoveries while avoiding false positives. The book addresses real-life problems faced by practitioners on a daily basis, and explains scientifically sound solutions using math, supported by code and examples. Readers become active users who can test the proposed solutions in their particular setting. Written by a recognized expert and portfolio manager, this book will equip investment professionals with the groundbreaking tools needed to succeed in modern finance.",2018,0,186,35,False,,144647352,M. L. Prado,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5fdc2223709079ba5c0f78661cdf66cec2173258,https://www.semanticscholar.org/paper/5fdc2223709079ba5c0f78661cdf66cec2173258,Current Applications and Future Impact of Machine Learning in Radiology.,"Recent advances and future perspectives of machine learning techniques offer promising applications in medical imaging. Machine learning has the potential to improve different steps of the radiology workflow including order scheduling and triage, clinical decision support systems, detection and interpretation of findings, postprocessing and dose estimation, examination quality control, and radiology reporting. In this article, the authors review examples of current applications of machine learning and artificial intelligence techniques in diagnostic radiology. In addition, the future impact and natural extension of these techniques in radiology practice are discussed.",2018,92,411,3,True,Medicine,2028947,G. Choy,2088138.0,O. Khalilzadeh,37305969.0,Mark H. Michalski,1788855.0,Synho Do,8132193.0,A. Samir,3135569.0,O. Pianykh,144304449.0,J. R. Geis,11577160.0,P. Pandharipande,,144685698.0,J. Brink,26654844.0,K. Dreyer,,,,,,,,,,,,,,,,
161ce338538f94b0b9be51ae2336db0aa4b012e5,https://www.semanticscholar.org/paper/161ce338538f94b0b9be51ae2336db0aa4b012e5,Potential Biases in Machine Learning Algorithms Using Electronic Health Record Data,"A promise of machine learning in health care is the avoidance of biases in diagnosis and treatment; a computer algorithm could objectively synthesize and interpret the data in the medical record. Integration of machine learning with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. Machine learning algorithms, however, may also be subject to biases. The biases include those related to missing data and patients not identified by algorithms, sample size and underestimation, and misclassification and measurement error. There is concern that biases and deficiencies in the data used by machine learning algorithms may contribute to socioeconomic disparities in health care. This Special Communication outlines the potential biases that may be introduced into machine learning–based clinical decision support tools that use electronic health record data and proposes potential solutions to the problems of overreliance on automation, algorithms based on biased data, and algorithms that do not provide information that is clinically meaningful. Existing health care disparities should not be amplified by thoughtless or excessive reliance on machines.",2018,32,499,4,True,Medicine,5086547,M. Gianfrancesco,2364709.0,S. Tamang,5441960.0,J. Yazdany,5589030.0,G. Schmajuk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33d9d4593d44792e17a045e5f3407f0fe7a40dd1,https://www.semanticscholar.org/paper/33d9d4593d44792e17a045e5f3407f0fe7a40dd1,Machine learning of accurate energy-conserving molecular force fields,"The law of energy conservation is used to develop an efficient machine learning approach to construct accurate force fields. Using conservation of energy—a fundamental property of closed classical and quantum mechanical systems—we develop an efficient gradient-domain machine learning (GDML) approach to construct accurate molecular force fields using a restricted number of samples from ab initio molecular dynamics (AIMD) trajectories. The GDML implementation is able to reproduce global potential energy surfaces of intermediate-sized molecules with an accuracy of 0.3 kcal mol−1 for energies and 1 kcal mol−1 Å̊−1 for atomic forces using only 1000 conformational geometries for training. We demonstrate this accuracy for AIMD trajectories of molecules, including benzene, toluene, naphthalene, ethanol, uracil, and aspirin. The challenge of constructing conservative force fields is accomplished in our work by learning in a Hilbert space of vector-valued functions that obey the law of energy conservation. The GDML approach enables quantitative molecular dynamics simulations for molecules at a fraction of cost of explicit AIMD calculations, thereby allowing the construction of efficient force fields with the accuracy and transferability of high-level ab initio methods.",2016,72,635,28,True,Physics,7631063,Stefan Chmiela,2462983.0,A. Tkatchenko,10667063.0,H. E. Sauceda,5667638.0,I. Poltavsky,33075217.0,Kristof T. Schütt,145034054.0,K. Müller,,,,,Medicine,,,,,,,Computer Science,,,,,,,,,,,,,
775a4e375cc79b53b94e37fa3eedff481823e4a6,https://www.semanticscholar.org/paper/775a4e375cc79b53b94e37fa3eedff481823e4a6,Efficient and Robust Automated Machine Learning,"The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.",2015,30,1239,176,False,Computer Science,2868444,Matthias Feurer,145227684.0,Aaron Klein,2607675.0,Katharina Eggensperger,2060551.0,J. T. Springenberg,2058090778.0,Manuel Blum,144661829.0,F. Hutter,,,,,,,,,,,,,,,,,,,,,,,,,
4e75a145f59400a8d646db770cc396de87d6b9d8,https://www.semanticscholar.org/paper/4e75a145f59400a8d646db770cc396de87d6b9d8,Image Reconstruction is a New Frontier of Machine Learning,"Over past several years, machine learning, or more generally artificial intelligence, has generated overwhelming research interest and attracted unprecedented public attention. As tomographic imaging researchers, we share the excitement from our imaging perspective [item 1) in the Appendix], and organized this special issue dedicated to the theme of “Machine learning for image reconstruction.” This special issue is a sister issue of the special issue published in May 2016 of this journal with the theme “Deep learning in medical imaging” [item 2) in the Appendix]. While the previous special issue targeted medical image processing/analysis, this special issue focuses on data-driven tomographic reconstruction. These two special issues are highly complementary, since image reconstruction and image analysis are two of the main pillars for medical imaging. Together we cover the whole workflow of medical imaging: from tomographic raw data/features to reconstructed images and then extracted diagnostic features/readings.",2018,78,279,1,False,Computer Science,2108295460,Ge Wang,2998762.0,J. C. Ye,3367666.0,K. Mueller,1711572.0,J. Fessler,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,
ca62b1904a4f3982b172c85204a588f494cb6a22,https://www.semanticscholar.org/paper/ca62b1904a4f3982b172c85204a588f494cb6a22,Taking Human out of Learning Applications: A Survey on Automated Machine Learning,"Machine learning techniques have deeply rooted in our everyday life. However, since it is knowledge- and labor-intensive to pursue good learning performance, human experts are heavily involved in every aspect of machine learning. In order to make machine learning techniques easier to apply and reduce the demand for experienced human experts, automated machine learning (AutoML) has emerged as a hot topic with both industrial and academic interest. In this paper, we provide an up to date survey on AutoML. First, we introduce and define the AutoML problem, with inspiration from both realms of automation and machine learning. Then, we propose a general AutoML framework that not only covers most existing approaches to date but also can guide the design for new methods. Subsequently, we categorize and review the existing works from two aspects, i.e., the problem setup and the employed techniques. Finally, we provide a detailed analysis of AutoML approaches and explain the reasons underneath their successful applications. We hope this survey can serve as not only an insightful guideline for AutoML beginners but also an inspiration for future research.",2018,222,256,16,False,Computer Science,3259992,Quanming Yao,9523174.0,Mengshuo Wang,1742688.0,H. Escalante,1743797.0,I. Guyon,2166411332.0,Yi-Qi Hu,2110463675.0,Yu-Feng Li,47178228.0,Wei-Wei Tu,152290618.0,Qiang Yang,Mathematics,144705629.0,Yang Yu,,,,,,,,,,,,,,,,,,
959c9dbfceda3825787f75f63fd7c87f332dc271,https://www.semanticscholar.org/paper/959c9dbfceda3825787f75f63fd7c87f332dc271,Machine Learning-Based Sentiment Analysis for Twitter Accounts,"Growth in the area of opinion mining and sentiment analysis has been rapid and aims to explore the opinions or text present on different platforms of social media through machine-learning techniques with sentiment, subjectivity analysis or polarity calculations. Despite the use of various machine-learning techniques and tools for sentiment analysis during elections, there is a dire need for a state-of-the-art approach. To deal with these challenges, the contribution of this paper includes the adoption of a hybrid approach that involves a sentiment analyzer that includes machine learning. Moreover, this paper also provides a comparison of techniques of sentiment analysis in the analysis of political views by applying supervised machine-learning algorithms such as Naive Bayes and support vector machines (SVM).",2018,60,248,8,True,Computer Science,152757679,A. Hasan,2069268061.0,Sana Moin,145867316.0,Ahmad Karim,1758091.0,Shahaboddin Shamshirband,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c46c0fc81d41d9561643d55f41626c5583b0b25e,https://www.semanticscholar.org/paper/c46c0fc81d41d9561643d55f41626c5583b0b25e,Machine Learning in Medicine.,"Spurred by advances in processing power, memory, storage, and an unprecedented wealth of data, computers are being asked to tackle increasingly complex learning tasks, often with astonishing success. Computers have now mastered a popular variant of poker, learned the laws of physics from experimental data, and become experts in video games - tasks that would have been deemed impossible not too long ago. In parallel, the number of companies centered on applying complex data analysis to varying industries has exploded, and it is thus unsurprising that some analytic companies are turning attention to problems in health care. The purpose of this review is to explore what problems in medicine might benefit from such learning approaches and use examples from the literature to introduce basic concepts in machine learning. It is important to note that seemingly large enough medical data sets and adequate learning algorithms have been available for many decades, and yet, although there are thousands of papers applying machine learning algorithms to medical data, very few have contributed meaningfully to clinical care. This lack of impact stands in stark contrast to the enormous relevance of machine learning to many other industries. Thus, part of my effort will be to identify what obstacles there may be to changing the practice of medicine through statistical learning approaches, and discuss how these might be overcome.",2015,38,1800,24,True,Medicine,2077989,R. Deo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4a8c332b09bb99333a8bce6a4640a20c1352aa63,https://www.semanticscholar.org/paper/4a8c332b09bb99333a8bce6a4640a20c1352aa63,A Survey on Security Threats and Defensive Techniques of Machine Learning: A Data Driven View,"Machine learning is one of the most prevailing techniques in computer science, and it has been widely applied in image processing, natural language processing, pattern recognition, cybersecurity, and other fields. Regardless of successful applications of machine learning algorithms in many scenarios, e.g., facial recognition, malware detection, automatic driving, and intrusion detection, these algorithms and corresponding training data are vulnerable to a variety of security threats, inducing a significant performance decrease. Hence, it is vital to call for further attention regarding security threats and corresponding defensive techniques of machine learning, which motivates a comprehensive survey in this paper. Until now, researchers from academia and industry have found out many security threats against a variety of learning algorithms, including naive Bayes, logistic regression, decision tree, support vector machine (SVM), principle component analysis, clustering, and prevailing deep neural networks. Thus, we revisit existing security threats and give a systematic survey on them from two aspects, the training phase and the testing/inferring phase. After that, we categorize current defensive techniques of machine learning into four groups: security assessment mechanisms, countermeasures in the training phase, those in the testing or inferring phase, data security, and privacy. Finally, we provide five notable trends in the research on security threats and defensive techniques of machine learning, which are worth doing in-depth studies in future.",2018,109,243,20,False,Computer Science,48873711,Qiang Liu,2112519091.0,Pan Li,1681475.0,Wentao Zhao,2089568220.0,Wei Cai,144958145.0,Shui Yu,143698682.0,Victor C. M. Leung,,,,,,,,,,,,,,,,,,,,,,,,,
1d41d6ec4805f80b84a1ccd17f6753ba71e107f7,https://www.semanticscholar.org/paper/1d41d6ec4805f80b84a1ccd17f6753ba71e107f7,Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning),"Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.",2005,0,2751,595,False,Computer Science,3472959,C. Rasmussen,145715698.0,Christopher K. I. Williams,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
