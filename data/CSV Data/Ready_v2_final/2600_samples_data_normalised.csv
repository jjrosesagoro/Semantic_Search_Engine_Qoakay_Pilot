paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,fieldsOfStudy/1,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,fieldsOfStudy/3
043b307af412fc7f9005822e6dabbe4f9d983472,https://www.semanticscholar.org/paper/043b307af412fc7f9005822e6dabbe4f9d983472,Mapping parallelism to multi-cores: a machine learning based approach,"The efficient mapping of program parallelism to multi-core processors is highly dependent on the underlying architecture. This paper proposes a portable and automatic compiler-based approach to mapping such parallelism using machine learning. It develops two predictors: a data sensitive and a data insensitive predictor to select the best mapping for parallel programs. They predict the number of threads and the scheduling policy for any given program using a model learnt off-line. By using low-cost profiling runs, they predict the mapping for a new unseen program across multiple input data sets. We evaluate our approach by selecting parallelism mapping configurations for OpenMP programs on two representative but different multi-core platforms (the Intel Xeon and the Cell processors). Performance of our technique is stable across programs and architectures. On average, it delivers above 96% performance of the maximum available on both platforms. It achieve, on average, a 37% (up to 17.5 times) performance improvement over the OpenMP runtime default scheme on the Cell platform. Compared to two recent prediction models, our predictors achieve better performance with a significant lower profiling cost.",2009,29,213,7,False,Computer Science,40072305,Zheng Wang,1401533251.0,M. O’Boyle,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3e50d6456492d20ad836658220202cbe1c9d7c9f,https://www.semanticscholar.org/paper/3e50d6456492d20ad836658220202cbe1c9d7c9f,Machine learning approaches for the prediction of signal peptides and other protein sorting signals.,"Prediction of protein sorting signals from the sequence of amino acids has great importance in the field of proteomics today. Recently, the growth of protein databases, combined with machine learning approaches, such as neural networks and hidden Markov models, have made it possible to achieve a level of reliability where practical use in, for example automatic database annotation is feasible. In this review, we concentrate on the present status and future perspectives of SignalP, our neural network-based method for prediction of the most well-known sorting signal: the secretory signal peptide. We discuss the problems associated with the use of SignalP on genomic sequences, showing that signal peptide prediction will improve further if integrated with predictions of start codons and transmembrane helices. As a step towards this goal, a hidden Markov model version of SignalP has been developed, making it possible to discriminate between cleaved signal peptides and uncleaved signal anchors. Furthermore, we show how SignalP can be used to characterize putative signal peptides from an archaeon, Methanococcus jannaschii. Finally, we briefly review a few methods for predicting other protein sorting signals and discuss the future of protein sorting prediction in general.",1999,62,625,42,True,Computer Science,145416108,H. Nielsen,8169197.0,S. Brunak,Medicine,3300090.0,G. von Heijne,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ac3f8372b9d893dbdb7e4b9cd3df5ed825ffb548,https://www.semanticscholar.org/paper/ac3f8372b9d893dbdb7e4b9cd3df5ed825ffb548,"Twitter Sentiment Analysis: Lexicon Method, Machine Learning Method and Their Combination","This paper covers the two approaches for sentiment analysis: i) lexicon based method; ii) machine learning method. We describe several techniques to implement these approaches and discuss how they can be adopted for sentiment classification of Twitter messages. We present a comparative study of different lexicon combinations and show that enhancing sentiment lexicons with emoticons, abbreviations and social-media slang expressions increases the accuracy of lexicon-based classification for Twitter. We discuss the importance of feature generation and feature selection processes for machine learning sentiment classification. To quantify the performance of the main sentiment analysis methods over Twitter we run these algorithms on a benchmark Twitter dataset from the SemEval-2013 competition, task 2-B. The results show that machine learning method based on SVM and Naive Bayes classifiers outperforms the lexicon method. We present a new ensemble method that uses a lexicon based sentiment score as input feature for the machine learning approach. The combined method proved to produce more precise classifications. We also show that employing a cost-sensitive classifier for highly unbalanced datasets yields an improvement of sentiment classification performance up to 7%.",2015,84,131,6,False,Computer Science,1891372,Olga Kolchyna,2314341.0,T. T. P. Souza,Mathematics,1761192.0,P. Treleaven,8903071.0,T. Aste,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8a9f26a4cee210e51c96f4016737605e31d490ee,https://www.semanticscholar.org/paper/8a9f26a4cee210e51c96f4016737605e31d490ee,A data ecosystem to support machine learning in materials science,"Facilitating the application of machine learning to materials science problems will require enhancing the data ecosystem to enable discovery and collection of data from many sources, automated dissemination of new data across the ecosystem, and the connecting of data with materials-specific machine learning models. Here, we present two projects, the Materials Data Facility (MDF) and the Data and Learning Hub for Science (DLHub), that address these needs. We use examples to show how MDF and DLHub capabilities can be leveraged to link data with machine learning models and how users can access those capabilities through web and programmatic interfaces.",2019,39,80,7,True,Materials Science,2338072,B. Blaiszik,47766095.0,Logan T. Ward,Physics,47549959.0,Marcus Schwarting,104220223.0,Jonathon Gaff,36319017.0,Ryan Chard,72559552.0,D. Pike,3091414.0,K. Chard,1698701.0,Ian T Foster,,,,,,,,,,,,,,,,,,,,,,
bcc81d8ab4ba6989d3be943540bd3885990c313f,https://www.semanticscholar.org/paper/bcc81d8ab4ba6989d3be943540bd3885990c313f,Toward Intelligent Vehicular Networks: A Machine Learning Framework,"As wireless networks evolve toward high mobility and providing better support for connected vehicles, a number of new challenges arise due to the resulting high dynamics in vehicular environments and thus motive rethinking of traditional wireless design methodologies. Future intelligent vehicles, which are at the heart of high mobility networks, are increasingly equipped with multiple advanced onboard sensors and keep generating large volumes of data. Machine learning, as an effective approach to artificial intelligence, can provide a rich set of tools to exploit such data for the benefit of the networks. In this paper, we first identify the distinctive characteristics of high mobility vehicular networks and motivate the use of machine learning to address the resulting challenges. After a brief introduction of the major concepts of machine learning, we discuss its applications to learn the dynamics of vehicular networks and make informed decisions to optimize network performance. In particular, we discuss in greater detail the application of reinforcement learning in managing network resources as an alternative to the prevalent optimization approach. Finally, some open issues worth further investigation are highlighted.",2018,92,143,3,False,Computer Science,144362942,L. Liang,2089063597.0,Hao Ye,Mathematics,1410112765.0,Geoffrey Y. Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bd20055d314fa7ffbee9d702dfd5e4fd99257c62,https://www.semanticscholar.org/paper/bd20055d314fa7ffbee9d702dfd5e4fd99257c62,Measuring Corporate Culture Using Machine Learning,"We create a culture dictionary using one of the latest machine learning techniques—the word embedding model—and 209,480 earnings call transcripts. We score the five corporate cultural values of innovation, integrity, quality, respect, and teamwork for 62,664 firm-year observations over the period 2001–2018. We show that an innovative culture is broader than the usual measures of corporate innovation – R&D expenses and the number of patents. Moreover, we show that corporate culture correlates with business outcomes, including operational efficiency, risk-taking, earnings management, executive compensation design, firm value, and deal making, and that the culture-performance link is more pronounced in bad times. Finally, we present suggestive evidence that corporate culture is shaped by major corporate events, such as mergers and acquisitions.",2020,71,110,14,False,Business,101769938,Kai Li,39544108.0,Feng Mai,,145109025.0,R. Shen,1390935916.0,Xinyan Yan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b646ba235ba49ed545c7903dd033b50e3fa99f34,https://www.semanticscholar.org/paper/b646ba235ba49ed545c7903dd033b50e3fa99f34,Machine learning for identifying Randomized Controlled Trials: An evaluation and practitioner's guide,"Machine learning (ML) algorithms have proven highly accurate for identifying Randomized Controlled Trials (RCTs) but are not used much in practice, in part because the best way to make use of the technology in a typical workflow is unclear. In this work, we evaluate ML models for RCT classification (support vector machines, convolutional neural networks, and ensemble approaches). We trained and optimized support vector machine and convolutional neural network models on the titles and abstracts of the Cochrane Crowd RCT set. We evaluated the models on an external dataset (Clinical Hedges), allowing direct comparison with traditional database search filters. We estimated area under receiver operating characteristics (AUROC) using the Clinical Hedges dataset.",2018,42,195,5,True,Medicine,1808775,I. Marshall,1401080041.0,A. Noel-Storr,,37912398.0,J. Kuiper,2110226596.0,James Thomas,1912476.0,Byron C. Wallace,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7f7925d27da15a877d2991a83085f7ff0bc4badd,https://www.semanticscholar.org/paper/7f7925d27da15a877d2991a83085f7ff0bc4badd,Neural and adaptive systems : fundamentals through simulations,"Data Fitting with Linear Models. Pattern Recognition. Multilayer Perceptrons. Designing and Training MLPs. Function Approximation with MLPs, Radial Basis Functions, and Support Vector Machines. Hebbian Learning and Principal Component Analysis. Competitive and Kohonen Networks. Principles of Digital Signal Processing. Adaptive Filters. Temporal Processing with Neural Networks. Training and Using Recurrent Networks. Appendices. Glossary. Index.",2000,6,474,22,False,Computer Science,143961030,J. Príncipe,2290387.0,N. Euliano,,145973983.0,W. C. Lefebvre,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5a43cc163f4e570b28617ad8a40872ad9189349c,https://www.semanticscholar.org/paper/5a43cc163f4e570b28617ad8a40872ad9189349c,Robust Truncated Hinge Loss Support Vector Machines,"The support vector machine (SVM) has been widely applied for classification problems in both machine learning and statistics. Despite its popularity, however, SVM has some drawbacks in certain situations. In particular, the SVM classifier can be very sensitive to outliers in the training sample. Moreover, the number of support vectors (SVs) can be very large in many applications. To circumvent these drawbacks, we propose the robust truncated hinge loss SVM (RSVM), which uses a truncated hinge loss. The RSVM is shown to be more robust to outliers and to deliver more accurate classifiers using a smaller set of SVs than the standard SVM. Our theoretical results show that the RSVM is Fisher-consistent, even when there is no dominating class, a scenario that is particularly challenging for multicategory classification. Similar results are obtained for a class of margin-based classifiers.",2007,33,336,26,False,Mathematics,47095791,Yichao Wu,46399637.0,Yufeng Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c,https://www.semanticscholar.org/paper/4f0a8cad6d6a8d0397ad1bd35acce6458aa7164c,Contrastive Representation Learning: A Framework and Review,"Contrastive Learning has recently received interest due to its success in self-supervised representation learning in the computer vision domain. However, the origins of Contrastive Learning date as far back as the 1990s and its development has spanned across many fields and domains including Metric Learning and natural language processing. In this paper, we provide a comprehensive literature review and we propose a general Contrastive Representation Learning framework that simplifies and unifies many different contrastive learning methods. We also provide a taxonomy for each of the components of contrastive learning in order to summarise it and distinguish it from other forms of machine learning. We then discuss the inductive biases which are present in any contrastive learning system and we analyse our framework under different views from various sub-fields of Machine Learning. Examples of how contrastive learning has been applied in computer vision, natural language processing, audio processing, and others, as well as in Reinforcement Learning are also presented. Finally, we discuss the challenges and some of the most promising future research directions ahead.",2020,122,188,9,True,Computer Science,1994194269,Phúc H. Lê Khắc,30978009.0,G. Healy,Mathematics,1680223.0,A. Smeaton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9,https://www.semanticscholar.org/paper/e70b9a38fcf8373865dd6e7b45e45cca7ff2eaa9,Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data,"Some machine learning applications involve training data that is sensitive, such as the medical histories of patients in a clinical trial. A model may inadvertently and implicitly store some of its training data; careful analysis of the model may therefore reveal sensitive information. To address this problem, we demonstrate a generally applicable approach to providing strong privacy guarantees for training data: Private Aggregation of Teacher Ensembles (PATE). The approach combines, in a black-box fashion, multiple models trained with disjoint datasets, such as records from different subsets of users. Because they rely directly on sensitive data, these models are not published, but instead used as ""teachers"" for a ""student"" model. The student learns to predict an output chosen by noisy voting among all of the teachers, and cannot directly access an individual teacher or the underlying data or parameters. The student's privacy properties can be understood both intuitively (since no single teacher and thus no single dataset dictates the student's training) and formally, in terms of differential privacy. These properties hold even if an adversary can not only query the student but also inspect its internal workings. Compared with previous work, the approach imposes only weak assumptions on how teachers are trained: it applies to any model, including non-convex models like DNNs. We achieve state-of-the-art privacy/utility trade-offs on MNIST and SVHN thanks to an improved privacy analysis and semi-supervised learning.",2016,42,685,118,False,Computer Science,1967156,Nicolas Papernot,2057642721.0,Martín Abadi,Mathematics,1758110.0,Ú. Erlingsson,153440022.0,Ian J. Goodfellow,35210462.0,Kunal Talwar,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d592544922d2a8849c4ca14867797ab76d0f0953,https://www.semanticscholar.org/paper/d592544922d2a8849c4ca14867797ab76d0f0953,Support vector machine techniques for nonlinear equalization,"The emerging machine learning technique called support vector machines is proposed as a method for performing nonlinear equalization in communication systems. The support vector machine has the advantage that a smaller number of parameters for the model can be identified in a manner that does not require the extent of prior information or heuristic assumptions that some previous techniques require. Furthermore, the optimization method of a support vector machine is quadratic programming, which is a well-studied and understood mathematical programming technique. Support vector machine simulations are carried out on nonlinear problems previously studied by other researchers using neural networks. This allows initial comparison against other techniques to determine the feasibility of using the proposed method for nonlinear detection. Results show that support vector machines perform as well as neural networks on the nonlinear problems investigated. A method is then proposed to introduce decision feedback processing to support vector machines to address the fact that intersymbol interference (ISI) data generates input vectors having temporal correlation, whereas a standard support vector machine assumes independent input vectors. Presenting the problem from the viewpoint of the pattern space illustrates the utility of a bank of support vector machines. This approach yields a nonlinear processing method that is somewhat different than the nonlinear decision feedback method whereby the linear feedback filter of the decision feedback equalizer is replaced by a Volterra filter. A simulation using a linear system shows that the proposed method performs equally to a conventional decision feedback equalizer for this problem.",2000,40,300,14,False,Computer Science,1736284,D. Sebald,1686036.0,J. Bucklew,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bef0912974f272d6951de503c2f3edfa725e899f,https://www.semanticscholar.org/paper/bef0912974f272d6951de503c2f3edfa725e899f,SURVEY ON EVOLVING DEEP LEARNING NEURAL NETWORK ARCHITECTURES,"The deep learning being a subcategory of the machine learning follows the human instincts of learning by example to produce accurate results. The deep learning performs training to the computer frame work to directly classify the tasks from the documents available either in the form of the text, image, or the sound. Most often the deep learning utilizes the neural network to perform the accurate classification and is referred as the deep neural networks; one of the most common deep neural networks used in a broader range of applications is the convolution neural network that provides an automated way of feature extraction by learning the features directly from the images or the text unlike the machine learning that extracts the features manually. This enables the deep learning neural networks to have a state of art accuracy that mostly expels even the human performance. So the paper is to present the survey on the deep learning neural network architectures utilized in various applications for having an accurate classification with an automated feature extraction.",2019,31,212,7,False,Computer Science,1423434950,A. Bashar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3883850e09fec66f389697f90d84d468ed8aa062,https://www.semanticscholar.org/paper/3883850e09fec66f389697f90d84d468ed8aa062,A Case Study of Incremental Concept Induction,"Application of machine induction techniques in complex domains promises to push the computational limits of non-incremental, search intensive induction methods. Learning effectiveness in complex domains requires the development of incremental, cost effective methods. However, discussion of dimensions for comparing the utility of differing incremental methods has been lacking. In this paper we introduce 3 dimensions for characterizing incremental concept induction systems which relate to the cost and quality of learning. The dimensions are used to compare the respective merits of 4 incremental variants of Quinlan's learning from examples program, ID3. This comparison indicates that cost effective induction can be obtained, without significantly detracting from the quality of induced knowledge.",1986,5,364,17,False,Computer Science,2620923,J. C. Schlimmer,8993101.0,D. Fisher,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d5344942fbba45b7f1a17a5e16b11d4f53a954ee,https://www.semanticscholar.org/paper/d5344942fbba45b7f1a17a5e16b11d4f53a954ee,A Note on the Utility of Incremental Learning,"Historically, inductive machine learning has focused on nondincremental learning tasks, i.e., where the training set can be constructed a priori and learning stops once this set has been duly processed. There are, however, a number of areas, such as agents, where learning tasks are incremental. This paper defines the notion of incrementality for learning tasks and algorithms. It then provides some motivation for incremental learning and argues in favour of the design of incremental learning algorithms for solving incremental learning tasks. A number of issues raised by such systems are outlined and the incremental learner ILA is used for illustration.",2000,31,198,14,False,Computer Science,1398517004,C. Giraud-Carrier,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
02550ca5b686ba5a95b2782ae1904c98cf402c03,https://www.semanticscholar.org/paper/02550ca5b686ba5a95b2782ae1904c98cf402c03,Prototype-based models in machine learning.,"An overview is given of prototype-based models in machine learning. In this framework, observations, i.e., data, are stored in terms of typical representatives. Together with a suitable measure of similarity, the systems can be employed in the context of unsupervised and supervised analysis of potentially high-dimensional, complex datasets. We discuss basic schemes of competitive vector quantization as well as the so-called neural gas approach and Kohonen's topology-preserving self-organizing map. Supervised learning in prototype systems is exemplified in terms of learning vector quantization. Most frequently, the familiar Euclidean distance serves as a dissimilarity measure. We present extensions of the framework to nonstandard measures and give an introduction to the use of adaptive distances in relevance learning.",2016,92,98,3,True,Computer Science,144951109,Michael Biehl,143684647.0,B. Hammer,Medicine,9320960.0,T. Villmann,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
090a3e91629759fb66dd7206c4c3ed4c1fce45c9,https://www.semanticscholar.org/paper/090a3e91629759fb66dd7206c4c3ed4c1fce45c9,Experimental realization of a quantum support vector machine.,"The fundamental principle of artificial intelligence is the ability of machines to learn from previous experience and do future work accordingly. In the age of big data, classical learning machines often require huge computational resources in many practical cases. Quantum machine learning algorithms, on the other hand, could be exponentially faster than their classical counterparts by utilizing quantum parallelism. Here, we demonstrate a quantum machine learning algorithm to implement handwriting recognition on a four-qubit NMR test bench. The quantum machine learns standard character fonts and then recognizes handwritten characters from a set with two candidates. Because of the wide spread importance of artificial intelligence and its tremendous consumption of computational resources, quantum speedup would be extremely attractive against the challenges of big data.",2015,0,110,3,True,Computer Science,5312421,Zhaokai Li,48032382.0,Xiaomei Liu,Medicine,145203231.0,Nanyang Xu,145084594.0,Jiangfeng Du,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0b6624f39c549f99422b49e1e7a004492ed3d11c,https://www.semanticscholar.org/paper/0b6624f39c549f99422b49e1e7a004492ed3d11c,bartMachine: Machine Learning with Bayesian Additive Regression Trees,"We present a new package in R implementing Bayesian additive regression trees (BART). The package introduces many new features for data analysis using BART such as variable selection, interaction detection, model diagnostic plots, incorporation of missing data and the ability to save trees for future prediction. It is significantly faster than the current R implementation, parallelized, and capable of handling both large sample sizes and high-dimensional data.",2013,30,250,20,True,Computer Science,50645721,A. Kapelner,1576051500.0,J. Bleich,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cd444f03cefc14ae5a322c4df9f7c4e361bbb927,https://www.semanticscholar.org/paper/cd444f03cefc14ae5a322c4df9f7c4e361bbb927,Atom-density representations for machine learning.,"The applications of machine learning techniques to chemistry and materials science become more numerous by the day. The main challenge is to devise representations of atomic systems that are at the same time complete and concise, so as to reduce the number of reference calculations that are needed to predict the properties of different types of materials reliably. This has led to a proliferation of alternative ways to convert an atomic structure into an input for a machine-learning model. We introduce an abstract definition of chemical environments that is based on a smoothed atomic density, using a bra-ket notation to emphasize basis set independence and to highlight the connections with some popular choices of representations for describing atomic systems. The correlations between the spatial distribution of atoms and their chemical identities are computed as inner products between these feature kets, which can be given an explicit representation in terms of the expansion of the atom density on orthogonal basis functions, that is equivalent to the smooth overlap of atomic positions power spectrum, but also in real space, corresponding to n-body correlations of the atom density. This formalism lays the foundations for a more systematic tuning of the behavior of the representations, by introducing operators that represent the correlations between structure, composition, and the target properties. It provides a unifying picture of recent developments in the field and indicates a way forward toward more effective and computationally affordable machine-learning schemes for molecules and materials.",2018,77,105,1,True,Materials Science,11042469,Michael J. Willatt,34778608.0,F. Musil,Physics,1917770.0,M. Ceriotti,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
551a2463db60c3b65074b016de83c0fbd996504d,https://www.semanticscholar.org/paper/551a2463db60c3b65074b016de83c0fbd996504d,Learning classifiers for misuse and anomaly detection using a bag of system calls representation,"In this paper, we propose a ""bag of system calls"" representation for intrusion detection in system call sequences and describe misuse and anomaly detection results with standard machine learning techniques on University of New Mexico (UNM) and MIT Lincoln Lab (MIT LL) system call sequences with the proposed representation. With the feature representation as input, we compare the performance of several machine learning techniques for misuse detection and show experimental results on anomaly detection. The results show that standard machine learning and clustering techniques on simple ""bag of system calls"" representation of system call sequences is effective and often performs better than those approaches that use foreign contiguous subsequences in detecting intrusive behaviors of compromised processes.",2005,34,156,8,True,Computer Science,1955615,Dae-Ki Kang,29616408.0,D. Fuller,,145513516.0,Vasant G Honavar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6ce7dbba9fd5492acbadbd44a8590571bffa144c,https://www.semanticscholar.org/paper/6ce7dbba9fd5492acbadbd44a8590571bffa144c,GeePS: scalable deep learning on distributed GPUs with a GPU-specialized parameter server,"Large-scale deep learning requires huge computational resources to train a multi-layer neural network. Recent systems propose using 100s to 1000s of machines to train networks with tens of layers and billions of connections. While the computation involved can be done more efficiently on GPUs than on more traditional CPU cores, training such networks on a single GPU is too slow and training on distributed GPUs can be inefficient, due to data movement overheads, GPU stalls, and limited GPU memory. This paper describes a new parameter server, called GeePS, that supports scalable deep learning across GPUs distributed among multiple machines, overcoming these obstacles. We show that GeePS enables a state-of-the-art single-node GPU implementation to scale well, such as to 13 times the number of training images processed per second on 16 machines (relative to the original optimized single-node code). Moreover, GeePS achieves a higher training throughput with just four GPU machines than that a state-of-the-art CPU-only system achieves with 108 machines.",2016,42,292,32,True,Computer Science,1874200,Henggang Cui,1682058.0,H. Zhang,,1707164.0,G. Ganger,1974678.0,Phillip B. Gibbons,143977260.0,E. Xing,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e27bccbf297f11e96ec574273b75bf19871dff40,https://www.semanticscholar.org/paper/e27bccbf297f11e96ec574273b75bf19871dff40,Advances in Machine Learning Based Text Categorization,"In recent years, there have been extensive studies and rapid progresses in automatic text categorization, which is one of the hotspots and key techniques in the information retrieval and data mining field. Highlighting the state-of-art challenging issues and research trends for content information processing of Internet and other complex applications, this paper presents a survey on the up-to-date development in text categorization based on machine learning, including model, algorithm and evaluation. It is pointed out that problems such as nonlinearity, skewed data distribution, labeling bottleneck, hierarchical categorization, scalability of algorithms and categorization of Web pages are the key problems to the study of text categorization. Possible solutions to these problems are also discussed respectively. Finally, some future directions of research are given.",2006,100,114,3,False,Computer Science,101111982,Su Jinshu,9441976.0,Zhang Bo-feng,,2054666190.0,Xu Xin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80e34049beab0e1aae5cc7a15f672d68e4ecf229,https://www.semanticscholar.org/paper/80e34049beab0e1aae5cc7a15f672d68e4ecf229,PyStruct: learning structured prediction in python,"Structured prediction methods have become a central tool for many machine learning applications. While more and more algorithms are developed, only very few implementations are available. PyStruct aims at providing a general purpose implementation of standard structured prediction methods, both for practitioners and as a baseline for researchers. It is written in Python and adapts paradigms and types from the scientific Python community for seamless integration with other projects.",2014,24,88,12,False,Computer Science,2113785713,Andreas C. Müller,1699019.0,Sven Behnke,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b95dda2f2e606c91b69f371c1a706248cb5f69bb,https://www.semanticscholar.org/paper/b95dda2f2e606c91b69f371c1a706248cb5f69bb,On the Feasibility of Deep Learning in Sensor Network Intrusion Detection,"In this letter, we present a comprehensive analysis of the use of machine and deep learning (DL) solutions for IDS systems in wireless sensor networks (WSNs). To accomplish this, we introduce restricted Boltzmann machine-based clustered IDS (RBC-IDS), a potential DL-based IDS methodology for monitoring critical infrastructures by WSNs. We study the performance of RBC-IDS, and compare it to the previously proposed adaptive machine learning-based IDS: the adaptively supervised and clustered hybrid IDS (ASCH-IDS). Numerical results show that RBC-IDS and ASCH-IDS achieve the same detection and accuracy rates, though the detection time of RBC-IDS is approximately twice that of ASCH-IDS.",2019,16,150,3,False,Computer Science,2823694,S. Otoum,2497479.0,B. Kantarci,,144769367.0,H. Mouftah,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d108b5fb580cc7bcee4a19d83ae429d8719f951c,https://www.semanticscholar.org/paper/d108b5fb580cc7bcee4a19d83ae429d8719f951c,"Interactive Supercomputing on 40,000 Cores for Machine Learning and Data Analysis","Interactive massively parallel computations are critical for machine learning and data analysis. These computations are a staple of the MIT Lincoln Laboratory Supercomputing Center (LLSC) and has required the LLSC to develop unique interactive supercomputing capabilities. Scaling interactive machine learning frameworks, such as TensorFlow, and data analysis environments, such as MATLAB/Octave, to tens of thousands of cores presents many technical challenges – in particular, rapidly dispatching many tasks through a scheduler, such as Slurm, and starting many instances of applications with thousands of dependencies. Careful tuning of launches and prepositioning of applications overcome these challenges and allow the launching of thousands of tasks in seconds on a 40,000-core supercomputer. Specifically, this work demonstrates launching 32,000 TensorFlow processes in 4 seconds and launching 262,000 Octave processes in 40 seconds. These capabilities allow researchers to rapidly explore novel machine learning architecture and data analysis algorithms.",2018,27,121,12,True,Computer Science,2097629,A. Reuther,3257323.0,J. Kepner,,2098646.0,C. Byun,2331418.0,S. Samsi,3302251.0,W. Arcand,2159806.0,David Bestor,34001612.0,Bill Bergeron,74882299.0,V. Gadepally,,4121232.0,Michael Houle,145238688.0,M. Hubbell,2111328084.0,Michael Jones,144414765.0,Anna Klein,3385550.0,Lauren Milechin,143913450.0,J. Mullen,2417672.0,Andrew Prout,144557576.0,Antonio Rosa,145378881.0,Charles Yee,1684116.0,P. Michaleas,
2abdca069a95add94f5c0c540c09efb7adeee230,https://www.semanticscholar.org/paper/2abdca069a95add94f5c0c540c09efb7adeee230,Reproducibility in machine learning for health research: Still a ways to go,"Machine learning applied to health falls short on several reproducibility metrics compared to other machine learning subfields. Machine learning for health must be reproducible to ensure reliable clinical use. We evaluated 511 scientific papers across several machine learning subfields and found that machine learning for health compared poorly to other areas regarding reproducibility metrics, such as dataset and code accessibility. We propose recommendations to address this problem.",2021,27,56,3,False,Medicine,41153596,Matthew B. A. McDermott,118188980.0,Shirly Wang,,150247231.0,N. Marinsek,2615814.0,R. Ranganath,1748978.0,L. Foschini,2804918.0,M. Ghassemi,,,,,,,,,,,,,,,,,,,,,,,,,,
1fbfe89fbcbbb61fb3ef6e9fb02cbe3bd8ce67ca,https://www.semanticscholar.org/paper/1fbfe89fbcbbb61fb3ef6e9fb02cbe3bd8ce67ca,A REVIEW OF STUDIES ON MACHINE LEARNING TECHNIQUES,"This paper provides an extensive review of studies related to expert estimation of software development using Machine-Learning Techniques (MLT). Machine learning in this new era, is demonstrating the promise of producing consistently accurate estimates. Machine learning system effectively “learns” how to estimate from training set of completed projects. The main goal and contribution of the review is to support the research on expert estimation, i.e. to ease other researchers for relevant expert estimation studies using machine-learning techniques. This paper presents the most commonly used machine learning techniques such as neural networks, case based reasoning, classification and regression trees, rule induction, genetic algorithm & genetic programming for expert estimation in the field of software development. In each of our study we found that the results of various machine-learning techniques depends on application areas on which they are applied. Our review of study not only suggests that these techniques are competitive with traditional estimators on one data set, but also illustrate that these methods are sensitive to the data on which they are trained.",2007,27,81,3,False,,144657236,Y. Singh,1847926.0,P. Bhatia,,2099912353.0,ys,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fe8db65fe5d94de49777388e40b7951fbea636cf,https://www.semanticscholar.org/paper/fe8db65fe5d94de49777388e40b7951fbea636cf,Quantum Entanglement in Deep Learning Architectures.,"Modern deep learning has enabled unprecedented achievements in various domains. Nonetheless, employment of machine learning for wave function representations is focused on more traditional architectures such as restricted Boltzmann machines (RBMs) and fully connected neural networks. In this Letter, we establish that contemporary deep learning architectures, in the form of deep convolutional and recurrent networks, can efficiently represent highly entangled quantum systems. By constructing tensor network equivalents of these architectures, we identify an inherent reuse of information in the network operation as a key trait which distinguishes them from standard tensor network-based representations, and which enhances their entanglement capacity. Our results show that such architectures can support volume-law entanglement scaling, polynomially more efficiently than presently employed RBMs. Thus, beyond a quantification of the entanglement capacity of leading deep learning architectures, our analysis formally motivates a shift of trending neural-network-based wave function representations closer to the state-of-the-art in machine learning.",2018,67,124,3,True,Medicine,152754428,Yoav Levine,3074811.0,Or Sharir,Physics,32289606.0,Nadav Cohen,3140335.0,A. Shashua,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,
107d68e984ec961dff26d4bd74687fef4d1a6564,https://www.semanticscholar.org/paper/107d68e984ec961dff26d4bd74687fef4d1a6564,Machine Learning and Pattern Recognition,"Learning is needed when there is no human expertise existing or when human beings are unable to explain their expertise. In such a situation, one simply collects all the possible previous information, analyse it and then make a rule for future prediction or taking meaningful decision. When we plan to conclude such a work with the help of a computer by providing it ample amount of data and our past experience with tools and techniques, then the whole process becomes machine learning. Hence, machine learning can be defined as programming computers to optimise a performance criterion using example data and past experience. For example, recognition of spoken speech is being done by human beings seemingly without any difficulty, but cannot explain how they do it. Defence Science Journal, 2010, 60(4), pp.345-347 , DOI:http://dx.doi.org/10.14429/dsj.60.502",2010,5,72,11,False,Computer Science,49824784,Shri Kant,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36b8c88c8b3dd4048ad7583ca41c1b21f6a71ef7,https://www.semanticscholar.org/paper/36b8c88c8b3dd4048ad7583ca41c1b21f6a71ef7,"Deep Learning: The Good, the Bad, and the Ugly.","Artificial vision has often been described as one of the key remaining challenges to be solved before machines can act intelligently. Recent developments in a branch of machine learning known as deep learning have catalyzed impressive gains in machine vision-giving a sense that the problem of vision is getting closer to being solved. The goal of this review is to provide a comprehensive overview of recent deep learning developments and to critically assess actual progress toward achieving human-level visual intelligence. I discuss the implications of the successes and limitations of modern machine vision algorithms for biological vision and the prospect for neuroscience to inform the design of future artificial vision systems. Expected final online publication date for the Annual Review of Vision Science, Volume 5 is September 16, 2019. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.",2019,37,139,6,False,Medicine,152684324,T. Serre,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6409189c1949945e57fa9033c2ec26247cfffb39,https://www.semanticscholar.org/paper/6409189c1949945e57fa9033c2ec26247cfffb39,Introduction to Tensor Decompositions and their Applications in Machine Learning,"Tensors are multidimensional arrays of numerical values and therefore generalize matrices to multiple dimensions. While tensors first emerged in the psychometrics community in the $20^{\text{th}}$ century, they have since then spread to numerous other disciplines, including machine learning. Tensors and their decompositions are especially beneficial in unsupervised learning settings, but are gaining popularity in other sub-disciplines like temporal and multi-relational data analysis, too. The scope of this paper is to give a broad overview of tensors, their decompositions, and how they are used in machine learning. As part of this, we are going to introduce basic tensor concepts, discuss why tensors can be considered more rigid than matrices with respect to the uniqueness of their decomposition, explain the most important factorization algorithms and their properties, provide concrete examples of tensor decomposition applications in machine learning, conduct a case study on tensor-based estimation of mixture models, talk about the current state of research, and provide references to available software libraries.",2017,43,152,10,False,Computer Science,29938263,Stephan Rabanser,32724677.0,Oleksandr Shchur,Mathematics,3075189.0,Stephan Günnemann,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eb45b073b52040d05aa9b462415cb881595b85fc,https://www.semanticscholar.org/paper/eb45b073b52040d05aa9b462415cb881595b85fc,Concept formation knowledge and experience in unsupervised learning,"Concept formation lies at the center of learning and cognition. Unlike much work in machine learning and cognitive psychology, research on this topic focuses on the unsupervised and incremental acquisition of conceptual knowledge. Recent work on concept formation addresses a number of important issues. Foremost among these are the principles of similarity that guide concept learning and retrieval in human and machine, including the contribution of surface features, goals, and `deep' features. Another active area of research explores mechanisms for efficiently reorganizing memory in response to the ongoing experiences that confront intelligent agents. Finally, methods for concept formation play an increasing role in work on problem solving and planning, developmental psychology, engineering applications, and constructive induction. This book brings together results on concept formation from cognitive psychology and machine learning, including explanation-based and inductive approaches. Chapters from these differing perspectives are intermingled to highlight the commonality of their research agendas. In addition to cognitive scientists and AI researchers, the book will interest data analysts involved in clustering, philosophers concerned with the nature and origin of concepts, and any researcher dealing with issues of similarity, memory organization, and problem solving.",1991,2,234,5,False,Psychology,8993101,D. Fisher,1694780.0,M. Pazzani,,1713919.0,P. Langley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81fc34df88b2293981380454e7259629ff645320,https://www.semanticscholar.org/paper/81fc34df88b2293981380454e7259629ff645320,Deep Learning the Ising Model Near Criticality,"It is well established that neural networks with deep architectures perform better than shallow networks for many tasks in machine learning. In statistical physics, while there has been recent interest in representing physical data with generative modelling, the focus has been on shallow neural networks. A natural question to ask is whether deep neural networks hold any advantage over shallow networks in representing such data. We investigate this question by using unsupervised, generative graphical models to learn the probability distribution of a two-dimensional Ising system. Deep Boltzmann machines, deep belief networks, and deep restricted Boltzmann networks are trained on thermal spin configurations from this system, and compared to the shallow architecture of the restricted Boltzmann machine. We benchmark the models, focussing on the accuracy of generating energetic observables near the phase transition, where these quantities are most difficult to approximate. Interestingly, after training the generative networks, we observe that the accuracy essentially depends only on the number of neurons in the first hidden layer of the network, and not on other model details such as network depth or model type. This is evidence that shallow networks are more efficient than deep networks at representing physical probability distributions associated with Ising systems near criticality.",2017,31,73,4,False,Computer Science,23976374,A. Morningstar,3422513.0,R. Melko,Physics,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,
55fc39658e9554f81bb29f95905ed8108d4e5f27,https://www.semanticscholar.org/paper/55fc39658e9554f81bb29f95905ed8108d4e5f27,Wheel Defect Detection With Machine Learning,"Wheel defects on railway wagons have been identified as an important source of damage to the railway infrastructure and rolling stock. They also cause noise and vibration emissions that are costly to mitigate. We propose two machine learning methods to automatically detect these wheel defects, based on the wheel vertical force measured by a permanently installed sensor system on the railway network. Our methods automatically learn different types of wheel defects and predict during normal operation if a wheel has a defect or not. The first method is based on novel features for classifying time series data and it is used for classification with a support vector machine. To evaluate the performance of our method we construct multiple data sets for the following defect types: flat spot, shelling, and non-roundness. We outperform classical defect detection methods for flat spots and demonstrate prediction for the other two defect types for the first time. Motivated by the recent success of artificial neural networks for image classification, we train custom artificial neural networks with convolutional layers on 2-D representations of the measurement time series. The neural network approach improves the performance on wheels with flat spots and non-roundness by explicitly modeling the multi sensor structure of the measurement system through multiple instance learning and shift invariant networks.",2018,35,109,5,False,Engineering,1762319,Gabriel Krummenacher,1706780.0,Cheng Soon Ong,Computer Science,2067087623.0,Stefan Koller,51194506.0,Seijin Kobayashi,1682548.0,J. Buhmann,,,,,,,,,,,,,,,,,,,,,,,,,,,,
89a0884dc1e456afda244357e45c0ea812869d4d,https://www.semanticscholar.org/paper/89a0884dc1e456afda244357e45c0ea812869d4d,Real-time human interaction with supervised learning algorithms for music composition and performance,"This thesis examines machine learning through the lens of human-computer interaction in order to address fundamental questions surrounding the application of machine learning to real-life problems, including: Can we make machine learning algorithms more usable and useful? Can we better understand the real-world consequences of algorithm choices and user interface designs for end-user machine learning? How can human interaction play a role in enabling users to efficiently create useful machine learning systems, in enabling successful application of algorithms by machine learning novices, and in ultimately making it possible in practice to apply machine learning to new problems? The scope of the research presented here is the application of supervised learning algorithms to contemporary computer music composition and performance. Computer music is a domain rich with computational problems requiring the modeling of complex phenomena, the construction of real-time interactive systems, and the support of human creativity. Though varied, many of these problems may be addressed using machine learning techniques, including supervised learning in particular. This work endeavors to gain a deeper knowledge of the human factors surrounding the application of supervised learning to these types of problems, to make supervised learning algorithms more usable by musicians, and to study how supervised learning can function as a creative tool. This thesis presents a general-purpose software system for applying standard supervised learning algorithms in music and other real-time problem domains. This system, called the Wekinator, supports human interaction throughout the entire supervised learning process, including the generation of training examples and the application of trained models to real-time inputs. The Wekinator is published as a freely-available, open source software project, and several composers have already employed it in the creation of new musical instruments and compositions. This thesis also presents work utilizing the Wekinator to study human-computer interaction with supervised learning in computer music. Research is presented which includes a participatory design process with practicing composers, pedagogical use with non-expert users in an undergraduate classroom, a study of the design of a gesture recognition system for a sensor-augmented cello bow, and case studies with three composers who have used the system in completed artistic works. The primary contributions of this work include (1) a new software tool allowing real-time human interaction with supervised learning algorithms, which includes a novel “playalong” interaction for generating training data in real-time; (2) a demonstration of the important roles that interaction|encompassing both human-computer control and computer-human feedback|can play in the development of supervised learning systems, and a greater understanding of the differences between interactive and conventional machine learning contexts; (3) a better understanding of the requirements and challenges in the analysis and design of algorithms and interfaces for interactive supervised learning in real-time and creative problem domains; (4) a clearer characterization of composers' goals and priorities for interacting with computers in music composition and instrument design; and (5) a demonstration of the usefulness of interactive supervised learning as a creativity support tool. This work both empowers musicians to create new forms of art and contributes to a broader HCI perspective on machine learning practice.",2011,180,104,5,False,Computer Science,1716507,P. Cook,1745615.0,R. Fiebrink,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
398ead8535b127521f609828e1cd15f26ce1b4e1,https://www.semanticscholar.org/paper/398ead8535b127521f609828e1cd15f26ce1b4e1,Learning Machine Translation,"The Internet gives us access to a wealth of information in languages we don't understand. The investigation of automated or semi-automated approaches to translation has become a thriving research field with enormous commercial potential. This volume investigates how machine learning techniques can improve statistical machine translation, currently at the forefront of research in the field. The book looks first at enabling technologiestechnologies that solve problems that are not machine translation proper but are linked closely to the development of a machine translation system. These include the acquisition of bilingual sentence-aligned data from comparable corpora, automatic construction of multilingual name dictionaries, and word alignment. The book then presents new or improved statistical machine translation techniques, including a discriminative training framework for leveraging syntactic information, the use of semi-supervised and kernel-based learning methods, and the combination of multiple machine translation outputs in order to improve overall translation quality. Contributors: Srinivas Bangalore, Nicola Cancedda, Josep M. Crego, Marc Dymetman, Jakob Elming, George Foster, Jess Gimnez, Cyril Goutte, Nizar Habash, Gholamreza Haffari, Patrick Haffner, Hitoshi Isahara, Stephan Kanthak, Alexandre Klementiev, Gregor Leusch, Pierre Mah, Llus Mrquez, Evgeny Matusov, I. Dan Melamed, Ion Muslea, Hermann Ney, Bruno Pouliquen, Dan Roth, Anoop Sarkar, John Shawe-Taylor, Ralf Steinberger, Joseph Turian, Nicola Ueffing, Masao Utiyama, Zhuoran Wang, Benjamin Wellington, Kenji Yamada Neural Information Processing series",2010,4,69,3,False,Computer Science,2788842,Cyril Goutte,1683776.0,Nicola Cancedda,,2954698.0,Marc Dymetman,2458308.0,George F. Foster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
54a13bcc9613dcaa76fb25fbe96572f376cfcca9,https://www.semanticscholar.org/paper/54a13bcc9613dcaa76fb25fbe96572f376cfcca9,Adafactor: Adaptive Learning Rates with Sublinear Memory Cost,"In several recently proposed stochastic optimization methods (e.g. RMSProp, Adam, Adadelta), parameter updates are scaled by the inverse square roots of exponential moving averages of squared past gradients. Maintaining these per-parameter second-moment estimators requires memory equal to the number of parameters. For the case of neural network weight matrices, we propose maintaining only the per-row and per-column sums of these moving averages, and estimating the per-parameter second moments based on these sums. We demonstrate empirically that this method produces similar results to the baseline. Secondly, we show that adaptive methods can produce larger-than-desired updates when the decay rate of the second moment accumulator is too slow. We propose update clipping and a gradually increasing decay rate scheme as remedies. Combining these methods and dropping momentum, we achieve comparable results to the published Adam regime in training the Transformer model on the WMT 2014 English-German machine translation task, while using very little auxiliary storage in the optimizer. Finally, we propose scaling the parameter updates based on the scale of the parameters themselves.",2018,13,390,69,False,Computer Science,1846258,Noam M. Shazeer,144872294.0,Mitchell Stern,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
150538d8117b8fb08d9efc340e49c52afd11399a,https://www.semanticscholar.org/paper/150538d8117b8fb08d9efc340e49c52afd11399a,Decision tree classifier for network intrusion detection with GA-based feature selection,"Machine Learning techniques such as Genetic Algorithms and Decision Trees have been applied to the field of intrusion detection for more than a decade. Machine Learning techniques can learn normal and anomalous patterns from training data and generate classifiers that then are used to detect attacks on computer systems. In general, the input data to classifiers is in a high dimension feature space, but not all of features are relevant to the classes to be classified. In this paper, we use a genetic algorithm to select a subset of input features for decision tree classifiers, with a goal of increasing the detection rate and decreasing the false alarm rate in network intrusion detection. We used the KDDCUP 99 data set to train and test the decision tree classifiers. The experiments show that the resulting decision trees can have better performance than those built with all available features.",2005,33,319,3,False,Computer Science,50435109,G. Stein,2146710489.0,Bing Chen,,2989050.0,A. Wu,1730455.0,K. Hua,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81af3058f2df78be332f50ea3813be5aa1f02f58,https://www.semanticscholar.org/paper/81af3058f2df78be332f50ea3813be5aa1f02f58,The Hidden Vulnerability of Distributed Learning in Byzantium,"While machine learning is going through an era of celebrated success, concerns have been raised about the vulnerability of its backbone: stochastic gradient descent (SGD). Recent approaches have been proposed to ensure the robustness of distributed SGD against adversarial (Byzantine) workers sending poisoned gradients during the training phase. Some of these approaches have been proven Byzantine-resilient: they ensure the convergence of SGD despite the presence of a minority of adversarial workers. We show in this paper that convergence is not enough. In high dimension $d \gg 1$, an adver\-sary can build on the loss function's non-convexity to make SGD converge to ineffective models. More precisely, we bring to light that existing Byzantine-resilient schemes leave a margin of poisoning of $\Omega\left(f(d)\right)$, where $f(d)$ increases at least like $\sqrt{d~}$. Based on this leeway, we build a simple attack, and experimentally show its strong to utmost effectivity on CIFAR-10 and MNIST. We introduce Bulyan, and prove it significantly reduces the attackers leeway to a narrow $O( \frac{1}{\sqrt{d~}})$ bound. We empirically show that Bulyan does not suffer the fragility of existing aggregation rules and, at a reasonable cost in terms of required batch size, achieves convergence as if only non-Byzantine gradients had been used to update the model.",2018,34,293,63,False,Computer Science,9623412,El Mahdi El Mhamdi,1727558.0,R. Guerraoui,Mathematics,36055256.0,Sébastien Rouault,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4c2a642effd543babace0c565b48cadcb6fce14f,https://www.semanticscholar.org/paper/4c2a642effd543babace0c565b48cadcb6fce14f,An Empirical Evaluation of Knowledge Sources and Learning Algorithms for Word Sense Disambiguation,"In this paper, we evaluate a variety of knowledge sources and supervised learning algorithms for word sense disambiguation on SENSEVAL-2 and SENSEVAL-1 data. Our knowledge sources include the part-of-speech of neighboring words, single words in the surrounding context, local collocations, and syntactic relations. The learning algorithms evaluated include Support Vector Machines (SVM), Naive Bayes, AdaBoost, and decision tree algorithms. We present empirical results showing the relative contribution of the component knowledge sources and the different learning algorithms. In particular, using all of these knowledge sources and SVM (i.e., a single learning algorithm) achieves accuracy higher than the best official scores on both SENSEVAL-2 and SENSEVAL-1 test data.",2002,42,290,22,True,Computer Science,2110391587,Yoong Keok Lee,34789794.0,H. Ng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1f6d30772a94d978c9f81e2f7c1f4b0bdec117dd,https://www.semanticscholar.org/paper/1f6d30772a94d978c9f81e2f7c1f4b0bdec117dd,Large Scale Incremental Learning,"Modern machine learning suffers from \textit{catastrophic forgetting} when learning new classes incrementally. The performance dramatically degrades due to the missing data of old classes. Incremental learning methods have been proposed to retain the knowledge acquired from the old classes, by using knowledge distilling and keeping a few exemplars from the old classes. However, these methods struggle to \textbf{scale up to a large number of classes}. We believe this is because of the combination of two factors: (a) the data imbalance between the old and new classes, and (b) the increasing number of visually similar classes. Distinguishing between an increasing number of visually similar classes is particularly challenging, when the training data is unbalanced. We propose a simple and effective method to address this data imbalance issue. We found that the last fully connected layer has a strong bias towards the new classes, and this bias can be corrected by a linear model. With two bias parameters, our method performs remarkably well on two large datasets: ImageNet (1000 classes) and MS-Celeb-1M (10000 classes), outperforming the state-of-the-art algorithms by 11.1\% and 13.2\% respectively.",2019,27,484,128,True,Computer Science,2119299240,Yue Wu,2109306087.0,Yinpeng Chen,,29957038.0,Lijuan Wang,3105254.0,Yuancheng Ye,2145253136.0,Zicheng Liu,3133575.0,Yandong Guo,46956675.0,Y. Fu,,,,,,,,,,,,,,,,,,,,,,,,
203392c8269d1ab241c71cd9df1cda829cc8b651,https://www.semanticscholar.org/paper/203392c8269d1ab241c71cd9df1cda829cc8b651,"Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning","Judea Pearl's Causal Model is a rich framework that provides deep insight into the nature of causal relations. As yet, however, the Pearl Causal Model (PCM) has had a lesser impact on economics or econometrics than on other disciplines. This may be due in part to the fact that the PCM is not as well suited to analyzing structures that exhibit features of central interest to economists and econometricians: optimization, equilibrium, and learning. We offer the settable systems framework as an extension of the PCM that permits causal discourse in systems embodying optimization, equilibrium, and learning. Because these are common features of physical, natural, or social systems, our framework may prove generally useful for machine learning. Important features distinguishing the settable system framework from the PCM are its countable dimensionality and the use of partitioning and partition-specific response functions to accommodate the behavior of optimizing and interacting agents and to eliminate the requirement of a unique fixed point for the system. Refinements of the PCM include the settable systems treatment of attributes, the causal role of exogenous variables, and the dual role of variables as causes and responses. A series of closely related machine learning examples and examples from game theory and machine learning with feedback demonstrates some limitations of the PCM and motivates the distinguishing features of settable systems.",2009,55,65,4,False,Computer Science,2149702798,H. White,2605889.0,Karim Chalak,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3c4b8f52f207939b6f959108bb81d008c4f9887d,https://www.semanticscholar.org/paper/3c4b8f52f207939b6f959108bb81d008c4f9887d,Missing Data Problems in Machine Learning,"Learning, inference, and prediction in the presence of missing data are pervasive problems in machine learning and statistical data analysis. This thesis focuses on the problems of collaborative prediction with non-random missing data and classification with missing features. We begin by presenting and elaborating on the theory of missing data due to Little and Rubin. We place a particular emphasis on the missing at random assumption in the multivariate setting with arbitrary patterns of missing data. We derive inference and prediction methods in the presence of random missing data for a variety of probabilistic models including finite mixture models, Dirichlet process mixture models, and factor analysis. Based on this foundation, we develop several novel models and inference procedures for both the collaborative prediction problem and the problem of classification with missing features. We develop models and methods for collaborative prediction with non-random missing data by combining standard models for complete data with models of the missing data process. Using a novel recommender system data set and experimental protocol, we show that each proposed method achieves a substantial increase in rating prediction performance compared to models that assume missing ratings are missing at random. We describe several strategies for classification with missing features including the use of generative classifiers, and the combination of standard discriminative classifiers with single imputation, multiple imputation, classification in subspaces, and an approach based on modifying the classifier input representation to include response indicators. Results on real and synthetic data sets show that in some cases performance gains over baseline methods can be achieved by methods that do not learn a detailed model of the feature space.",2008,87,116,6,False,Computer Science,1805742,Benjamin M Marlin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
916c816f16e4934e41f09a3ff81a10e5fc4bb459,https://www.semanticscholar.org/paper/916c816f16e4934e41f09a3ff81a10e5fc4bb459,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,"We develop and study multicalibration as a new measure of fairness in machine learning that aims to mitigate inadvertent or malicious discrimination that is introduced at training time (even from ground truth data). Multicalibration guarantees meaningful (calibrated) predictions for every subpopulation that can be identified within a specified class of computations. The specified class can be quite rich; in particular, it can contain many overlapping subgroups of a protected group. We demonstrate that in many settings this strong notion of protection from discrimination is provably attainable and aligned with the goal of accurate predictions. Along the way, we present algorithms for learning a multicalibrated predictor, study the computational complexity of this task, and illustrate tight connections to the agnostic learning model.",2018,34,142,16,False,Computer Science,1405130584,Úrsula Hébert-Johnson,2110079050.0,Michael P. Kim,,1746057.0,O. Reingold,2551824.0,G. Rothblum,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c16629bf5286cb30d5ccbee276a5270127a3530e,https://www.semanticscholar.org/paper/c16629bf5286cb30d5ccbee276a5270127a3530e,Robust feature selection algorithms,"Selecting a set of features which is optimal for a given task is a problem which plays an important role in wide variety of contexts including pattern recognition, adaptive control and machine learning. Experience with traditional feature selection algorithms in the domain of machine learning leads to an appreciation for their computational efficiency and a concern for their brittleness. The authors describe an alternative approach to feature selection which uses genetic algorithms as the primary search component. Results are presented which suggested that genetic algorithms can be used to increase the robustness of feature selection algorithms without a significant decrease in compuational efficiency.",1993,8,197,3,False,Computer Science,2020670,H. Vafaie,2069839824.0,K. A. Jong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0506e3089918a2d9e24043e0919ae2d20f6fd09e,https://www.semanticscholar.org/paper/0506e3089918a2d9e24043e0919ae2d20f6fd09e,Metric learning for text documents,"Many algorithms in machine learning rely on being given a good distance metric over the input space. Rather than using a default metric such as the Euclidean metric, it is desirable to obtain a metric based on the provided data. We consider the problem of learning a Riemannian metric associated with a given differentiable manifold and a set of points. Our approach to the problem involves choosing a metric from a parametric family that is based on maximizing the inverse volume of a given data set of points. From a statistical perspective, it is related to maximum likelihood under a model that assigns probabilities inversely proportional to the Riemannian volume element. We discuss in detail learning a metric on the multinomial simplex where the metric candidates are pull-back metrics of the Fisher information under a Lie group of transformations. When applied to text document classification the resulting geodesic distance resemble, but outperform, the tfidf cosine similarity measure.",2006,12,145,10,False,Computer Science,1717932,G. Lebanon,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b68e8d2f4d2c709bb5919b82effcb6a7bbd3db37,https://www.semanticscholar.org/paper/b68e8d2f4d2c709bb5919b82effcb6a7bbd3db37,Stock Market Forecasting Using Machine Learning Algorithms,"Prediction of stock market is a long-time attractive topic to researchers from different fields. In particular, numerous studies have been conducted to predict the movement of stock market using machine learning algorithms such as support vector machine (SVM) and reinforcement learning. In this project, we propose a new prediction algorithm that exploits the temporal correlation among global stock markets and various financial products to predict the next-day stock trend with the aid of SVM. Numerical results indicate a prediction accuracy of 74.4% in NASDAQ, 76% in S&P500 and 77.6% in DJIA. The same algorithm is also applied with different regression algorithms to trace the actual increment in the markets. Finally, a simple trading model is established to study the performance of the proposed prediction algorithm against other benchmarks.",2012,3,109,3,False,Computer Science,31157189,S. Shen,2484506.0,Haomiao Jiang,,2116382.0,Tongda Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4baee71da9b4e8ea1feec5bbed8249eed670272e,https://www.semanticscholar.org/paper/4baee71da9b4e8ea1feec5bbed8249eed670272e,Machine Learning Methods for Property Prediction in Chemoinformatics: Quo Vadis?,"This paper is focused on modern approaches to machine learning, most of which are as yet used infrequently or not at all in chemoinformatics. Machine learning methods are characterized in terms of the ""modes of statistical inference"" and ""modeling levels"" nomenclature and by considering different facets of the modeling with respect to input/ouput matching, data types, models duality, and models inference. Particular attention is paid to new approaches and concepts that may provide efficient solutions of common problems in chemoinformatics: improvement of predictive performance of structure-property (activity) models, generation of structures possessing desirable properties, model applicability domain, modeling of properties with functional endpoints (e.g., phase diagrams and dose-response curves), and accounting for multiple molecular species (e.g., conformers or tautomers).",2012,305,173,2,False,Computer Science,1685042,A. Varnek,2539452.0,I. Baskin,Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fbff6e316722053f5233f4c7869cc18e705af2e3,https://www.semanticscholar.org/paper/fbff6e316722053f5233f4c7869cc18e705af2e3,Learning to Filter Unsolicited Commercial E-Mail,"We present a thorough investigation on using machine learning to construct effective personalized anti-spam filters. The investigation includes four learning algorithms, Naive Bayes, Flexible Bayes, LogitBoost, and Support Vector Machines, and four datasets, constructed from the mailboxes of different users. We discuss the model and search biases of the learning algorithms, along with worst-case computational complexity figures, and observe how the latter relate to experimental measurements. We study how classification accuracy is affected when using attributes that represent sequences of tokens, as opposed to single tokens, and explore the effect of the size of the attribute and training set, all within a cost-sensitive framework. Furthermore, we describe the architecture of a fully implemented learning-based anti-spam filter, and present an analysis of its behavior in real use over a period of seven months. Information is also provided on other available learning-based anti-spam filters, and alternative filtering approaches.",2006,52,175,26,False,Computer Science,1752430,Ion Androutsopoulos,4738873.0,G. Paliouras,,31650939.0,E. Michelakis,31650939.0,E. Michelakis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
371f7ac8d33a044b71d392638c81077b72030814,https://www.semanticscholar.org/paper/371f7ac8d33a044b71d392638c81077b72030814,ProfilIoT: a machine learning approach for IoT device identification based on network traffic analysis,"In this work we apply machine learning algorithms on network traffic data for accurate identification of IoT devices connected to a network. To train and evaluate the classifier, we collected and labeled network traffic data from nine distinct IoT devices, and PCs and smartphones. Using supervised learning, we trained a multi-stage meta classifier; in the first stage, the classifier can distinguish between traffic generated by IoT and non-IoT devices. In the second stage, each IoT device is associated a specific IoT device class. The overall IoT classification accuracy of our model is 99.281+.",2017,13,261,6,True,Computer Science,11034542,Yair Meidan,11055183.0,Michael Bohadana,,1720589.0,A. Shabtai,144953724.0,J. Guarnizo,145010553.0,Martín Ochoa,2225170.0,Nils Ole Tippenhauer,1724372.0,Y. Elovici,,,,,,,,,,,,,,,,,,,,,,,,
c141b7c4ccb4a0e5d2a327aa260b318c7c3bcfbb,https://www.semanticscholar.org/paper/c141b7c4ccb4a0e5d2a327aa260b318c7c3bcfbb,Real-Time Adaptive Image Compression,"We present a machine learning-based approach to lossy image compression which outperforms all existing codecs, while running in real-time. Our algorithm typically produces files 2.5 times smaller than JPEG and JPEG 2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets of generic images across all quality levels. At the same time, our codec is designed to be lightweight and deployable: for example, it can encode or decode the Kodak dataset in around 10ms per image on GPU. Our architecture is an autoencoder featuring pyramidal analysis, an adaptive coding module, and regularization of the expected codelength. We also supplement our approach with adversarial training specialized towards use in a compression setting: this enables us to produce visually pleasing reconstructions for very low bitrates.",2017,24,424,53,False,Mathematics,1757324,Oren Rippel,1769383.0,Lubomir D. Bourdev,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
314913e088d254f49890e1feb32f3b70c92170a4,https://www.semanticscholar.org/paper/314913e088d254f49890e1feb32f3b70c92170a4,Learning Program Behavior Profiles for Intrusion Detection,"Profiling the behavior of programs can be a useful reference for detecting potential intrusions against systems. This paper presents three anomaly detection techniques for profiling program behavior that evolve from memorization to generalization. The goal of monitoring program behavior is to be able to detect potential intrusions by noting irregularities in program behavior. The techniques start from a simple equality matching algorithm for determining anomalous behavior, and evolve to a feed-forward backpropagation neural network for learning program behavior, and finally to an Elman network for recognizing recurrent features in program execution traces. In order to detect future attacks against systems, intrusion detection systems must be able to generalize from past observed behavior. The goal of this research is to employ machine learning techniques that can generalize from past observed behavior to the problem of intrusion detection. The performance of these systems is compared by testing them with data provided by the DARPA Intrusion Detection Evaluation program.",1999,35,510,21,False,Computer Science,144034315,Anup K. Ghosh,38901901.0,A. Schwartzbard,,145258307.0,M. Schatz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0e2b3faed39561f712c3b14a08c7c36272d9857a,https://www.semanticscholar.org/paper/0e2b3faed39561f712c3b14a08c7c36272d9857a,Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units,"Recently, convolutional neural networks (CNNs) have been used as a powerful tool to solve many problems of machine learning and computer vision. In this paper, we aim to provide insight on the property of convolutional neural networks, as well as a generic method to improve the performance of many CNN architectures. Specifically, we first examine existing CNN models and observe an intriguing property that the filters in the lower layers form pairs (i.e., filters with opposite phase). Inspired by our observation, we propose a novel, simple yet effective activation scheme called concatenated ReLU (CRelu) and theoretically analyze its reconstruction property in CNNs. We integrate CRelu into several state-of-the-art CNN architectures and demonstrate improvement in their recognition performance on CIFAR-10/100 and ImageNet datasets with fewer trainable parameters. Our results suggest that better understanding of the properties of CNNs can lead to significant performance improvement with a simple modification.",2016,35,411,43,False,Computer Science,3163480,Wenling Shang,1729571.0,Kihyuk Sohn,Mathematics,2061137049.0,Diogo Almeida,1697141.0,Honglak Lee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5c5be36e3111e42247d78a6d529e4b1d7d2ced12,https://www.semanticscholar.org/paper/5c5be36e3111e42247d78a6d529e4b1d7d2ced12,Ilastik: Interactive learning and segmentation toolkit,"Segmentation is the process of partitioning digital images into meaningful regions. The analysis of biological high content images often requires segmentation as a first step. We propose ilastik as an easy-to-use tool which allows the user without expertise in image processing to perform segmentation and classification in a unified way. ilastik learns from labels provided by the user through a convenient mouse interface. Based on these labels, ilastik infers a problem specific segmentation. A random forest classifier is used in the learning step, in which each pixel's neighborhood is characterized by a set of generic (nonlinear) features. ilastik supports up to three spatial plus one spectral dimension and makes use of all dimensions in the feature calculation. ilastik provides realtime feedback that enables the user to interactively refine the segmentation result and hence further fine-tune the classifier. An uncertainty measure guides the user to ambiguous regions in the images. Real time performance is achieved by multi-threading which fully exploits the capabilities of modern multi-core machines. Once a classifier has been trained on a set of representative images, it can be exported and used to automatically process a very large number of images (e.g. using the CellProfiler pipeline). ilastik is an open source project and released under the BSD license at www.ilastik.org.",2011,17,1067,103,False,Computer Science,2059204163,Christoph Sommer,145486652.0,C. Straehle,,1708103.0,U. Köthe,1685187.0,F. Hamprecht,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0565c3e3374a8edf372f0fa25386b8325a47b037,https://www.semanticscholar.org/paper/0565c3e3374a8edf372f0fa25386b8325a47b037,Automatic document metadata extraction using support vector machines,"Automatic metadata generation provides scalability and usability for digital libraries and their collections. Machine learning methods offer robust and adaptable automatic metadata extraction. We describe a support vector machine classification-based method for metadata extraction from header part of research papers and show that it outperforms other machine learning methods on the same task. The method first classifies each line of the header into one or more of 15 classes. An iterative convergence procedure is then used to improve the line classification by using the predicted class labels of its neighbor lines in the previous round. Further metadata extraction is done by seeking the best chunk boundaries of each line. We found that discovery and use of the structural patterns of the data and domain based word clustering can improve the metadata extraction performance. An appropriate feature normalization also greatly improves the classification performance. Our metadata extraction method was originally designed to improve the metadata extraction quality of the digital libraries Citeseer [S. Lawrence et al., (1999)] and EbizSearch [Y. Petinot et al., (2003)]. We believe it can be generalized to other digital libraries.",2003,36,340,28,True,Computer Science,144910499,Hui Han,145157784.0,C. Lee Giles,,2690730.0,Eren Manavoglu,145203884.0,H. Zha,2923061.0,Zhenyue Zhang,1705950.0,E. Fox,,,,,,,,,,,,,,,,,,,,,,,,,,
8db9df2eadea654f128c1887722c677c708e8a47,https://www.semanticscholar.org/paper/8db9df2eadea654f128c1887722c677c708e8a47,Deep Reinforcement Learning framework for Autonomous Driving,"Reinforcement learning is considered to be a strong AI paradigm which can be used to teach machines through interaction with the environment and learning from their mistakes. Despite its perceived utility, it has not yet been successfully applied in automotive applications. Motivated by the successful demonstrations of learning of Atari games and Go by Google DeepMind, we propose a framework for autonomous driving using deep reinforcement learning. This is of particular relevance as it is difficult to pose autonomous driving as a supervised learning problem due to strong interactions with the environment including other vehicles, pedestrians and roadworks. As it is a relatively new area of research for autonomous driving, we provide a short overview of deep reinforcement learning and then describe our proposed framework. It incorporates Recurrent Neural Networks for information integration, enabling the car to handle partially observable scenarios. It also integrates the recent work on attention models to focus on relevant information, thereby reducing the computational complexity for deployment on embedded hardware. The framework was tested in an open source 3D car racing simulator called TORCS. Our simulation results demonstrate learning of autonomous maneuvering in a scenario of complex road curvatures and simple interaction of other vehicles.",2017,24,652,8,True,Computer Science,7353741,Ahmad El Sallab,144026300.0,Mohammed Abdou,Mathematics,8211183.0,E. Perot,2601522.0,S. Yogamani,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3029a4610f719c917db7eb1ac05cdb6120deadfb,https://www.semanticscholar.org/paper/3029a4610f719c917db7eb1ac05cdb6120deadfb,Wave physics as an analog recurrent neural network,"Analog machine learning computations are performed passively by propagating light and sound waves through programmed materials. Analog machine learning hardware platforms promise to be faster and more energy efficient than their digital counterparts. Wave physics, as found in acoustics and optics, is a natural candidate for building analog processors for time-varying signals. Here, we identify a mapping between the dynamics of wave physics and the computation in recurrent neural networks. This mapping indicates that physical wave systems can be trained to learn complex features in temporal data, using standard training techniques for neural networks. As a demonstration, we show that an inverse-designed inhomogeneous medium can perform vowel classification on raw audio signals as their waveforms scatter and propagate through it, achieving performance comparable to a standard digital implementation of a recurrent neural network. These findings pave the way for a new class of analog machine learning platforms, capable of fast and efficient processing of information in its native domain.",2019,45,155,3,False,Mathematics,39932230,Tyler W. Hughes,6049231.0,Ian A. D. Williamson,Medicine,5325132.0,M. Minkov,144567568.0,S. Fan,,,,,,,,,Physics,,,,,,,,,,,,,,,,,,,,,Computer Science
4d8f0ae904779a50b2e18fec49e51a5661a98d8a,https://www.semanticscholar.org/paper/4d8f0ae904779a50b2e18fec49e51a5661a98d8a,MRI-Based Brain Tumor Classification Using Ensemble of Deep Features and Machine Learning Classifiers,"Brain tumor classification plays an important role in clinical diagnosis and effective treatment. In this work, we propose a method for brain tumor classification using an ensemble of deep features and machine learning classifiers. In our proposed framework, we adopt the concept of transfer learning and uses several pre-trained deep convolutional neural networks to extract deep features from brain magnetic resonance (MR) images. The extracted deep features are then evaluated by several machine learning classifiers. The top three deep features which perform well on several machine learning classifiers are selected and concatenated as an ensemble of deep features which is then fed into several machine learning classifiers to predict the final output. To evaluate the different kinds of pre-trained models as a deep feature extractor, machine learning classifiers, and the effectiveness of an ensemble of deep feature for brain tumor classification, we use three different brain magnetic resonance imaging (MRI) datasets that are openly accessible from the web. Experimental results demonstrate that an ensemble of deep features can help improving performance significantly, and in most cases, support vector machine (SVM) with radial basis function (RBF) kernel outperforms other machine learning classifiers, especially for large datasets.",2021,77,74,6,True,Medicine,2837279,Jaeyong Kang,48740398.0,Z. Ullah,Computer Science,1969352.0,Jeonghwan Gwak,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0fc10de6129f61fb362de48ebeca1d61b9724294,https://www.semanticscholar.org/paper/0fc10de6129f61fb362de48ebeca1d61b9724294,Harnessing the power of big data: infusing the scientific method with machine learning to transform ecology,"Most efforts to harness the power of big data for ecology and environmental sciences focus on data and metadata sharing, standardization, and accuracy. However, many scientists have not accepted the data deluge as an integral part of their research because the current scientific method is not scalable to large, complex datasets. Here, we explain how integrating a data-intensive, machine learning approach with a hypothesis-driven, mechanistic approach can lead to a novel knowledge, learning, analysis system (KLAS) for discovery and problem solving. Machine learning leads to more efficient, user-friendly analytics as the streams of data increase while hypothesis-driven decisions lead to the strategic design of experiments to fill knowledge gaps and to elucidate mechanisms. KLAS will transform ecology and environmental sciences by shortening the time lag between individual discoveries and leaps in knowledge by the scientific community, and will lead to paradigm shifts predicated on open access data and analytics in a machine learning environment.",2014,48,107,5,True,,144020586,D. Peters,2341684.0,K. Havstad,,1988802.0,J. Cushing,2474084.0,C. Tweedie,152401643.0,O. Fuentes,1402807854.0,Natalia Villanueva-Rosales,,,,,,,,,,,,,,,,,,,,,,,,,,
ebcc0e71ef6a77d05e7ab064435bc2da87c55e91,https://www.semanticscholar.org/paper/ebcc0e71ef6a77d05e7ab064435bc2da87c55e91,Deep Hidden Physics Models: Deep Learning of Nonlinear Partial Differential Equations,"A long-standing problem at the interface of artificial intelligence and applied mathematics is to devise an algorithm capable of achieving human level or even superhuman proficiency in transforming observed data into predictive mathematical models of the physical world. In the current era of abundance of data and advanced machine learning capabilities, the natural question arises: How can we automatically uncover the underlying laws of physics from high-dimensional data generated from experiments? In this work, we put forth a deep learning approach for discovering nonlinear partial differential equations from scattered and potentially noisy observations in space and time. Specifically, we approximate the unknown solution as well as the nonlinear dynamics by two deep neural networks. The first network acts as a prior on the unknown solution and essentially enables us to avoid numerical differentiations which are inherently ill-conditioned and unstable. The second network represents the nonlinear dynamics and helps us distill the mechanisms that govern the evolution of a given spatiotemporal data-set. We test the effectiveness of our approach for several benchmark problems spanning a number of scientific domains and demonstrate how the proposed framework can help us accurately learn the underlying dynamics and forecast future states of the system. In particular, we study the Burgers', Korteweg-de Vries (KdV), Kuramoto-Sivashinsky, nonlinear Schr\""{o}dinger, and Navier-Stokes equations.",2018,58,463,47,False,Computer Science,145401977,M. Raissi,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2dec4f52b1ce552b416f086d4ea1040626675dfa,https://www.semanticscholar.org/paper/2dec4f52b1ce552b416f086d4ea1040626675dfa,Toward an Integration of Deep Learning and Neuroscience,"Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.",2016,548,459,16,True,Biology,2367822,Adam H. Marblestone,89504302.0,Greg Wayne,Computer Science,3282030.0,Konrad Paul Kording,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,
843c1f0d1721f513cf91054a9321978536d5bd5b,https://www.semanticscholar.org/paper/843c1f0d1721f513cf91054a9321978536d5bd5b,Android HIV: A Study of Repackaging Malware for Evading Machine-Learning Detection,"Machine learning-based solutions have been successfully employed for the automatic detection of malware on Android. However, machine learning models lack robustness to adversarial examples, which are crafted by adding carefully chosen perturbations to the normal inputs. So far, the adversarial examples can only deceive detectors that rely on syntactic features (e.g., requested permissions, API calls, etc.), and the perturbations can only be implemented by simply modifying application’s manifest. While recent Android malware detectors rely more on semantic features from Dalvik bytecode rather than manifest, existing attacking/defending methods are no longer effective. In this paper, we introduce a new attacking method that generates adversarial examples of Android malware and evades being detected by the current models. To this end, we propose a method of applying optimal perturbations onto Android APK that can successfully deceive the machine learning detectors. We develop an automated tool to generate the adversarial examples without human intervention. In contrast to existing works, the adversarial examples crafted by our method can also deceive recent machine learning-based detectors that rely on semantic features such as control-flow-graph. The perturbations can also be implemented directly onto APK’s Dalvik bytecode rather than Android manifest to evade from recent detectors. We demonstrate our attack on two state-of-the-art Android malware detection schemes, MaMaDroid and Drebin. Our results show that the malware detection rates decreased from 96% to 0% in MaMaDroid, and from 97% to 0% in Drebin, with just a small number of codes to be inserted into the APK.",2018,53,133,14,True,Computer Science,2117025915,Xiao Chen,2150357175.0,Chaoran Li,,2860169.0,Derui Wang,145018147.0,S. Wen,37269546.0,Jun Zhang,1681657.0,S. Nepal,2068334260.0,Yang Xiang,2072596749.0,K. Ren,,,,,,,,,,,,,,,,,,,,,,
3e864a40b40b64ddc3a6a59af239146aabd9abd4,https://www.semanticscholar.org/paper/3e864a40b40b64ddc3a6a59af239146aabd9abd4,A review of machine learning techniques using decision tree and support vector machine,"In this paper, the brief survey of data mining classification by using the machine learning techniques is presented. The machine learning techniques like decision tree and support vector machine play the important role in all the applications of artificial intelligence. Decision tree works efficiently with discrete data and SVM is capable of building the nonlinear boundaries among the classes. Both of these techniques have their own set of strengths which makes them suitable in almost all classification tasks.",2016,18,90,5,False,Computer Science,9728522,Madan Somvanshi,115699877.0,Pranjali Chavan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a4febe19161b1a5478fdebddedf3a564c5e44637,https://www.semanticscholar.org/paper/a4febe19161b1a5478fdebddedf3a564c5e44637,Machine-Learning-Based Coadaptive Calibration for Brain-Computer Interfaces,"Brain-computer interfaces (BCIs) allow users to control a computer application by brain activity as acquired (e.g., by EEG). In our classic machine learning approach to BCIs, the participants undertake a calibration measurement without feedback to acquire data to train the BCI system. After the training, the user can control a BCI and improve the operation through some type of feedback. However, not all BCI users are able to perform sufficiently well during feedback operation. In fact, a nonnegligible portion of participants (estimated 1530) cannot control the system (a BCI illiteracy problem, generic to all motor-imagery-based BCIs). We hypothesize that one main difficulty for a BCI user is the transition from offline calibration to online feedback. In this work, we investigate adaptive machine learning methods to eliminate offline calibration and analyze the performance of 11 volunteers in a BCI based on the modulation of sensorimotor rhythms. We present an adaptation scheme that individually guides the user. It starts with a subject-independent classifier that evolves to a subject-optimized state-of-the-art classifier within one session while the user interacts continuously. These initial runs use supervised techniques for robust coadaptive learning of user and machine. Subsequent runs use unsupervised adaptation to track the features drift during the session and provide an unbiased measure of BCI performance. Using this approach, without any offline calibration, six users, including one novice, obtained good performance after 3 to 6 minutes of adaptation. More important, this novel guided learning also allows participants with BCI illiteracy to gain significant control with the BCI in less than 60 minutes. In addition, one volunteer without sensorimotor idle rhythm peak at the beginning of the BCI experiment developed it during the course of the session and used voluntary modulation of its amplitude to control the feedback application.",2011,49,180,6,False,Computer Science,1753498,C. Vidaurre,2221418.0,C. Sannelli,Medicine,145034054.0,K. Müller,3156886.0,B. Blankertz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63a6bc3e0dbb8f1c0aaa6c6193330094553005ae,https://www.semanticscholar.org/paper/63a6bc3e0dbb8f1c0aaa6c6193330094553005ae,Using machine learning and GA to solve time-cost trade-off problems,"Existing genetic algorithms (GA) based systems for solving time-cost trade-off problems suffer from two limitations. First, these systems require the user to manually craft the time-cost curves for formulating the objective functions. Second, these systems only deal with linear time-cost relationships. To overcome these limitations, this paper presents a computer system called MLGAS (Machine Learning and Genetic Algorithms based System), which integrates a machine learning method with GA. A quadratic template is introduced to capture the nonlinearity of time-cost relationships. The machine learning method automatically generates the quadratic time-cost curves from historical data and also measures the credibility of each quadratic time-cost curve. The quadratic curves are then used to formulate the objective function that can be solved by the GA. Several improvements are made to enhance the capacity of GA to prevent premature convergence. Comparisons of MLGAS with an experienced project manager indicate that MLGAS generates better solutions to nonlinear time-cost trade-off problems.",1999,30,123,6,False,Engineering,46382469,Heng Li,73205692.0,Jn Cao,,81800053.0,P. Love,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e39b586e561b36a3b71fa3d9ee7cb15c35d84203,https://www.semanticscholar.org/paper/e39b586e561b36a3b71fa3d9ee7cb15c35d84203,Abusive Language Detection in Online User Content,"Detection of abusive language in user generated online content has become an issue of increasing importance in recent years. Most current commercial methods make use of blacklists and regular expressions, however these measures fall short when contending with more subtle, less ham-fisted examples of hate speech. In this work, we develop a machine learning based method to detect hate speech on online user comments from two domains which outperforms a state-of-the-art deep learning approach. We also develop a corpus of user comments annotated for abusive language, the first of its kind. Finally, we use our detection tool to analyze abusive language over time and in different settings to further enhance our knowledge of this behavior.",2016,23,837,87,False,Computer Science,3209949,Chikashi Nobata,1739099.0,J. Tetreault,,2873535.0,A. Thomas,2263803.0,Yashar Mehdad,145882798.0,Yi Chang,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ef08bad72793f7f44edb66531d39d5153282d5aa,https://www.semanticscholar.org/paper/ef08bad72793f7f44edb66531d39d5153282d5aa,The Higgs boson machine learning challenge,"The Higgs Boson Machine Learning Challenge (HiggsML or the Challenge for short) was organized to promote collaboration between high energy physicists and data scientists. The ATLAS experiment at CERN provided simulated data that has been used by physicists in a search for the Higgs boson. The Challenge was organized by a small group of ATLAS physicists and data scientists. It was hosted by Kaggle at https://www.kaggle. com/c/higgs-boson; the challenge data is now available on http://opendata.cern.ch/ collection/ATLAS-Higgs-Challenge-2014. This paper provides the physics background and explains the challenge setting, the challenge design, and analyzes its results.",2014,27,108,9,False,Computer Science,1404968468,C. Adam-Bourdarios,146784092.0,G. Cowan,,144296177.0,Cécile Germain,1743797.0,I. Guyon,143674326.0,B. Kégl,3200334.0,D. Rousseau,,,,,,,,,,,,,,,,,,,,,,,,,,
8d41cf63e1455b27fad5b9299c49aaa658c0cd85,https://www.semanticscholar.org/paper/8d41cf63e1455b27fad5b9299c49aaa658c0cd85,Machine learning for heterogeneous catalyst design and discovery,"A dvances in machine learning (ML) are making a large impact in many fields, including: artificial intelligence, materials science, and chemical engineering. Generally, ML tools learn from data to find insights or make fast predictions of target properties. Recently, ML is also greatly influencing heterogeneous catalysis research due to the availability of ML (e.g., Python Scikit-learn, TensorFlow) and workflow management tools (e.g., ASE, Atomate), the growing amount of data in materials databases (e.g., Novel Materials Discovery Laboratory, Citrination, Materials Project, CatApp), and algorithmic improvements. New catalysts are needed for sustainable chemical production, alternative energy, and pollution mitigation applications to meet the demands of our world’s rising population. It is a challenging endeavor, however, to make novel heterogeneous catalysts with good performance (i.e., stable, active, selective) because their performance depends on many properties: composition, support, surface termination, particle size, particle morphology, and atomic coordination environment. Additionally, the properties of heterogeneous catalysts can change under reaction conditions through various phenomena such as Ostwald ripening, particle disintegration, surface oxidation, and surface reconstruction. Many heterogeneous catalyst structures are disordered or amorphous in their active state, which further complicates their atomic-level characterization by modeling and experiment. Computational modeling using quantum mechanical (QM) methods such as density functional theory (DFT) can accelerate catalyst screening by enabling rapid prototyping and revealing active sites and structure-activity relations. The high computational cost of QM methods, however, limits the range of catalyst spaces that can be examined. Recent progress in merging ML with QM modeling and experiments promises to drive forward rational catalyst design. Therefore, it is timely to highlight the ability of ML tools to accelerate heterogeneous catalyst research. A key question we aim to address in this perspective is how machine learning can aid heterogeneous catalyst design and discovery. ML has been used in catalysis research since at least the 1990s. Early studies used neural networks to correlate catalyst physicochemical properties and reaction conditions with measured catalytic performance, but these studies were limited in the number of systems considered. Recently, ML has been applied to the high-throughput screening of heterogeneous catalysts and found to be predictive and applicable across a broad space of catalysts. ML algorithms such as decision trees, kernel ridge regression, neural networks, support vector machines, principal component analysis, and compressed sensing can help create predictive models of catalyst target properties, which are typically figures of merit corresponding to stability, activity, selectivity. In this perspective, we discuss various areas where ML is making an impact on heterogeneous catalysis research. ML is also aiding homogeneous catalysis research and shares many similarities (and differences) with ML for heterogeneous catalysis, but this discussion is beyond the perspective’s scope (for interested readers, see Ref. 26–28). Here, we emphasize the ability of ML combined with QM calculations to speed-up the search for optimal catalysts in combinatorial large spaces, such as alloys. ML-derived interatomic potentials for accurate and fast catalyst simulations will also be assessed, as well as the opportunity for ML to help find descriptors of catalyst performance in large datasets. The use of ML to aid transition state search algorithms (to compute reaction mechanisms) will Correspondence concerning this article should be addressed to B. R. Goldsmith at bgoldsm@umich.edu.",2018,126,202,1,True,Chemistry,8797649,B. Goldsmith,144292869.0,J. Esterhuizen,,48211311.0,Jin-Xun Liu,38683639.0,Christopher J. Bartel,152549861.0,Christopher Sutton,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aba50e02e6a798e69c5c7419bca38ddaaf1c4b90,https://www.semanticscholar.org/paper/aba50e02e6a798e69c5c7419bca38ddaaf1c4b90,Label Propagation through Linear Neighborhoods,"In many practical data mining applications such as text classification, unlabeled training examples are readily available, but labeled ones are fairly expensive to obtain. Therefore, semi supervised learning algorithms have aroused considerable interests from the data mining and machine learning fields. In recent years, graph-based semi supervised learning has been becoming one of the most active research areas in the semi supervised learning community. In this paper, a novel graph-based semi supervised learning approach is proposed based on a linear neighborhood model, which assumes that each data point can be linearly reconstructed from its neighborhood. Our algorithm, named linear neighborhood propagation (LNP), can propagate the labels from the labeled points to the whole data set using these linear neighborhoods with sufficient smoothness. A theoretical analysis of the properties of LNP is presented in this paper. Furthermore, we also derive an easy way to extend LNP to out-of-sample data. Promising experimental results are presented for synthetic data, digit, and text classification tasks.",2006,54,801,126,False,Computer Science,1682816,Fei Wang,14966740.0,Changshui Zhang,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8bd60f6ca987a107a289263a043b8e9e505fbd62,https://www.semanticscholar.org/paper/8bd60f6ca987a107a289263a043b8e9e505fbd62,Multimodal learning analytics,"New high-frequency data collection technologies and machine learning analysis techniques could offer new insights into learning, especially in tasks in which students have ample space to generate unique, personalized artifacts, such as a computer program, a robot, or a solution to an engineering challenge. To date most of the work on learning analytics and educational data mining has focused on online courses or cognitive tutors, in which the tasks are more structured and the entirety of interaction happens in front of a computer. In this paper, I argue that multimodal learning analytics could offer new insights into students' learning trajectories, and present several examples of this work and its educational application.",2013,24,230,12,False,Computer Science,3181883,Paulo Blikstein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
100a038fdf29b4b20801887f0ec40e3f10d9a4f9,https://www.semanticscholar.org/paper/100a038fdf29b4b20801887f0ec40e3f10d9a4f9,One shot learning of simple visual concepts,"One shot learning of simple visual concepts Brenden M. Lake, Ruslan Salakhutdinov, Jason Gross, and Joshua B. Tenenbaum Department of Brain and Cognitive Sciences Massachusetts Institute of Technology Abstract People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the shar- ing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich inter- nal part structure, yet they are particularly tractable for com- putational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing state- of-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data. Keywords: category learning; transfer learning; Bayesian modeling; neural networks Figure 1: Test yourself on one shot learning. From the example boxed in red, can you find the others in the array? On the left is a Segway and on the right is the first character of the Bengali alphabet. Answer for the Bengali character: Row 2, Column 3; Row 4, Column 2. A hallmark of human cognition is learning from just a few examples. For instance, a person only needs to see one Seg- way to acquire the concept and be able to discriminate future Segways from other vehicles like scooters and unicycles (Fig. 1 left). Similarly, children can acquire a new word from one encounter (Carey & Bartlett, 1978). How is one shot learning possible? New concepts are almost never learned in a vacuum. Past experience with other concepts in a domain can support the rapid learning of novel concepts, by showing the learner what matters for generalization. Many authors have suggested this as a route to one shot learning: transfer of abstract knowledge from old to new concepts, often called transfer learning, rep- resentation learning, or learning to learn. But what is the nature of the learned abstract knowledge that lets humans ac- quire new object concepts so quickly? The most straightforward proposals invoke attentional learning (Smith, Jones, Landau, Gershkoff-Stowe, & Samuel- son, 2002) or overhypotheses (Kemp, Perfors, & Tenenbaum, 2007; Dewar & Xu, in press), like the shape bias in word learning. Prior experience with concepts that are clearly orga- nized along one dimension (e.g., shape, as opposed to color or material) draws a learner’s attention to that same dimension (Smith et al., 2002) – or increases the prior probability of new concepts concentrating on that same dimension (Kemp et al., 2007). But this approach is limited since it requires that the relevant dimensions of similarity be defined in advance. For many real-world concepts, the relevant dimensions of similarity may be constructed in the course of learning to learn. For instance, when we first see a Segway, we may parse it into a structure of familiar parts arranged in a novel configuration: it has two wheels, connected by a platform, supporting a motor and a central post at the top of which are two handlebars. These parts and their relations comprise a Figure 2: Examples from a new 1600 character database. useful representational basis for many different vehicle and artifact concepts – a representation that is likely learned in the course of learning the concepts that they support. Several papers from the recent machine learning and computer vision literature argue for such an approach: joint learning of many concepts and a high-level part vocabulary that underlies those concepts (e.g., Torralba, Murphy, & Freeman, 2007; Fei-Fei, Fergus, & Perona, 2006). Another recently popular machine learning approach is based on deep learning (Salakhutdinov & Hinton, 2009): unsupervised learning of hierarchies of dis- tributed feature representations in neural-network-style prob- abilistic generative models. These models do not specify ex- plicit parts and structural relations, but they can still construct meaningful representations of what makes two objects deeply similar that go substantially beyond low-level image features. These approaches from machine learning may be com- pelling ways to understand how humans learn so quickly, but there is little experimental evidence that directly supports them. Models that construct parts or features from sensory data (pixels) while learning object concepts have been tested in elegant behavioral experiments with very simple stimuli and a very small number of concepts (Austerweil & Griffiths, 2009; Schyns, Goldstone, & Thibaut, 1998). But there have been few systematic comparisons of multiple state-of-the-art computational approaches to representation learning with hu-",2011,20,674,101,False,Computer Science,2373318,B. Lake,145124475.0,R. Salakhutdinov,,145372150.0,Jason Gross,1763295.0,J. Tenenbaum,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5f4f970e18c09aafeafaeb42d729ca243f811db0,https://www.semanticscholar.org/paper/5f4f970e18c09aafeafaeb42d729ca243f811db0,Learning to Rank for Information Retrieval and Natural Language Processing,"Learning to rank refers to machine learning techniques for training the model in a ranking task. Learning to rank is useful for many applications in information retrieval, natural language processing, and data mining. Intensive studies have been conducted on the problem recently and significant progress has been made. This lecture gives an introduction to the area including the fundamental problems, existing approaches, theories, applications, and future work. The author begins by showing that various ranking problems in information retrieval and natural language processing can be formalized as two basic ranking tasks, namely ranking creation (or simply ranking) and ranking aggregation. In ranking creation, given a request, one wants to generate a ranking list of offerings based on the features derived from the request and the offerings. In ranking aggregation, given a request, as well as a number of ranking lists of offerings, one wants to generate a new ranking list of the offerings. Ranking creation (or ranking) is the major problem in learning to rank. It is usually formalized as a supervised learning task. The author gives detailed explanations on learning for ranking creation and ranking aggregation, including training and testing, evaluation, feature creation, and major approaches. Many methods have been proposed for ranking creation. The methods can be categorized as the pointwise, pairwise, and listwise approaches according to the loss functions they employ. They can also be categorized according to the techniques they employ, such as the SVM based, Boosting SVM, Neural Network based approaches. The author also introduces some popular learning to rank methods in details. These include PRank, OC SVM, Ranking SVM, IR SVM, GBRank, RankNet, LambdaRank, ListNet & ListMLE, AdaRank, SVM MAP, SoftRank, Borda Count, Markov Chain, and CRanking. The author explains several example applications of learning to rank including web search, collaborative filtering, definition search, keyphrase extraction, query dependent summarization, and re-ranking in machine translation. A formulation of learning for ranking creation is given in the statistical learning framework. Ongoing and future research directions for learning to rank are also discussed. Table of Contents: Introduction / Learning for Ranking Creation / Learning for Ranking Aggregation / Methods of Learning to Rank / Applications of Learning to Rank / Theory of Learning to Rank / Ongoing and Future Work",2011,166,367,43,True,Computer Science,49404233,Hang Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
83d4b94527cb0bf9519f0fdd1f3b643c7f98a408,https://www.semanticscholar.org/paper/83d4b94527cb0bf9519f0fdd1f3b643c7f98a408,Detection and classification of micro-grid faults based on HHT and machine learning techniques,"This study presents a novel micro-grid protection scheme based on Hilbert-Huang transform (HHT) and machine learning techniques. Initialisation of the proposed approach is done by extracting the three-phase current signals at the targeted buses of different feeders. The obtained non-stationary signals are passed through the empirical mode decomposition method to extract different intrinsic mode functions (IMFs). In the next step using HHT to the selected IMFs component, different needful differential features are computed. The extracted features are further used as an input vector to the machine learning models to classify the fault events. The proposed micro-grid protection scheme is tested for different protection scenarios, such as the type of fault (symmetrical, asymmetrical and high impedance fault), micro-grid structure (radial and mesh) and mode of operation (islanded and grid connected) and so on. Three different machine learning models are tested and compared in this framework: Naive Bayes classifier, support vector machine and extreme learning machine. The extensive simulated results from a standard IEC micro-grid model prove the effectiveness and reliability of the proposed micro-grid protection scheme.",2017,25,114,3,False,Computer Science,9736746,Manohar Mishra,34851668.0,P. Rout,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
064cd41d323441209ce1484a9bba02a22b625088,https://www.semanticscholar.org/paper/064cd41d323441209ce1484a9bba02a22b625088,Selective Transfer Machine for Personalized Facial Action Unit Detection,"Automatic facial action unit (AFA) detection from video is a long-standing problem in facial expression analysis. Most approaches emphasize choices of features and classifiers. They neglect individual differences in target persons. People vary markedly in facial morphology (e.g., heavy versus delicate brows, smooth versus deeply etched wrinkles) and behavior. Individual differences can dramatically influence how well generic classifiers generalize to previously unseen persons. While a possible solution would be to train person-specific classifiers, that often is neither feasible nor theoretically compelling. The alternative that we propose is to personalize a generic classifier in an unsupervised manner (no additional labels for the test subjects are required). We introduce a transductive learning method, which we refer to Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific biases. STM achieves this effect by simultaneously learning a classifier and re-weighting the training samples that are most relevant to the test subject. To evaluate the effectiveness of STM, we compared STM to generic classifiers and to cross-domain learning methods in three major databases: CK+, GEMEP-FERA and RU-FACS. STM outperformed generic classifiers in all.",2013,40,274,28,True,Computer Science,39336289,Wen-Sheng Chu,143867160.0,F. D. L. Torre,Medicine,1737918.0,J. Cohn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
