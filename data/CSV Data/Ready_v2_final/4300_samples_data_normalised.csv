paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,authors/19/authorId,authors/19/name,authors/20/authorId,authors/20/name,authors/21/authorId,authors/21/name,authors/22/authorId,authors/22/name,fieldsOfStudy/2
e2145add1318af0654a4901fe92080bc8168a9f4,https://www.semanticscholar.org/paper/e2145add1318af0654a4901fe92080bc8168a9f4,Classification of musical genre: a machine learning approach,"In this paper, we investigate the impact of machine learning algorithms in the development of automatic music classification models aiming to capture genres distinctions. The study of genres as bodies of musical items aggregated according to subjective and local criteria requires corresponding inductive models of such a notion. This process can be thus modeled as an example-driven learning task. We investigated the impact of different musical features on the inductive accuracy by first creating a medium-sized collection of examples for widely recognized genres and then evaluating the performances of different learning algorithms. In this work, features are derived from the MIDI transcriptions of the song collection.",2004,15,82,7,False,Computer Science,,144654543,Roberto Basili,28868488.0,Alfredo Serafini,1763333.0,A. Stellato,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e837b79de602c69395498c1fbbe39bbb4e6f75ad,https://www.semanticscholar.org/paper/e837b79de602c69395498c1fbbe39bbb4e6f75ad,Learning to Transduce with Unbounded Memory,"Recently, strong results have been demonstrated by Deep Recurrent Neural Networks on natural language transduction problems. In this paper we explore the representational power of these models using synthetic grammars designed to exhibit phenomena similar to those found in real transduction problems such as machine translation. These experiments lead us to propose new memory-based recurrent networks that implement continuously differentiable analogues of traditional data structures such as Stacks, Queues, and DeQues. We show that these architectures exhibit superior generalisation performance to Deep RNNs and are often able to learn the underlying generating algorithms in our transduction experiments.",2015,22,270,22,False,Computer Science,,1864353,Edward Grefenstette,2910877.0,K. Hermann,2573615.0,Mustafa Suleyman,1685771.0,P. Blunsom,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c5491cc42ec80a59e843790393e2b6117efd78a1,https://www.semanticscholar.org/paper/c5491cc42ec80a59e843790393e2b6117efd78a1,Feature Subset Selection: A Correlation Based Filter Approach,"Recent work has shown that feature subset selection can have a positive affect on the performance of machine learning algorithms. Some algorithms can be slowed or their performance irrelevant or redundant to the learning task. Feature subset selection, then, is a method for enhancing the performance of learning algorithms, reducing the hypothesis search space, and, in some cases, reducing the storage requirement. This paper describes a feature subset selector that uses a correlation based evaluates its effectiveness with three common ML algorithms: a decision tree inducer (C4.5), a naive Bayes classifier, and an instance based learner (IB1). Experiments using a number of standard data sets drawn from real and artificial domains are presented. Feature subset selection gave significant improvement for all three algorithms; C4.5 generated smaller decision trees.",1997,6,303,34,False,Computer Science,,118860642,M. Hall,2107559941.0,L. A. Smith,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ff304304fddfb4de368b45894c20f44fdab817d5,https://www.semanticscholar.org/paper/ff304304fddfb4de368b45894c20f44fdab817d5,Evaluating machine learning for information extraction,"Comparative evaluation of Machine Learning (ML) systems used for Information Extraction (IE) has suffered from various inconsistencies in experimental procedures. This paper reports on the results of the Pascal Challenge on Evaluating Machine Learning for Information Extraction, which provides a standardised corpus, set of tasks, and evaluation methodology. The challenge is described and the systems submitted by the ten participants are briefly introduced and their performance is analysed.",2005,6,64,3,False,Computer Science,,2668441,N. Ireson,1758555.0,F. Ciravegna,1967815.0,Mary Elaine Califf,1758106.0,D. Freitag,8551365.0,N. Kushmerick,2192424.0,A. Lavelli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6b44ed0ea3163f9c3f6930b71f5390177584edcf,https://www.semanticscholar.org/paper/6b44ed0ea3163f9c3f6930b71f5390177584edcf,An Overview on Application of Machine Learning Techniques in Optical Networks,"Today’s telecommunication networks have become sources of enormous amounts of widely heterogeneous data. This information can be retrieved from network traffic traces, network alarms, signal quality indicators, users’ behavioral data, etc. Advanced mathematical tools are required to extract meaningful information from these data and take decisions pertaining to the proper functioning of the networks from the network-generated data. Among these mathematical tools, machine learning (ML) is regarded as one of the most promising methodological approaches to perform network-data analysis and enable automated network self-configuration and fault management. The adoption of ML techniques in the field of optical communication networks is motivated by the unprecedented growth of network complexity faced by optical networks in the last few years. Such complexity increase is due to the introduction of a huge number of adjustable and interdependent system parameters (e.g., routing configurations, modulation format, symbol rate, coding schemes, etc.) that are enabled by the usage of coherent transmission/reception technologies, advanced digital signal processing, and compensation of nonlinear effects in optical fiber propagation. In this paper we provide an overview of the application of ML to optical communications and networking. We classify and survey relevant literature dealing with the topic, and we also provide an introductory tutorial on ML for researchers and practitioners interested in this field. Although a good number of research papers have recently appeared, the application of ML to optical networks is still in its infancy: to stimulate further work in this area, we conclude this paper proposing new possible research directions.",2018,127,317,12,True,Computer Science,Mathematics,48419853,F. Musumeci,2370043.0,C. Rottondi,2499946.0,A. Nag,2129842.0,I. Macaluso,2735803.0,D. Zibar,2987837.0,M. Ruffini,1759410.0,M. Tornatore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8dc871b80e50135c9d99de9f8eb8c64b63ee924f,https://www.semanticscholar.org/paper/8dc871b80e50135c9d99de9f8eb8c64b63ee924f,Understanding Self-Training for Gradual Domain Adaptation,"Machine learning systems must adapt to data distributions that evolve over time, in applications ranging from sensor networks and self-driving car perception modules to brain-machine interfaces. We consider gradual domain adaptation, where the goal is to adapt an initial classifier trained on a source domain given only unlabeled data that shifts gradually in distribution towards a target domain. We prove the first non-vacuous upper bound on the error of self-training with gradual shifts, under settings where directly adapting to the target domain can result in unbounded error. The theoretical analysis leads to algorithmic insights, highlighting that regularization and label sharpening are essential even when we have infinite data, and suggesting that self-training works particularly well for shifts with small Wasserstein-infinity distance. Leveraging the gradual shift structure leads to higher accuracies on a rotating MNIST dataset and a realistic Portraits dataset.",2020,50,98,23,False,Computer Science,Mathematics,32423266,Ananya Kumar,1901958.0,Tengyu Ma,145419642.0,Percy Liang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5c63fc87400a4d3afea63ab8a068a47249f815c2,https://www.semanticscholar.org/paper/5c63fc87400a4d3afea63ab8a068a47249f815c2,Noise or Signal: The Role of Image Backgrounds in Object Recognition,"We assess the tendency of state-of-the-art object recognition models to depend on signals from image backgrounds. We create a toolkit for disentangling foreground and background signal on ImageNet images, and find that (a) models can achieve non-trivial accuracy by relying on the background alone, (b) models often misclassify images even in the presence of correctly classified foregrounds--up to 87.5% of the time with adversarially chosen backgrounds, and (c) more accurate models tend to depend on backgrounds less. Our analysis of backgrounds brings us closer to understanding which correlations machine learning models use, and how they determine models' out of distribution performance.",2020,28,155,31,False,Computer Science,,2066515966,Kai Y. Xiao,39468283.0,Logan Engstrom,34562927.0,Andrew Ilyas,143826246.0,A. Madry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a09f13a31ff1f9f7fe06ac37b2ebddb5e6630995,https://www.semanticscholar.org/paper/a09f13a31ff1f9f7fe06ac37b2ebddb5e6630995,Predicting Multiprocessor Memory Access Patterns with Learning Models,"Machine learning techniques are applicable to computer system optimization. We show that shared memory multiprocessors can successfully utilize machine learning algorithms for memory access pattern prediction. In particular three different on-line machine learning prediction techniques were tested to learn and predict repetitive memory access patterns for three typical parallel processing applications, the 2-D relaxation algorithm, matrix multiply and Fast Fourier Transform on a shared memory multiprocessor. The predictions were then used by a routing control algorithm to reduce control latency in the interconnection network by configuring the interconnection network to provide needed memory access paths before they were requested. Three trainable prediction techniques were used and tested: 1). a Markov predictor, 2). a linear predictor and 3). a time delay neural network (TDNN) predictor. Different predictors performed best on different applications, but the TDNN produced uniformly good results.",1997,21,35,1,False,Computer Science,,145470743,M. Sakr,1687100.0,S. Levitan,1757442.0,D. M. Chiarulli,35216199.0,B. Horne,145157784.0,C. Lee Giles,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b1b800aacf850a18e6504c693b4c5d33b8b3ac32,https://www.semanticscholar.org/paper/b1b800aacf850a18e6504c693b4c5d33b8b3ac32,"State of the Art—A Survey of Partially Observable Markov Decision Processes: Theory, Models, and Algorithms","This paper surveys models and algorithms dealing with partially observable Markov decision processes. A partially observable Markov decision process (POMDP) is a generalization of a Markov decision process which permits uncertainty regarding the state of a Markov process and allows for state information acquisition. A general framework for finite state and action POMDP's is presented. Next, there is a brief discussion of the development of POMDP's and their relationship with other decision processes. A wide range of models in such areas as quality control, machine maintenance, internal auditing, learning, and optimal stopping are discussed within the POMDP-framework. Lastly, algorithms for computing optimal solutions to POMDP's are presented.",1982,0,620,44,False,Mathematics,,3254214,G. Monahan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9a0ef2e00a28623c49b695ec6088ea1d965db257,https://www.semanticscholar.org/paper/9a0ef2e00a28623c49b695ec6088ea1d965db257,Classification of brain tumor type and grade using MRI texture and shape in a machine learning scheme,"The objective of this study is to investigate the use of pattern classification methods for distinguishing different types of brain tumors, such as primary gliomas from metastases, and also for grading of gliomas. The availability of an automated computer analysis tool that is more objective than human readers can potentially lead to more reliable and reproducible brain tumor diagnostic procedures. A computer‐assisted classification method combining conventional MRI and perfusion MRI is developed and used for differential diagnosis. The proposed scheme consists of several steps including region‐of‐interest definition, feature extraction, feature selection, and classification. The extracted features include tumor shape and intensity characteristics, as well as rotation invariant texture features. Feature subset selection is performed using support vector machines with recursive feature elimination. The method was applied on a population of 102 brain tumors histologically diagnosed as metastasis ( 24 ), meningiomas ( 4 ), gliomas World Health Organization grade II ( 22 ), gliomas World Health Organization grade III ( 18 ), and glioblastomas ( 34 ). The binary support vector machine classification accuracy, sensitivity, and specificity, assessed by leave‐one‐out cross‐validation, were, respectively, 85%, 87%, and 79% for discrimination of metastases from gliomas and 88%, 85%, and 96% for discrimination of high‐grade (grades III and IV) from low‐grade (grade II) neoplasms. Multiclass classification was also performed via a one‐vs‐all voting scheme. Magn Reson Med, 2009. © 2009 Wiley‐Liss, Inc.",2009,48,630,34,True,Computer Science,Medicine,1784303,E. Zacharaki,40658597.0,Sumei Wang,143990587.0,S. Chawla,9012366.0,Dong Soo Yoo,48750802.0,R. Wolf,1771697.0,E. Melhem,1740714.0,C. Davatzikos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
922838dd98d599d1d229cc73896d55e7a769aa7c,https://www.semanticscholar.org/paper/922838dd98d599d1d229cc73896d55e7a769aa7c,Learning hierarchical representations for face verification with convolutional deep belief networks,"Most modern face recognition systems rely on a feature representation given by a hand-crafted image descriptor, such as Local Binary Patterns (LBP), and achieve improved performance by combining several such representations. In this paper, we propose deep learning as a natural source for obtaining additional, complementary representations. To learn features in high-resolution images, we make use of convolutional deep belief networks. Moreover, to take advantage of global structure in an object class, we develop local convolutional restricted Boltzmann machines, a novel convolutional learning model that exploits the global structure by not assuming stationarity of features across the image, while maintaining scalability and robustness to small misalignments. We also present a novel application of deep learning to descriptors other than pixel intensity values, such as LBP. In addition, we compare performance of networks trained using unsupervised learning against networks with random filters, and empirically show that learning weights not only is necessary for obtaining good multilayer representations, but also provides robustness to the choice of the network architecture parameters. Finally, we show that a recognition system using only representations obtained from deep learning can achieve comparable accuracy with a system using a combination of hand-crafted image descriptors. Moreover, by combining these representations, we achieve state-of-the-art results on a real-world face verification database.",2012,45,401,22,True,Computer Science,,3219900,Gary B. Huang,1697141.0,Honglak Lee,1389846455.0,E. Learned-Miller,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23f425d6cb57938ceaa98fce8133a6924c2f953b,https://www.semanticscholar.org/paper/23f425d6cb57938ceaa98fce8133a6924c2f953b,Three scenarios for continual learning,"Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and--in case it is not--whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted MNIST task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.",2019,36,348,30,False,Computer Science,Mathematics,118439707,Gido M. van de Ven,1739838.0,A. Tolias,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e1bb329621de73d08c47beae9b5439a1c244eb1a,https://www.semanticscholar.org/paper/e1bb329621de73d08c47beae9b5439a1c244eb1a,CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances,"Novelty detection, i.e., identifying whether a given sample is drawn from outside the training distribution, is essential for reliable machine learning. To this end, there have been many attempts at learning a representation well-suited for novelty detection and designing a score based on such representation. In this paper, we propose a simple, yet effective method named contrasting shifted instances (CSI), inspired by the recent success on contrastive learning of visual representations. Specifically, in addition to contrasting a given sample with other instances as in conventional contrastive learning methods, our training scheme contrasts the sample with distributionally-shifted augmentations of itself. Based on this, we propose a new detection score that is specific to the proposed training scheme. Our experiments demonstrate the superiority of our method under various novelty detection scenarios, including unlabeled one-class, unlabeled multi-class and labeled multi-class settings, with various image benchmark datasets.",2020,87,231,65,False,Computer Science,Mathematics,1750599181,Jihoon Tack,9962692.0,Sangwoo Mo,83125078.0,Jongheon Jeong,143720148.0,Jinwoo Shin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8f984259d156a223d01349b366e6943d8ddc20b6,https://www.semanticscholar.org/paper/8f984259d156a223d01349b366e6943d8ddc20b6,Semantic similarity and machine learning with ontologies,"Abstract Ontologies have long been employed in the life sciences to formally represent and reason over domain knowledge and they are employed in almost every major biological database. Recently, ontologies are increasingly being used to provide background knowledge in similarity-based analysis and machine learning models. The methods employed to combine ontologies and machine learning are still novel and actively being developed. We provide an overview over the methods that use ontologies to compute similarity and incorporate them in machine learning methods; in particular, we outline how semantic similarity measures and ontology embeddings can exploit the background knowledge in ontologies and how ontologies can provide constraints that improve machine learning models. The methods and experiments we describe are available as a set of executable notebooks, and we also provide a set of slides and additional resources at https://github.com/bio-ontology-research-group/machine-learning-with-ontologies.",2020,151,46,0,True,Computer Science,Medicine,8351299,Maxat Kulmanov,14823788.0,F. Z. Smaili,143703146.0,Xin Gao,1798963.0,R. Hoehndorf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8b3183a2051f50520f074d92d15037fb0cde5f27,https://www.semanticscholar.org/paper/8b3183a2051f50520f074d92d15037fb0cde5f27,Hitting and commute times in large random neighborhood graphs,"In machine learning, a popular tool to analyze the structure of graphs is the hitting time and the commute distance (resistance distance). For two vertices u and v, the hitting time Huv is the expected time it takes a random walk to travel from u to v. The commute distance is its symmetrized version Cuv = Huv +Hvu. In our paper we study the behavior of hitting times and commute distances when the number n of vertices in the graph tends to infinity. We focus on random geometric graphs (e-graphs, kNN graphs and Gaussian similarity graphs), but our results also extend to graphs with a given expected degree distribution or Erdos-Renyi graphs with planted partitions. We prove that in these graph families, the suitably rescaled hitting time Huv converges to 1/dv and the rescaled commute time to 1/du+1=dv where du and dv denote the degrees of vertices u and v. In these cases, hitting and commute times do not provide information about the structure of the graph, and their use is discouraged in many machine learning applications.",2014,74,99,16,False,Computer Science,Mathematics,1728654,U. V. Luxburg,47187712.0,Agnes Radl,143610806.0,Matthias Hein,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e80d63e35f35179287ef0a94dc2ef7f538c4b41f,https://www.semanticscholar.org/paper/e80d63e35f35179287ef0a94dc2ef7f538c4b41f,Genetic algorithms for fuzzy control.1. Offline system development and application,"Although fuzzy logic controllers and expert systems have been successfully applied in many complex industrial processes, they experience a deficiency in knowledge acquisition and rely to a great extent on empirical and heuristic knowledge which, in many cases, cannot be objectively elicited. Among the problems to be resolved in fuzzy controller design are the determination of the linguistic state space, definition of the membership functions of each linguistic term and the derivation of the control rules. Some of these problems can be solved by application of machine learning. First, it is desirable to simplify and automate the specification of linguistic rules. Secondly, it is also desirable that modification of control rules is possible in order to cope with previously unknown or changes in process dynamics. Machine learning methods have, in recent years, emerged from the use of learning algorithms modelled on natural and biological systems. These methods attempt to abstract the advanced mechanisms of learning exhibited by such systems, which can consequently be applied to intelligent control. One of these new algorithms is the genetic algorithm which is modelled on the processes of natural evolution. The paper develops the application of genetic algorithm techniques for fuzzy controller design. Genetic algorithms are used to automate and introduce objective criteria in defining fuzzy controller parameters.",1995,0,199,2,False,Computer Science,,20513909,D. Linkens,1903882.0,H. Nyongesa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
37a59e8953e62fe61cb9723e1dcc2382bb427767,https://www.semanticscholar.org/paper/37a59e8953e62fe61cb9723e1dcc2382bb427767,Survey on machine learning-based QoE-QoS correlation models,"The machine learning provides a theoretical and methodological framework to quantify the relationship between user OoE (Quality of Experience) and network QoS (Quality of Service). This paper presents an overview of QoE-QoS correlation models based on machine learning techniques. According to the learning type, we propose a categorization of correlation models. For each category, we review the main existing works by citing deployed learning methods and model parameters (QoE measurement, QoS parameters and service type). Moreover, the survey will provide researchers with the latest trends and findings in this field.",2014,32,63,6,False,Computer Science,,3024857,Sana Aroussi,1692655.0,A. Mellouk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13ba3b487ed129afe749cf5a12bb7759341ca776,https://www.semanticscholar.org/paper/13ba3b487ed129afe749cf5a12bb7759341ca776,Learning for Safety-Critical Control with Control Barrier Functions,"Modern nonlinear control theory seeks to endow systems with properties of stability and safety, and have been deployed successfully in multiple domains. Despite this success, model uncertainty remains a significant challenge in synthesizing safe controllers, leading to degradation in the properties provided by the controllers. This paper develops a machine learning framework utilizing Control Barrier Functions (CBFs) to reduce model uncertainty as it impact the safe behavior of a system. This approach iteratively collects data and updates a controller, ultimately achieving safe behavior. We validate this method in simulation and experimentally on a Segway platform.",2019,47,101,9,False,Computer Science,Engineering,2110342359,Andrew J. Taylor,152614574.0,Andrew W. Singletary,1740159.0,Yisong Yue,37952580.0,A. Ames,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6207a5933d5f7971486ce73323a37567c70aeb0f,https://www.semanticscholar.org/paper/6207a5933d5f7971486ce73323a37567c70aeb0f,Did you hear that? Adversarial Examples Against Automatic Speech Recognition,"Speech is a common and effective way of communication between humans, and modern consumer devices such as smartphones and home hubs are equipped with deep learning based accurate automatic speech recognition to enable natural interaction between humans and machines. Recently, researchers have demonstrated powerful attacks against machine learning models that can fool them to produceincorrect results. However, nearly all previous research in adversarial attacks has focused on image recognition and object detection models. In this short paper, we present a first of its kind demonstration of adversarial attacks against speech classification model. Our algorithm performs targeted attacks with 87% success by adding small background noise without having to know the underlying model parameter and architecture. Our attack only changes the least significant bits of a subset of audio clip samples, and the noise does not change 89% the human listener's perception of the audio clip as evaluated in our human study.",2018,13,190,31,False,Computer Science,,3030212,M. Alzantot,144019834.0,Bharathan Balaji,1702254.0,M. Srivastava,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e1c13fe8de68ec9fa8b7dbf0807a7621e1311839,https://www.semanticscholar.org/paper/e1c13fe8de68ec9fa8b7dbf0807a7621e1311839,Machine Learning for motor skills in robotics,"Autonomous robots that can adapt to novel situations has been a long standing vision of robotics, artificial intelligence, and the cognitive sciences. Early approaches to this goal during the heydays of artificial intelligence research in the late 1980s, however, made it clear that an approach purely based on reasoning or human insights would not be able to model all the perceptuomotor tasks of future robots. Instead, new hope was put in the growing wake of machine learning that promised fully adaptive control algorithms which learn both by observation and trial-and-error. However, to date, learning techniques have yet to fulfill this promise as only few methods manage to scale into the high-dimensional domains of manipulator and humanoid robotics and usually scaling was only achieved in precisely pre-structured domains. We have investigated the ingredients for a general approach to motor skill learning in order to get one step closer towards human-like performance. For doing so, we study two major components for such an approach, i.e., firstly, a theoretically well-founded general approach to representing the required control structures for task representation and execution and, secondly, appropriate learning algorithms which can be applied in this setting.",2008,217,68,6,False,Computer Science,,145197867,Jan Peters,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
06f7087ee1a796eeb65ef30c10427b313af05743,https://www.semanticscholar.org/paper/06f7087ee1a796eeb65ef30c10427b313af05743,Manifold regularization and semi-supervised learning: some theoretical analyses,"Manifold regularization (Belkin et al., 2006) is a geometrically motivated framework for machine learning within which several semi-supervised algorithms have been constructed. Here we try to provide some theoretical understanding of this approach. Our main result is to expose the natural structure of a class of problems on which manifold regularization methods are helpful. We show that for such problems, no supervised learner can learn effectively. On the other hand, a manifold based learner (that knows the manifold or ""learns"" it from unlabeled examples) can learn with relatively few labeled examples. Our analysis follows a minimax style with an emphasis on finite sample results (in terms of n: the number of labeled examples). These results allow us to properly interpret manifold regularization and related spectral and geometric algorithms in terms of their potential use in semi-supervised learning.",2013,32,101,8,False,Computer Science,Mathematics,1770745,P. Niyogi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fc3fb8de45d2376df82e8d43d2f4119942609d7d,https://www.semanticscholar.org/paper/fc3fb8de45d2376df82e8d43d2f4119942609d7d,Machine Learning Techniques for Cooperative Spectrum Sensing in Cognitive Radio Networks,"We propose novel cooperative spectrum sensing (CSS) algorithms for cognitive radio (CR) networks based on machine learning techniques which are used for pattern classification. In this regard, unsupervised (e.g., K-means clustering and Gaussian mixture model (GMM)) and supervised (e.g., support vector machine (SVM) and weighted K-nearest-neighbor (KNN)) learning-based classification techniques are implemented for CSS. For a radio channel, the vector of the energy levels estimated at CR devices is treated as a feature vector and fed into a classifier to decide whether the channel is available or not. The classifier categorizes each feature vector into either of the two classes, namely, the ""channel available class"" and the ""channel unavailable class"". Prior to the online classification, the classifier needs to go through a training phase. For classification, the K-means clustering algorithm partitions the training feature vectors into K clusters, where each cluster corresponds to a combined state of primary users (PUs) and then the classifier determines the class the test energy vector belongs to. The GMM obtains a mixture of Gaussian density functions that well describes the training feature vectors. In the case of the SVM, the support vectors (i.e., a subset of training vectors which fully specify the decision function) are obtained by maximizing the margin between the separating hyperplane and the training feature vectors. Furthermore, the weighted KNN classification technique is proposed for CSS for which the weight of each feature vector is calculated by evaluating the area under the receiver operating characteristic (ROC) curve of that feature vector. The performance of each classification technique is quantified in terms of the average training time, the sample classification delay, and the ROC curve. Our comparative results clearly reveal that the proposed algorithms outperform the existing state-of-the-art CSS techniques.",2013,23,292,30,False,Computer Science,,1757321,K. Thilina,34647273.0,K. Choi,1706468.0,N. Saquib,144158811.0,E. Hossain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4876f8df26b3eb92b8169c3811fb772d8c8f6fd2,https://www.semanticscholar.org/paper/4876f8df26b3eb92b8169c3811fb772d8c8f6fd2,Modulation Classification Based on Signal Constellation Diagrams and Deep Learning,"Deep learning (DL) is a new machine learning (ML) methodology that has found successful implementations in many application domains. However, its usage in communications systems has not been well explored. This paper investigates the use of the DL in modulation classification, which is a major task in many communications systems. The DL relies on a massive amount of data and, for research and applications, this can be easily available in communications systems. Furthermore, unlike the ML, the DL has the advantage of not requiring manual feature selections, which significantly reduces the task complexity in modulation classification. In this paper, we use two convolutional neural network (CNN)-based DL models, AlexNet and GoogLeNet. Specifically, we develop several methods to represent modulated signals in data formats with gridlike topologies for the CNN. The impacts of representation on classification performance are also analyzed. In addition, comparisons with traditional cumulant and ML-based algorithms are presented. Experimental results demonstrate the significant performance advantage and application feasibility of the DL-based approach for modulation classification.",2019,24,217,14,False,Computer Science,Medicine,2233748,Shengliang Peng,145337201.0,Hanyu Jiang,1825155.0,Huaxia Wang,11013929.0,H. Alwageed,2110633627.0,Yu Zhou,51134994.0,Marjan Mazrouei Sebdani,145259429.0,Yu-dong Yao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c82982f7c4504910ab40bc9b6ad86d92d11f43e4,https://www.semanticscholar.org/paper/c82982f7c4504910ab40bc9b6ad86d92d11f43e4,Machine learning in agricultural and applied economics,"This review presents machine learning (ML) approaches from an applied economist’s perspective. We first introduce the key ML methods drawing connections to econometric practice. We then identify current limitations of the econometric and simulation model toolbox in applied economics and explore potential solutions afforded by ML. We dive into cases such as inflexible functional forms, unstructured data sources and large numbers of explanatory variables in both prediction and causal analysis, and highlight the challenges of complex simulation models. Finally, we argue that economists have a vital role in addressing the shortcomings of ML when used for quantitative economic analysis.",2019,195,68,2,True,Computer Science,,25700449,Hugo Storm,38692135.0,K. Baylis,2516120.0,T. Heckelei,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41d6ef9101d70ac1dc0bc6d514a5e1b1d32ebf8f,https://www.semanticscholar.org/paper/41d6ef9101d70ac1dc0bc6d514a5e1b1d32ebf8f,The UCI KDD archive of large data sets for data mining research and experimentation,"Advances in data collection and storage have allowed organizations to create massive, complex and heterogeneous databases, which have stymied traditional methods of data analysis. This has led to the development of new analytical tools that often combine techniques from a variety of elds such as statistics, computer science, and mathematics to extract meaningful knowledge from the data. To support research in this area, UC Irvine has created the UCI Knowledge Discovery in Databases (KDD) Archive (http://kdd.ics.uci.edu)which is a new online archive of large and complex data sets that encompasses a wide variety of data types, analysis tasks, and application areas. This article describes the objectives and philosophy of the UCI KDD Archive. We draw parallels with the development of the UCI Machine Learning Repository and its a ect on the Machine Learning community.",2000,10,184,17,False,Computer Science,,2305700,Stephen D. Bay,2787844.0,D. Kibler,1694780.0,M. Pazzani,50860274.0,Padhraic Smyth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10d21ca7728cb3dd15731accedda9ea711d8a0f4,https://www.semanticscholar.org/paper/10d21ca7728cb3dd15731accedda9ea711d8a0f4,An End-to-End Discriminative Approach to Machine Translation,"We present a perceptron-style discriminative approach to machine translation in which large feature sets can be exploited. Unlike discriminative reranking approaches, our system can take advantage of learned features in all stages of decoding. We first discuss several challenges to error-driven discriminative approaches. In particular, we explore different ways of updating parameters given a training example. We find that making frequent but smaller updates is preferable to making fewer but larger updates. Then, we discuss an array of features and show both how they quantitatively increase BLEU score and how they qualitatively interact on specific examples. One particular feature we investigate is a novel way to introduce learning into the initial phrase extraction process, which has previously been entirely heuristic.",2006,25,318,49,True,Computer Science,,2075292388,P. Liang,1398531195.0,A. Bouchard-Côté,38666915.0,D. Klein,1685978.0,B. Taskar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5260df181b79a5c91622d4c2da6d2c618852d6ff,https://www.semanticscholar.org/paper/5260df181b79a5c91622d4c2da6d2c618852d6ff,Kernel Fisher Discriminants,"In this thesis we consider statistical learning problems and machines. A statistical learning machine tries to infer rules from a given set of examples such that it is able to make correct predictions on unseen examples. These predictions can for example be a classification or a regression. We consider the class of kernel based learning techniques. The main contributions of this work can be summarized as follows. Building upon the theory of reproducing kernels we propose a number of new learning algorithms based on the maximization of a Rayleigh coefficient in a kernel feature space. We exemplify this for oriented (kernel) PCA, and especially for Fisher’s discriminant, yielding kernel Fisher discriminants (KFD). Furthermore, we show that KFD is intimately related to quadratic and linear optimization. Building upon this connection we propose several ways to deal with the optimization problems arising in kernel based methods and especially for KFD. This mathematical programming formulation is the starting point to derive several important and interesting variants of KFD, namely robust KFD, sparse KFD and linear KFD. Several algorithms to solve the resulting optimization problems are discussed. As a last consequence of the mathematical programming formulation we are able to relate KFD to other techniques like support vector machines, relevance vector machines and Arc-GV. Through a structural comparison of the underlying optimization problems we illustrate that many modern learning techniques, including KFD, are highly similar. In a separate chapter we present first results dealing with learning guarantees for eigenvalues and eigenvectors estimated from covariance matrices. We show that under some mild assumptions empirical eigenvalues are with high probability close to the expected eigenvalues when training on a specific, finite sample size. For eigenvectors we show that also with high probability an empirical eigenvector will be close to an eigenvector of the underlying distribution. In a large collection of experiments we demonstrate that KFD and its variants proposed here are capable of producing state of the art results. We compare KFD to techniques like AdaBoost and support vector machines, carefully discussing its advantages and also its difficulties.",2003,165,156,17,False,Computer Science,,2459012,S. Mika,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13755563644c43f4d0d2378338c61cbf89d3d2f8,https://www.semanticscholar.org/paper/13755563644c43f4d0d2378338c61cbf89d3d2f8,Machine‐learning scoring functions for structure‐based drug lead optimization,"Molecular docking can be used to predict how strongly small‐molecule binders and their chemical derivatives bind to a macromolecular target using its available three‐dimensional structures. Scoring functions (SFs) are employed to rank these molecules by their predicted binding affinity (potency). A classical SF assumes a predetermined theory‐inspired functional form for the relationship between the features characterizing the structure of the protein–ligand complex and its predicted binding affinity (this relationship is almost always assumed to be linear). Recent years have seen the prosperity of machine‐learning SFs, which are fast regression models built instead with contemporary supervised learning algorithms. In this review, we analyzed machine‐learning SFs for drug lead optimization in the 2015–2019 period. The performance gap between classical and machine‐learning SFs was large and has now broadened owing to methodological improvements and the availability of more training data. Against the expectations of many experts, SFs employing deep learning techniques were not always more predictive than those based on more established machine learning techniques and, when they were, the performance gain was small. More codes and webservers are available and ready to be applied to prospective structure‐based drug lead optimization studies. These have exhibited excellent predictive accuracy in compelling retrospective tests, outperforming in some cases much more computationally demanding molecular simulation‐based methods. A discussion of future work completes this review.",2020,116,66,1,True,Computer Science,,1704421,Hongjian Li,1581615496.0,Kam-Heung Sze,2114181414.0,Gang Lu,9998035.0,P. Ballester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2444be7584d1f5a7e2aa9f65078de09154f14ea1,https://www.semanticscholar.org/paper/2444be7584d1f5a7e2aa9f65078de09154f14ea1,Born Again Neural Networks,"Knowledge distillation (KD) consists of transferring knowledge from one machine learning model (the teacher}) to another (the student). Commonly, the teacher is a high-capacity model with formidable performance, while the student is more compact. By transferring knowledge, one hopes to benefit from the student's compactness. %we desire a compact model with performance close to the teacher's. We study KD from a new perspective: rather than compressing models, we train students parameterized identically to their teachers. Surprisingly, these {Born-Again Networks (BANs), outperform their teachers significantly, both on computer vision and language modeling tasks. Our experiments with BANs based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10 (3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional experiments explore two distillation objectives: (i) Confidence-Weighted by Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP). Both methods elucidate the essential components of KD, demonstrating a role of the teacher outputs on both predicted and non-predicted classes. We present experiments with students of various capacities, focusing on the under-explored case where students overpower teachers. Our experiments show significant advantages from transferring knowledge between DenseNets and ResNets in either direction.",2018,55,606,75,False,Computer Science,Mathematics,2067208583,Tommaso Furlanello,32219137.0,Zachary Chase Lipton,143902495.0,M. Tschannen,7326223.0,L. Itti,2047844.0,Anima Anandkumar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b2eadf142091cea03bfcc333d78f9edde025f7b8,https://www.semanticscholar.org/paper/b2eadf142091cea03bfcc333d78f9edde025f7b8,How does Machine Learning Change Software Development Practices?,"Adding an ability for a system to learn inherently adds uncertainty into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work characteristics (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.",2021,45,74,11,False,Computer Science,,3453740,Zhiyuan Wan,144558659.0,Xin Xia,143960552.0,David Lo,1739674.0,G. Murphy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ddb451cb57f2ed71004fdc218e0b23cc90b8233c,https://www.semanticscholar.org/paper/ddb451cb57f2ed71004fdc218e0b23cc90b8233c,Artificial Intelligence and Black-Box Medical Decisions: Accuracy versus Explainability.,"Although decision-making algorithms are not new to medicine, the availability of vast stores of medical data, gains in computing power, and breakthroughs in machine learning are accelerating the pace of their development, expanding the range of questions they can address, and increasing their predictive power. In many cases, however, the most powerful machine learning techniques purchase diagnostic or predictive accuracy at the expense of our ability to access ""the knowledge within the machine."" Without an explanation in terms of reasons or a rationale for particular decisions in individual cases, some commentators regard ceding medical decision-making to black box systems as contravening the profound moral responsibilities of clinicians. I argue, however, that opaque decisions are more common in medicine than critics realize. Moreover, as Aristotle noted over two millennia ago, when our knowledge of causal systems is incomplete and precarious-as it often is in medicine-the ability to explain how results are produced can be less important than the ability to produce such results and empirically verify their accuracy.",2019,34,238,8,False,Medicine,,2329084,A. London,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15d24d32bafe9edfc453108601a3fee41ab2a31c,https://www.semanticscholar.org/paper/15d24d32bafe9edfc453108601a3fee41ab2a31c,The Machine Learning Algorithm as Creative Musical Tool,"Machine learning is the capacity of a computational system to learn structures from datasets in order to make prediction in front of newly seen datasets. Such approach offers a significant advantage in music scenarios in which musicians can teach the system to learn an idiosyncratic style, or can break the rules to explore the system capacity in unexpected ways. In this chapter we draw on music, machine learning, and human-computer interaction to elucidate an understanding of machine learning algorithms as creative tools for music and the sonic arts. We motivate a new understanding of learning algorithms as human-computer interfaces. We show that, like other interfaces, learning algorithms can be characterised by the ways their affordances intersect with goals of human users. We also argue that the nature of interaction between users and algorithms impacts the usability and usefulness of those algorithms in profound ways. This human-centred view of machine learning motivates our concluding discussion of what it means to employ machine learning as a creative tool.",2016,68,53,3,True,Computer Science,,1745615,R. Fiebrink,2046048.0,Baptiste Caramiaux,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3185fd6ca0664a06ad0db58ea92142f0e97cb89e,https://www.semanticscholar.org/paper/3185fd6ca0664a06ad0db58ea92142f0e97cb89e,Weakly Supervised Disentanglement with Guarantees,"Learning disentangled representations that correspond to factors of variation in real-world data is critical to interpretable and human-controllable machine learning. Recently, concerns about the viability of learning disentangled representations in a purely unsupervised manner has spurred a shift toward the incorporation of weak supervision. However, there is currently no formalism that identifies when and how weak supervision will guarantee disentanglement. To address this issue, we provide a theoretical framework to assist in analyzing the disentanglement guarantees (or lack thereof) conferred by weak supervision when coupled with learning algorithms based on distribution matching. We empirically verify the guarantees and limitations of several weak supervision methods (restricted labeling, match-pairing, and rank-pairing), demonstrating the predictive power and usefulness of our theoretical framework.",2019,37,82,11,False,Computer Science,Mathematics,1978777,Rui Shu,2145262885.0,Yining Chen,50333123.0,Abhishek Kumar,2490652.0,S. Ermon,16443937.0,Ben Poole,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f50dfcc143bc1cc8ded1d88d31a59140b0a0ebd8,https://www.semanticscholar.org/paper/f50dfcc143bc1cc8ded1d88d31a59140b0a0ebd8,Deep Mixtures of Factor Analysers,"An efficient way to learn deep density models that have many layers of latent variables is to learn one layer at a time using a model that has only one layer of latent variables. After learning each layer, samples from the posterior distributions for that layer are used as training data for learning the next layer. This approach is commonly used with Restricted Boltzmann Machines, which are undirected graphical models with a single hidden layer, but it can also be used with Mixtures of Factor Analysers (MFAs) which are directed graphical models. In this paper, we present a greedy layer-wise learning algorithm for Deep Mixtures of Factor Analysers (DMFAs). Even though a DMFA can be converted to an equivalent shallow MFA by multiplying together the factor loading matrices at different levels, learning and inference are much more efficient in a DMFA and the sharing of each lower-level factor loading matrix by many different higher level MFAs prevents overfitting. We demonstrate empirically that DMFAs learn better density models than both MFAs and two types of Restricted Boltzmann Machine on a wide variety of datasets.",2012,15,66,14,False,Computer Science,Mathematics,34312504,Yichuan Tang,145124475.0,R. Salakhutdinov,1695689.0,Geoffrey E. Hinton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c7ba786c84c9c5161604e021551a23f098028eba,https://www.semanticscholar.org/paper/c7ba786c84c9c5161604e021551a23f098028eba,EBImage—an R package for image processing with applications to cellular phenotypes,"Summary: EBImage provides general purpose functionality for reading, writing, processing and analysis of images. Furthermore, in the context of microscopy-based cellular assays, EBImage offers tools to segment cells and extract quantitative cellular descriptors. This allows the automation of such tasks using the R programming language and use of existing tools in the R environment for signal processing, statistical modeling, machine learning and data visualization. Availability: EBImage is free and open source, released under the LGPL license and available from the Bioconductor project (http://www.bioconductor.org/packages/release/bioc/html/EBImage.html). Contact: gregoire.pau@ebi.ac.uk",2010,8,527,31,True,Computer Science,Medicine,47965474,Grégoire Pau,49349098.0,Florian Fuchs,46655534.0,O. Sklyar,144016011.0,M. Boutros,144493753.0,W. Huber,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
55ae79ca10937e3921003b4f1172467ae0be9065,https://www.semanticscholar.org/paper/55ae79ca10937e3921003b4f1172467ae0be9065,Very Deep Convolutional Neural Networks for Complex Land Cover Mapping Using Multispectral Remote Sensing Imagery,"Despite recent advances of deep Convolutional Neural Networks (CNNs) in various computer vision tasks, their potential for classification of multispectral remote sensing images has not been thoroughly explored. In particular, the applications of deep CNNs using optical remote sensing data have focused on the classification of very high-resolution aerial and satellite data, owing to the similarity of these data to the large datasets in computer vision. Accordingly, this study presents a detailed investigation of state-of-the-art deep learning tools for classification of complex wetland classes using multispectral RapidEye optical imagery. Specifically, we examine the capacity of seven well-known deep convnets, namely DenseNet121, InceptionV3, VGG16, VGG19, Xception, ResNet50, and InceptionResNetV2, for wetland mapping in Canada. In addition, the classification results obtained from deep CNNs are compared with those based on conventional machine learning tools, including Random Forest and Support Vector Machine, to further evaluate the efficiency of the former to classify wetlands. The results illustrate that the full-training of convnets using five spectral bands outperforms the other strategies for all convnets. InceptionResNetV2, ResNet50, and Xception are distinguished as the top three convnets, providing state-of-the-art classification accuracies of 96.17%, 94.81%, and 93.57%, respectively. The classification accuracies obtained using Support Vector Machine (SVM) and Random Forest (RF) are 74.89% and 76.08%, respectively, considerably inferior relative to CNNs. Importantly, InceptionResNetV2 is consistently found to be superior compared to all other convnets, suggesting the integration of Inception and ResNet modules is an efficient architecture for classifying complex remote sensing scenes such as wetlands.",2018,50,248,19,True,Computer Science,Geology,1961067,M. Mahdianpari,35204649.0,B. Salehi,143745699.0,M. Rezaee,31244965.0,F. Mohammadimanesh,2122995911.0,Yun Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f3d78e1c503bb8ac8e0ff50d26d4c89aa3691b98,https://www.semanticscholar.org/paper/f3d78e1c503bb8ac8e0ff50d26d4c89aa3691b98,Data Poisoning Attacks on Federated Machine Learning,"Federated machine learning which enables resource-constrained node devices (e.g., Internet of Things (IoT) devices and smartphones) to establish a knowledge-shared model while keeping the raw data local, could provide privacy preservation, and economic benefit by designing an effective communication protocol. However, this communication protocol can be adopted by attackers to launch data poisoning attacks for different nodes, which has been shown as a big threat to most machine learning models. Therefore, we in this article intend to study the model vulnerability of federated machine learning, and even on IoT systems. To be specific, we here attempt to attacking a popular federated multitask learning framework, which uses a general multitask learning framework to handle statistical challenges in the federated learning setting. The problem of calculating optimal poisoning attacks on federated multitask learning is formulated as a bilevel program, which is adaptive to the arbitrary selection of target nodes and source attacking nodes. We then propose a novel systems-aware optimization method, called as attack on federated learning (AT2FL), to efficiently derive the implicit gradients for poisoned data, and further attain optimal attack strategies in the federated machine learning. This is an earlier work, to our knowledge, that explores attacking federated machine learning via data poisoning. Finally, experiments on several real-world data sets demonstrate that when the attackers directly poison the target nodes or indirectly poison the related nodes via using the communication protocol, the federated multitask learning model is sensitive to both poisoning attacks.",2020,21,46,3,True,Computer Science,,7332901,Gan Sun,145702758.0,Yang Cong,46436215.0,Jiahua Dong,2153018830.0,Qiang Wang,40478933.0,Ji Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62312d957c63d85e9ba446bdbfa4143e8fbd13d3,https://www.semanticscholar.org/paper/62312d957c63d85e9ba446bdbfa4143e8fbd13d3,Simple and Scalable Response Prediction for Display Advertising,"Clickthrough and conversation rates estimation are two core predictions tasks in display advertising. We present in this article a machine learning framework based on logistic regression that is specifically designed to tackle the specifics of display advertising. The resulting system has the following characteristics: It is easy to implement and deploy, it is highly scalable (we have trained it on terabytes of data), and it provides models with state-of-the-art accuracy.",2014,76,301,27,True,Computer Science,,1730609,O. Chapelle,2690730.0,Eren Manavoglu,144956884.0,Rómer Rosales,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33c3f816bde8ee63ee9f2e60d4387b9390696371,https://www.semanticscholar.org/paper/33c3f816bde8ee63ee9f2e60d4387b9390696371,Beyond Inferring Class Representatives: User-Level Privacy Leakage From Federated Learning,"Federated learning, i.e., a mobile edge computing framework for deep learning, is a recent advance in privacy-preserving machine learning, where the model is trained in a decentralized manner by the clients, i.e., data curators, preventing the server from directly accessing those private data from the clients. This learning mechanism significantly challenges the attack from the server side. Although the state-of-the-art attacking techniques that incorporated the advance of Generative adversarial networks (GANs) could construct class representatives of the global data distribution among all clients, it is still challenging to distinguishably attack a specific client (i.e., user-level privacy leakage), which is a stronger privacy threat to precisely recover the private data from a specific client. This paper gives the first attempt to explore user-level privacy leakage against the federated learning by the attack from a malicious server. We propose a framework incorporating GAN with a multi-task discriminator, which simultaneously discriminates category, reality, and client identity of input samples. The novel discrimination on client identity enables the generator to recover user specified private data. Unlike existing works that tend to interfere the training process of the federated learning, the proposed method works “invisibly” on the server side. The experimental results demonstrate the effectiveness of the proposed attacking approach and the superior to the state-of-the-art.",2018,28,363,22,True,Computer Science,Mathematics,3623271,Zhibo Wang,51114861.0,Mengkai Song,1786391.0,Zhifei Zhang,144404428.0,Yang Song,2183687338.0,Qian Wang,1698645.0,H. Qi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dff87a341b365d654edd640ae1f962b0b7736cd2,https://www.semanticscholar.org/paper/dff87a341b365d654edd640ae1f962b0b7736cd2,Design of the 2015 ChaLearn AutoML challenge,"ChaLearn is organizing the Automatic Machine Learning (AutoML) contest for IJCNN 2015, which challenges participants to solve classification and regression problems without any human intervention. Participants' code is automatically run on the contest servers to train and test learning machines. However, there is no obligation to submit code; half of the prizes can be won by submitting prediction results only. Datasets of progressively increasing difficulty are introduced throughout the six rounds of the challenge. (Participants can enter the competition in any round.) The rounds alternate phases in which learners are tested on datasets participants have not seen, and phases in which participants have limited time to tweak their algorithms on those datasets to improve performance. This challenge will push the state of the art in fully automatic machine learning on a wide range of real-world problems. The platform will remain available beyond the termination of the challenge.",2015,74,97,7,True,Computer Science,,1743797,I. Guyon,2065549778.0,Kristin P. Bennett,8974886.0,G. Cawley,1742688.0,H. Escalante,7855312.0,Sergio Escalera,1795578.0,T. Ho,2179558.0,Núria Macià,1723198.0,Bisakha Ray,144102090.0,M. Saeed,1702228.0,A. Statnikov,2832706.0,E. Viegas,,,,,,,,,,,,,,,,,,,,,,,,,
edbc873a248768a626ef2bc57b3d1eff30de0e11,https://www.semanticscholar.org/paper/edbc873a248768a626ef2bc57b3d1eff30de0e11,Learning Graphical State Transitions,"Graph-structured data is important in modeling relationships between multiple entities, and can be used to represent states of the world as well as many data structures. Li et al. (2016) describe a model known as a Gated Graph Sequence Neural Network (GGS-NN) that produces sequences from graph-structured input. In this work I introduce the Gated Graph Transformer Neural Network (GGTNN), an extension of GGS-NNs that uses graph-structured data as an intermediate representation. The model can learn to construct and modify graphs in sophisticated ways based on textual input, and also to use the graphs to produce a variety of outputs. For example, the model successfully learns to solve almost all of the bAbI tasks (Weston et al., 2016), and also discovers the rules governing graphical formulations of a simple cellular automaton and a family of Turing machines.",2016,23,87,7,False,Computer Science,,2150444707,Daniel D. Johnson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8454aef70de13fc8d75d2f6a8fd31f4d53886dab,https://www.semanticscholar.org/paper/8454aef70de13fc8d75d2f6a8fd31f4d53886dab,How accurately can sitting and the intensity of walking and cycling be classified using an accelerometer on the waist for the purpose of the “Global recommendations on physical activity for health”?,"The society has become more sedentary and has developed a lack of physical activity, therefore increasing health risks. Feedback is needed to change these behaviours. For this feedback, first accurate monitoring is needed: sedentary behaviour must be classified as well as the intensity of physical activity. In this report a State of the Art analysis is performed to compare different classification techniques and finally two methods, both using an accelerometer on the waist, are worked out. These methods are Integral of the Modulus of the Accelerometer (IMA) classification and a machine learning technique (MLT): support vector machine (SVM). These methods are then applied in a laboratory experiment to study their quality. A measurement setup is made to create a dataset of the following activities: standing, sitting, lying, walking (2.4 - 7.5 km/h) and cycling (10.1-19 km/h). This dataset (n=15) is analysed and classified using Matlab for both methods.The IMA method was unable to monitor sedentary behaviour, but could classify the physical activity (PA) intensity with an accuracy of 66%. The SVM method within subjects was able to monitor sedentary behaviour with an accuracy of 91±20% and the classification of the PA intensity has an accuracy of 94±5%. For between subjects the accuracies decrease to 71±13% for PA intensity accuracy and 45±35% for the sedentary behaviour classification. IMA was implemented in the old feedback system, monitoring the overall daily amount of physical activity, but can significantly be outperformed by replacing it with the current SVM implementation. At this moment however, SVM can only be used to improve the old system, it cannot yet be used to create new additions to the feedback system, such as the implementation of the feedback of the sedentary behaviour and specific physical activity intensities. New methods and properties of the current SVM system have been found that might increase the accuracies of the between subject analysis and therefore might enable SVM to become applicable for the extra feedback options.",2015,12,2706,138,False,Engineering,,1581793152,D. V. D. Valk,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
df137487e20ba7c6e1e2b9a1e749f2a578b5ad99,https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99,Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks,"Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used succesfully in our winning entry to the MSCOCO image captioning challenge, 2015.",2015,26,1536,174,False,Computer Science,,1751569,Samy Bengio,1689108.0,Oriol Vinyals,3111912.0,N. Jaitly,1846258.0,Noam M. Shazeer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f60b025bc86740f60f6fa7b227cf7897426dc776,https://www.semanticscholar.org/paper/f60b025bc86740f60f6fa7b227cf7897426dc776,Domain Invariant Transfer Kernel Learning,"Domain transfer learning generalizes a learning model across training data and testing data with different distributions. A general principle to tackle this problem is reducing the distribution difference between training data and testing data such that the generalization error can be bounded. Current methods typically model the sample distributions in input feature space, which depends on nonlinear feature mapping to embody the distribution discrepancy. However, this nonlinear feature space may not be optimal for the kernel-based learning machines. To this end, we propose a transfer kernel learning (TKL) approach to learn a domain-invariant kernel by directly matching source and target distributions in the reproducing kernel Hilbert space (RKHS). Specifically, we design a family of spectral kernels by extrapolating target eigensystem on source samples with Mercer's theorem. The spectral kernel minimizing the approximation error to the ground truth kernel is selected to construct domain-invariant kernel machines. Comprehensive experimental evidence on a large number of text categorization, image classification, and video event recognition datasets verifies the effectiveness and efficiency of the proposed TKL approach over several state-of-the-art methods.",2015,49,166,29,False,Computer Science,,35776445,Mingsheng Long,2144499343.0,Jianmin Wang,2109517420.0,Jiaguang Sun,144019071.0,Philip S. Yu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d9665992ee36699b8ae4a2e2294552cd4be9003a,https://www.semanticscholar.org/paper/d9665992ee36699b8ae4a2e2294552cd4be9003a,Statistical fraud detection: A review,"Fraud is increasing dramatically with the expansion of modem technology and the global superhighways of communication, resulting in the loss of billions of dollars worldwide each year. Although prevention technologies are the best way to reduce fraud, fraudsters are adaptive and, given time, will usually find ways to circumvent such measures. Methodologies for the detection of fraud are essential if we are to catch fraudsters once fraud prevention has failed. Statistics and machine learning provide effective technologies for fraud detection and have been applied successfully to detect activities such as money laundering, e-commerce credit card fraud, telecommunications fraud and computer intrusion, to name but a few. We describe the tools available for statistical fraud detection and the areas in which fraud detection technologies are most used.",2002,126,1193,60,True,Mathematics,Engineering,3002426,R. J. Bolton,1781982.0,D. Hand,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
35c70cb330fe44dffe926289fb467962b1f64b0e,https://www.semanticscholar.org/paper/35c70cb330fe44dffe926289fb467962b1f64b0e,OTL: A Framework of Online Transfer Learning,"In this paper, we investigate a new machine learning framework called Online Transfer Learning (OTL) that aims to transfer knowledge from some source domain to an online learning task on a target domain. We do not assume the target data follows the same class or generative distribution as the source data, and our key motivation is to improve a supervised online learning task in a target domain by exploiting the knowledge that had been learned from large amount of training data in source domains. OTL is in general challenging since data in both domains not only can be different in their class distributions but can be also different in their feature representations. As a first attempt to this problem, we propose techniques to address two kinds of OTL tasks: one is to perform OTL in a homogeneous domain, and the other is to perform OTL across heterogeneous domains. We show the mistake bounds of the proposed OTL algorithms, and empirically examine their performance on several challenging OTL tasks. Encouraging results validate the efficacy of our techniques.",2010,14,111,18,False,Computer Science,,144259957,P. Zhao,1741126.0,S. Hoi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c1075602e28f5b61ec0320a64937398f23e3fc70,https://www.semanticscholar.org/paper/c1075602e28f5b61ec0320a64937398f23e3fc70,Predicting cloud resource provisioning using machine learning techniques,"In order to meet Service Level Agreement (SLA) requirements, Virtual Machine (VM) resources must be provisioned few minutes ahead due to the VM boot-up time. One way to do this is by predicting future resource demands. In this research, we have developed and evaluated cloud client prediction models for TPCW benchmark web application using three machine learning techniques: Support Vector Machine (SVM), Neural Networks (NN) and Linear Regression (LR). We included the SLA metrics for Response Time and Throughput to the prediction model with the aim of providing the client with a more robust scaling decision choice. Our results show that Support Vector Machine provides the best prediction model.",2013,24,68,7,False,Computer Science,,31495507,A. A. Bankole,145428138.0,S. Ajila,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60a67687d892d39c6aeac3ca3e2758fb947c0791,https://www.semanticscholar.org/paper/60a67687d892d39c6aeac3ca3e2758fb947c0791,Genetic algorithms in controller design and tuning,"A three-phased framework for learning dynamic system control is presented. A genetic algorithm is employed to derive control rules encoded as decision tables. Next, the rules are automatically transformed into comprehensible form by means of inductive machine learning. Finally, a genetic algorithm is applied again to optimize the numerical parameters of the induced rules. The approach is experimentally verified on a benchmark problem of inverted pendulum control, with special emphasis on robustness and reliability. It is also shown that the proposed framework enables exploiting available domain knowledge. In this case, genetic algorithm makes qualitative control rules operational by providing interpretation of symbols in terms of numerical values. >",1993,10,239,6,False,Computer Science,,1931927,A. Varsek,2654837.0,T. Urbancic,1691028.0,B. Filipič,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6b67847dbd87a80ac23a06767357f43bd19086a0,https://www.semanticscholar.org/paper/6b67847dbd87a80ac23a06767357f43bd19086a0,Learning low-rank kernel matrices,"Kernel learning plays an important role in many machine learning tasks. However, algorithms for learning a kernel matrix often scale poorly, with running times that are cubic in the number of data points. In this paper, we propose efficient algorithms for learning low-rank kernel matrices; our algorithms scale linearly in the number of data points and quadratically in the rank of the kernel. We introduce and employ Bregman matrix divergences for rank-deficient matrices---these divergences are natural for our problem since they preserve the rank as well as positive semi-definiteness of the kernel matrix. Special cases of our framework yield faster algorithms for various existing kernel learning problems. Experimental results demonstrate the effectiveness of our algorithms in learning both low-rank and full-rank kernels.",2006,14,185,10,False,Mathematics,Computer Science,1692670,B. Kulis,2190189.0,Mátyás A. Sustik,1783667.0,I. Dhillon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39e2e0ca2a3c1116fa26568eb58ef344ce4e042e,https://www.semanticscholar.org/paper/39e2e0ca2a3c1116fa26568eb58ef344ce4e042e,An introduction to artificial neural networks in bioinformatics - application to complex microarray and mass spectrometry datasets in cancer studies,"Applications of genomic and proteomic technologies have seen a major increase, resulting in an explosion in the amount of highly dimensional and complex data being generated. Subsequently this has increased the effort by the bioinformatics community to develop novel computational approaches that allow for meaningful information to be extracted. This information must be of biological relevance and thus correlate to disease phenotypes of interest. Artificial neural networks are a form of machine learning from the field of artificial intelligence with proven pattern recognition capabilities and have been utilized in many areas of bioinformatics. This is due to their ability to cope with highly dimensional complex datasets such as those developed by protein mass spectrometry and DNA microarray experiments. As such, neural networks have been applied to problems such as disease classification and identification of biomarkers. This review introduces and describes the concepts related to neural networks, the advantages and caveats to their use, examples of their applications in mass spectrometry and microarray research (with a particular focus on cancer studies), and illustrations from recent literature showing where neural networks have performed well in comparison to other machine learning methods. This should form the necessary background knowledge and information enabling researchers with an interest in these methodologies, but not necessarily from a machine learning background, to apply the concepts to their own datasets, thus maximizing the information gain from these complex biological systems.",2008,115,162,8,True,Computer Science,Biology,2873684,L. Lancashire,3331820.0,C. Lemetre,144313587.0,G. Ball,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Medicine
da8a949f9c9f1df3a38f12c2cac97b789c705465,https://www.semanticscholar.org/paper/da8a949f9c9f1df3a38f12c2cac97b789c705465,A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security,"The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention. IoT is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020. However, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems have introduced new security challenges. Implementing security measures, such as encryption, authentication, access control, network and application security for IoT devices and their inherent vulnerabilities is ineffective. Therefore, existing security methods should be enhanced to effectively secure the IoT ecosystem. Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory novelty to practical machinery in several important applications. Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems. The goal of this work is to provide a comprehensive survey of ML methods and recent advances in DL methods that can be used to develop enhanced security methods for IoT systems. IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed. We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method. We discuss the opportunities and challenges involved in applying ML/DL to IoT security. These opportunities and challenges can serve as potential future research directions.",2018,303,366,17,True,Computer Science,,1403206186,M. Al-garadi,143634114.0,Amr M. Mohamed,1403346505.0,A. Al-Ali,144335971.0,Xiaojiang Du,2096342291.0,Ihsan Ali,145837053.0,M. Guizani,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
be813b90620b2627226864eaf5e0f3eec9d50e85,https://www.semanticscholar.org/paper/be813b90620b2627226864eaf5e0f3eec9d50e85,A Review and Tutorial of Machine Learning Methods for Microbiome Host Trait Prediction,"With the growing importance of microbiome research, there is increasing evidence that host variation in microbial communities is associated with overall host health. Advancement in genetic sequencing methods for microbiomes has coincided with improvements in machine learning, with important implications for disease risk prediction in humans. One aspect specific to microbiome prediction is the use of taxonomy-informed feature selection. In this review for non-experts, we explore the most commonly used machine learning methods, and evaluate their prediction accuracy as applied to microbiome host trait prediction. Methods are described at an introductory level, and R/Python code for the analyses is provided.",2019,77,92,4,False,Biology,Medicine,34661060,Yi‐Hui Zhou,5822509.0,P. Gallins,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dbea1bba0dd798bfc8463480083b8fc3d2eab3ad,https://www.semanticscholar.org/paper/dbea1bba0dd798bfc8463480083b8fc3d2eab3ad,Realistic Atomistic Structure of Amorphous Silicon from Machine-Learning-Driven Molecular Dynamics.,"Amorphous silicon ( a-Si) is a widely studied noncrystalline material, and yet the subtle details of its atomistic structure are still unclear. Here, we show that accurate structural models of a-Si can be obtained using a machine-learning-based interatomic potential. Our best a-Si network is obtained by simulated cooling from the melt at a rate of 1011 K/s (that is, on the 10 ns time scale), contains less than 2% defects, and agrees with experiments regarding excess energies, diffraction data, and 29Si NMR chemical shifts. We show that this level of quality is impossible to achieve with faster quench simulations. We then generate a 4096-atom system that correctly reproduces the magnitude of the first sharp diffraction peak (FSDP) in the structure factor, achieving the closest agreement with experiments to date. Our study demonstrates the broader impact of machine-learning potentials for elucidating structures and properties of technologically important amorphous materials.",2018,67,139,1,True,Physics,Medicine,2432235,Volker L. Deringer,2105796.0,N. Bernstein,3938091.0,A. Bartók,2323690.0,M. Cliffe,1875111.0,R. Kerber,11666716.0,L. Marbella,2470773.0,C. Grey,2169428271.0,S. Elliott,2559761.0,Gábor Csányi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Materials Science
93d53bd1c7e8f887d85be2c83a0f5f8c061b4c2f,https://www.semanticscholar.org/paper/93d53bd1c7e8f887d85be2c83a0f5f8c061b4c2f,Semi-Supervised Learning Using Semi-Definite Programming,"We discuss the problem of support vector machine (SVM) transduction, which is a combinatorial problem with exponential computational complexity in the number of unlabeled samples. Different approaches to such combinatorial problems exist, among which are exact integer programming approaches (only feasible for very small sample sizes, e.g. [1]) and local search heuristics starting from a suitably chosen start value such as the approach explained in Chapter 5, Transductive Support Vector Machines , and introduced in [2] (scalable to large problem sizes, but sensitive to local optima). In this chapter, we discuss an alternative approach introduced in [3], which is based on a convex relaxation of the optimization problem associated to support vector machine transduction. The result is a semi-definite programming (SDP) problem which can be optimized in polynomial time, the solution of which is an approximation of the optimal labeling as well as a bound on the true optimum of the original transduction objective function. To further decrease the computational complexity, we propose an approximation that allows to solve transduction problems of up to 1000 unlabeled samples. Lastly, we extend the formulation to more general settings of semi-supervised learning, where equivalence and inequivalence constraints are given on labels of some of the samples.",2006,9,55,2,False,Computer Science,,51204489,T. D. Bie,1685083.0,N. Cristianini,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14014c024674991149f3ecf9314c93f7e029ef1a,https://www.semanticscholar.org/paper/14014c024674991149f3ecf9314c93f7e029ef1a,"Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges","The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.",2021,0,318,24,False,Computer Science,Mathematics,1732570,M. Bronstein,143627859.0,Joan Bruna,2056266.0,Taco Cohen,1742197495.0,Petar Velivckovi'c,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
994ddbea26882f70131ca01cc1bd474dabf0ace3,https://www.semanticscholar.org/paper/994ddbea26882f70131ca01cc1bd474dabf0ace3,Learning based digital matting,"We cast some new insights into solving the digital matting problem by treating it as a semi-supervised learning task in machine learning. A local learning based approach and a global learning based approach are then produced, to fit better the scribble based matting and the trimap based matting, respectively. Our approaches are easy to implement because only some simple matrix operations are needed. They are also extremely accurate because they can efficiently handle the nonlinear local color distributions by incorporating the kernel trick, that are beyond the ability of many previous works. Our approaches can outperform many recent matting methods, as shown by the theoretical analysis and comprehensive experiments. The new insights may also inspire several more works.",2009,23,183,36,False,Computer Science,,1746086,Yuanjie Zheng,1708413.0,C. Kambhamettu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8fcf38e6a758a32140a74cffce0a8044dc81ac23,https://www.semanticscholar.org/paper/8fcf38e6a758a32140a74cffce0a8044dc81ac23,Regularized Machine Learning in the Genetic Prediction of Complex Traits,"Supervised machine learning aims at constructing a genotype–phenotype model by learning such genetic patterns from a labeled set of training examples that will also provide accurate phenotypic predictions in new cases with similar genetic background. Such predictive models are increasingly being applied to the mining of panels of genetic variants, environmental, or other nongenetic factors in the prediction of various complex traits and disease phenotypes [1]–[8]. These studies are providing increasing evidence in support of the idea that machine learning provides a complementary view into the analysis of high-dimensional genetic datasets as compared to standard statistical association testing approaches. In contrast to identifying variants explaining most of the phenotypic variation at the population level, supervised machine learning models aim to maximize the predictive (or generalization) power at the level of individuals, hence providing exciting opportunities for e.g., individualized risk prediction based on personal genetic profiles [9]–[11]. Machine learning models can also deal with genetic interactions, which are known to play an important role in the development and treatment of many complex diseases [12]–[16], but are often missed by single-locus association tests [17]. Even in the absence of significant single-loci marginal effects, multilocus panels from distinct molecular pathways may provide synergistic contribution to the prediction power, thereby revealing part of such hidden heritability component that has remained missing because of too small marginal effects to pass the stringent genome-wide significance filters [18]. Multivariate modeling approaches have already been shown to provide improved insights into genetic mechanisms and the interaction networks behind many complex traits, including atherosclerosis, coronary heart disease, and lipid levels, which would have gone undetected using the standard univariate modeling [2], [19]–[22]. However, machine learning models also come with inherent pitfalls, such as increased computational complexity and the risk for model overfitting, which must be understood in order to avoid reporting unrealistic prediction models or over-optimistic prediction results. We argue here that many medical applications of machine learning models in genetic disease risk prediction rely essentially on two factors: effective model regularization and rigorous model validation. We demonstrate the effects of these factors using representative examples from the literature as well as illustrative case examples. This review is not meant to be a comprehensive survey of all predictive modeling approaches, but we focus on regularized machine learning models, which enforces constraints on the complexity of the learned models so that they would ignore irrelevant patterns in the training examples. Simple risk allele counting or other multilocus risk models that do not incorporate any model parameters to be learned are outside the scope of this review; in fact, such simplistic models that assume independent variants may lead to suboptimal prediction performance in the presence of either direct or indirect interactions through epistasis effects or linkage disequilibrium, respectively [23], [24]. Perhaps the simplest models considered here as learning approaches are those based on weighted risk allele summaries [23], [25]. However, even with such basic risk models intended for predictive purposes, it is important to learn the model parameters (e.g., select the variants and determine their weights) based on training data only; otherwise there is a severe risk of model overfitting, i.e., models not being capable of generalizing to new samples [5]. Representative examples of how model learning and regularization approaches address the overfitting problem are briefly summarized in Box 1, while those readers interested in their implementation details are referred to the accompanying Text S1. We specifically promote here the use of such regularized machine learning models that are scalable to the entire genome-wide scale, often based on linear models, which are easy to interpret and also enable straightforward variable selection. Genome-scale approaches avoid the need of relying on two-stage approaches [26], which apply standard statistical procedures to reduce the number of variants, since such prefiltering may miss predictive interactions across loci and therefore lead to reduced predictive performance [8], [24], [25], [27], [28]. Box 1. Synthesis of Learning Models for Genetic Risk Prediction The aim of risk models is to capture in a mathematical form the patterns in the genetic and non-genetic data most important for the prediction of disease susceptibility. The first step in model building involves choosing the functional form of the model (e.g., linear or nonlinear), and then making use of a given training data to determine the adjustable parameters of the model (e.g., a subset of variants, their weights, and other model parameters). While it is often sufficient for a statistical model to enable high enough explanatory power in the discovery material, without being overly complicated, a predictive model is also required to generalize to unseen cases. One consideration in the model construction is how to encode the genotypic measurements using genotype models, such as the dominant, recessive, multiplicative, or additive model, each implying different assumptions about the genetic effects in the data [79]. Categorical variables 0, 1, and 2 are typically used for treating genetic predictor variables (e.g., minor allele dosage), while numeric values are required for continuous risk factors (e.g., blood pressure). Expected posterior probabilities of the genotypes can also be used, especially for imputed genotypes. Transforming the genotype categories into three binary features is an alternative way to deal with missing values without imputation (used in the T1D example; see Text S1 for details). Statistical or machine learning models identify statistical or predictive interactions, respectively, rather than biological interactions between or within variants [12], [80]. While nonlinear models may better capture complex genetic interactions [7], [81], linear models are easier to interpret and provide a scalable option for performing supervised selection of multilocus variant panels at the genome-wide scale [3]. In linear models, genetic interactions are modeled implicitly by selecting such variant combinations that together are predictive of the phenotype, rather than considering pairwise gene–gene relationships explicitly. Formally, trait yi to be predicted for an individual i is modeled as a linear combination of the individual's predictor variables xij: (1) Here, the weights wj are assumed constant across the n individuals, w 0 is the bias offset term and p indicates the number of predictors discovered in the training data. In its basic form, Eq. 1 can be used for modeling continuous traits y (linear regression). For case-control classification, the binary dependent variable y is often transformed using a logistic loss function, which models the probability of a case class given a genotype profile and other risk factor covariates x (logistic regression). It has been shown that the logistic regression and naive Bayes risk models are mathematically very closely related in the context of genetic risk prediction [81].",2014,124,114,2,True,Biology,Medicine,2013961,S. Okser,1731090.0,T. Pahikkala,1735715.0,A. Airola,1680811.0,T. Salakoski,2407947.0,S. Ripatti,1728404.0,T. Aittokallio,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84c760b4fd083b76495bd98ce7eeef466331b8e1,https://www.semanticscholar.org/paper/84c760b4fd083b76495bd98ce7eeef466331b8e1,"Recent applications of deep learning and machine intelligence on in silico drug discovery: methods, tools and databases","Abstract The identification of interactions between drugs/compounds and their targets is crucial for the development of new drugs. In vitro screening experiments (i.e. bioassays) are frequently used for this purpose; however, experimental approaches are insufficient to explore novel drug-target interactions, mainly because of feasibility problems, as they are labour intensive, costly and time consuming. A computational field known as ‘virtual screening’ (VS) has emerged in the past decades to aid experimental drug discovery studies by statistically estimating unknown bio-interactions between compounds and biological targets. These methods use the physico-chemical and structural properties of compounds and/or target proteins along with the experimentally verified bio-interaction information to generate predictive models. Lately, sophisticated machine learning techniques are applied in VS to elevate the predictive performance. The objective of this study is to examine and discuss the recent applications of machine learning techniques in VS, including deep learning, which became highly popular after giving rise to epochal developments in the fields of computer vision and natural language processing. The past 3 years have witnessed an unprecedented amount of research studies considering the application of deep learning in biomedicine, including computational drug discovery. In this review, we first describe the main instruments of VS methods, including compound and protein features (i.e. representations and descriptors), frequently used libraries and toolkits for VS, bioactivity databases and gold-standard data sets for system training and benchmarking. We subsequently review recent VS studies with a strong emphasis on deep learning applications. Finally, we discuss the present state of the field, including the current challenges and suggest future directions. We believe that this survey will provide insight to the researchers working in the field of computational drug discovery in terms of comprehending and developing novel bio-prediction methods.",2018,261,219,7,True,Computer Science,Medicine,12373665,A. Rifaioglu,50646671.0,Heval Atas,46502933.0,M. Martin,101903368.0,R. Cetin-Atalay,1737543.0,V. Atalay,2407842.0,Tunca Dogan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
545ce673b236ec4413a64df42204ab9c79ed6e15,https://www.semanticscholar.org/paper/545ce673b236ec4413a64df42204ab9c79ed6e15,"Machine Audition: Principles, Algorithms and Systems","Machine audition is the study of algorithms and systems for the automatic analysis and understanding of sound by machine. It has recently attracted increasing interest within several research communities, such as signal processing, machine learning, auditory modeling, perception and cognition, psychology, pattern recognition, and artificial intelligence. However, the developments made so far are fragmented within these disciplines, lacking connections and incurring potentially overlapping research activities in this subject area. Machine Audition: Principles, Algorithms and Systems contains advances in algorithmic developments, theoretical frameworks, and experimental research findings. This book is useful for professionals who want an improved understanding about how to design algorithms for performing automatic analysis of audio signals, construct a computing system for understanding sound, and learn how to build advanced human-computer interactive systems.",2010,311,169,9,False,Computer Science,,2134821831,Wenwu Wang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
505bee3f5e750c4affa49023585a513210d35a60,https://www.semanticscholar.org/paper/505bee3f5e750c4affa49023585a513210d35a60,Feasibility of Supervised Machine Learning for Cloud Security,"Cloud computing is gaining significant attention, however, security is the biggest hurdle in its wide acceptance. Users of cloud services are under constant fear of data loss, security threats and availability issues. Recently, learning-based methods for security applications are gaining popularity in the literature with the advents in machine learning techniques. However, the major challenge in these methods is obtaining real-time and unbiased datasets. Many datasets are internal and cannot be shared due to privacy issues or may lack certain statistical characteristics. As a result of this, researchers prefer to generate datasets for training and testing purpose in the simulated or closed experimental environments which may lack comprehensiveness. Machine learning models trained with such a single dataset generally result in a semantic gap between results and their application. There is a dearth of research work which demonstrates the effectiveness of these models across multiple datasets obtained in different environments. We argue that it is necessary to test the robustness of the machine learning models, especially in diversified operating conditions, which are prevalent in cloud scenarios. In this work, we use the UNSW dataset to train the supervised machine learning models. We then test these models with ISOT dataset. We present our results and argue that more research in the field of machine learning is still required for its applicability to the cloud security.",2016,31,57,5,True,Computer Science,Mathematics,3116378,D. Bhamare,1935864.0,Tara Salman,1932846.0,M. Samaka,2884607.0,A. Erbad,145889709.0,R. Jain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
217c3e37092bb094bf226b58f44357db5c284a60,https://www.semanticscholar.org/paper/217c3e37092bb094bf226b58f44357db5c284a60,Learning to Resolve Bridging References,"We use machine learning techniques to find the best combination of local focus and lexical distance features for identifying the anchor of mereological bridging references. We find that using first mention, utterance distance, and lexical distance computed using either Google or WordNet results in an accuracy significantly higher than obtained in previous experiments.",2004,43,113,21,True,Computer Science,,1678591,Massimo Poesio,2067925708.0,Rahul Mehta,2470445.0,Axel Maroudas,2165202.0,J. Hitzeman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ec570b827cf0cd132da7ebd37537df4f0bb7f877,https://www.semanticscholar.org/paper/ec570b827cf0cd132da7ebd37537df4f0bb7f877,Learning De-biased Representations with Biased Representations,"Many machine learning algorithms are trained and evaluated by splitting data from a single source into training and test sets. While such focus on in-distribution learning scenarios has led to interesting advancement, it has not been able to tell if models are relying on dataset biases as shortcuts for successful prediction (e.g., using snow cues for recognising snowmobiles), resulting in biased models that fail to generalise when the bias shifts to a different class. The cross-bias generalisation problem has been addressed by de-biasing training data through augmentation or re-sampling, which are often prohibitive due to the data collection cost (e.g., collecting images of a snowmobile on a desert) and the difficulty of quantifying or expressing biases in the first place. In this work, we propose a novel framework to train a de-biased representation by encouraging it to be different from a set of representations that are biased by design. This tactic is feasible in many scenarios where it is much easier to define a set of biased representations than to define and quantify bias. We demonstrate the efficacy of our method across a variety of synthetic and real-world biases; our experiments show that the method discourages models from taking bias shortcuts, resulting in improved generalisation. Source code is available at this https URL.",2019,55,112,27,False,Computer Science,,41019737,Hyojin Bahng,2647582.0,Sanghyuk Chun,2151587.0,Sangdoo Yun,1795455.0,J. Choo,2390510.0,Seong Joon Oh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66e70d7d6af0c51b9b907d9c4a8de0dfca70b1a7,https://www.semanticscholar.org/paper/66e70d7d6af0c51b9b907d9c4a8de0dfca70b1a7,Will machine learning end the viability of radiology as a thriving medical specialty?,"There have been tremendous advances in artificial intelligence (AI) and machine learning (ML) within the past decade, especially in the application of deep learning to various challenges. These include advanced competitive games (such as Chess and Go), self-driving cars, speech recognition, and intelligent personal assistants. Rapid advances in computer vision for recognition of objects in pictures have led some individuals, including computer science experts and health care system experts in machine learning, to make predictions that ML algorithms will soon lead to the replacement of the radiologist. However, there are complex technological, regulatory, and medicolegal obstacles facing the implementation of machine learning in radiology that will definitely preclude replacement of the radiologist by these algorithms within the next two decades and beyond. While not a comprehensive review of machine learning, this article is intended to highlight specific features of machine learning which face significant technological and health care systems challenges. Rather than replacing radiologists, machine learning will provide quantitative tools that will increase the value of diagnostic imaging as a biomarker, increase image quality with decreased acquisition times, and improve workflow, communication, and patient safety. In the foreseeable future, we predict that today's generation of radiologists will be replaced not by ML algorithms, but by a new breed of data science-savvy radiologists who have embraced and harnessed the incredible potential that machine learning has to advance our ability to care for our patients. In this way, radiology will remain a viable medical specialty for years to come.",2019,112,46,2,True,Engineering,Medicine,2107300376,Stephen Chan,1691257.0,E. Siegel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44aac57800bc8090338153f421682282a90da922,https://www.semanticscholar.org/paper/44aac57800bc8090338153f421682282a90da922,"Machine learning and modeling: Data, validation, communication challenges","With the era of big data, the utilization of machine learning algorithms in radiation oncology is rapidly growing with applications including: treatment response modeling, treatment planning, contouring, organ segmentation, image-guidance, motion tracking, quality assurance, and more. Despite this interest, practical clinical implementation of machine learning as part of the day-to-day clinical operations is still lagging. The aim of this white paper is to further promote progress in this new field of machine learning in radiation oncology by highlighting its untapped advantages and potentials for clinical advancement, while also presenting current challenges and open questions for future research. The targeted audience of this paper includes newcomers as well as practitioners in the field of medical physics/radiation oncology. The paper also provides general recommendations to avoid common pitfalls when applying these powerful data analytic tools to medical physics and radiation oncology problems and suggests some guidelines for transparent and informative reporting of machine learning results.",2018,86,55,1,True,Medicine,Computer Science,65739579,I. El Naqa,143903039.0,D. Ruan,145295389.0,G. Valdes,48742163.0,A. Dekker,2176030.0,T. McNutt,37007400.0,Y. Ge,2167223315.0,Q. Wu,1743648.0,J. Oh,1787832.0,M. Thor,3467448.0,W. Smith,1849484.0,A. Rao,2863660.0,C. Fuller,143927628.0,Ying Xiao,1781787.0,F. Manion,3746794.0,M. Schipper,34839615.0,C. Mayo,48227976.0,J. Moran,115533597.0,R. T. Ten Haken,,,,,,,,,,,
ec129af4c59e7813ea1e60a5a098b569afcdf4de,https://www.semanticscholar.org/paper/ec129af4c59e7813ea1e60a5a098b569afcdf4de,The Kernel-Adatron : A fast and simple learning procedure for support vector machines,"The present invention is directed to non-hygroscopic, water-soluble sugar compositions which are prepared by grinding together in a dry, solid state, a white sugar component and a ""pulverizing aid"" in the form of a water-soluble maltodextrin having a measurable dextrose equivalent value not substantially above 20, said ""pulverizing aid"" being employed in amounts ranging from about 5 to about 20% by weight of said total composition, the resulting product having an average particle size such that 95% by weight of the composition passes through a 325 mesh, said composition being further characterized as having a ratio of weight average particle size to number average particle size of less than 2. The compositions are free-flowing powders useful in preparing icings, buttercreams and fudges.",1998,0,115,10,False,Computer Science,,34999823,T. Frieß,1685083.0,N. Cristianini,153410082.0,I. Campbell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
feb272d9bdeff301d267ece37b5387c61203c609,https://www.semanticscholar.org/paper/feb272d9bdeff301d267ece37b5387c61203c609,Machine Learning Approaches for Thermoelectric Materials Research,"Thermoelectric (TE) materials provide a solid‐state solution in waste heat recovery and refrigeration. During the past few decades, considerable effort has been devoted towards improving the performance of TE materials, which requires the optimization of multiple interrelated properties. A fundamental understanding of the interaction processes between the various energy carriers, such as electrons and phonons, is critical for advances in the development of TE materials. However, this understanding remains challenging primarily due to the inaccessibility of time scales using standard atomistic simulations. Machine learning methods, well known for their data‐analysis capability, have been successfully applied in research on TE materials in recent years. Here, an overview of the machine learning methods used in thermoelectric studies is provided, with the role that each machine learning method plays being systematically discussed. Furthermore, to date, the scale of thermoelectric‐related databases is much smaller than those in other fields, such as e‐commerce, image identification, and speech recognition. To overcome this limitation, possible strategies to utilize small databases in promoting materials science are also discussed. Finally, a brief conclusion and outlook are presented.",2019,78,67,0,False,Materials Science,,152987957,T. Wang,50445724.0,Cheng Zhang,2103629.0,H. Snoussi,145448010.0,Gang Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c489ced6b820e8609eec130a7484477ff27cfff4,https://www.semanticscholar.org/paper/c489ced6b820e8609eec130a7484477ff27cfff4,DP-ADMM: ADMM-Based Distributed Learning With Differential Privacy,"Alternating direction method of multipliers (ADMM) is a widely used tool for machine learning in distri-buted settings where a machine learning model is trained over distributed data sources through an interactive process of local computation and message passing. Such an iterative process could cause privacy concerns of data owners. The goal of this paper is to provide differential privacy for ADMM-based distributed machine learning. Prior approaches on differentially private ADMM exhibit low utility under high privacy guarantee and assume the objective functions of the learning problems to be smooth and strongly convex. To address these concerns, we propose a novel differentially private ADMM-based distributed learning algorithm called DP-ADMM, which combines an approximate augmented Lagrangian function with time-varying Gaussian noise addition in the iterative process to achieve higher utility for general objective functions under the same differential privacy guarantee. We also apply the moments accountant method to analyze the end-to-end privacy loss. The theoretical analysis shows that the DP-ADMM can be applied to a wider class of distributed learning problems, is provably convergent, and offers an explicit utility-privacy tradeoff. To our knowledge, this is the first paper to provide explicit convergence and utility properties for differentially private ADMM-based distributed learning algorithms. The evaluation results demonstrate that our approach can achieve good convergence and model accuracy under high end-to-end differential privacy guarantee.",2018,53,96,11,False,Computer Science,Mathematics,1388738367,Zonghao Huang,1471616367.0,Rui Hu,1795475.0,Yuanxiong Guo,1400755941.0,E. Chan-Tin,144010840.0,Yanmin Gong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3440ebeda19d658b91c51206be3519343663b9c1,https://www.semanticscholar.org/paper/3440ebeda19d658b91c51206be3519343663b9c1,"Personalized Multitask Learning for Predicting Tomorrow's Mood, Stress, and Health","While accurately predicting mood and wellbeing could have a number of important clinical benefits, traditional machine learning (ML) methods frequently yield low performance in this domain. We posit that this is because a one-size-fits-all machine learning model is inherently ill-suited to predicting outcomes like mood and stress, which vary greatly due to individual differences. Therefore, we employ Multitask Learning (MTL) techniques to train personalized ML models which are customized to the needs of each individual, but still leverage data from across the population. Three formulations of MTL are compared: i) MTL deep neural networks, which share several hidden layers but have final layers unique to each task; ii) Multi-task Multi-Kernel learning, which feeds information across tasks through kernel weights on feature types; and iii) a Hierarchical Bayesian model in which tasks share a common Dirichlet Process prior. We offer the code for this work in open source. These techniques are investigated in the context of predicting future mood, stress, and health using data collected from surveys, wearable sensors, smartphone logs, and the weather. Empirical results demonstrate that using MTL to account for individual differences provides large performance improvements over traditional machine learning methods and provides personalized, actionable insights.",2020,61,111,11,False,Computer Science,Medicine,144996285,Sara Taylor,3106683.0,Natasha Jaques,9259311.0,Ehimwenma Nosakhare,2804453.0,A. Sano,1719389.0,Rosalind W. Picard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
bbd0e204f48a45735e1065c8b90b298077b73192,https://www.semanticscholar.org/paper/bbd0e204f48a45735e1065c8b90b298077b73192,One-shot Learning with Memory-Augmented Neural Networks,"Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of “one-shot learning.” Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.",2016,21,478,30,False,Computer Science,,35030998,Adam Santoro,2258504.0,Sergey Bartunov,46378362.0,M. Botvinick,1688276.0,Daan Wierstra,2542999.0,T. Lillicrap,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
4d3fb523b7892e0b7a7990366e02fae46d63dcb4,https://www.semanticscholar.org/paper/4d3fb523b7892e0b7a7990366e02fae46d63dcb4,Fast Image Tagging,"Automatic image annotation is a difficult and highly relevant machine learning task. Recent advances have significantly improved the state-of-the-art in retrieval accuracy with algorithms based on nearest neighbor classification in carefully learned metric spaces. But this comes at a price of increased computational complexity during training and testing. We propose FastTag, a novel algorithm that achieves comparable results with two simple linear mappings that are co-regularized in a joint convex loss function. The loss function can be efficiently optimized in closed form updates, which allows us to incorporate a large number of image descriptors cheaply. On several standard real-world benchmark data sets, we demonstrate that FastTag matches the current state-of-the-art in tagging quality, yet reduces the training and testing times by several orders of magnitude and has lower asymptotic complexity.",2013,28,213,47,False,Mathematics,Computer Science,1743082,Minmin Chen,3001424.0,A. Zheng,7446832.0,Kilian Q. Weinberger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2ef26af206f7ebbbd90a7d68d77a7639c8dfc6b6,https://www.semanticscholar.org/paper/2ef26af206f7ebbbd90a7d68d77a7639c8dfc6b6,Comparing machines and humans on a visual categorization test,"Automated scene interpretation has benefited from advances in machine learning, and restricted tasks, such as face detection, have been solved with sufficient accuracy for restricted settings. However, the performance of machines in providing rich semantic descriptions of natural scenes from digital images remains highly limited and hugely inferior to that of humans. Here we quantify this “semantic gap” in a particular setting: We compare the efficiency of human and machine learning in assigning an image to one of two categories determined by the spatial arrangement of constituent parts. The images are not real, but the category-defining rules reflect the compositional structure of real images and the type of “reasoning” that appears to be necessary for semantic parsing. Experiments demonstrate that human subjects grasp the separating principles from a handful of examples, whereas the error rates of computer programs fluctuate wildly and remain far behind that of humans even after exposure to thousands of examples. These observations lend support to current trends in computer vision such as integrating machine learning with parts-based modeling.",2011,32,112,22,True,Computer Science,Medicine,2721983,F. Fleuret,2118549112.0,Ting Li,1720207.0,Charles Dubout,6403684.0,E. Wampler,2054882.0,S. Yantis,1707642.0,D. Geman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
846981890b81ae5d9ff5cedfcdbd99150a8bde13,https://www.semanticscholar.org/paper/846981890b81ae5d9ff5cedfcdbd99150a8bde13,Uma Introdução às Support Vector Machines,"This paper presents an introduction to the Support Vector Machines (SVMs), a Machine Learning technique that has received increasing attention in the last years. The SVMs have been applied to several pattern recognition tasks, obtaining results superior to those of other learning techniques in various applications.",2007,42,72,1,True,Computer Science,,145268980,Ana Carolina Lorena,133574843.0,A. C. P. L. F. D. Carvalho,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8aabf5ba342d37edc1ebd89ba898c70b0a4ca121,https://www.semanticscholar.org/paper/8aabf5ba342d37edc1ebd89ba898c70b0a4ca121,On the Convergence of the Concave-Convex Procedure,"The concave-convex procedure (CCCP) is a majorization-minimization algorithm that solves d.c. (difference of convex functions) programs as a sequence of convex programs. In machine learning, CCCP is extensively used in many learning algorithms like sparse support vector machines (SVMs), transductive SVMs, sparse principal component analysis, etc. Though widely used in many applications, the convergence behavior of CCCP has not gotten a lot of specific attention. Yuille and Rangarajan analyzed its convergence in their original paper, however, we believe the analysis is not complete. Although the convergence of CCCP can be derived from the convergence of the d.c. algorithm (DCA), its proof is more specialized and technical than actually required for the specific case of CCCP. In this paper, we follow a different reasoning and show how Zangwill's global convergence theory of iterative algorithms provides a natural framework to prove the convergence of CCCP, allowing a more elegant and simple proof. This underlines Zangwill's theory as a powerful and general framework to deal with the convergence issues of iterative algorithms, after also being used to prove the convergence of algorithms like expectation-maximization, generalized alternating minimization, etc. In this paper, we provide a rigorous analysis of the convergence of CCCP by addressing these questions: (i) When does CCCP find a local minimum or a stationary point of the d.c. program under consideration? (ii) When does the sequence generated by CCCP converge? We also present an open problem on the issue of local convergence of CCCP.",2009,36,418,42,False,Computer Science,,3313411,Bharath K. Sriperumbudur,1725533.0,G. Lanckriet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a8639fae55b0bbb58c7dee826ccd42a611814cb4,https://www.semanticscholar.org/paper/a8639fae55b0bbb58c7dee826ccd42a611814cb4,Current Research in Learning Design,"A 'learning design' is defined as the description of the teaching-learning process that takes place in a unit of learning (eg, a course, a lesson or any other designed learning event). The key principle in learning design is that it represents the learning activities and the support activities that are performed by different persons (learners, teachers) in the context of a unit of learning. The IMS Learning Design specification aims to represent the learning design of units of learning in a semantic, formal and machine interpretable way. Since its release in 2003 various parties have been active to develop tools, to experiment with Learning Design in practice, or to do research on the further advancement of the specification. The aim of this special issue is to provide an overview of current work in the area. This papers introduces Learning Design, analyses the different papers and provides an overview of current research in Learning Design. The major research issues are at the moment: a) the use of ontologies and semantic web principles & tools related to Learning Design; b) the use of learning design patterns; c) the development of learrning design authoring and content management systems, and d) the development of learning design players, including the issues how to use the integrated set of learning design tools in a variety of settings.",2006,46,227,14,False,Computer Science,,1747579,R. Koper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0b97e343364adf2409a666aaf35133b4b4b82740,https://www.semanticscholar.org/paper/0b97e343364adf2409a666aaf35133b4b4b82740,A geometric framework for machine learning,"Due to advances in the sciences, the ability of mankind to collect data has increased enormously in recent years. In many different areas, the research bottleneck is no longer in data collection, but rather in data interpretation. Often, the underlying processes described by the data are very complex, compounding the problem. In response, much research in computer analysis of large datasets is under way. Machine learning is one of the fields responding to the challenge of this problem. This thesis considers the interpretation of machine learning problems and techniques under a geometric model. Geometry is a useful for several reasons. It aids in visualization, allowing for alternative ways of thinking. It provides a rigorous framework for analyzing learning problems and methods. It suggests modifications to methods which can increase their usefulness and efficiency. In this thesis, geometric analysis is used to formulate and analyze two theoretical machine learning problems and to improve an existing machine learning method. A form of best-case analysis is presented which can be used to generate bounds on the number of examples needed for learning. A formal trade-off between available memory and speed of learning is established. In addition, geometry is used to generalize the decision tree method of machine learning. An algorithm for learning based on this generalization is presented, and its usefulness is demonstrated on a variety of artificial and real-world databases.",1993,0,49,9,False,Computer Science,,2059696865,David G. Heath,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18000ef9b6e02308ae299c4e1e2b3a32e951a508,https://www.semanticscholar.org/paper/18000ef9b6e02308ae299c4e1e2b3a32e951a508,Prediction of premature all-cause mortality: A prospective general population cohort study comparing machine-learning and standard epidemiological approaches,"Background Prognostic modelling using standard methods is well-established, particularly for predicting risk of single diseases. Machine-learning may offer potential to explore outcomes of even greater complexity, such as premature death. This study aimed to develop novel prediction algorithms using machine-learning, in addition to standard survival modelling, to predict premature all-cause mortality. Methods A prospective population cohort of 502,628 participants aged 40–69 years were recruited to the UK Biobank from 2006–2010 and followed-up until 2016. Participants were assessed on a range of demographic, biometric, clinical and lifestyle factors. Mortality data by ICD-10 were obtained from linkage to Office of National Statistics. Models were developed using deep learning, random forest and Cox regression. Calibration was assessed by comparing observed to predicted risks; and discrimination by area under the ‘receiver operating curve’ (AUC). Findings 14,418 deaths (2.9%) occurred over a total follow-up time of 3,508,454 person-years. A simple age and gender Cox model was the least predictive (AUC 0.689, 95% CI 0.681–0.699). A multivariate Cox regression model significantly improved discrimination by 6.2% (AUC 0.751, 95% CI 0.748–0.767). The application of machine-learning algorithms further improved discrimination by 3.2% using random forest (AUC 0.783, 95% CI 0.776–0.791) and 3.9% using deep learning (AUC 0.790, 95% CI 0.783–0.797). These ML algorithms improved discrimination by 9.4% and 10.1% respectively from a simple age and gender Cox regression model. Random forest and deep learning achieved similar levels of discrimination with no significant difference. Machine-learning algorithms were well-calibrated, while Cox regression models consistently over-predicted risk. Conclusions Machine-learning significantly improved accuracy of prediction of premature all-cause mortality in this middle-aged population, compared to standard methods. This study illustrates the value of machine-learning for risk prediction within a traditional epidemiological study design, and how this approach might be reported to assist scientific verification.",2019,38,58,0,True,Medicine,,8955394,S. Weng,145513333.0,L. Vaz,4757323.0,N. Qureshi,3428487.0,J. Kai,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
df51e3aa05047aec4646b9810236f01840f911bc,https://www.semanticscholar.org/paper/df51e3aa05047aec4646b9810236f01840f911bc,Predicting outcomes of case based legal arguments,"In this paper, we introduce IBP, an algorithm that combines reasoning with an abstract domain model and case-based reasoning techniques to predict the outcome of case-based legal arguments. Unlike the predictions generated by statistical or machine-learning techniques, IBP's predictions are accompanied by explanations.We describe an empirical evaluation of IBP, in which we compare our algorithm to prediction based on Hypo's and CATO's relevance criteria, and to a number of widely used machine learning algorithms. IBP reaches higher accuracy than all competitors, and hypothesis testing shows that the observed differences are statistically significant. An ablation study indicates that both sources of knowledge in IBP contribute to the accuracy of its predictions.",2003,25,117,21,False,Computer Science,,2001479,Stefanie Brüninghaus,1770311.0,Kevin D. Ashley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e3b74d8b51cf67e07d754718d040c51c580f7db6,https://www.semanticscholar.org/paper/e3b74d8b51cf67e07d754718d040c51c580f7db6,Machine learning for the solution of the Schrödinger equation,"Machine learning (ML) methods have recently been increasingly widely used in quantum chemistry. While ML methods are now accepted as high accuracy approaches to construct interatomic potentials for applications, the use of ML to solve the Schrödinger equation, either vibrational or electronic, while not new, is only now making significant headway towards applications. We survey recent uses of ML techniques to solve the Schrödinger equation, including the vibrational Schrödinger equation, the electronic Schrödinger equation and the related problems of constructing functionals for density functional theory (DFT) as well as potentials which enter semi-empirical approximations to DFT. We highlight similarities and differences and specific difficulties that ML faces in these applications and possibilities for cross-fertilization of ideas.",2020,161,41,0,False,Computer Science,Physics,2971347,S. Manzhos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics
