paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,fieldsOfStudy/1,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,fieldsOfStudy/2,fieldsOfStudy/3,authors/16/authorId,authors/16/name
955fe2ee26d888ae22749b0853981b8b581b133d,https://www.semanticscholar.org/paper/955fe2ee26d888ae22749b0853981b8b581b133d,Holographic Embeddings of Knowledge Graphs,"Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.",2015,35,832,147,True,Computer Science,Mathematics,1729762,Maximilian Nickel,1690976.0,L. Rosasco,1685292.0,T. Poggio,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6d0bd45930fcbdc64f826ae210980dfb6e0b8636,https://www.semanticscholar.org/paper/6d0bd45930fcbdc64f826ae210980dfb6e0b8636,Making Machine Learning Models Clinically Useful.,"Recent advances in supervised machine learning have improved diagnostic accuracy and prediction of treatment outcomes, in some cases surpassing the performance of clinicians.1 In supervised machine learning, a mathematical function is constructed via automated analysis of training data, which consists of input features (such as retinal images) and output labels (such as the grade of macular edema). With large training data sets and minimal human guidance, a computer learns to generalize from the information contained in the training data. The result is a mathematical function, a model, that can be used to map a new record to the corresponding diagnosis, such as an image to grade macular edema. Although machine learning–based models for classification or for predicting a future health state are being developed for diverse clinical applications, evidence is lacking that deployment of these models has improved care and patient outcomes.2 One barrier to demonstrating such improvement is the basis used to assess the performance of a model. Current approaches gauge performance by quantifying how closely the diagnosis or prediction made by the model matches known diagnoses or health outcomes. Quantifications include sensitivity, specificity, and positive predictive value, as well as measures such as the",2019,7,128,2,False,Medicine,,143665076,N. Shah,46802048.0,A. Milstein,151491825.0,Steven C Bagley PhD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d988c0ff9b6f023fa01c8f96f7218a30ca085de6,https://www.semanticscholar.org/paper/d988c0ff9b6f023fa01c8f96f7218a30ca085de6,Socially guided machine learning,"Social interaction will be key to enabling robots and machines in general to learn new tasks from ordinary people (not experts in robotics or machine learning). Everyday people who need to teach their machines new things will find it natural for to rely on their interpersonal interaction skills. This thesis provides several contributions towards the understanding of this Socially Guided Machine Learning scenario. While the topic of human input to machine learning algorithms has been explored to some extent, prior works have not gone far enough to understand what people will try to communicate when teaching a machine and how algorithms and learning systems can be modified to better accommodate a human partner. Interface techniques have been based on intuition and assumptions rather than grounded in human behavior, and often techniques are not demonstrated or evaluated with everyday people. Using a computer game, Sophie's Kitchen, an experiment with human subjects provides several insights about how people approach the task of teaching a machine. In particular, people want to direct and guide an agent's exploration process, they quickly use the behavior of the agent to infer a mental model of the learning process, and they utilize positive and negative feedback in asymmetric ways. Using a robotic platform, Leonardo, and 200 people in follow-up studies of modified versions of the Sophie's Kitchen game, four research themes are developed. The use of human guidance in a machine learning exploration can be successfully incorporated to improve learning performance. Novel learning approaches demonstrate aspects of goal-oriented learning. The transparency of the machine learner can have significant effects on the nature of the instruction received from the human teacher, which in turn positively impacts the learning process. Utilizing asymmetric interpretations of positive and negative feedback from a human partner, can result in a more efficient and robust learning experience. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)",2006,107,74,4,False,Engineering,,1682788,A. Thomaz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a456265138c088a894301c0433dae938705a9bec,https://www.semanticscholar.org/paper/a456265138c088a894301c0433dae938705a9bec,Deep Sets,"We study the problem of designing models for machine learning tasks defined on sets. In contrast to the traditional approach of operating on fixed dimensional vectors, we consider objective functions defined on sets and are invariant to permutations. Such problems are widespread, ranging from the estimation of population statistics, to anomaly detection in piezometer data of embankment dams, to cosmology. Our main theorem characterizes the permutation invariant objective functions and provides a family of functions to which any permutation invariant objective function must belong. This family of functions has a special structure which enables us to design a deep network architecture that can operate on sets and which can be deployed on a variety of scenarios including both unsupervised and supervised learning tasks. We demonstrate the applicability of our method on population statistic estimation, point cloud classification, set expansion, and outlier detection.",2017,63,1322,167,False,Computer Science,Mathematics,1771307,M. Zaheer,2150275.0,Satwik Kottur,2111187.0,Siamak Ravanbakhsh,1719347.0,B. Póczos,145124475.0,R. Salakhutdinov,46234526.0,Alex Smola,,,,,,,,,,,,,,,,,,,,,,,,
bf864fa6c4ce7fba5e9be1ed61d514ce67bb9346,https://www.semanticscholar.org/paper/bf864fa6c4ce7fba5e9be1ed61d514ce67bb9346,Machine learning for precise quantum measurement.,"Adaptive feedback schemes are promising for quantum-enhanced measurements yet are complicated to design. Machine learning can autonomously generate algorithms in a classical setting. Here we adapt machine learning for quantum information and use our framework to generate autonomous adaptive feedback schemes for quantum measurement. In particular, our approach replaces guesswork in quantum measurement by a logical, fully automatic, programable routine. We show that our method yields schemes that outperform the best known adaptive scheme for interferometric phase estimation.",2009,25,139,3,True,Physics,Medicine,1878626,A. Hentschel,34655154.0,B. Sanders,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science,,,
30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70,https://www.semanticscholar.org/paper/30e0ffeb519a4df2d4a2067e899c5fb5c5e85e70,Exploiting Unintended Feature Leakage in Collaborative Learning,"Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates. We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points -- for example, specific locations -- in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier. We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses.",2018,70,724,74,True,Computer Science,,145557680,Luca Melis,3469125.0,Congzheng Song,1728207.0,Emiliano De Cristofaro,1723945.0,Vitaly Shmatikov,,,,,,,,,,,,,,,,,,,,,,,,,,,,
180a03aa6f09e2b06417b86e8f1828861633bd37,https://www.semanticscholar.org/paper/180a03aa6f09e2b06417b86e8f1828861633bd37,Privacy-preserving Machine Learning as a Service,"Abstract Machine learning algorithms based on deep Neural Networks (NN) have achieved remarkable results and are being extensively used in different domains. On the other hand, with increasing growth of cloud services, several Machine Learning as a Service (MLaaS) are offered where training and deploying machine learning models are performed on cloud providers’ infrastructure. However, machine learning algorithms require access to the raw data which is often privacy sensitive and can create potential security and privacy risks. To address this issue, we present CryptoDL, a framework that develops new techniques to provide solutions for applying deep neural network algorithms to encrypted data. In this paper, we provide the theoretical foundation for implementing deep neural network algorithms in encrypted domain and develop techniques to adopt neural networks within practical limitations of current homomorphic encryption schemes. We show that it is feasible and practical to train neural networks using encrypted data and to make encrypted predictions, and also return the predictions in an encrypted form. We demonstrate applicability of the proposed CryptoDL using a large number of datasets and evaluate its performance. The empirical results show that it provides accurate privacy-preserving training and classification.",2018,44,136,6,True,Computer Science,,2599072,Ehsan Hesamifard,1718305.0,H. Takabi,2053305594.0,Mehdi Ghasemi,1701402.0,Rebecca N. Wright,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d1d8980d04d411c314910d1926f3bbaac46c2197,https://www.semanticscholar.org/paper/d1d8980d04d411c314910d1926f3bbaac46c2197,DeepMIMO: A Generic Deep Learning Dataset for Millimeter Wave and Massive MIMO Applications,"Machine learning tools are finding interesting applications in millimeter wave (mmWave) and massive MIMO systems. This is mainly thanks to their powerful capabilities in learning unknown models and tackling hard optimization problems. To advance the machine learning research in mmWave/massive MIMO, however, there is a need for a common dataset. This dataset can be used to evaluate the developed algorithms, reproduce the results, set benchmarks, and compare the different solutions. In this work, we introduce the DeepMIMO dataset, which is a generic dataset for mmWave/massive MIMO channels. The DeepMIMO dataset generation framework has two important features. First, the DeepMIMO channels are constructed based on accurate ray-tracing data obtained from Remcom Wireless InSite. The DeepMIMO channels, therefore, capture the dependence on the environment geometry/materials and transmitter/receiver locations, which is essential for several machine learning applications. Second, the DeepMIMO dataset is generic/parameterized as the researcher can adjust a set of system and channel parameters to tailor the generated DeepMIMO dataset for the target machine learning application. The DeepMIMO dataset can then be completely defined by the (i) the adopted ray-tracing scenario and (ii) the set of parameters, which enables the accurate definition and reproduction of the dataset. In this paper, an example DeepMIMO dataset is described based on an outdoor ray-tracing scenario of 18 base stations and more than one million users. The paper also shows how this dataset can be used in an example deep learning application of mmWave beam prediction.",2019,21,182,24,False,Computer Science,Engineering,145719185,A. Alkhateeb,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mathematics,,,
412b230127c05dbeab72b9d9c8f6bc9c55d566f7,https://www.semanticscholar.org/paper/412b230127c05dbeab72b9d9c8f6bc9c55d566f7,The Mortality and Medical Costs of Air Pollution: Evidence from Changes in Wind Direction,"We estimate the causal effects of acute fine particulate matter exposure on mortality, health care use, and medical costs among the US elderly using Medicare data. We instrument for air pollution using changes in local wind direction and develop a new approach that uses machine learning to estimate the life-years lost due to pollution exposure. Finally, we characterize treatment effect heterogeneity using both life expectancy and generic machine learning inference. Both approaches find that mortality effects are concentrated in about 25 percent of the elderly population.",2016,111,277,51,True,Geography,Medicine,4292991,T. Deryugina,66372515.0,Garth Heutel,2099940622.0,Nolan H. Miller,40051475.0,D. Molitor,39573999.0,J. Reif,,,,,,,,,,,,,,,,,,,,,,,,,,
3e317d0a505535bc2ae045b587ac2a9492ddc86f,https://www.semanticscholar.org/paper/3e317d0a505535bc2ae045b587ac2a9492ddc86f,On the Use of Stochastic Hessian Information in Optimization Methods for Machine Learning,"This paper describes how to incorporate sampled curvature information in a Newton-CG method and in a limited memory quasi-Newton method for statistical learning. The motivation for this work stems from supervised machine learning applications involving a very large number of training points. We follow a batch approach, also known in the stochastic optimization literature as a sample average approximation approach. Curvature information is incorporated in two subsampled Hessian algorithms, one based on a matrix-free inexact Newton iteration and one on a preconditioned limited memory BFGS iteration. A crucial feature of our technique is that Hessian-vector multiplications are carried out with a significantly smaller sample size than is used for the function and gradient. The efficiency of the proposed methods is illustrated using a machine learning application involving speech recognition.",2011,26,247,18,True,Mathematics,Computer Science,144448267,R. Byrd,2302020.0,Gillian M. Chin,2471268.0,Will Neveitt,2784955.0,J. Nocedal,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21faf54f062bb3061885e407539ce43e7ce19156,https://www.semanticscholar.org/paper/21faf54f062bb3061885e407539ce43e7ce19156,Anticipating Cryptocurrency Prices Using Machine Learning,"Machine learning and AI-assisted trading have attracted growing interest for the past few years. Here, we use this approach to test the hypothesis that the inefficiency of the cryptocurrency market can be exploited to generate abnormal profits. We analyse daily data for 1,681 cryptocurrencies for the period between Nov. 2015 and Apr. 2018. We show that simple trading strategies assisted by state-of-the-art machine learning algorithms outperform standard benchmarks. Our results show that nontrivial, but ultimately simple, algorithmic mechanisms can help anticipate the short-term evolution of the cryptocurrency market.",2018,98,133,3,False,Computer Science,Physics,2818774,Laura Alessandretti,70058324.0,Abeer ElBahrawy,2905635.0,L. Aiello,2836702.0,A. Baronchelli,,,,,,,,,,,,,,,,,,,,,,,,,Economics,,,
7a6121c4ac99b0d21aa20424df4390a38537c063,https://www.semanticscholar.org/paper/7a6121c4ac99b0d21aa20424df4390a38537c063,Machine learning with operational costs,"This work proposes a way to align statistical modeling with decision making. We provide a method that propagates the uncertainty in predictive modeling to the uncertainty in operational cost, where operational cost is the amount spent by the practitioner in solving the problem. The method allows us to explore the range of operational costs associated with the set of reasonable statistical models, so as to provide a useful way for practitioners to understand uncertainty. To do this, the operational cost is cast as a regularization term in a learning algorithm's objective function, allowing either an optimistic or pessimistic view of possible costs, depending on the regularization parameter. From another perspective, if we have prior knowledge about the operational cost, for instance that it should be low, this knowledge can help to restrict the hypothesis space, and can help with generalization. We provide a theoretical generalization bound for this scenario. We also show that learning with operational costs is related to robust optimization.",2011,51,49,3,False,Computer Science,Mathematics,1782469,Theja Tulabandhula,48395540.0,C. Rudin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8a5d0579590465494c9aba58a857af43b190b6a6,https://www.semanticscholar.org/paper/8a5d0579590465494c9aba58a857af43b190b6a6,Deep Learning in Mobile and Wireless Networking: A Survey,"The rapid uptake of mobile devices and the rising popularity of mobile applications and services pose unprecedented demands on mobile and wireless networking infrastructure. Upcoming 5G systems are evolving to support exploding mobile traffic volumes, real-time extraction of fine-grained analytics, and agile management of network resources, so as to maximize user experience. Fulfilling these tasks is challenging, as mobile environments are increasingly complex, heterogeneous, and evolving. One potential solution is to resort to advanced machine learning techniques, in order to help manage the rise in data volumes and algorithm-driven applications. The recent success of deep learning underpins new and powerful tools that tackle problems in this space. In this paper, we bridge the gap between deep learning and mobile and wireless networking research, by presenting a comprehensive survey of the crossovers between the two areas. We first briefly introduce essential background and state-of-the-art in deep learning techniques with potential applications to networking. We then discuss several techniques and platforms that facilitate the efficient deployment of deep learning onto mobile systems. Subsequently, we provide an encyclopedic review of mobile and wireless networking research based on deep learning, which we categorize by different domains. Drawing from our experience, we discuss how to tailor deep learning to mobile environments. We complete this survey by pinpointing current challenges and open future directions for research.",2018,588,880,52,True,Computer Science,,3194878,Chaoyun Zhang,144555592.0,P. Patras,1763096.0,H. Haddadi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93aa063d330ed7509f55b1297138cf20300fb969,https://www.semanticscholar.org/paper/93aa063d330ed7509f55b1297138cf20300fb969,Kernels for Vector-Valued Functions: a Review,"Kernel methods are among the most popular techniques in machine learning. From a regularization perspective they play a central role in regularization theory as they provide a natural choice for the hypotheses space and the regularization functional through the notion of reproducing kernel Hilbert spaces. From a probabilistic perspective they are the key in the context of Gaussian processes, where the kernel function is known as the covariance function. Traditionally, kernel methods have been used in supervised learning problems with scalar outputs and indeed there has been a considerable amount of work devoted to designing and learning kernels. More recently there has been an increasing interest in methods that deal with multiple outputs, motivated partially by frameworks like multitask learning. In this monograph, we review different methods to design or learn valid kernel functions for multiple outputs, paying particular attention to the connection between probabilistic and functional methods.",2011,115,619,71,True,Computer Science,Mathematics,144491954,Mauricio A Álvarez,1690976.0,L. Rosasco,145306271.0,Neil D. Lawrence,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2521c3d76bc439c961b7003080f4a7a661949547,https://www.semanticscholar.org/paper/2521c3d76bc439c961b7003080f4a7a661949547,Causal Protein-Signaling Networks Derived from Multiparameter Single-Cell Data,"Machine learning was applied for the automated derivation of causal influences in cellular signaling networks. This derivation relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells. Perturbing these cells with molecular interventions drove the ordering of connections between pathway components, wherein Bayesian network computational methods automatically elucidated most of the traditionally reported signaling relationships and predicted novel interpathway network causalities, which we verified experimentally. Reconstruction of network models from physiologically relevant primary single cells might be applied to understanding native-state tissue signaling biology, complex drug actions, and dysfunctional signaling in diseased cells.",2005,42,1584,182,False,Biology,Medicine,46599630,K. Sachs,3289622.0,O. Perez,1397424343.0,D. Pe’er,1761370.0,D. Lauffenburger,1857137.0,G. Nolan,,,,,,,,,,,,,,,,,,,,,,,,,,
44f4b1b90f8d5515f2486e07e4cb4b9589c27518,https://www.semanticscholar.org/paper/44f4b1b90f8d5515f2486e07e4cb4b9589c27518,Deep Learning and Its Applications to Machine Health Monitoring: A Survey,"Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). Finally, some new trends of DL-based machine health monitoring methods are discussed.",2016,112,142,4,False,Computer Science,Mathematics,49832912,Rui Zhao,35374692.0,Ruqiang Yan,48354147.0,Zhenghua Chen,144067957.0,K. Mao,48319740.0,Peng Wang,1700762.0,R. Gao,,,,,,,,,,,,,,,,,,,,,,,,
a486e2839291111bb44fa1f07731ada123539f75,https://www.semanticscholar.org/paper/a486e2839291111bb44fa1f07731ada123539f75,Google’s Multilingual Neural Machine Translation System: Enabling Zero-Shot Translation,"We propose a simple solution to use a single Neural Machine Translation (NMT) model to translate between multiple languages. Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language. Using a shared wordpiece vocabulary, our approach enables Multilingual NMT systems using a single model. On the WMT’14 benchmarks, a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German. Similarly, a single multilingual model surpasses state-of-the-art results for French→English and German→English on WMT’14 and WMT’15 benchmarks, respectively. On production corpora, multilingual models of up to twelve language pairs allow for better translation of many individual pairs. Our models can also learn to perform implicit bridging between language pairs never seen explicitly during training, showing that transfer learning and zero-shot translation is possible for neural translation. Finally, we show analyses that hints at a universal interlingua representation in our models and also show some interesting examples when mixing languages.",2016,35,1571,193,True,Computer Science,,145657834,Melvin Johnson,144927151.0,M. Schuster,2827616.0,Quoc V. Le,2048712.0,M. Krikun,48607963.0,Yonghui Wu,2545358.0,Z. Chen,144203200.0,Nikhil Thorat,1765169.0,F. Viégas,145233583.0,M. Wattenberg,32131713.0,G. Corrado,48342565.0,Macduff Hughes,49959210.0,J. Dean,,,,,,,,,,,,
d56fb220b4995272d830fe115a2eedd54448d1c3,https://www.semanticscholar.org/paper/d56fb220b4995272d830fe115a2eedd54448d1c3,A Performance and Cost Assessment of Machine Learning Interatomic Potentials.,"Machine learning of the quantitative relationship between local environment descriptors and the potential energy surface of a system of atoms has emerged as a new frontier in the development of interatomic potentials (IAPs). Here, we present a comprehensive evaluation of ML-IAPs based on four local environment descriptors --- atom-centered symmetry functions (ACSF), smooth overlap of atomic positions (SOAP), the Spectral Neighbor Analysis Potential (SNAP) bispectrum components, and moment tensors --- using a diverse data set generated using high-throughput density functional theory (DFT) calculations. The data set comprising bcc (Li, Mo) and fcc (Cu, Ni) metals and diamond group IV semiconductors (Si, Ge) is chosen to span a range of crystal structures and bonding. All descriptors studied show excellent performance in predicting energies and forces far surpassing that of classical IAPs, as well as predicting properties such as elastic constants and phonon dispersion curves. We observe a general trade-off between accuracy and the degrees of freedom of each model, and consequently computational cost. We will discuss these trade-offs in the context of model selection for molecular dynamics and other applications.",2019,130,262,6,True,Physics,Medicine,11844524,Yunxing Zuo,143915066.0,Chi Chen,2108568792.0,Xiang-Guo Li,98796862.0,Z. Deng,2109366932.0,Yiming Chen,144136091.0,J. Behler,2559761.0,Gábor Csányi,2810901.0,A. Shapeev,144056220.0,A. Thompson,47817335.0,M. Wood,2381325.0,S. Ong,,,,,,,,,,,Mathematics,Chemistry,,
0ea2f1f5c470c4947b48bbd21245fb327282f3b4,https://www.semanticscholar.org/paper/0ea2f1f5c470c4947b48bbd21245fb327282f3b4,Stock market's price movement prediction with LSTM neural networks,"Predictions on stock market prices are a great challenge due to the fact that it is an immensely complex, chaotic and dynamic environment. There are many studies from various areas aiming to take on that challenge and Machine Learning approaches have been the focus of many of them. There are many examples of Machine Learning algorithms been able to reach satisfactory results when doing that type of prediction. This article studies the usage of LSTM networks on that scenario, to predict future trends of stock prices based on the price history, alongside with technical analysis indicators. For that goal, a prediction model was built, and a series of experiments were executed and theirs results analyzed against a number of metrics to assess if this type of algorithm presents and improvements when compared to other Machine Learning methods and investment strategies. The results that were obtained are promising, getting up to an average of 55.9% of accuracy when predicting if the price of a particular stock is going to go up or not in the near future.",2017,21,398,23,False,Computer Science,,2112887403,David M. Q. Nelson,38964525.0,Adriano M. Pereira,153714464.0,Renato A. de Oliveira,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c2f4c6d7e06da14c4b3ce3a9b97394a64708dc52,https://www.semanticscholar.org/paper/c2f4c6d7e06da14c4b3ce3a9b97394a64708dc52,Database Dependency Discovery: A Machine Learning Approach,"Database dependencies, such as functional and multivalued dependencies, express the presence of structure in database relations, that can be utilised in the database design process. The discovery of database dependencies can be viewed as an induction problem, in which general rules (dependencies) are obtained from specific facts (the relation). This viewpoint has the advantage of abstracting away as much as possible from the particulars of the dependencies. The algorithms in this paper are designed such that they can easily be generalised to other kinds of dependencies.Like in current approaches to computational induction such as inductive logic programming, we distinguish between top-down algorithms and bottom-up algorithms. In a top-down approach, hypotheses are generated in a systematic way and then tested against the given relation. In a bottom-up approach, the relation is inspected in order to see what dependencies it may satisfy or violate. We give a simple (but inefficient) top-down algorithm, a bi-directional algorithm, and a bottom-up algorithm. In the case of functional dependencies, these algorithms have been implemented in the FDEP system and evaluated experimentally. The bottom-up algorithm is the most efficient of the three, and also outperforms other algorithms from the literature.",1999,34,185,26,False,Computer Science,,47840704,Peter A. Flach,2263707.0,Iztok Savnik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
821e3d348ea9761d5dcf6470235b7a73931d84cd,https://www.semanticscholar.org/paper/821e3d348ea9761d5dcf6470235b7a73931d84cd,Chinese Word Segmentation as Character Tagging,"In this paper we report results of a supervised machine-learning approach to Chinese word segmentation. A maximum entropy tagger is trained on manually annotated data to automatically assign to Chinese characters, or hanzi, tags that indicate the position of a hanzi within a word. The tagged output is then converted into segmented text for evaluation. Preliminary results show that this approach is competitive against other supervised machine-learning segmenters reported in previous studies, achieving precision and recall rates of 95.01% and 94.94% respectively, trained on a 237K-word training set.",2003,31,276,18,False,Computer Science,,3432785,Nianwen Xu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d17a3e9f34125ba6454e365ffe403ce8a91f2632,https://www.semanticscholar.org/paper/d17a3e9f34125ba6454e365ffe403ce8a91f2632,SGD and Hogwild! Convergence Without the Bounded Gradients Assumption,"Stochastic gradient descent (SGD) is the optimization algorithm of choice in many machine learning applications such as regularized empirical risk minimization and training deep neural networks. The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is always violated for cases where the objective function is strongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. Here we show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime, which results in more relaxed conditions than those in (Bottou et al.,2016). We then move on the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime, obtaining the first convergence results for this method in the case of diminished learning rate.",2018,24,144,10,False,Mathematics,Computer Science,144274166,Lam M. Nguyen,143671628.0,Phuong Ha Nguyen,144534186.0,Marten van Dijk,2662221.0,Peter Richtárik,2005127.0,K. Scheinberg,144696183.0,Martin Takác,,,,,,,,,,,,,,,,,,,,,,,,
6a61b4967c161347525abc3ab5dba590c0cd99ca,https://www.semanticscholar.org/paper/6a61b4967c161347525abc3ab5dba590c0cd99ca,Analysis of function of rectified linear unit used in deep learning,"Deep Learning is attracting much attention in object recognition and speech processing. A benefit of using the deep learning is that it provides automatic pre-training. Several proposed methods that include auto-encoder are being successfully used in various applications. Moreover, deep learning uses a multilayer network that consists of many layers, a huge number of units, and huge amount of data. Thus, executing deep learning requires heavy computation, so deep learning is usually utilized with parallel computation with many cores or many machines. Deep learning employs the gradient algorithm, however this traps the learning into the saddle point or local minima. To avoid this difficulty, a rectified linear unit (ReLU) is proposed to speed up the learning convergence. However, the reasons the convergence is speeded up are not well understood. In this paper, we analyze the ReLU by a using simpler network called the soft-committee machine and clarify the reason for the speedup. We also train the network in an on-line manner. The soft-committee machine provides a good test bed to analyze deep learning. The results provide some reasons for the speedup of the convergence of the deep learning.",2015,18,209,8,False,Computer Science,,3217681,K. Hara,34282232.0,D. Saitoh,144548336.0,Hayaru Shouno,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aea2d6337264545a3da2ed5958845d6b622d176f,https://www.semanticscholar.org/paper/aea2d6337264545a3da2ed5958845d6b622d176f,Prognosis of Bearing Acoustic Emission Signals Using Supervised Machine Learning,"Acoustic emission (AE) technique can be successfully utilized for condition monitoring of various machining and industrial processes. To keep machines function at optimal levels, fault prognosis model to predict the remaining useful life (RUL) of machine components is required. This model is used to analyze the output signals of a machine whilst in operation and accordingly helps to set an early alarm tool that reduces the untimely replacement of components and the wasteful machine downtime. Recent improvements indicate the drive on the way towards incorporation of prognosis and diagnosis machine learning techniques in future machine health management systems. With this in mind, this work employs three supervised machine learning techniques; support vector machine regression, multilayer artificial neural network model and gaussian process regression, to correlate AE features with corresponding natural wear of slow speed bearings throughout series of laboratory experiments. Analysis of signal parameters such as signal intensity estimator and root mean square was undertaken to discriminate individual types of early damage. It was concluded that neural networks model with back propagation learning algorithm has an advantage over the other models in estimating the RUL for slow speed bearings if the proper network structure is chosen and sufficient data is provided.",2018,27,128,2,True,Computer Science,,30988326,M. Elforjani,31380622.0,Suliman Shanbr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8f54b85fcd5074482a74f32a96e808b5be3a9da7,https://www.semanticscholar.org/paper/8f54b85fcd5074482a74f32a96e808b5be3a9da7,Towards energy-aware scheduling in data centers using machine learning,"As energy-related costs have become a major economical factor for IT infrastructures and data-centers, companies and the research community are being challenged to find better and more efficient power-aware resource management strategies. There is a growing interest in ""Green"" IT and there is still a big gap in this area to be covered.
 In order to obtain an energy-efficient data center, we propose a framework that provides an intelligent consolidation methodology using different techniques such as turning on/off machines, power-aware consolidation algorithms, and machine learning techniques to deal with uncertain information while maximizing performance. For the machine learning approach, we use models learned from previous system behaviors in order to predict power consumption levels, CPU loads, and SLA timings, and improve scheduling decisions. Our framework is vertical, because it considers from watt consumption to workload features, and cross-disciplinary, as it uses a wide variety of techniques.
 We evaluate these techniques with a framework that covers the whole control cycle of a real scenario, using a simulation with representative heterogeneous workloads, and we measure the quality of the results according to a set of metrics focused toward our goals, besides traditional policies. The results obtained indicate that our approach is close to the optimal placement and behaves better when the level of uncertainty increases.",2010,34,256,9,True,Computer Science,,2658652,Josep Lluís Berral,2495308.0,Íñigo Goiri,2526886.0,Ramon Nou,144322760.0,F. Julià,143814317.0,Jordi Guitart,1745702.0,Ricard Gavaldà,144345280.0,J. Torres,,,,,,,,,,,,,,,,,,,,,,
5f54adfd6d6959e0c9ae8953ac00ea675087085f,https://www.semanticscholar.org/paper/5f54adfd6d6959e0c9ae8953ac00ea675087085f,Named Entity Extraction using AdaBoost,"This paper presents a Named Entity Extraction (NEE) system for the CoNLL 2002 competition. The two main sub-tasks of the problem, recognition (NER) and classification (NEC), are performed sequentially and independently with separate modules. Both modules are machine learning based systems, which make use of binary AdaBoost classifiers.",2002,5,198,18,True,Computer Science,,1701734,X. Carreras,3049328.0,Lluís Màrquez i Villodre,1778523.0,Lluís Padró,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9c9ba700f9871a41cfc007658c9ff24f84dc4dcb,https://www.semanticscholar.org/paper/9c9ba700f9871a41cfc007658c9ff24f84dc4dcb,Deep Learning with Topological Signatures,"Inferring topological and geometrical information from data can offer an alternative perspective on machine learning problems. Methods from topological data analysis, e.g., persistent homology, enable us to obtain such information, typically in the form of summary representations of topological features. However, such topological signatures often come with an unusual structure (e.g., multisets of intervals) that is highly impractical for most machine learning techniques. While many strategies have been proposed to map these topological signatures into machine learning compatible representations, they suffer from being agnostic to the target learning task. In contrast, we propose a technique that enables us to input topological signatures to deep neural networks and learn a task-optimal representation during training. Our approach is realized as a novel input layer with favorable theoretical properties. Classification experiments on 2D object shapes and social network graphs demonstrate the versatility of the approach and, in case of the latter, we even outperform the state-of-the-art by a large margin.",2017,32,170,20,False,Computer Science,Mathematics,2059648771,Christoph Hofer,2132917.0,R. Kwitt,1695046.0,M. Niethammer,30134366.0,A. Uhl,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8529c088924433f2c80c77bc2346129ab75db081,https://www.semanticscholar.org/paper/8529c088924433f2c80c77bc2346129ab75db081,Selective Transfer Machine for Personalized Facial Expression Analysis,"Automatic facial action unit (AU) and expression detection from videos is a long-standing problem. The problem is challenging in part because classifiers must generalize to previously unknown subjects that differ markedly in behavior and facial morphology (e.g., heavy versus delicate brows, smooth versus deeply etched wrinkles) from those on which the classifiers are trained. While some progress has been achieved through improvements in choices of features and classifiers, the challenge occasioned by individual differences among people remains. Person-specific classifiers would be a possible solution but for a paucity of training data. Sufficient training data for person-specific classifiers typically is unavailable. This paper addresses the problem of how to <italic>personalize</italic> a generic classifier without additional labels from the test subject. We propose a transductive learning method, which we refer to as a Selective Transfer Machine (STM), to personalize a generic classifier by attenuating person-specific mismatches. STM achieves this effect by simultaneously learning a classifier and re-weighting the training samples that are most relevant to the test subject. We compared STM to both generic classifiers and cross-domain learning methods on four benchmarks: CK+ <xref ref-type=""bibr"" rid=""ref44"">[44]</xref> , GEMEP-FERA <xref ref-type=""bibr"" rid=""ref67"">[67]</xref> , RU-FACS <xref ref-type=""bibr"" rid=""ref4"">[4]</xref> and GFT <xref ref-type=""bibr"" rid=""ref57"">[57]</xref> . STM outperformed generic classifiers in all.",2017,94,155,18,False,Computer Science,Medicine,39336289,Wen-Sheng Chu,143867160.0,F. D. L. Torre,1737918.0,J. Cohn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a43d7b8e5e1bcb7c3fbf82164cfc9d12737176e8,https://www.semanticscholar.org/paper/a43d7b8e5e1bcb7c3fbf82164cfc9d12737176e8,Task Clustering and Gating for Bayesian Multitask Learning,"Modeling a collection of similar regression or classification tasks can be improved by making the tasks 'learn from each other'. In machine learning, this subject is approached through 'multitask learning', where parallel tasks are modeled as multiple outputs of the same network. In multilevel analysis this is generally implemented through the mixed-effects linear model where a distinction is made between 'fixed effects', which are the same for all tasks, and 'random effects', which may vary between tasks. In the present article we will adopt a Bayesian approach in which some of the model parameters are shared (the same for all tasks) and others more loosely connected through a joint prior distribution that can be learned from the data. We seek in this way to combine the best parts of both the statistical multilevel approach and the neural network machinery. The standard assumption expressed in both approaches is that each task can learn equally well from any other task. In this article we extend the model by allowing more differentiation in the similarities between tasks. One such extension is to make the prior mean depend on higher-level task characteristics. More unsupervised clustering of tasks is obtained if we go from a single Gaussian prior to a mixture of Gaussians. This can be further generalized to a mixture of experts architecture with the gates depending on task characteristics. All three extensions are demonstrated through application both on an artificial data set and on two real-world problems, one a school problem and the other involving single-copy newspaper sales.",2003,27,612,44,False,Computer Science,,143626983,B. Bakker,1790356.0,T. Heskes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c529f5b08675f787cdcc094ee495239592339f82,https://www.semanticscholar.org/paper/c529f5b08675f787cdcc094ee495239592339f82,Learning to Simulate Complex Physics with Graph Networks,"Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term ""Graph Network-based Simulators"" (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.",2020,42,422,32,False,Computer Science,Physics,1398105826,Alvaro Sanchez-Gonzalez,2069002234.0,Jonathan Godwin,2054956.0,T. Pfaff,83539859.0,Rex Ying,1702139.0,J. Leskovec,2019153.0,P. Battaglia,,,,,,,,,,,,,,,,,,,,,Mathematics,,,
4601c715a8042543e88a0bd63095ae6d6a6a6faa,https://www.semanticscholar.org/paper/4601c715a8042543e88a0bd63095ae6d6a6a6faa,Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence Algorithms,"With the reinvigoration of neural networks in the 2000s, deep learning has become an extremely active area of research, one thats paving the way for modern machine learning. In this practical book, author Nikhil Buduma provides examples and clear explanations to guide you through major concepts of this complicated field. Companies such as Google, Microsoft, and Facebook are actively growing in-house deep-learning teams. For the rest of us, however, deep learning is still a pretty complex and difficult subject to grasp. If youre familiar with Python, and have a background in calculus, along with a basic understanding of machine learning, this book will get you started. Examine the foundations of machine learning and neural networks Learn how to train feed-forward neural networks Use Tensor Flow to implement your first neural network Manage problems that arise as you begin to make networks deeper Build neural networks that analyze complex images Perform effective dimensionality reduction using autoencoders Dive deep into sequence analysis to examine language Understand the fundamentals of reinforcement learning",2017,0,168,15,False,Computer Science,,90635111,Nikhil Buduma,36278644.0,N. Locascio,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9239696d0dc5b029e0946e4b84a1515cb31d2e6b,https://www.semanticscholar.org/paper/9239696d0dc5b029e0946e4b84a1515cb31d2e6b,Learning from Distributions via Support Measure Machines,"This paper presents a kernel-based discriminative learning framework on probability measures. Rather than relying on large collections of vectorial training examples, our framework learns using a collection of probability distributions that have been constructed to meaningfully represent training data. By representing these probability distributions as mean embeddings in the reproducing kernel Hilbert space (RKHS), we are able to apply many standard kernel-based learning techniques in straightforward fashion. To accomplish this, we construct a generalization of the support vector machine (SVM) called a support measure machine (SMM). Our analyses of SMMs provides several insights into their relationship to traditional SVMs. Based on such insights, we propose a flexible SVM (Flex-SVM) that places different kernel functions on each training example. Experimental results on both synthetic and real-world data demonstrate the effectiveness of our proposed framework.",2012,21,176,20,False,Mathematics,Computer Science,2276351,Krikamol Muandet,1693668.0,K. Fukumizu,3125402.0,Francesco Dinuzzo,1707625.0,B. Schölkopf,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a6bf288da1c2cdfc31004e44daaa1344aa50ebfb,https://www.semanticscholar.org/paper/a6bf288da1c2cdfc31004e44daaa1344aa50ebfb,Kernel techniques: From machine learning to meshless methods,"Kernels are valuable tools in various fields of numerical analysis, including approximation, interpolation, meshless methods for solving partial differential equations, neural networks, and machine learning. This contribution explains why and how kernels are applied in these disciplines. It uncovers the links between them, in so far as they are related to kernel techniques. It addresses non-expert readers and focuses on practical guidelines for using kernels in applications.",2006,315,254,13,False,Computer Science,,3261621,R. Schaback,3235534.0,H. Wendland,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3dd8bf5cca76b1690a2642b73b509fb3a27e4f36,https://www.semanticscholar.org/paper/3dd8bf5cca76b1690a2642b73b509fb3a27e4f36,MetaReg: Towards Domain Generalization using Meta-Regularization,"Training models that generalize to new domains at test time is a problem of fundamental importance in machine learning. In this work, we encode this notion of domain generalization using a novel regularization function. We pose the problem of finding such a regularization function in a Learning to Learn (or) meta-learning framework. The objective of domain generalization is explicitly modeled by learning a regularizer that makes the model trained on one domain to perform well on another domain. Experimental validations on computer vision and natural language datasets indicate that our method can learn regularizers that achieve good cross-domain generalization.",2018,34,361,48,False,Computer Science,,3458479,Y. Balaji,2716670.0,S. Sankaranarayanan,9215658.0,R. Chellappa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e,https://www.semanticscholar.org/paper/6a26268d2ba9d34e5b59ae6e5c11a83cdca1a85e,Matching Words and Pictures,"We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann's hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation (MoM-LDA). All models are assessed using a large collection of annotated images of real scenes. We study in depth the difficult problem of measuring performance. For the annotation task, we look at prediction performance on held out data. We present three alternative measures, oriented toward different types of task. Measuring the performance of correspondence methods is harder, because one must determine whether a word has been placed on the right region of an image. We can use annotation performance as a proxy measure, but accurate measurement requires hand labeled data, and thus must occur on a smaller scale. We show results using both an annotation proxy, and manually labeled data.",2003,68,1789,104,False,Computer Science,,145602732,Kobus Barnard,2446509.0,P. D. Sahin,144016256.0,D. Forsyth,1737568.0,N. D. Freitas,1796335.0,D. Blei,1694621.0,Michael I. Jordan,,,,,,,,,,,,,,,,,,,,,,,,
e9ecc83042f6d439a32815a19c1bc11cc82b6a8b,https://www.semanticscholar.org/paper/e9ecc83042f6d439a32815a19c1bc11cc82b6a8b,Introduction to MAchine Learning & Knowledge Extraction (MAKE),"The grand goal of Machine Learning is to develop software which can learn from previous experience—similar to how we humans do. Ultimately, to reach a level of usable intelligence, we need (1) to learn from prior data, (2) to extract knowledge, (3) to generalize—i.e., guessing where probability function mass/density concentrates, (4) to fight the curse of dimensionality, and (5) to disentangle underlying explanatory factors of the data—i.e., to make sense of the data in the context of an application domain. To address these challenges and to ensure successful machine learning applications in various domains an integrated machine learning approach is important. This requires a concerted international effort without boundaries, supporting collaborative, cross-domain, interdisciplinary and transdisciplinary work of experts from seven sections, ranging from data pre-processing to data visualization, i.e., to map results found in arbitrarily high dimensional spaces into the lower dimensions to make it accessible, usable and useful to the end user. An integrated machine learning approach needs also to consider issues of privacy, data protection, safety, security, user acceptance and social implications. This paper is the inaugural introduction to the new journal of MAchine Learning & Knowledge Extraction (MAKE). The goal is to provide an incomplete, personally biased, but consistent introduction into the concepts of MAKE and a brief overview of some selected topics to stimulate future research in the international research community.",2017,123,50,3,True,Computer Science,,1749801,Andreas Holzinger,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee,https://www.semanticscholar.org/paper/37acbbbcfe9d8eb89e5b01da28dac6d44c3903ee,"Data Programming: Creating Large Training Sets, Quickly","Large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques. For some applications, creating labeled training sets is the most time-consuming and expensive part of applying machine learning. We therefore propose a paradigm for the programmatic creation of training sets called data programming in which users express weak supervision strategies or domain heuristics as labeling functions, which are programs that label subsets of the data, but that are noisy and may conflict. We show that by explicitly representing this training set labeling process as a generative model, we can ""denoise"" the generated training set, and establish theoretically that we can recover the parameters of these generative models in a handful of settings. We then show how to modify a discriminative loss function to make it noise-aware, and demonstrate our method over a range of discriminative models including logistic regression and LSTMs. Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data programming would have led to a new winning score, and also show that applying data programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points over a state-of-the-art LSTM baseline (and into second place in the competition). Additionally, in initial user studies we observed that data programming may be an easier way for non-experts to create machine learning models when training data is limited or unavailable.",2016,34,507,81,False,Computer Science,Mathematics,143711421,Alexander J. Ratner,1801197.0,Christopher De Sa,144766615.0,Sen Wu,2196579.0,Daniel Selsam,2114485554.0,C. Ré,,,,,,,,,,,,,,,,,,,,,,,Medicine,,,
e406c7d0bf67ea13dc9553fd4514ceaa3a61f6df,https://www.semanticscholar.org/paper/e406c7d0bf67ea13dc9553fd4514ceaa3a61f6df,Learning to Identify Review Spam,"In the past few years, sentiment analysis and opinion mining becomes a popular and important task. These studies all assume that their opinion resources are real and trustful. However, they may encounter the faked opinion or opinion spam problem. In this paper, we study this issue in the context of our product review mining system. On product review site, people may write faked reviews, called review spam, to promote their products, or defame their competitors' products. It is important to identify and filter out the review spam. Previous work only focuses on some heuristic rules, such as helpfulness voting, or rating deviation, which limits the performance of this task. In this paper, we exploit machine learning methods to identify review spam. Toward the end, we manually build a spam collection from our crawled reviews. We first analyze the effect of various features in spam identification. We also observe that the review spammer consistently writes spam. This provides us another view to identify review spam: we can identify if the author of the review is spammer. Based on this observation, we provide a twoview semi-supervised method, co-training, to exploit the large amount of unlabeled data. The experiment results show that our proposed method is effective. Our designed machine learning methods achieve significant improvements in comparison to the heuristic baselines.",2011,24,369,36,False,Computer Science,,1794976,Fangtao Li,1730108.0,Minlie Huang,2143684688.0,Yi Yang,145213540.0,Xiaoyan Zhu,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e90f281bcc5ca3499bfb5e56983ba82c97e81490,https://www.semanticscholar.org/paper/e90f281bcc5ca3499bfb5e56983ba82c97e81490,Bayesian compressive sensing and projection optimization,"This paper introduces a new problem for which machine-learning tools may make an impact. The problem considered is termed ""compressive sensing"", in which a real signal of dimension N is measured accurately based on K << N real measurements. This is achieved under the assumption that the underlying signal has a sparse representation in some basis (e.g., wavelets). In this paper we demonstrate how techniques developed in machine learning, specifically sparse Bayesian regression and active learning, may be leveraged to this new problem. We also point out future research directions in compressive sensing of interest to the machine-learning community.",2007,26,51,12,True,Computer Science,,144576567,Shihao Ji,145006560.0,L. Carin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a2d1aaedb70777d1fa047af6db30e84c55b81023,https://www.semanticscholar.org/paper/a2d1aaedb70777d1fa047af6db30e84c55b81023,Bayesian Optimization of Combinatorial Structures,"The optimization of expensive-to-evaluate black-box functions over combinatorial structures is an ubiquitous task in machine learning, engineering and the natural sciences. The combinatorial explosion of the search space and costly evaluations pose challenges for current techniques in discrete optimization and machine learning, and critically require new algorithmic ideas. This article proposes, to the best of our knowledge, the first algorithm to overcome these challenges, based on an adaptive, scalable model that identifies useful combinatorial structure even when data is scarce. Our acquisition function pioneers the use of semidefinite programming to achieve efficiency and scalability. Experimental evaluations demonstrate that this algorithm consistently outperforms other methods from combinatorial and Bayesian optimization.",2018,50,90,22,False,Mathematics,Computer Science,145539374,R. Baptista,31925701.0,Matthias Poloczek,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d42f875d9580de703a29c9b6c05cd535a41976dc,https://www.semanticscholar.org/paper/d42f875d9580de703a29c9b6c05cd535a41976dc,Statistical Reinforcement Learning - Modern Machine Learning Approaches,"Reinforcement learning (RL) is a framework for decision making in unknown environments based on a large amount of data. Several practical RL applications for business intelligence, plant control, and game players have been successfully explored in recent years. Providing an accessible introduction to the field, this book covers model-based and model-free approaches, policy iteration, and policy search methods. It presents illustrative examples and state-of-the-art results, including dimensionality reduction in RL and risk-sensitive RLm. The book provides a bridge between RL and data mining and machine learning research.",2015,0,37,2,False,Computer Science,,67154907,Masashi Sugiyama,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d9a2cfd0e7991de8bd19749d78be26c44ccae94c,https://www.semanticscholar.org/paper/d9a2cfd0e7991de8bd19749d78be26c44ccae94c,Extreme Learning Machine with Randomly Assigned RBF Kernels,"A new learning algorithm called extreme learning machine (ELM) has recently been proposed for single-hidden layer feedforward neural networks (SLFNs) with additive neurons to easily achieve good generalization performance at extremely fast learning speed. ELM randomly chooses the input weights and analytically determines the output weights of SLFNs. It is proved in theory that ELM can be extended to single-hidden layer feedforward neural networks (SLFNs) with radial basis function (RBF) kernels RBF networks, which allows the centers and impact widths of RBF kernels to be randomly generated and the output weights to be simply analytically calculated instead of iteratively tuned. The kernel function of ELM can be any nonlinear bounded integrable function which is almost continuous anywhere. Interestingly, the experimental results show that the ELM algorithm for RBF networks can complete learning at extremely fast speed and produce generalization performance very close to that of SVM in some benchmarking function approximation and classification problems. Index terms Radial basis function network, feedforward neural networks, real time learning, extreme learning machine, ELM, arbitrary kernels. The preliminary idea of the ELM algorithm for RBF networks has been shown in the Proceedings of the Eighth International Conference on Control, Automation, Robotics and Vision (ICARCV 2004), Dec 6-9, Kunming, China. Guang-Bin Huang and Chee-Kheong Siew Extreme Learning Machine with Randomly Assigned RBF Kernels",2005,13,185,13,False,,,145678691,G. Huang,1683268.0,C. Siew,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
805b8935d0a5937f67a6058c9cac6c18a55029cd,https://www.semanticscholar.org/paper/805b8935d0a5937f67a6058c9cac6c18a55029cd,Learning on the border: active learning in imbalanced data classification,"This paper is concerned with the class imbalance problem which has been known to hinder the learning performance of classification algorithms. The problem occurs when there are significantly less number of observations of the target concept. Various real-world classification tasks, such as medical diagnosis, text categorization and fraud detection suffer from this phenomenon. The standard machine learning algorithms yield better prediction performance with balanced datasets. In this paper, we demonstrate that active learning is capable of solving the class imbalance problem by providing the learner more balanced classes. We also propose an efficient way of selecting informative instances from a smaller pool of samples for active learning which does not necessitate a search through the entire dataset. The proposed method yields an efficient querying system and allows active learning to be applied to very large datasets. Our experimental results show that with an early stopping criteria, active learning achieves a fast solution with competitive prediction performance in imbalanced data classification.",2007,96,380,33,False,Computer Science,,1769472,S. Ertekin,40537842.0,Jian Huang,52184096.0,L. Bottou,145157784.0,C. Lee Giles,,,,,,,,,,,,,,,,,,,,,,,,,,,,
af702d6e8137ef5143e09b22b8bc7209e73fb0a3,https://www.semanticscholar.org/paper/af702d6e8137ef5143e09b22b8bc7209e73fb0a3,A Brief Survey of Machine Learning Methods in Protein Sub-Golgi Localization,"The location of proteins in a cell can provide important clues to their functions in various biological processes. Thus, the application of machine learning method in the prediction of protein subcellular localization has become a hotspot in bioinformatics. As one of key organelles, the Golgi apparatus is in charge of protein storage, package, and distribution.The identification of protein location in Golgi apparatus will provide in-depth insights into their functions. Thus, the machine learning-based method of predicting protein location in Golgi apparatus has been extensively explored. The development of protein sub-Golgi apparatus localization prediction should be reviewed for providing a whole background for the fields.The benchmark dataset, feature extraction, machine learning method and published results were summarized.We briefly introduced the recent progresses in protein sub-Golgi apparatus localization prediction using machine learning methods and discussed their advantages and disadvantages.We pointed out the perspective of machine learning methods in protein sub-Golgi localization prediction.",2019,100,95,4,False,Computer Science,,19323213,Wuritu Yang,145384708.0,Xiao-Juan Zhu,47513577.0,Jian Huang,145634032.0,H. Ding,2051534436.0,Hao Lin,,,,,,,,,,,,,,,,,,,,,,,,,,
8221ed66d16b608653393757eaf443187ffe60a0,https://www.semanticscholar.org/paper/8221ed66d16b608653393757eaf443187ffe60a0,A Machine Learning Approach to Building Domain-Specific Search Engines,"Domain-specific search engines are becoming increasingly popular because they offer increased accuracy and extra features not possible with general, Web-wide search engines. Unfortunately, they are also difficult and time-consuming to maintain. This paper proposes the use of machine learning techniques to greatly automate the creation and maintenance of domain-specific search engines. We describe new research in reinforcement learning, text classification and information extraction that enables efficient spidering, populates topic hierarchies, and identifies informative text segments. Using these techniques, we have built a demonstration system: a search engine for computer science research papers available at www.cora.justrcsettrch.com.",1999,19,211,11,False,Computer Science,,143753639,A. McCallum,145172877.0,K. Nigam,35211659.0,Jason D. M. Rennie,2544946.0,K. Seymore,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1a2fb75103ea9dc9ff31711ba5aa357088c026bc,https://www.semanticscholar.org/paper/1a2fb75103ea9dc9ff31711ba5aa357088c026bc,Automated Vulnerability Detection in Source Code Using Deep Representation Learning,"Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a largescale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection.",2018,18,210,34,True,Computer Science,Mathematics,2070634196,Rebecca L. Russell,47714368.0,Louis Y. Kim,40902376.0,Lei H. Hamilton,40900798.0,T. Lazovich,4413381.0,Jacob A. Harer,2066070614.0,Onur Ozdemir,40900236.0,Paul M. Ellingwood,1940574.0,M. McConley,,,,,,,,,,,,,,,,,,,,
99b43d6dd6923e94b304fe294f43be159630f628,https://www.semanticscholar.org/paper/99b43d6dd6923e94b304fe294f43be159630f628,On the ethics of algorithmic decision-making in healthcare,"In recent years, a plethora of high-profile scientific publications has been reporting about machine learning algorithms outperforming clinicians in medical diagnosis or treatment recommendations. This has spiked interest in deploying relevant algorithms with the aim of enhancing decision-making in healthcare. In this paper, we argue that instead of straightforwardly enhancing the decision-making capabilities of clinicians and healthcare institutions, deploying machines learning algorithms entails trade-offs at the epistemic and the normative level. Whereas involving machine learning might improve the accuracy of medical diagnosis, it comes at the expense of opacity when trying to assess the reliability of given diagnosis. Drawing on literature in social epistemology and moral responsibility, we argue that the uncertainty in question potentially undermines the epistemic authority of clinicians. Furthermore, we elucidate potential pitfalls of involving machine learning in healthcare with respect to paternalism, moral responsibility and fairness. At last, we discuss how the deployment of machine learning algorithms might shift the evidentiary norms of medical diagnosis. In this regard, we hope to lay the grounds for further ethical reflection of the opportunities and pitfalls of machine learning for enhancing decision-making in healthcare.",2019,43,132,2,True,Psychology,Medicine,1423968387,Thomas Grote,1689077.0,Philipp Berens,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eaf5b3a28606da5014d5c3d106b2fc4306933808,https://www.semanticscholar.org/paper/eaf5b3a28606da5014d5c3d106b2fc4306933808,Graphite: Iterative Generative Modeling of Graphs,"Graphs are a fundamental abstraction for modeling relational data. However, graphs are discrete and combinatorial in nature, and learning representations suitable for machine learning tasks poses statistical and computational challenges. In this work, we propose Graphite, an algorithmic framework for unsupervised learning of representations over nodes in large graphs using deep latent variable generative models. Our model parameterizes variational autoencoders (VAE) with graph neural networks, and uses a novel iterative graph refinement strategy inspired by low-rank approximations for decoding. On a wide variety of synthetic and benchmark datasets, Graphite outperforms competing approaches for the tasks of density estimation, link prediction, and node classification. Finally, we derive a theoretical connection between message passing in graph neural networks and mean-field variational inference.",2018,83,198,32,False,Computer Science,Mathematics,1954250,Aditya Grover,40576688.0,Aaron Zweig,2490652.0,S. Ermon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9ed53d949959165188ab2e5fd76f686d692d43ea,https://www.semanticscholar.org/paper/9ed53d949959165188ab2e5fd76f686d692d43ea,Dynamic control flow in large-scale machine learning,"Many recent machine learning models rely on fine-grained dynamic control flow for training and inference. In particular, models based on recurrent neural networks and on reinforcement learning depend on recurrence relations, data-dependent conditional execution, and other features that call for dynamic control flow. These applications benefit from the ability to make rapid control-flow decisions across a set of computing devices in a distributed system. For performance, scalability, and expressiveness, a machine learning system must support dynamic control flow in distributed and heterogeneous environments. This paper presents a programming model for distributed machine learning that supports dynamic control flow. We describe the design of the programming model, and its implementation in TensorFlow, a distributed machine learning system. Our approach extends the use of dataflow graphs to represent machine learning models, offering several distinctive features. First, the branches of conditionals and bodies of loops can be partitioned across many machines to run on a set of heterogeneous devices, including CPUs, GPUs, and custom ASICs. Second, programs written in our model support automatic differentiation and distributed gradient computations, which are necessary for training machine learning models that use control flow. Third, our choice of non-strict semantics enables multiple loop iterations to execute in parallel across machines, and to overlap compute and I/O operations. We have done our work in the context of TensorFlow, and it has been used extensively in research and production. We evaluate it using several real-world applications, and demonstrate its performance and scalability.",2018,42,86,9,True,Computer Science,,47112093,Yuan Yu,2057642721.0,Martín Abadi,144758007.0,P. Barham,2445241.0,E. Brevdo,32623151.0,M. Burrows,36347083.0,Andy Davis,48448318.0,J. Dean,1780892.0,S. Ghemawat,3367786.0,Tim Harley,2052793706.0,Peter Hawkins,2090818.0,M. Isard,1942300.0,M. Kudlur,3089272.0,R. Monga,20154699.0,D. Murray,2152198093.0,Xiaoqiang Zheng,,,,,,
3a62d3759631153ff135184202792977fbdd265b,https://www.semanticscholar.org/paper/3a62d3759631153ff135184202792977fbdd265b,Learning And Soft Computing Support Vector Machines Neural Networks And Fuzzy Logic Models,"Thank you for reading learning and soft computing support vector machines neural networks and fuzzy logic models. As you may know, people have search hundreds times for their chosen books like this learning and soft computing support vector machines neural networks and fuzzy logic models, but end up in malicious downloads. Rather than enjoying a good book with a cup of coffee in the afternoon, instead they juggled with some infectious bugs inside their computer.",2016,0,186,10,False,Computer Science,,52615285,D. Eichel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6cd7a47bbba11a994cd8e68ee5eae2fcb0033054,https://www.semanticscholar.org/paper/6cd7a47bbba11a994cd8e68ee5eae2fcb0033054,Driving in the Matrix: Can virtual worlds replace human-generated annotations for real world tasks?,"Deep learning has rapidly transformed the state of the art algorithms used to address a variety of problems in computer vision and robotics. These breakthroughs have relied upon massive amounts of human annotated training data. This time consuming process has begun impeding the progress of these deep learning efforts. This paper describes a method to incorporate photo-realistic computer images from a simulation engine to rapidly generate annotated data that can be used for the training of machine learning algorithms. We demonstrate that a state of the art architecture, which is trained only using these synthetic annotations, performs better than the identical architecture trained on human annotated real-world data, when tested on the KITTI data set for vehicle detection. By training machine learning algorithms on a rich virtual world, real objects in real scenes can be learned and classified using synthetic data. This approach offers the possibility of accelerating deep learning's application to sensor-based classification problems like those that appear in self-driving cars. The source code and data to train and validate the networks described in this paper are made available for researchers.",2016,24,402,59,True,Computer Science,,1389944402,M. Johnson-Roberson,116731556.0,Charlie Barto,2067925945.0,Rounak Mehta,2057436877.0,S. N. Sridhar,2748006.0,Karl Rosaen,145386932.0,R. Vasudevan,,,,,,,,,,,,,,,,,,,,,,,,
c2a561b725b03de41f02106d1c27305997cc9126,https://www.semanticscholar.org/paper/c2a561b725b03de41f02106d1c27305997cc9126,Artificial intelligence and machine learning to fight COVID-19,"Ahmad Alimadadi,* Sachin Aryal,* Ishan Manandhar,* X Patricia B. Munroe, Bina Joe, and X Xi Cheng Center for Hypertension and Precision Medicine, Program in Physiological Genomics, Department of Physiology and Pharmacology, University of Toledo College of Medicine and Life Sciences, Toledo, Ohio; and Clinical Pharmacology, William Harvey Research Institute, National Institute of Health Research Barts Cardiovascular Biomedical Research Centre, Barts and The London School of Medicine and Dentistry, Queen Mary University of London, London, United Kingdom",2020,14,357,8,False,Medicine,Biology,88872117,A. Alimadadi,88799661.0,Sachin Aryal,1596635009.0,Ishan Manandhar,2786361.0,P. Munroe,32239942.0,B. Joe,29986658.0,Xi Cheng,,,,,,,,,,,,,,,,,,,,,,,,
410d06ff1dc1aa602681ff947c781522df4ae02f,https://www.semanticscholar.org/paper/410d06ff1dc1aa602681ff947c781522df4ae02f,Data Integration and Machine Learning: A Natural Synergy,"There is now more data to analyze than ever before. As data volume and variety have increased, so have the ties between machine learning and data integration become stronger. For machine learning to be effective, one must utilize data from the greatest possible variety of sources; and this is why data integration plays a key role. At the same time machine learning is driving automation in data integration, resulting in overall reduction of integration costs and improved accuracy. This tutorial focuses on three aspects of the synergistic relationship between data integration and machine learning: (1) we survey how state-of-the-art data integration solutions rely on machine learning-based approaches for accurate results and effective human-in-the-loop pipelines, (2) we review how end-to-end machine learning applications rely on data integration to identify accurate, clean, and relevant data for their analytics exercises, and (3) we discuss open research challenges and opportunities that span across data integration and machine learning.",2018,62,71,2,False,Computer Science,,145867172,Xin Dong,145071799.0,Theodoros Rekatsinas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
72d194dda60affd2728deca833a10028960d28a2,https://www.semanticscholar.org/paper/72d194dda60affd2728deca833a10028960d28a2,Data Management Challenges in Production Machine Learning,"The tutorial discusses data-management issues that arise in the context of machine learning pipelines deployed in production. Informed by our own experience with such largescale pipelines, we focus on issues related to understanding, validating, cleaning, and enriching training data. The goal of the tutorial is to bring forth these issues, draw connections to prior work in the database literature, and outline the open research questions that are not addressed by prior art.",2017,35,139,7,True,Computer Science,,1763100,Neoklis Polyzotis,1473253195.0,Sudip Roy,3288247.0,Steven Euijong Whang,8195063.0,Martin A. Zinkevich,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c4e7410be72006f91462fb291668069efe8dcc33,https://www.semanticscholar.org/paper/c4e7410be72006f91462fb291668069efe8dcc33,The Logic Programming Paradigm: A 25-Year Perspective,"This exciting new text reveals both the evolution of this programming paradigm since its inception and the impressively broad scope of current research in the field. The contributors to this book are all leading world experts in Logic Programming, and they deal with both theoretical and practical issues. They address such diverse topics as: computational molecular biology, machine learning, mobile computing, multi-agent systems, planning, numerical computing and dynamical systems, database systems, an alternative to the ""formulas as types"" approach, program semantics and analysis, and natural language processing. XXXXXXX Neuer Text Logic Programming was founded 25 years ago. This exciting book reveals both the evolution of this programming paradigm and its impressively broad scope of current research. The contributions by leading computer scientists deal with both theoretical and practical issues. They address diverse topics such as: computational molecular biology, machine learning, mobile computing, multi-agent systems, numerical computing and dynamical systems, database systems, program semantics, natural language processing, and promising future directions.",2011,37,434,13,False,Mathematics,Physics,1748061,K. Apt,1707833.0,V. Marek,38119663.0,M. Truszczynski,2678443.0,D. Warren,,,,,,,,,,,,,,,,,,,,,,,,,Computer Science,,,
1b4c906704cd125adf5c9a974e16c56e49925bf3,https://www.semanticscholar.org/paper/1b4c906704cd125adf5c9a974e16c56e49925bf3,Variational Relevance Vector Machines,"The Support Vector Machine (SVM) of Vapnik (1998) has become widely established as one of the leading approaches to pattern recognition and machine learning. It expresses predictions in terms of a linear combination of kernel functions centred on a subset of the training data, known as support vectors. 
Despite its widespread success, the SVM suffers from some important limitations, one of the most significant being that it makes point predictions rather than generating predictive distributions. Recently Tipping (1999) has formulated the Relevance Vector Machine (RVM), a probabilistic model whose functional form is equivalent to the SVM. It achieves comparable recognition accuracy to the SVM, yet provides a full predictive distribution, and also requires substantially fewer kernel functions. 
The original treatment of the RVM relied on the use of type II maximum likelihood (the `evidence framework') to provide point estimates of the hyperparameters which govern model sparsity. In this paper we show how the RVM can be formulated and solved within a completely Bayesian paradigm through the use of variational inference, thereby giving a posterior distribution over both parameters and hyperparameters. We demonstrate the practicality and performance of the variational RVM using both synthetic and real world examples.",2000,16,394,53,False,Computer Science,Mathematics,1792884,Charles M. Bishop,2831141.0,Michael E. Tipping,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9ef319ead5ec24f9ed46dcdb8951804e8338a2eb,https://www.semanticscholar.org/paper/9ef319ead5ec24f9ed46dcdb8951804e8338a2eb,Machine learned job recommendation,"We address the problem of recommending suitable jobs to people who are seeking a new job. We formulate this recommendation problem as a supervised machine learning problem. Our technique exploits all past job transitions as well as the data associated with employees and institutions to predict an employee's next job transition. We train a machine learning model using a large number of job transitions extracted from the publicly available employee profiles in the Web. Experiments show that job transitions can be accurately predicted, significantly improving over a baseline that always predicts the most frequent institution in the data.",2011,10,129,10,False,Computer Science,,2418446,Ioannis K. Paparrizos,1776940.0,B. B. Cambazoglu,1682878.0,A. Gionis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b33ca9ba9a9790cc308c8a1244316e270c9dbb33,https://www.semanticscholar.org/paper/b33ca9ba9a9790cc308c8a1244316e270c9dbb33,Wrapper Maintenance: A Machine Learning Approach,"The proliferation of online information sources has led to an increased use of wrappers for extracting data from Web sources. While most of the previous research has focused on quick and efficient generation of wrappers, the development of tools for wrapper maintenance has received less attention. This is an important research problem because Web sources often change in ways that prevent the wrappers from extracting data correctly. We present an efficient algorithm that learns structural information about data from positive examples alone. We describe how this information can be used for two wrapper maintenance applications: wrapper verification and reinduction. The wrapper verification system detects when a wrapper is not extracting correct data, usually because the Web source has changed its format. The reinduction algorithm automatically recovers from changes in the Web source by identifying data on Web pages so that a new wrapper may be generated for this source. To validate our approach, we monitored 27 wrappers over a period of a year. The verification algorithm correctly discovered 35 of the 37 wrapper changes, and made 16 mistakes, resulting in precision of 0.73 and recall of 0.95. We validated the reinduction algorithm on ten Web sources. We were able to successfully reinduce the wrappers, obtaining precision and recall values of 0.90 and 0.80 on the data extraction task.",2011,39,178,10,True,Computer Science,,1745117,Craig A. Knoblock,1782658.0,Kristina Lerman,26602711.0,Steven N. Minton,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
486574b08c57e70d1ac3345f306efe6979682bda,https://www.semanticscholar.org/paper/486574b08c57e70d1ac3345f306efe6979682bda,Machine Learning Topological Invariants with Neural Networks,"In this Letter we supervisedly train neural networks to distinguish different topological phases in the context of topological band insulators. After training with Hamiltonians of one-dimensional insulators with chiral symmetry, the neural network can predict their topological winding numbers with nearly 100% accuracy, even for Hamiltonians with larger winding numbers that are not included in the training data. These results show a remarkable success that the neural network can capture the global and nonlinear topological features of quantum phases from local inputs. By opening up the neural network, we confirm that the network does learn the discrete version of the winding number formula. We also make a couple of remarks regarding the role of the symmetry and the opposite effect of regularization techniques when applying machine learning to physical systems.",2017,56,145,3,True,Computer Science,Medicine,144664224,Pengfei Zhang,5060396.0,Huitao Shen,47939671.0,H. Zhai,,,,,,,,,,,,,,,,,,,,,,,,,,,Physics,,,
7e152e587fbc73b5bd23048c71c1b36c569416c5,https://www.semanticscholar.org/paper/7e152e587fbc73b5bd23048c71c1b36c569416c5,EMBER: An Open Dataset for Training Static PE Malware Machine Learning Models,"This paper describes EMBER: a labeled benchmark dataset for training machine learning models to statically detect malicious Windows portable executable files. The dataset includes features extracted from 1.1M binary files: 900K training samples (300K malicious, 300K benign, 300K unlabeled) and 200K test samples (100K malicious, 100K benign). To accompany the dataset, we also release open source code for extracting features from additional binaries so that additional sample features can be appended to the dataset. This dataset fills a void in the information security machine learning community: a benign/malicious dataset that is large, open and general enough to cover several interesting use cases. We enumerate several use cases that we considered when structuring the dataset. Additionally, we demonstrate one use case wherein we compare a baseline gradient boosted decision tree model trained using LightGBM with default settings to MalConv, a recently published end-to-end (featureless) deep learning model for malware detection. Results show that even without hyper-parameter optimization, the baseline EMBER model outperforms MalConv. The authors hope that the dataset, code and baseline model provided by EMBER will help invigorate machine learning research for malware detection, in much the same way that benchmark datasets have advanced computer vision research.",2018,31,222,61,False,Computer Science,,2639880,H. Anderson,153379407.0,P. Roth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
310910704c82332cedc465afa3bdc15a5add0af0,https://www.semanticscholar.org/paper/310910704c82332cedc465afa3bdc15a5add0af0,Unified Theories of Cognition,"Introduction The Nature of Theories What Are Unified Theories of Cognition? Is Psychology Ready for Unified Theories? The Task of the Book Foundations of Cognitive Science Behaving Systems Knowledge Systems Representation Machines and Computation Symbols Architectures Intelligence Search and Problem Spaces Preparation and Deliberation Summary Human Cognitive Architecture The Human Is a Symbol System System Levels The Time Scale of Human Action The Biological Band The Neural Circuit Level The Real-Time Constraint on Cognition The Cognitive Band The Level of Simple Operations The First Level of Composed Operations The Intendedly Rational Band Higher Bands: Social, Historical, and Evolutionary Summary Symbolic Processing for Intelligence The Central Architecture for Performance Chunking The Total Cognitive System RI-Soar: Knowledge-Intensive and Knowledge-Lean Operation Designer-Soar: Difficult Intellectual Tasks Soar as an Intelligent System Mapping Soar onto Human Cognition Soar and the Shape of Human Cognition Summary Immediate Behavior The Scientific Role of Immediate-Response Data Methodological Preliminaries Functional Analysis of Immediate Responses The Simplest Response Task (SRI) The Two-Choice Response Task (2CRT) Stimulus-Response Compatibility (SRC) Discussion of the Three Analyses Item Recognition Typing Summary Memory, Learning, and Skill The Memory and Learning Hypothesis of Soar The Soar Qualitative Theory of Learning The Distinction between Episodic and Semantic Memory Data Chunking Skill Acquisition Short-Term Memory (STM) Summary Intendedly Rational Behavior Ciyptarithmetic Syllogisms Sentence Verification Summary Along the Frontiers Language Development The Biological Band The Social Band The Role of Applications How to Move toward Unified Theories of Cognition References Name Index Subject Index",1990,0,2575,188,False,Psychology,,48603437,A. Newell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2de06861c42928581aec8ddd932e68ad450a2c0a,https://www.semanticscholar.org/paper/2de06861c42928581aec8ddd932e68ad450a2c0a,Adversarial support vector machine learning,"Many learning tasks such as spam filtering and credit card fraud detection face an active adversary that tries to avoid detection. For learning problems that deal with an active adversary, it is important to model the adversary's attack strategy and develop robust learning models to mitigate the attack. These are the two objectives of this paper. We consider two attack models: a free-range attack model that permits arbitrary data corruption and a restrained attack model that anticipates more realistic attacks that a reasonable adversary would devise under penalties. We then develop optimal SVM learning strategies against the two attack models. The learning algorithms minimize the hinge loss while assuming the adversary is modifying data to maximize the loss. Experiments are performed on both artificial and real data sets. We demonstrate that optimal solutions may be overly pessimistic when the actual attacks are much weaker than expected. More important, we demonstrate that it is possible to develop a much more resilient SVM learning model while making loose assumptions on the data corruption models. When derived under the restrained attack model, our optimal SVM learning strategy provides more robust overall performance under a wide range of attack parameters.",2012,25,114,11,True,Computer Science,,2150920617,Yan Zhou,1741044.0,Murat Kantarcioglu,72558235.0,B. Thuraisingham,35476307.0,B. Xi,,,,,,,,,,,,,,,,,,,,,,,,,,,,
91ed985917cf4c317b7d91e15c1ec55e746153bf,https://www.semanticscholar.org/paper/91ed985917cf4c317b7d91e15c1ec55e746153bf,What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use,"Translating machine learning (ML) models effectively to clinical practice requires establishing clinicians' trust. Explainability, or the ability of an ML model to justify its outcomes and assist clinicians in rationalizing the model prediction, has been generally understood to be critical to establishing trust. However, the field suffers from the lack of concrete definitions for usable explanations in different settings. To identify specific aspects of explainability that may catalyze building trust in ML models, we surveyed clinicians from two distinct acute care specialties (Intenstive Care Unit and Emergency Department). We use their feedback to characterize when explainability helps to improve clinicians' trust in ML models. We further identify the classes of explanations that clinicians identified as most relevant and crucial for effective translation to clinical practice. Finally, we discern concrete metrics for rigorous evaluation of clinical explainability methods. By integrating perceptions of explainability between clinicians and ML researchers we hope to facilitate the endorsement and broader adoption and sustained use of ML systems in healthcare.",2019,81,182,10,False,Computer Science,Mathematics,23152217,S. Tonekaboni,34287745.0,Shalmali Joshi,46223842.0,M. McCradden,49800482.0,A. Goldenberg,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3ffe41c72ace4b5ccf8e76d713f48dc644bf5a51,https://www.semanticscholar.org/paper/3ffe41c72ace4b5ccf8e76d713f48dc644bf5a51,Predicting MOOC Dropout over Weeks Using Machine Learning Methods,"With high dropout rates as observed in many current larger-scale online courses, mechanisms that are able to predict student dropout become increasingly important. While this problem is partially solved for students that are active in online forums, this is not yet the case for the more general student population. In this paper, we present an approach that works on click-stream data. Among other features, the machine learning algorithm takes the weekly history of student data into account and thus is able to notice changes in student behavior over time. In the later phases of a course (i.e., once such history data is available), this approach is able to predict dropout significantly better than baseline methods.",2014,12,270,27,True,Computer Science,,1412607411,Marius Kloft,70124120.0,Felix Stiehler,2369706.0,Zhilin Zheng,1698561.0,Niels Pinkwart,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5ef2edfe51d3d768b1d89ad7e74e4ce8e55d1d49,https://www.semanticscholar.org/paper/5ef2edfe51d3d768b1d89ad7e74e4ce8e55d1d49,Delta TFIDF: An Improved Feature Space for Sentiment Analysis,"Mining opinions and sentiment from social networking sites is a popular application for social media systems. Common approaches use a machine learning system with a bag of words feature set. We present Delta TFIDF, an intuitive general purpose technique to efficiently weight word scores before classification. Delta TFIDF is easy to compute, implement, and understand. We use Support Vector Machines to show that Delta TFIDF significantly improves accuracy for sentiment analysis problems using three well known data sets.",2009,11,348,34,True,Computer Science,,40378713,Justin Martineau,144121212.0,Timothy W. Finin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cb030975a3dbcdf52a01cbd1c140711332313e13,https://www.semanticscholar.org/paper/cb030975a3dbcdf52a01cbd1c140711332313e13,Intelligible Models for HealthCare: Predicting Pneumonia Risk and Hospital 30-day Readmission,"In machine learning often a tradeoff must be made between accuracy and intelligibility. More accurate models such as boosted trees, random forests, and neural nets usually are not intelligible, but more intelligible models such as logistic regression, naive-Bayes, and single decision trees often have significantly worse accuracy. This tradeoff sometimes limits the accuracy of models that can be applied in mission-critical applications such as healthcare where being able to understand, validate, edit, and trust a learned model is important. We present two case studies where high-performance generalized additive models with pairwise interactions (GA2Ms) are applied to real healthcare problems yielding intelligible models with state-of-the-art accuracy. In the pneumonia risk prediction case study, the intelligible model uncovers surprising patterns in the data that previously had prevented complex learned models from being fielded in this domain, but because it is intelligible and modular allows these patterns to be recognized and removed. In the 30-day hospital readmission case study, we show that the same methods scale to large datasets containing hundreds of thousands of patients and thousands of attributes while remaining intelligible and providing accuracy comparable to the best (unintelligible) machine learning methods.",2015,7,1087,55,False,Computer Science,,145727186,R. Caruana,91993942.0,Yin Lou,143614516.0,J. Gehrke,143831110.0,Paul Koch,46525681.0,M. Sturm,2763493.0,Noémie Elhadad,,,,,,,,,,,,,,,,,,,,,,,,
