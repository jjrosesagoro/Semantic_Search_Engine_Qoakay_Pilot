paperId,url,title,abstract,year,referenceCount,citationCount,influentialCitationCount,isOpenAccess,fieldsOfStudy/0,authors/0/authorId,authors/0/name,authors/1/authorId,authors/1/name,authors/2/authorId,authors/2/name,authors/3/authorId,authors/3/name,authors/4/authorId,authors/4/name,authors/5/authorId,authors/5/name,authors/6/authorId,authors/6/name,authors/7/authorId,authors/7/name,fieldsOfStudy/1,fieldsOfStudy/2,authors/8/authorId,authors/8/name,authors/9/authorId,authors/9/name,authors/10/authorId,authors/10/name,authors/11/authorId,authors/11/name,authors/12/authorId,authors/12/name,authors/13/authorId,authors/13/name,authors/14/authorId,authors/14/name,authors/15/authorId,authors/15/name,authors/16/authorId,authors/16/name,authors/17/authorId,authors/17/name,authors/18/authorId,authors/18/name,fieldsOfStudy/3
5ef22b9f1c51d45434176e84b3f61959fddd5bd3,https://www.semanticscholar.org/paper/5ef22b9f1c51d45434176e84b3f61959fddd5bd3,Machine Learning Models and Algorithms for Big Data Classification: Thinking with Examples for Effective Learning,"This book presents machine learning models and algorithms to address big data classification problems. Existing machine learning techniques like the decision tree (a hierarchical approach), random forest (an ensemble hierarchical approach), and deep learning (a layered approach) are highly suitable for the system that can handle such problems. This book helps readers, especially students and newcomers to the field of big data and machine learning, to gain a quick understanding of the techniques and technologies; therefore, the theory, examples, and programs (Matlab and R) presented in this book have been simplified, hardcoded, repeated, or spaced for improvements. They provide vehicles to test and understand the complicated concepts of various topics in the field. It is expected that the readers adopt these programs to experiment with the examples, and then modify or write their own programs toward advancing their knowledge for solving more complex and challenging problems. The presentation format of this book focuses on simplicity, readability, and dependability so that both undergraduate and graduate students as well as new researchers, developers, and practitioners in this field can easily trust and grasp the concepts, and learn them effectively. It has been written to reduce the mathematical complexity and help the vast majority of readers to understand the topics and get interested in the field. This book consists of four parts, with the total of 14 chapters. The first part mainly focuses on the topics that are needed to help analyze and understand data and big data. The second part covers the topics that can explain the systems required for processing big data. The third part presents the topics required to understand and select machine learning techniques to classify big data. Finally, the fourth part concentrates on the topics that explain the scaling-up machine learning, an important solution for modern big data problems.",2015,0,67,2,False,Computer Science,3339259.0,S. Suthaharan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
eaf52f290fa8c7d725ec4b2e7ad3af40e559d0f9,https://www.semanticscholar.org/paper/eaf52f290fa8c7d725ec4b2e7ad3af40e559d0f9,Short-Term Wind Speed Forecasting via Stacked Extreme Learning Machine With Generalized Correntropy,"Recently, wind speed forecasting as an effective computing technique plays an important role in advancing industry informatics, while dealing with these issues of control and operation for renewable power systems. However, it is facing some increasing difficulties to handle the large-scale dataset generated in these forecasting applications, with the purpose of ensuring stable computing performance. In response to such limitation, this paper proposes a more practical approach through the combination of extreme-learning machine (ELM) method and deep-learning model. ELM is a novel computing paradigm that enables the neural network (NN) based learning to be achieved with fast training speed and good generalization performance. The stacked ELM (SELM) is an advanced ELM algorithm under deep-learning framework, which works efficiently on memory consumption decrease. In this paper, an enhanced SELM is accordingly developed via replacing the Euclidean norm of the mean square error (MSE) criterion in ELM with the generalized correntropy criterion to further improve the forecasting performance. The advantage of the enhanced SELM with generalized correntropy to achieve better forecasting performance mainly relies on the following aspect. Generalized correntropy is a stable and robust nonlinear similarity measure while employing machine learning method to forecast wind speed, where the outliers may exist in some industrially measured values. Specifically, the experimental results of short-term and ultra-short-term forecasting on real wind speed data show that the proposed approach can achieve better computing performance compared with other traditional and more recent methods.",2018,24,141,5,True,Computer Science,144118283.0,Xiong Luo,2152147795.0,Jiankun Sun,102520410.0,Long Wang,38485868.0,Weiping Wang,144101027.0,Wenbing Zhao,2109246526.0,Jinsong Wu,2110221223.0,Jenq-Haur Wang,47294059.0,Zijun Zhang,,,,,,,,,,,,,,,,,,,,,,,,,
b13e9d23983273c0c67b91ae70c55d4c3f745b8b,https://www.semanticscholar.org/paper/b13e9d23983273c0c67b91ae70c55d4c3f745b8b,Learning to Translate in Real-time with Neural Machine Translation,"Translating in real-time, a.k.a.simultaneous translation, outputs translation words before the input sentence ends, which is a challenging problem for conventional machine translation methods. We propose a neural machine translation (NMT) framework for simultaneous translation in which an agent learns to make decisions on when to translate from the interaction with a pre-trained NMT environment. To trade off quality and delay, we extensively explore various targets for delay and design a method for beam-search applicable in the simultaneous MT setting. Experiments against state-of-the-art baselines on two language pairs demonstrate the efficacy of the proposed framework both quantitatively and qualitatively.",2016,25,146,37,True,Computer Science,1700325.0,Graham Neubig,1979489.0,Kyunghyun Cho,3016273.0,Jiatao Gu,2052674293.0,V. Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f9d119346b0773ea83251598fa5305bc75bac8ab,https://www.semanticscholar.org/paper/f9d119346b0773ea83251598fa5305bc75bac8ab,Spectral–Spatial Classification of Hyperspectral Data Based on Deep Belief Network,"Hyperspectral data classification is a hot topic in remote sensing community. In recent years, significant effort has been focused on this issue. However, most of the methods extract the features of original data in a shallow manner. In this paper, we introduce a deep learning approach into hyperspectral image classification. A new feature extraction (FE) and image classification framework are proposed for hyperspectral data analysis based on deep belief network (DBN). First, we verify the eligibility of restricted Boltzmann machine (RBM) and DBN by the following spectral information-based classification. Then, we propose a novel deep architecture, which combines the spectral-spatial FE and classification together to get high classification accuracy. The framework is a hybrid of principal component analysis (PCA), hierarchical learning-based FE, and logistic regression (LR). Experimental results with hyperspectral data indicate that the classifier provide competitive solution with the state-of-the-art methods. In addition, this paper reveals that deep learning system has huge potential for hyperspectral data classification.",2015,55,801,48,False,Computer Science,2597809.0,Yushi Chen,2143711163.0,Xing Zhao,144787387.0,X. Jia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66e70d7d6af0c51b9b907d9c4a8de0dfca70b1a7,https://www.semanticscholar.org/paper/66e70d7d6af0c51b9b907d9c4a8de0dfca70b1a7,Will machine learning end the viability of radiology as a thriving medical specialty?,"There have been tremendous advances in artificial intelligence (AI) and machine learning (ML) within the past decade, especially in the application of deep learning to various challenges. These include advanced competitive games (such as Chess and Go), self-driving cars, speech recognition, and intelligent personal assistants. Rapid advances in computer vision for recognition of objects in pictures have led some individuals, including computer science experts and health care system experts in machine learning, to make predictions that ML algorithms will soon lead to the replacement of the radiologist. However, there are complex technological, regulatory, and medicolegal obstacles facing the implementation of machine learning in radiology that will definitely preclude replacement of the radiologist by these algorithms within the next two decades and beyond. While not a comprehensive review of machine learning, this article is intended to highlight specific features of machine learning which face significant technological and health care systems challenges. Rather than replacing radiologists, machine learning will provide quantitative tools that will increase the value of diagnostic imaging as a biomarker, increase image quality with decreased acquisition times, and improve workflow, communication, and patient safety. In the foreseeable future, we predict that today's generation of radiologists will be replaced not by ML algorithms, but by a new breed of data science-savvy radiologists who have embraced and harnessed the incredible potential that machine learning has to advance our ability to care for our patients. In this way, radiology will remain a viable medical specialty for years to come.",2019,112,46,2,True,Engineering,2107300376.0,Stephen Chan,1691257.0,E. Siegel,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
55212c3934663fc825842e85980f74b4254eaeb0,https://www.semanticscholar.org/paper/55212c3934663fc825842e85980f74b4254eaeb0,A parallel genetic/neural network learning algorithm for MIMD shared memory machines,"A new algorithm is presented for training of multilayer feedforward neural networks by integrating a genetic algorithm with an adaptive conjugate gradient neural network learning algorithm. The parallel hybrid learning algorithm has been implemented in C on an MIMD shared memory machine (Cray Y-MP8/864 supercomputer). It has been applied to two different domains, engineering design and image recognition. The performance of the algorithm has been evaluated by applying it to three examples. The superior convergence property of the parallel hybrid neural network learning algorithm presented in this paper is demonstrated.",1994,19,151,6,False,Computer Science,2830443.0,S. Hung,1750050.0,H. Adeli,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
c23c5edc98cde3a002bd7b588f089f8819e7c470,https://www.semanticscholar.org/paper/c23c5edc98cde3a002bd7b588f089f8819e7c470,Mortality risk score prediction in an elderly population using machine learning.,"Standard practice for prediction often relies on parametric regression methods. Interesting new methods from the machine learning literature have been introduced in epidemiologic studies, such as random forest and neural networks. However, a priori, an investigator will not know which algorithm to select and may wish to try several. Here I apply the super learner, an ensembling machine learning approach that combines multiple algorithms into a single algorithm and returns a prediction function with the best cross-validated mean squared error. Super learning is a generalization of stacking methods. I used super learning in the Study of Physical Performance and Age-Related Changes in Sonomans (SPPARCS) to predict death among 2,066 residents of Sonoma, California, aged 54 years or more during the period 1993-1999. The super learner for predicting death (risk score) improved upon all single algorithms in the collection of algorithms, although its performance was similar to that of several algorithms. Super learner outperformed the worst algorithm (neural networks) by 44% with respect to estimated cross-validated mean squared error and had an R2 value of 0.201. The improvement of super learner over random forest with respect to R2 was approximately 2-fold. Alternatives for risk score prediction include the super learner, which can provide improved performance.",2013,63,138,7,False,Medicine,2054921570.0,S. Rose,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
67b60c720e9691c0d98dbd0b9004e99e6da3fc47,https://www.semanticscholar.org/paper/67b60c720e9691c0d98dbd0b9004e99e6da3fc47,Efficient Vector Representation for Documents through Corruption,"We present an efficient document representation learning framework, Document Vector through Corruption (Doc2VecC). Doc2VecC represents each document as a simple average of word embeddings. It ensures a representation generated as such captures the semantic meanings of the document during learning. A corruption model is included, which introduces a data-dependent regularization that favors informative or rare words while forcing the embeddings of common and non-discriminative ones to be close to zero. Doc2VecC produces significantly better word embeddings than Word2Vec. We compare Doc2VecC with several state-of-the-art document representation learning algorithms. The simple model architecture introduced by Doc2VecC matches or out-performs the state-of-the-art in generating high-quality document representations for sentiment analysis, document classification as well as semantic relatedness tasks. The simplicity of the model enables training on billions of words per hour on a single machine. At the same time, the model is very efficient in generating representations of unseen documents at test time.",2017,37,106,22,False,Computer Science,1743082.0,Minmin Chen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d469fd8152689e71cecfe862f42e9a6e9952d372,https://www.semanticscholar.org/paper/d469fd8152689e71cecfe862f42e9a6e9952d372,Hardware Design of Smart Home Energy Management System With Dynamic Price Response,"The smart grid initiative and electricity market operation drive the development known as demand-side management or controllable load. Home energy management has received increasing interest due to the significant amount of loads in the residential sector. This paper presents a hardware design of smart home energy management system (SHEMS) with the applications of communication, sensing technology, and machine learning algorithm. With the proposed design, consumers can easily achieve a real-time, price-responsive control strategy for residential home loads such as electrical water heater (EWH), heating, ventilation, and air conditioning (HVAC), electrical vehicle (EV), dishwasher, washing machine, and dryer. Also, consumers may interact with suppliers or load serving entities (LSEs) to facilitate the load management at the supplier side. Further, SHEMS is designed with sensors to detect human activities and then a machine learning algorithm is applied to intelligently help consumers reduce total payment on electricity without or with little consumer involvement. Finally, simulation and experiment results are presented based on an actual SHEMS prototype to verify the hardware system.",2013,39,230,5,False,Engineering,3305560.0,Qinran Hu,33480933.0,Fangxing Li,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,
23c9f0d19fad7baf5f68f5ff7c15463f9648443b,https://www.semanticscholar.org/paper/23c9f0d19fad7baf5f68f5ff7c15463f9648443b,Joint Demosaicing and Denoising via Learned Nonparametric Random Fields,"We introduce a machine learning approach to demosaicing, the reconstruction of color images from incomplete color filter array samples. There are two challenges to overcome by a demosaicing method: 1) it needs to model and respect the statistics of natural images in order to reconstruct natural looking images and 2) it should be able to perform well in the presence of noise. To facilitate an objective assessment of current methods, we introduce a public ground truth data set of natural images suitable for research in image demosaicing and denoising. We then use this large data set to develop a machine learning approach to demosaicing. Our proposed method addresses both demosaicing challenges by learning a statistical model of images and noise from hundreds of natural images. The resulting model performs simultaneous demosaicing and denoising. We show that the machine learning approach has a number of benefits: 1) the model is trained to directly optimize a user-specified performance measure such as peak signal-to-noise ratio (PSNR) or structural similarity; 2) we can handle novel color filter array layouts by retraining the model on such layouts; and 3) it outperforms the previous state-of-the-art, in some setups by 0.7-dB PSNR, faithfully reconstructing edges, textures, and smooth areas. Our results demonstrate that in demosaicing and related imaging applications, discriminatively trained machine learning models have the potential for peak performance at comparatively low engineering effort.",2014,71,88,12,True,Mathematics,1783281.0,Daniel Khashabi,2388416.0,S. Nowozin,2137033.0,Jeremy Jancsary,47139824.0,A. Fitzgibbon,,,,,,,,,Computer Science,Medicine,,,,,,,,,,,,,,,,,,,,,,,
7e3224180c274ce8bb64a998ba2aafa6427dfbb0,https://www.semanticscholar.org/paper/7e3224180c274ce8bb64a998ba2aafa6427dfbb0,Kymatio: Scattering Transforms in Python,"The wavelet scattering transform is an invariant signal representation suitable for many signal processing and machine learning applications. We present the Kymatio software package, an easy-to-use, high-performance Python implementation of the scattering transform in 1D, 2D, and 3D that is compatible with modern deep learning frameworks. All transforms may be executed on a GPU (in addition to CPU), offering a considerable speed up over CPU implementations. The package also has a small memory footprint, resulting inefficient memory usage. The source code, documentation, and examples are available undera BSD license at this https URL",2018,20,67,7,False,Computer Science,3357294.0,M. Andreux,3433059.0,Tomás Angles,2969624.0,Georgios Exarchakis,48077877.0,R. Leonarduzzi,51518656.0,G. Rochette,46199268.0,L. Thiry,67004796.0,J. Zarka,1746242.0,S. Mallat,Engineering,Mathematics,2708847.0,J. Andén,1829344.0,Eugene Belilovsky,143627859.0,Joan Bruna,2507441.0,V. Lostanlen,145500870.0,M. Hirn,3306593.0,Edouard Oyallon,66686215.0,Sixhin Zhang,1881241.0,Carmine-Emanuele Cella,1823753.0,Michael Eickenberg,,,,,
64ed5d1ee562207d7e8d9921be981a3a00e50405,https://www.semanticscholar.org/paper/64ed5d1ee562207d7e8d9921be981a3a00e50405,Learning Constraints From Examples,"While constraints are ubiquitous in artificial intelligence and constraints are also commonly used in machine learning and data mining, the problem of learning constraints from examples has received less attention. In this paper, we discuss the problem of constraint learning in detail, indicate some subtle differences with standard machine learning problems, sketch some applications and summarize the state-of-the-art.",2018,50,58,1,True,Computer Science,1740042.0,L. D. Raedt,1702610.0,Andrea Passerini,2580338.0,Stefano Teso,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
00107f0f32068ee03e9e254f712dd0358449e119,https://www.semanticscholar.org/paper/00107f0f32068ee03e9e254f712dd0358449e119,Random Rotation Ensembles,"In machine learning, ensemble methods combine the predictions of multiple base learners to construct more accurate aggregate predictions. Established supervised learning algorithms inject randomness into the construction of the individual base learners in an effort to promote diversity within the resulting ensembles. An undesirable side effect of this approach is that it generally also reduces the accuracy of the base learners. In this paper, we introduce a method that is simple to implement yet general and effective in improving ensemble diversity with only modest impact on the accuracy of the individual base learners. By randomly rotating the feature space prior to inducing the base learners, we achieve favorable aggregate predictions on standard data sets compared to state of the art ensemble methods, most notably for tree-based ensembles, which are particularly sensitive to rotation.",2016,53,104,14,False,Computer Science,33444231.0,R. Blaser,3350586.0,P. Fryzlewicz,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
9bd957c67683bc873998b242b331e9c9d6992db9,https://www.semanticscholar.org/paper/9bd957c67683bc873998b242b331e9c9d6992db9,A review of approaches to identifying patient phenotype cohorts using electronic health records,"Objective To summarize literature describing approaches aimed at automatically identifying patients with a common phenotype. Materials and methods We performed a review of studies describing systems or reporting techniques developed for identifying cohorts of patients with specific phenotypes. Every full text article published in (1) Journal of American Medical Informatics Association, (2) Journal of Biomedical Informatics, (3) Proceedings of the Annual American Medical Informatics Association Symposium, and (4) Proceedings of Clinical Research Informatics Conference within the past 3 years was assessed for inclusion in the review. Only articles using automated techniques were included. Results Ninety-seven articles met our inclusion criteria. Forty-six used natural language processing (NLP)-based techniques, 24 described rule-based systems, 41 used statistical analyses, data mining, or machine learning techniques, while 22 described hybrid systems. Nine articles described the architecture of large-scale systems developed for determining cohort eligibility of patients. Discussion We observe that there is a rise in the number of studies associated with cohort identification using electronic medical records. Statistical analyses or machine learning, followed by NLP techniques, are gaining popularity over the years in comparison with rule-based systems. Conclusions There are a variety of approaches for classifying patients into a particular phenotype. Different techniques and data sources are used, and good performance is reported on datasets at respective institutions. However, no system makes comprehensive use of electronic medical records addressing all of their known weaknesses.",2013,104,388,14,True,Computer Science,1866532.0,Chaitanya P. Shivade,30088877.0,Preethi Raghavan,1398481836.0,E. Fosler-Lussier,1797944.0,P. Embí,2763493.0,Noémie Elhadad,47163349.0,Stephen B. Johnson,145812029.0,A. Lai,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
75c364909914f17791837ec88090262aa6656d3e,https://www.semanticscholar.org/paper/75c364909914f17791837ec88090262aa6656d3e,Big data in IBD: big progress for clinical practice,"IBD is a complex multifactorial inflammatory disease of the gut driven by extrinsic and intrinsic factors, including host genetics, the immune system, environmental factors and the gut microbiome. Technological advancements such as next-generation sequencing, high-throughput omics data generation and molecular networks have catalysed IBD research. The advent of artificial intelligence, in particular, machine learning, and systems biology has opened the avenue for the efficient integration and interpretation of big datasets for discovering clinically translatable knowledge. In this narrative review, we discuss how big data integration and machine learning have been applied to translational IBD research. Approaches such as machine learning may enable patient stratification, prediction of disease progression and therapy responses for fine-tuning treatment options with positive impacts on cost, health and safety. We also outline the challenges and opportunities presented by machine learning and big data in clinical IBD research.",2020,134,67,1,True,Computer Science,11918365.0,N. S. Seyed Tabib,89037982.0,M. Madgwick,47798382.0,P. Sudhakar,6050881.0,B. Verstockt,2961601.0,T. Korcsmáros,3615640.0,S. Vermeire,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
77b5185dafb9e5b884a677a32713e54c253a4e0b,https://www.semanticscholar.org/paper/77b5185dafb9e5b884a677a32713e54c253a4e0b,Improving Performance in Neural Networks Using a Boosting Algorithm,"A boosting algorithm converts a learning machine with error rate less than 50% to one with an arbitrarily low error rate. However, the algorithm discussed here depends on having a large supply of independent training samples. We show how to circumvent this problem and generate an ensemble of learning machines whose performance in optical character recognition problems is dramatically improved over that of a single network. We report the effect of boosting on four databases (all handwritten) consisting of 12,000 digits from segmented ZIP codes from the United State Postal Service (USPS) and the following from the National Institute of Standards and Testing (NIST): 220,000 digits, 45,000 upper case alphas, and 45,000 lower case alphas. We use two performance measures: the raw error rate (no rejects) and the reject rate required to achieve a 1% error rate on the patterns not rejected. Boosting improved performance in some cases by a factor of three.",1992,10,202,4,False,Computer Science,2050470845.0,H. Drucker,1716301.0,R. Schapire,2812486.0,P. Simard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f971658ab845d7573c4bbb760d5e7e5332025254,https://www.semanticscholar.org/paper/f971658ab845d7573c4bbb760d5e7e5332025254,Beyond Data and Model Parallelism for Deep Neural Networks,"The computational requirements for training deep neural networks (DNNs) have grown to the point that it is now standard practice to parallelize training. Existing deep learning systems commonly use data or model parallelism, but unfortunately, these strategies often result in suboptimal parallelization performance. In this paper, we define a more comprehensive search space of parallelization strategies for DNNs called SOAP, which includes strategies to parallelize a DNN in the Sample, Operation, Attribute, and Parameter dimensions. We also propose FlexFlow, a deep learning framework that uses guided randomized search of the SOAP space to find a fast parallelization strategy for a specific parallel machine. To accelerate this search, FlexFlow introduces a novel execution simulator that can accurately predict a parallelization strategy's performance and is three orders of magnitude faster than prior approaches that have to execute each strategy. We evaluate FlexFlow with six real-world DNN benchmarks on two GPU clusters and show that FlexFlow can increase training throughput by up to 3.8x over state-of-the-art approaches, even when including its search time, and also improves scalability.",2018,46,270,33,False,Computer Science,2072782550.0,Zhihao Jia,143834867.0,M. Zaharia,144653825.0,A. Aiken,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5817758f0c0fe5242239fa8fe32aba713c893e11,https://www.semanticscholar.org/paper/5817758f0c0fe5242239fa8fe32aba713c893e11,DeepSynergy: predicting anti-cancer drug synergy with Deep Learning,"Abstract Motivation While drug combination therapies are a well-established concept in cancer treatment, identifying novel synergistic combinations is challenging due to the size of combinatorial space. However, computational approaches have emerged as a time- and cost-efficient way to prioritize combinations to test, based on recently available large-scale combination screening data. Recently, Deep Learning has had an impact in many research areas by achieving new state-of-the-art model performance. However, Deep Learning has not yet been applied to drug synergy prediction, which is the approach we present here, termed DeepSynergy. DeepSynergy uses chemical and genomic information as input information, a normalization strategy to account for input data heterogeneity, and conical layers to model drug synergies. Results DeepSynergy was compared to other machine learning methods such as Gradient Boosting Machines, Random Forests, Support Vector Machines and Elastic Nets on the largest publicly available synergy dataset with respect to mean squared error. DeepSynergy significantly outperformed the other methods with an improvement of 7.2% over the second best method at the prediction of novel drug combinations within the space of explored drugs and cell lines. At this task, the mean Pearson correlation coefficient between the measured and the predicted values of DeepSynergy was 0.73. Applying DeepSynergy for classification of these novel drug combinations resulted in a high predictive performance of an AUC of 0.90. Furthermore, we found that all compared methods exhibit low predictive performance when extrapolating to unexplored drugs or cell lines, which we suggest is due to limitations in the size and diversity of the dataset. We envision that DeepSynergy could be a valuable tool for selecting novel synergistic drug combinations. Availability and implementation DeepSynergy is available via www.bioinf.jku.at/software/DeepSynergy. Supplementary information Supplementary data are available at Bioinformatics online.",2017,78,210,18,True,Computer Science,32764807.0,Kristina Preuer,49350357.0,Richard P. I. Lewis,3308557.0,S. Hochreiter,144917032.0,A. Bender,3044083.0,K. Bulusu,1994964.0,G. Klambauer,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
0f46311c0c7a2c7deabd9ede92aaf6525c5f030b,https://www.semanticscholar.org/paper/0f46311c0c7a2c7deabd9ede92aaf6525c5f030b,SVM selective sampling for ranking with application to data retrieval,"Learning ranking (or preference) functions has been a major issue in the machine learning community and has produced many applications in information retrieval. SVMs (Support Vector Machines) - a classification and regression methodology - have also shown excellent performance in learning ranking functions. They effectively learn ranking functions of high generalization based on the ""large-margin"" principle and also systematically support nonlinear ranking by the ""kernel trick"". In this paper, we propose an SVM selective sampling technique for learning ranking functions. SVM selective sampling (or active learning with SVM) has been studied in the context of classification. Such techniques reduce the labeling effort in learning classification functions by selecting only the most informative samples to be labeled. However, they are not extendable to learning ranking functions, as the labeled data in ranking is relative ordering, or partial orders of data. Our proposed sampling technique effectively learns an accurate SVM ranking function with fewer partial orders. We apply our sampling technique to the data retrieval application, which enables fuzzy search on relational databases by interacting with users for learning their preferences. Experimental results show a significant reduction of the labeling effort in inducing accurate ranking functions.",2005,18,127,9,False,Computer Science,1723357.0,Hwanjo Yu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6e1836fe278b1e9fe8b39f6295d387dc1f4d96e6,https://www.semanticscholar.org/paper/6e1836fe278b1e9fe8b39f6295d387dc1f4d96e6,A machine learning approach to improve congestion control over wireless computer networks,"In this paper, we present the application of machine learning techniques to the improvement of the congestion control of TCP in wired/wireless networks. TCP is sub-optimal in hybrid wired/wireless networks because it reacts in the same way to losses due to congestion and losses due to link errors. We thus propose to use machine learning techniques to build automatically a loss classifier from a database obtained by simulations of random network topologies. Several machine learning algorithms are compared for this task and the best method for this application turns out to be decision tree boosting. It outperforms ad hoc classifiers proposed in the networking literature.",2004,17,58,2,True,Computer Science,50206577.0,P. Geurts,1927410.0,Ibtissam El Khayat,143742222.0,G. Leduc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fb76df7b3e0fb9353b5d8aabb2a1e1468f6d2878,https://www.semanticscholar.org/paper/fb76df7b3e0fb9353b5d8aabb2a1e1468f6d2878,SOIL MOISTURE PREDICTION USING SUPPORT VECTOR MACHINES 1,"ABSTRACT: Herein, a recently developed methodology, Support Vector Machines (SVMs), is presented and applied to the challenge of soil moisture prediction. Support Vector Machines are derived from statistical learning theory and can be used to predict a quantity forward in time based on training that uses past data, hence providing a statistically sound approach to solving inverse problems. The principal strength of SVMs lies in the fact that they employ Structural Risk Minimization (SRM) instead of Empirical Risk Minimization (ERM). The SVMs formulate a quadratic optimization problem that ensures a global optimum, which makes them superior to traditional learning algorithms such as Artificial Neural Networks (ANNs). The resulting model is sparse and not characterized by the “curse of dimensionality.” Soil moisture distribution and variation is helpful in predicting and understanding various hydrologic processes, including weather changes, energy and moisture fluxes, drought, irrigation scheduling, and rainfall/runoff generation. Soil moisture and meteorological data are used to generate SVM predictions for four and seven days ahead. Predictions show good agreement with actual soil moisture measurements. Results from the SVM modeling are compared with predictions obtained from ANN models and show that SVM models performed better for soil moisture forecasting than ANN models.",2006,31,217,7,False,Geology,143700349.0,M. Gill,6177758.0,T. Asefa,5677979.0,M. Kemblowski,38543517.0,M. McKee,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e5e41ca6d5ebbf5f8ef1c77791fa4c75ef1ceb1b,https://www.semanticscholar.org/paper/e5e41ca6d5ebbf5f8ef1c77791fa4c75ef1ceb1b,Secure and Robust Machine Learning for Healthcare: A Survey,"Recent years have witnessed widespread adoption of machine learning (ML)/deep learning (DL) techniques due to their superior performance for a variety of healthcare applications ranging from the prediction of cardiac arrest from one-dimensional heart signals to computer-aided diagnosis (CADx) using multi-dimensional medical images. Notwithstanding the impressive performance of ML/DL, there are still lingering doubts regarding the robustness of ML/DL in healthcare settings (which is traditionally considered quite challenging due to the myriad security and privacy issues involved), especially in light of recent results that have shown that ML/DL are vulnerable to adversarial attacks. In this paper, we present an overview of various application areas in healthcare that leverage such techniques from security and privacy point of view and present associated challenges. In addition, we present potential methods to ensure secure and privacy-preserving ML for healthcare applications. Finally, we provide insight into the current research challenges and promising directions for future research.",2020,211,110,3,True,Computer Science,9514351.0,A. Qayyum,1734917.0,Junaid Qadir,144769156.0,M. Bilal,1404786833.0,A. Al-Fuqaha,,,,,,,,,Medicine,Engineering,,,,,,,,,,,,,,,,,,,,,,,Mathematics
33987e58b45755a6120905ce582fc9cbec434763,https://www.semanticscholar.org/paper/33987e58b45755a6120905ce582fc9cbec434763,A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks,"Today’s smartphone users face a security dilemma: many apps they install operate on privacy-sensitive data, although 
they might originate from developers whose trustworthiness is hard to judge. Researchers have addressed the problem with more and more sophisticated static and dynamic analysis tools as an aid to assess how apps use private user data. Those tools, however, rely on the manual configuration of lists of sources of sensitive data as well as sinks which might leak data to untrusted observers. Such lists are hard to come by. We thus propose SUSI, a novel machine-learning guided approach for identifying sources and sinks directly from the code of any Android API. Given a training set of hand-annotated sources and sinks, SUSI identifies other sources and sinks in the entire API. To provide more fine-grained information, SUSI further categorizes the sources (e.g., unique identifier, location information, etc.) and sinks (e.g., network, file, etc.). For Android 4.2, SUSI identifies hundreds of sources and sinks with over 92% accuracy, many of which are missed by current information-flow tracking tools. An evaluation of about 11,000 malware samples confirms that many of these sources and sinks are indeed used. We furthermore show that SUSI can reliably classify sources and sinks even in new, previously unseen Android versions and components like Google Glass or the Chromecast API.",2014,46,312,38,True,Computer Science,2864202.0,Siegfried Rasthofer,2524362.0,Steven Arzt,1752222.0,E. Bodden,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cf4bbe1e39c6f0f88aa69da2a95125b47de0ec7b,https://www.semanticscholar.org/paper/cf4bbe1e39c6f0f88aa69da2a95125b47de0ec7b,Explaining Explanations in AI,"Recent work on interpretability in machine learning and AI has focused on the building of simplified models that approximate the true criteria used to make decisions. These models are a useful pedagogical device for teaching trained professionals how to predict what decisions will be made by the complex system, and most importantly how the system might break. However, when considering any such model it's important to remember Box's maxim that ""All models are wrong but some are useful."" We focus on the distinction between these models and explanations in philosophy and sociology. These models can be understood as a ""do it yourself kit"" for explanations, allowing a practitioner to directly answer ""what if questions"" or generate contrastive explanations without external assistance. Although a valuable ability, giving these models as explanations appears more difficult than necessary, and other forms of explanation may not have the same trade-offs. We contrast the different schools of thought on what makes an explanation, and suggest that machine learning might benefit from viewing the problem more broadly.",2018,87,387,28,True,Computer Science,3127701.0,B. Mittelstadt,2052380526.0,Chris Russell,12806133.0,Sandra Wachter,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
663108c231afdb91ca1e8af8ef8a6a937b5a6e20,https://www.semanticscholar.org/paper/663108c231afdb91ca1e8af8ef8a6a937b5a6e20,Automated Machine Learning: State-of-The-Art and Open Challenges,"With the continuous and vast increase in the amount of data in our digital world, it has been acknowledged that the number of knowledgeable data scientists can not scale to address these challenges. Thus, there was a crucial need for automating the process of building good machine learning models. In the last few years, several techniques and frameworks have been introduced to tackle the challenge of automating the process of Combined Algorithm Selection and Hyper-parameter tuning (CASH) in the machine learning domain. The main aim of these techniques is to reduce the role of the human in the loop and fill the gap for non-expert machine learning users by playing the role of the domain expert. In this paper, we present a comprehensive survey for the state-of-the-art efforts in tackling the CASH problem. In addition, we highlight the research work of automating the other steps of the full complex machine learning pipeline (AutoML) from data understanding till model deployment. Furthermore, we provide comprehensive coverage for the various tools and frameworks that have been introduced in this domain. Finally, we discuss some of the research directions and open challenges that need to be addressed in order to achieve the vision and goals of the AutoML process.",2019,145,77,5,False,Computer Science,1805967.0,Radwa El Shawi,2097409976.0,Mohamed Maher,1783693.0,S. Sakr,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
6af34ec6a8899f7316cb2b5f731b3db0412f7e10,https://www.semanticscholar.org/paper/6af34ec6a8899f7316cb2b5f731b3db0412f7e10,ROC analysis of classifiers in machine learning: A survey,"The use of ROC Receiver Operating Characteristics analysis as a tool for evaluating the performance of classification models in machine learning has been increasing in the last decade. Among the most notable advances in this area are the extension of two-class ROC analysis to the multi-class case as well as the employment of ROC analysis in cost-sensitive learning. Methods now exist which take instance-varying costs into account. The purpose of our paper is to present a survey of this field with the aim of gathering important achievements in one place. In the paper, we present application areas of the ROC analysis in machine learning, describe its problems and challenges and provide a summarized list of alternative approaches to ROC analysis. In addition to presented theory, we also provide a couple of examples intended to illustrate the described approaches.",2013,65,87,4,False,Computer Science,2786043.0,Matjaz Majnik,2025112.0,Z. Bosnić,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aad973a0028e0f41c0d1fc25e5ee1015ddf25a50,https://www.semanticscholar.org/paper/aad973a0028e0f41c0d1fc25e5ee1015ddf25a50,Detecting Accounting Fraud in Publicly Traded U.S. Firms Using a Machine Learning Approach,"We develop a state‐of‐the‐art fraud prediction model using a machine learning approach. We demonstrate the value of combining domain knowledge and machine learning methods in model building. We select our model input based on existing accounting theories, but we differ from prior accounting research by using raw accounting numbers rather than financial ratios. We employ one of the most powerful machine learning methods, ensemble learning, rather than the commonly used method of logistic regression. To assess the performance of fraud prediction models, we introduce a new performance evaluation metric commonly used in ranking problems that is more appropriate for the fraud prediction task. Starting with an identical set of theory‐motivated raw accounting numbers, we show that our new fraud prediction model outperforms two benchmark models by a large margin: the Dechow et al. logistic regression model based on financial ratios, and the Cecchini et al. support‐vector‐machine model with a financial kernel that maps raw accounting numbers into a broader set of ratios.",2020,74,81,9,False,Economics,2075376652.0,Yang Bao,3520523.0,B. Ke,2156072566.0,Bin Li,2107621779.0,Y. J. Yu,2159190859.0,Jie Zhang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
5631c90289822891c59282c640d012b8e76e6060,https://www.semanticscholar.org/paper/5631c90289822891c59282c640d012b8e76e6060,A machine learning approach for filtering Monte Carlo noise,"The most successful approaches for filtering Monte Carlo noise use feature-based filters (e.g., cross-bilateral and cross non-local means filters) that exploit additional scene features such as world positions and shading normals. However, their main challenge is finding the optimal weights for each feature in the filter to reduce noise but preserve scene detail. In this paper, we observe there is a complex relationship between the noisy scene data and the ideal filter parameters, and propose to learn this relationship using a nonlinear regression model. To do this, we use a multilayer perceptron neural network and combine it with a matching filter during both training and testing. To use our framework, we first train it in an offline process on a set of noisy images of scenes with a variety of distributed effects. Then at run-time, the trained network can be used to drive the filter parameters for new scenes to produce filtered images that approximate the ground truth. We demonstrate that our trained network can generate filtered images in only a few seconds that are superior to previous approaches on a wide range of distributed effects such as depth of field, motion blur, area lighting, glossy reflections, and global illumination.",2015,59,139,12,False,Computer Science,1717070.0,N. Kalantari,2770981.0,Steve Bako,143881938.0,P. Sen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
d012519a924e41aa7ff49d9b6be58033bd60fd9c,https://www.semanticscholar.org/paper/d012519a924e41aa7ff49d9b6be58033bd60fd9c,Predicting hospital admission at emergency department triage using machine learning,"Objective To predict hospital admission at the time of ED triage using patient history in addition to information collected at triage. Methods This retrospective study included all adult ED visits between March 2014 and July 2017 from one academic and two community emergency rooms that resulted in either admission or discharge. A total of 972 variables were extracted per patient visit. Samples were randomly partitioned into training (80%), validation (10%), and test (10%) sets. We trained a series of nine binary classifiers using logistic regression (LR), gradient boosting (XGBoost), and deep neural networks (DNN) on three dataset types: one using only triage information, one using only patient history, and one using the full set of variables. Next, we tested the potential benefit of additional training samples by training models on increasing fractions of our data. Lastly, variables of importance were identified using information gain as a metric to create a low-dimensional model. Results A total of 560,486 patient visits were included in the study, with an overall admission risk of 29.7%. Models trained on triage information yielded a test AUC of 0.87 for LR (95% CI 0.86–0.87), 0.87 for XGBoost (95% CI 0.87–0.88) and 0.87 for DNN (95% CI 0.87–0.88). Models trained on patient history yielded an AUC of 0.86 for LR (95% CI 0.86–0.87), 0.87 for XGBoost (95% CI 0.87–0.87) and 0.87 for DNN (95% CI 0.87–0.88). Models trained on the full set of variables yielded an AUC of 0.91 for LR (95% CI 0.91–0.91), 0.92 for XGBoost (95% CI 0.92–0.93) and 0.92 for DNN (95% CI 0.92–0.92). All algorithms reached maximum performance at 50% of the training set or less. A low-dimensional XGBoost model built on ESI level, outpatient medication counts, demographics, and hospital usage statistics yielded an AUC of 0.91 (95% CI 0.91–0.91). Conclusion Machine learning can robustly predict hospital admission using triage information and patient history. The addition of historical information improves predictive performance significantly compared to using triage information alone, highlighting the need to incorporate these variables into prediction models.",2018,60,126,8,True,Medicine,47469641.0,W. Hong,3013842.0,A. Haimovich,2107598798.0,R. A. Taylor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2f4e42ab1368b83e38e3011fcec4edb57267b5d2,https://www.semanticscholar.org/paper/2f4e42ab1368b83e38e3011fcec4edb57267b5d2,Manipulating and Measuring Model Interpretability,"With machine learning models being increasingly used to aid decision making even in high-stakes domains, there has been a growing interest in developing interpretable models. Although many supposedly interpretable models have been proposed, there have been relatively few experimental studies investigating whether these models achieve their intended effects, such as making people more closely follow a model’s predictions when it is beneficial for them to do so or enabling them to detect when a model has made a mistake. We present a sequence of pre-registered experiments (N = 3, 800) in which we showed participants functionally identical models that varied only in two factors commonly thought to make machine learning models more or less interpretable: the number of features and the transparency of the model (i.e., whether the model internals are clear or black box). Predictably, participants who saw a clear model with few features could better simulate the model’s predictions. However, we did not find that participants more closely followed its predictions. Furthermore, showing participants a clear model meant that they were less able to detect and correct for the model’s sizable mistakes, seemingly due to information overload. These counterintuitive findings emphasize the importance of testing over intuition when developing interpretable models.",2018,134,378,38,True,Computer Science,1405364889.0,Forough Poursabzi-Sangdeh,2463533.0,D. Goldstein,40368603.0,J. Hofman,4006636.0,Jennifer Wortman Vaughan,1831395.0,H. Wallach,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a15745129b1a25012f16745f53512d9558f04c8a,https://www.semanticscholar.org/paper/a15745129b1a25012f16745f53512d9558f04c8a,Interpretable Predictions of Clinical Outcomes with An Attention-based Recurrent Neural Network,"The increasing accumulation of healthcare data provides researchers with ample opportunities to build machine learning approaches for clinical decision support and to improve the quality of health care. Several studies have developed conventional machine learning approaches that rely heavily on manual feature engineering and result in task-specific models for health care. In contrast, healthcare researchers have begun to use deep learning, which has emerged as a revolutionary machine learning technique that obviates manual feature engineering but still achieves impressive results in research fields such as image classification. However, few of them have addressed the lack of the interpretability of deep learning models although interpretability is essential for the successful adoption of machine learning approaches by healthcare communities. In addition, the unique characteristics of healthcare data such as high dimensionality and temporal dependencies pose challenges for building models on healthcare data. To address these challenges, we develop a gated recurrent unit-based recurrent neural network with hierarchical attention for mortality prediction, and then, using the diagnostic codes from the Medical Information Mart for Intensive Care, we evaluate the model. We find that the prediction accuracy of the model outperforms baseline models and demonstrate the interpretability of the model in visualizations.",2017,34,78,7,True,Computer Science,2295696.0,Ying Sha,152176821.0,May D. Wang,,,,,,,,,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
ed2b19734b7001c324e711524f39225e9cbb46af,https://www.semanticscholar.org/paper/ed2b19734b7001c324e711524f39225e9cbb46af,Hybrid Deep Learning for Face Verification,"This paper proposes a hybrid convolutional network (ConvNet)-Restricted Boltzmann Machine (RBM) model for face verification in wild conditions. A key contribution of this work is to directly learn relational visual features, which indicate identity similarities, from raw pixels of face pairs with a hybrid deep network. The deep ConvNets in our model mimic the primary visual cortex to jointly extract local relational visual features from two face images compared with the learned filter pairs. These relational features are further processed through multiple layers to extract high-level and global features. Multiple groups of ConvNets are constructed in order to achieve robustness and characterize face similarities from different aspects. The top-layer RBM performs inference from complementary high-level features extracted from different ConvNet groups with a two-level average pooling hierarchy. The entire hybrid deep network is jointly fine-tuned to optimize for the task of face verification. Our model achieves competitive face verification performance on the LFW dataset.",2013,71,370,16,True,Medicine,2143795572.0,Yi Sun,31843833.0,Xiaogang Wang,50295995.0,Xiaoou Tang,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,
c0677fc798f5acc5db3d8eaa0a21dd8e8b0b44fa,https://www.semanticscholar.org/paper/c0677fc798f5acc5db3d8eaa0a21dd8e8b0b44fa,"Deep-Learning Methods for Parallel Magnetic Resonance Imaging Reconstruction: A Survey of the Current Approaches, Trends, and Issues","Following the success of deep learning in a wide range of applications, neural network-based machine-learning techniques have received interest as a means of accelerating magnetic resonance imaging (MRI). A number of ideas inspired by deeplearning techniques for computer vision and image processing have been successfully applied to nonlinear image reconstruction in the spirit of compressed sensing for both low-dose computed tomography and accelerated MRI. The additional integration of multicoil information to recover missing k-space lines in the MRI reconstruction process is studied less frequently, even though it is the de facto standard for the currently used accelerated MR acquisitions. This article provides an overview of the recent machine-learning approaches that have been proposed specifically for improving parallel imaging. A general background introduction to parallel MRI is given and structured around the classical view of image- and k-space-based methods. Linear and nonlinear methods are covered, followed by a discussion of the recent efforts to further improve parallel imaging using machine learning and, specifically, artificial neural networks. Image domain-based techniques that introduce improved regularizers are covered as well as k-space-based methods, where the focus is on better interpolation strategies using neural networks. Issues and open problems are discussed and recent efforts for producing open data sets and benchmarks for the community are examined.",2020,41,128,1,False,Computer Science,3597472.0,F. Knoll,3366210.0,Kerstin Hammernik,2115812521.0,Chi Zhang,3292782.0,S. Moeller,1730097.0,T. Pock,2827060.0,D. Sodickson,3307984.0,M. Akçakaya,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
98fd96e1f2dd457a0ae35fb9512c4a8c2cd431b4,https://www.semanticscholar.org/paper/98fd96e1f2dd457a0ae35fb9512c4a8c2cd431b4,A Metalearning Approach to Processing the Scope of Negation,"Finding negation signals and their scope in text is an important subtask in information extraction. In this paper we present a machine learning system that finds the scope of negation in biomedical texts. The system combines several classifiers and works in two phases. To investigate the robustness of the approach, the system is tested on the three subcorpora of the BioScope corpus representing different text types. It achieves the best results to date for this task, with an error reduction of 32.07% compared to current state of the art results.",2009,27,148,16,True,Computer Science,1844868.0,R. Morante,1735272.0,Walter Daelemans,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0d6ef817813d04a3b3ec6c3ce008e104fb3e587a,https://www.semanticscholar.org/paper/0d6ef817813d04a3b3ec6c3ce008e104fb3e587a,Classification Based on Decision Tree Algorithm for Machine Learning,"Decision tree classifiers are regarded to be a standout of the most well-known methods to data classification representation of classifiers. Different researchers from various fields and backgrounds have considered the problem of extending a decision tree from available data, such as machine study, pattern recognition, and statistics. In various fields such as medical disease analysis, text classification, user smartphone classification, images, and many more the employment of Decision tree classifiers has been proposed in many ways. This paper provides a detailed approach to the decision trees. Furthermore, paper specifics, such as algorithms/approaches used, datasets, and outcomes achieved, are evaluated and outlined comprehensively. In addition, all of the approaches analyzed were discussed to illustrate the themes of the authors and identify the most accurate classifiers. As a result, the uses of different types of datasets are discussed and their findings are analyzed.",2021,85,144,7,True,Computer Science,2087620751.0,Bahzad Charbuty,35323115.0,A. Abdulazeez,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52e844b5cc587dfb9641f74f35a3fbc1af4cd4ee,https://www.semanticscholar.org/paper/52e844b5cc587dfb9641f74f35a3fbc1af4cd4ee,Achieving standards in urban systemic reform: An example of a sixth grade project‐based science curriculum,"A challenge for urban systemic reform initiatives in science education has been to achieve local, state, and national standards for teaching and learning. We have collaborated with teachers in the Detroit Public School System to design project-based curriculum materials that contextualize the learning of science in meaningful real-world problems, engage students in science inquiry, and use learning tech- nologies. We present a sixth grade project-based science unit in which students explored the driving question ''How Do Machines Help Me Build Big Things?'' and address the science learning goals of balanced and unbalanced forces, simple and complex machines, and mechanical advantage. Twenty-four teachers and over 2500 students in Detroit participated in enactments of this project over 4 years. Student learning outcomes were determined for the three learning goals and inquiry process skills using pre- and postachievement tests. Achievement outcomes as measured by the pre/posttest show significant and con- sistently high learning gains, even as participation in the project increased to include greater numbers of teachers and students in successive enactments, and leadership of the professional development support for this project transitioned from university researchers to district teacher leaders. These results illustrate that materials which contextualize learning and support student inquiry as part of an urban systemic reform effort can promote learning of important and meaningful science content aligned with standards. 2004 Wiley Periodicals, Inc. J Res Sci Teach 41: 669-692, 2004",2004,51,134,6,False,Sociology,1965080.0,Ann E. Rivet,1794213.0,J. Krajcik,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
dcaf35c5accca75b69f3909566c54cf77ea45f34,https://www.semanticscholar.org/paper/dcaf35c5accca75b69f3909566c54cf77ea45f34,I tried a bunch of things: The dangers of unexpected overfitting in classification of brain data,"Machine learning is a powerful set of techniques that has enhanced the abilities of neuroscientists to interpret information collected through EEG, fMRI, MEG, and PET data. With these new techniques come new dangers of overfitting that are not well understood by the neuroscience community. In this article, we use Support Vector Machine (SVM) classifiers, and genetic algorithms to demonstrate the ease by which overfitting can occur, despite the use of cross validation. We demonstrate that comparable and non-generalizable results can be obtained on informative and non-informative (i.e. random) data by iteratively modifying hyperparameters in seemingly innocuous ways. We recommend a number of techniques for limiting overfitting, such as lock boxes, blind analyses, and pre-registrations. These techniques, although uncommon in neuroscience applications, are common in many other fields that use machine learning, including computer science and physics. Adopting similar safeguards is critical for ensuring the robustness of machine-learning techniques.",2016,41,76,3,True,Biology,3207240.0,Michael J. Skocik,2106809868.0,John Collins,1404640530.0,Chloe Callahan-Flintoft,145042515.0,H. Bowman,46520750.0,B. Wyble,,,,,,,Medicine,Computer Science,,,,,,,,,,,,,,,,,,,,,,,
76f12afb768f0b7e52bbb96a6f8ae91b1804cd27,https://www.semanticscholar.org/paper/76f12afb768f0b7e52bbb96a6f8ae91b1804cd27,Network Traffic Classification Using K-means Clustering,"Network traffic classification and application identification provide important benefits for IP network engineering, management and control and other key domains. Current popular methods, such as port-based and payload-based, have shown some disadvantages, and the machine learning based method is a potential one. The traffic is classified according to the payload-independent statistical characters. This paper introduces the different levels in network traffic-analysis and the relevant knowledge in machine learning domain, analysis the problems of port-based and payload-based methods in traffic classification. Considering the priority of the machine learning-based method, we experiment with unsupervised K-means to evaluate the efficiency and performance. We adopt feature selection to find an optimal feature set and log transformation to improve the accuracy. The experimental results on different datasets convey that the method can obtain up to 80% overall accuracy, and, after a log transformation, the accuracy is improved to 90% or more.",2007,43,91,6,False,Computer Science,90163153.0,Liu Yingqiu,2113556624.0,Li Wei,104185288.0,Lin Yunchun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
256b7cc35bc110c3a34c50669c50ccec60474680,https://www.semanticscholar.org/paper/256b7cc35bc110c3a34c50669c50ccec60474680,Physics‐Constrained Machine Learning of Evapotranspiration,"Estimating ecosystem evapotranspiration (ET) is important to understanding the global water cycle and to study land‐atmosphere interactions. We developed a physics constrained machine learning (ML) model (hybrid model) to estimate latent heat flux (LE), which conserves the surface energy budget. By comparing model predictions with observations at 82 eddy covariance tower sites, our hybrid model shows similar performance to the pure ML model in terms of mean metrics (e.g., mean absolute percent errors) but, importantly, the hybrid model conserves the surface energy balance, while the pure ML model does not. A second key result is that the hybrid model extrapolates much better than the pure ML model, emphasizing the benefits of combining physics with ML for increased generalizations. The hybrid model allows inferring the structural dependence of ET and surface resistance (rs), and we find that vegetation height and soil moisture are the main regulators of ET and rs.",2019,88,66,3,False,,2118226069.0,W. Zhao,15572823.0,P. Gentine,2530948.0,M. Reichstein,2118389081.0,Yao Zhang,49219305.0,Sha Zhou,34496874.0,Yeqiang Wen,30772456.0,Changjie Lin,2144433379.0,X. Li,,,5314691.0,G. Qiu,,,,,,,,,,,,,,,,,,,,,
d0a41bf42ece9a2ff9140b0240d52a8248f2f928,https://www.semanticscholar.org/paper/d0a41bf42ece9a2ff9140b0240d52a8248f2f928,Exposing Digital Image Forgeries by Illumination Color Classification,"In this paper, we tend to analyze one amongst the foremost common styles of photographic manipulation,called image composition or splice. We tend to propose a forgery detection methodology that exploits refinedinconsistencies within the color of the illumination of pictures. Our approach is machine-learning primarily basedand needs borderline user interaction. The technique is applicable to pictures containing 2 or a lot of folks and needsno professional interaction for the meddling call. To attain this, we tend to incorporate info from physicsandstatistical-based fuel estimators on image regions of comparable material. From these fuel estimates, we tend toextract texture- and edge-based options that square measure then provided to a machine-learning approach forautomatic decision-making. The classification performance victimization associate degree SVM meta-fusion classifieris promising.",2015,15,173,40,False,Computer Science,49905735.0,Shaziya Khan,97312618.0,S. S. Kulkarni,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fc3aa939cae2792c65a10d11704c3405635da13e,https://www.semanticscholar.org/paper/fc3aa939cae2792c65a10d11704c3405635da13e,"Big Data, Data Mining, and Machine Learning: Value Creation for Business Leaders and Practitioners","With big data analytics comes big insights into profitability Big data is big business. But having the data and the computational power to process it isn't nearly enough to produce meaningful results. Big Data, Data Mining, and Machine Learning: Value Creation for Business Leaders and Practitioners is a complete resource for technology and marketing executives looking to cut through the hype and produce real results that hit the bottom line. Providing an engaging, thorough overview of the current state of big data analytics and the growing trend toward high performance computing architectures, the book is a detail-driven look into how big data analytics can be leveraged to foster positive change and drive efficiency. With continued exponential growth in data and ever more competitive markets, businesses must adapt quickly to gain every competitive advantage available. Big data analytics can serve as the linchpin for initiatives that drive business, but only if the underlying technology and analysis is fully understood and appreciated by engaged stakeholders. This book provides a view into the topic that executives, managers, and practitioners require, and includes: A complete overview of big data and its notable characteristics Details on high performance computing architectures for analytics, massively parallel processing (MPP), and in-memory databases Comprehensive coverage of data mining, text analytics, and machine learning algorithms A discussion of explanatory and predictive modeling, and how they can be applied to decision-making processes Big Data, Data Mining, and Machine Learning provides technology and marketing executives with the complete resource that has been notably absent from the veritable libraries of published books on the topic. Take control of your organization's big data analytics to produce real results with a resource that is comprehensive in scope and light on hyperbole.",2014,5,178,6,False,Engineering,46936957.0,J. Dean,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12d7f31813a3d4336cfe6e9d6e3c8b7797b39b99,https://www.semanticscholar.org/paper/12d7f31813a3d4336cfe6e9d6e3c8b7797b39b99,Machine Learning With AIBO Robots in the Four-Legged League of RoboCup,"Robot learning is a growing area of research at the intersection of robotics and machine learning. The main contributions of this paper include a review of how machine learning has been used on Sony AIBO robots and at RoboCup, with a focus on the four-legged league during the years 1998-2004. The review shows that the application-oriented use of machine learning in the four-legged league was still conservative and restricted to a few well-known and easy-to-use methods such as standard decision trees, evolutionary hill climbing, and support vector machines. Method-oriented spin-off studies emerged more frequently and increasingly addressed new and advanced machine learning techniques. Further, the paper presents some details about the growing impact of machine learning in the software system developed by the authors' robot soccer team-the NUbots",2007,146,40,0,True,Computer Science,1716539.0,S. Chalup,2619228.0,Craig L. Murch,2072708240.0,Michael J. Quinlan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79bd2319c53eaa92c456ede0da22942f4197bfd7,https://www.semanticscholar.org/paper/79bd2319c53eaa92c456ede0da22942f4197bfd7,Secure Federated Matrix Factorization,"To protect user privacy and meet law regulations, federated (machine) learning is obtaining vast interests in recent years. The key principle of federated learning is training a machine learning model without needing to know each user’s personal raw private data. In this article, we propose a secure matrix factorization framework under the federated learning setting, called FedMF. First, we design a user-level distributed matrix factorization framework where the model can be learned when each user only uploads the gradient information (instead of the raw preference data) to the server. While gradient information seems secure, we prove that it could still leak users’ raw data. To this end, we enhance the distributed matrix factorization framework with homomorphic encryption. We implement the prototype of FedMF and test it with a real movie rating dataset. Results verify the feasibility of FedMF. We also discuss the challenges for applying FedMF in practice for future research.",2019,28,108,26,True,Computer Science,2064208321.0,Di Chai,1690696.0,Leye Wang,40611817.0,Kai Chen,153096457.0,Qiang Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c9bd15c7838c1d3cdd5f5113a2efd9440f86b3da,https://www.semanticscholar.org/paper/c9bd15c7838c1d3cdd5f5113a2efd9440f86b3da,English Conversational Telephone Speech Recognition by Humans and Machines,"One of the most difficult speech recognition tasks is accurate recognition of human to human communication. Advances in deep learning over the last few years have produced major speech recognition improvements on the representative Switchboard conversational corpus. Word error rates that just a few years ago were 14% have dropped to 8.0%, then 6.6% and most recently 5.8%, and are now believed to be within striking range of human performance. This then raises two issues - what IS human performance, and how far down can we still drive speech recognition error rates? A recent paper by Microsoft suggests that we have already achieved human performance. In trying to verify this statement, we performed an independent set of human performance measurements on two conversational tasks and found that human performance may be considerably better than what was earlier reported, giving the community a significantly harder goal to achieve. We also report on our own efforts in this area, presenting a set of acoustic and language modeling techniques that lowered the word error rate of our own English conversational telephone LVCSR system to the level of 5.5%/10.3% on the Switchboard/CallHome subsets of the Hub5 2000 evaluation, which - at least at the writing of this paper - is a new performance milestone (albeit not at what we measure to be human performance!). On the acoustic side, we use a score fusion of three models: one LSTM with multiple feature inputs, a second LSTM trained with speaker-adversarial multi-task learning and a third residual net (ResNet) with 25 convolutional layers and time-dilated convolutions. On the language modeling side, we use word and character LSTMs and convolutional WaveNet-style language models.",2017,30,335,15,True,Computer Science,1698208.0,G. Saon,1787226.0,Gakuto Kurata,2500466.0,Tom Sercu,3104038.0,Kartik Audhkhasi,152809214.0,Samuel Thomas,1780137.0,D. Dimitriadis,2357983.0,Xiaodong Cui,1720857.0,B. Ramabhadran,,,1774515.0,M. Picheny,47965835.0,L. Lim,9917359.0,Bergul Roomi,2055178701.0,Phil Hall,,,,,,,,,,,,,,,
fada7c9bf6b7098ae187d8e4e5a482a6a61c377e,https://www.semanticscholar.org/paper/fada7c9bf6b7098ae187d8e4e5a482a6a61c377e,Deep Machine Learning and Neural Networks: An Overview,"Deep learning is a technique of machine learning in artificial intelligence area. Deep learning in a refined ""machine learning"" algorithm that far surpasses a considerable lot of its forerunners in its capacities to perceive syllables and picture. Deep learning is as of now a greatly dynamic examination territory in machine learning and example acknowledgment society. It has increased colossal triumphs in an expansive zone of utilizations, for example, speech recognition, computer vision and natural language processing and numerous industry item. Neural network is used to implement the machine learning or to design intelligent machines. In this paper brief introduction to all machine learning paradigm and application area of deep machine learning and different types of neural networks with applications is discussed.",2016,22,34,2,True,Computer Science,71660315.0,C. Mishra,66594936.0,D. Gupta,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
40d626ee930868b9e502e8c7d223192020b8c01d,https://www.semanticscholar.org/paper/40d626ee930868b9e502e8c7d223192020b8c01d,Infinite SVM: a Dirichlet Process Mixture of Large-margin Kernel Machines,"We present Infinite SVM (iSVM), a Dirichlet process mixture of large-margin kernel machines for multi-way classification. An iSVM enjoys the advantages of both Bayesian non-parametrics in handling the unknown number of mixing components, and large-margin kernel machines in robustly capturing local nonlinearity of complex data. We develop an efficient variational learning algorithm for posterior inference of iSVM, and we demonstrate the advantages of iSVM over Dirichlet process mixture of generalized linear models and other benchmarks on both synthetic and real Flickr image classification datasets.",2011,30,62,2,False,Computer Science,145254043.0,Jun Zhu,1406245631.0,Ning Chen,143977260.0,E. Xing,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
f13ba8f58399b91fd0ecd86f68089d5a305886df,https://www.semanticscholar.org/paper/f13ba8f58399b91fd0ecd86f68089d5a305886df,Using Learning for Approximation in Stochastic Processes,"To monitor or control a stochastic dynamic system, we need to reason about its current state. Exact inference for this task requires that we maintain a complete joint probability distribution over the possible states, an impossible requirement for most processes. Stochastic simulation algorithms provide an alternative solution by approximating the distribution at time t via a (relatively small) set of samples. The time t samples are used as the basis for generating the samples at time t + 1. However, since only existing samples are used as the basis for the next sampling phase, new parts of the space are never explored. We propose an approach whereby we try to generalize from the time t samples to unsampled regions of the state space. Thus, these samples are used as data for learning a distribution over the states at time t, which is then used to generate the time t+1 samples. We examine different representations for a distribution, including density trees, Bayesian networks, and tree-structured Bayesian networks, and evaluate their appropriateness to the task. The machine learning perspective allows us to examine issues such as the tradeoffs of using more complex models, and to utilize important techniques such as regularization and priors. We validate the performance of our algorithm on both artificial and real domains, and show significant improvement in accuracy over the existing approach.",1998,20,101,5,False,Mathematics,1736370.0,D. Koller,2101099812.0,Raya Fratkina,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,
b6bc0e56cfd57b3571adc469e2d830474b82c66e,https://www.semanticscholar.org/paper/b6bc0e56cfd57b3571adc469e2d830474b82c66e,Experimental Phase Estimation Enhanced By Machine Learning,"Phase estimation protocols provide a fundamental benchmark for the field of quantum metrology. The latter represents one of the most relevant applications of quantum theory, potentially enabling the capability of measuring unknown physical parameters with improved precision over classical strategies. Within this context, most theoretical and experimental studies have focused on determining the fundamental bounds and how to achieve them in the asymptotic regime where a large number of resources is employed. However, in most applications it is necessary to achieve optimal precisions by performing only a limited number of measurements. To this end, machine learning techniques can be applied as a powerful optimization tool. Here, we implement experimentally single-photon adaptive phase estimation protocols enhanced by machine learning, showing the capability of reaching optimal precision after a small number of trials. In particular, we introduce a new approach for Bayesian estimation that exhibit best performances for very low number of photons N. Furthermore, we study the resilience to noise of the tested methods, showing that the optimized Bayesian approach is very robust in the presence of imperfections. Application of this methodology can be envisaged in the more general multiparameter case, that represents a paradigmatic scenario for several tasks including imaging or Hamiltonian learning.",2017,112,64,3,True,Physics,32687701.0,Alessandro Lumino,27067685.0,E. Polino,26947571.0,A. S. Rab,152872062.0,G. Milani,35933774.0,N. Spagnolo,3253856.0,N. Wiebe,102982226.0,F. Sciarrino,,,Computer Science,Mathematics,,,,,,,,,,,,,,,,,,,,,,,
31cf4c96c5dd4ac5a6bbb4ac7b6bab763651624a,https://www.semanticscholar.org/paper/31cf4c96c5dd4ac5a6bbb4ac7b6bab763651624a,Prediction of Heart Disease Using a Combination of Machine Learning and Deep Learning,"The correct prediction of heart disease can prevent life threats, and incorrect prediction can prove to be fatal at the same time. In this paper different machine learning algorithms and deep learning are applied to compare the results and analysis of the UCI Machine Learning Heart Disease dataset. The dataset consists of 14 main attributes used for performing the analysis. Various promising results are achieved and are validated using accuracy and confusion matrix. The dataset consists of some irrelevant features which are handled using Isolation Forest, and data are also normalized for getting better results. And how this study can be combined with some multimedia technology like mobile devices is also discussed. Using deep learning approach, 94.2% accuracy was obtained.",2021,39,83,1,True,Computer Science,2066165404.0,Rohit Bharti,6806161.0,A. Khamparia,66402249.0,Mohammad Shabaz,2758504.0,Gaurav Dhiman,1577665701.0,Sagar Dhanraj Pande,2192028560.0,Parneet Singh,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
561f002fb739ced3f2f967a8809744a063d9fba4,https://www.semanticscholar.org/paper/561f002fb739ced3f2f967a8809744a063d9fba4,Sub-sampled Cubic Regularization for Non-convex Optimization,"We consider the minimization of non-convex functions that typically arise in machine learning. Specifically, we focus our attention on a variant of trust region methods known as cubic regularization. This approach is particularly attractive because it escapes strict saddle points and it provides stronger convergence guarantees than first- and second-order as well as classical trust region methods. However, it suffers from a high computational complexity that makes it impractical for large-scale learning. Here, we propose a novel method that uses sub-sampling to lower this computational cost. By the use of concentration inequalities we provide a sampling scheme that gives sufficiently accurate gradient and Hessian approximations to retain the strong global and local convergence guarantees of cubically regularized methods. To the best of our knowledge this is the first work that gives global convergence guarantees for a sub-sampled variant of cubic regularization on non-convex functions. Furthermore, we provide experimental results supporting our theory.",2017,33,102,19,False,Mathematics,21673214.0,J. Kohler,40401747.0,Aurélien Lucchi,,,,,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,
85a184fb63ad75a06df858094c0de20a39670128,https://www.semanticscholar.org/paper/85a184fb63ad75a06df858094c0de20a39670128,An Adaptive Ensemble Machine Learning Model for Intrusion Detection,"In recent years, advanced threat attacks are increasing, but the traditional network intrusion detection system based on feature filtering has some drawbacks which make it difficult to find new attacks in time. This paper takes NSL-KDD data set as the research object, analyses the latest progress and existing problems in the field of intrusion detection technology, and proposes an adaptive ensemble learning model. By adjusting the proportion of training data and setting up multiple decision trees, we construct a MultiTree algorithm. In order to improve the overall detection effect, we choose several base classifiers, including decision tree, random forest, kNN, DNN, and design an ensemble adaptive voting algorithm. We use NSL-KDD Test+ to verify our approach, the accuracy of the MultiTree algorithm is 84.2%, while the final accuracy of the adaptive voting algorithm reaches 85.2%. Compared with other research papers, it is proved that our ensemble model effectively improves detection accuracy. In addition, through the analysis of data, it is found that the quality of data features is an important factor to determine the detection effect. In the future, we should optimize the feature selection and preprocessing of intrusion detection data to achieve better results.",2019,29,141,11,True,Computer Science,3024285.0,Xianwei Gao,144703313.0,Chun Shan,1791611.0,Changzhen Hu,150357505.0,Zequn Niu,2109343335.0,Zhen Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a4dd3297e19f37592500d0d6ee2fb659e43b466d,https://www.semanticscholar.org/paper/a4dd3297e19f37592500d0d6ee2fb659e43b466d,Subspace Distribution Alignment for Unsupervised Domain Adaptation,"We propose a novel method for unsupervised domain adaptation. Traditional machine learning algorithms often fail to generalize to new input distributions, causing reduced accuracy. Domain adaptation attempts to compensate for the performance degradation by transferring and adapting source knowledge to target domain. Existing unsupervised methods project domains into a lower-dimensional space and attempt to align the subspace bases, effectively learning a mapping from source to target points or vice versa. However, they fail to take into account the difference of the two distributions in the subspaces, resulting in misalignment even after adaptation. We present a unified view of existing subspace mapping based methods and develop a generalized approach that also aligns the distributions as well as the subspace bases. We provide a detailed evaluation of our approach on benchmark datasets and show improved results over published approaches.",2015,20,123,14,True,Computer Science,2636783.0,Baochen Sun,2903226.0,Kate Saenko,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
e2f9132f47594e051e2ebaf0de4f06be7c5dddc0,https://www.semanticscholar.org/paper/e2f9132f47594e051e2ebaf0de4f06be7c5dddc0,Machine Learning Approach for Ontology Mapping Using Multiple Concept Similarity Measures,"This paper presents a new framework for the ontology mapping problem. We organized the ontology mapping problem into a standard machine learning framework, which uses multiple concept similarity measures. We presented several concept similarity measures for the machine learning framework and conducted experiments for testing the framework using real-world data. Our experimental results show that our approach has increased performance with respect to precision, recall and F-measure in comparison with other methods.",2008,23,69,7,False,Computer Science,143758327.0,R. Ichise,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
861839d67bacd1d2e5a956a172dddc8644e634fb,https://www.semanticscholar.org/paper/861839d67bacd1d2e5a956a172dddc8644e634fb,Learning Globally-Consistent Local Distance Functions for Shape-Based Image Retrieval and Classification,"We address the problem of visual category recognition by learning an image-to-image distance function that attempts to satisfy the following property: the distance between images from the same category should be less than the distance between images from different categories. We use patch-based feature vectors common in object recognition work as a basis for our image-to-image distance functions. Our large-margin formulation for learning the distance functions is similar to formulations used in the machine learning literature on distance metric learning, however we differ in that we learn local distance functions¿a different parameterized function for every image of our training set¿whereas typically a single global distance function is learned. This was a novel approach first introduced in Frome, Singer, & Malik, NIPS 2006. In that work we learned the local distance functions independently, and the outputs of these functions could not be compared at test time without the use of additional heuristics or training. Here we introduce a different approach that has the advantage that it learns distance functions that are globally consistent in that they can be directly compared for purposes of retrieval and classification. The output of the learning algorithm are weights assigned to the image features, which is intuitively appealing in the computer vision setting: some features are more salient than others, and which are more salient depends on the category, or image, being considered. We train and test using the Caltech 101 object recognition benchmark.",2007,28,398,28,True,Mathematics,2279670.0,Andrea Frome,1740765.0,Y. Singer,145757665.0,Fei Sha,143751119.0,Jitendra Malik,,,,,,,,,Computer Science,,,,,,,,,,,,,,,,,,,,,,,,
9d384c40d5d74f425d891a4ad997bd2090056324,https://www.semanticscholar.org/paper/9d384c40d5d74f425d891a4ad997bd2090056324,Smartphone Based Colorimetric Detection via Machine Learning,"We report the application of machine learning to smartphone-based colorimetric detection of pH values. The strip images were used as the training set for Least Squares-Support Vector Machine (LS-SVM) classifier algorithms that were able to successfully classify the distinct pH values. The difference in the obtained image formats was found not to significantly affect the performance of the proposed machine learning approach. Moreover, the influence of the illumination conditions on the perceived color of pH strips was investigated and further experiments were conducted to study the effect of color change on the learning model. Non-integer pH levels are identified as their nearest integer pH values, whereas the test results for integer pH levels using JPEG, RAW and RAW-corrected image formats captured under different lighting conditions lead to perfect classification accuracy, sensitivity and specificity, which proves that colorimetric detection using machine learning based systems is able to adapt to various experimental conditions and is a great candidate for smartphone-based sensing in paper-based colorimetric assays.",2017,44,63,2,True,Computer Science,1814920.0,A. Mutlu,144089638.0,V. Kılıç,2069514167.0,Gizem K. Özdemir,2067556709.0,A. Bayram,50527566.0,N. Horzum,3616522.0,M. Solmaz,,,,,Medicine,,,,,,,,,,,,,,,,,,,,,,,,
2a7e9736b5632cb5332ff21c1fbf9bcfeafd50db,https://www.semanticscholar.org/paper/2a7e9736b5632cb5332ff21c1fbf9bcfeafd50db,End-to-end Symmetry Preserving Inter-atomic Potential Energy Model for Finite and Extended Systems,"Machine learning models are changing the paradigm of molecular modeling, which is a fundamental tool for material science, chemistry, and computational biology. Of particular interest is the inter-atomic potential energy surface (PES). Here we develop Deep Potential - Smooth Edition (DeepPot-SE), an end-to-end machine learning-based PES model, which is able to efficiently represent the PES for a wide variety of systems with the accuracy of ab initio quantum mechanics models. By construction, DeepPot-SE is extensive and continuously differentiable, scales linearly with system size, and preserves all the natural symmetries of the system. Further, we show that DeepPot-SE describes finite and extended systems including organic molecules, metals, semiconductors, and insulators with high fidelity.",2018,37,173,6,False,Mathematics,2125538501.0,Linfeng Zhang,7181694.0,Jiequn Han,2113289384.0,Han Wang,2317758.0,W. Saidi,2990747.0,R. Car,1789499.0,E. Weinan,,,,,Computer Science,Physics,,,,,,,,,,,,,,,,,,,,,,,
c62359d8382fc971a301993ad2d30d6cdc909e68,https://www.semanticscholar.org/paper/c62359d8382fc971a301993ad2d30d6cdc909e68,Big Learning with Bayesian Methods,"Explosive growth in data and availability of cheap computing resources have sparked increasing interest in Big learning, an emerging subfield that studies scalable machine learning algorithms, systems, and applications with Big Data. Bayesian methods represent one important class of statistic methods for machine learning, with substantial recent developments on adaptive, flexible and scalable Bayesian learning. This article provides a survey of the recent advances in Big learning with Bayesian methods, termed Big Bayesian Learning, including nonparametric Bayesian methods for adaptively inferring model complexity, regularized Bayesian inference for improving the flexibility via posterior regularization, and scalable algorithms and systems based on stochastic subsampling and distributed computing for dealing with large-scale applications.",2014,240,68,2,True,Computer Science,145254043.0,Jun Zhu,2276707.0,Jianfei Chen,143783026.0,Wenbo Hu,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
38eb43ea485e7d288c75ee514e0d51b8bffa3d18,https://www.semanticscholar.org/paper/38eb43ea485e7d288c75ee514e0d51b8bffa3d18,sktime: A Unified Interface for Machine Learning with Time Series,"We present sktime -- a new scikit-learn compatible Python library with a unified interface for machine learning with time series. Time series data gives rise to various distinct but closely related learning tasks, such as forecasting and time series classification, many of which can be solved by reducing them to related simpler tasks. We discuss the main rationale for creating a unified interface, including reduction, as well as the design of sktime's core API, supported by a clear overview of common time series tasks and reduction approaches.",2019,60,94,1,False,Computer Science,153840718.0,M. Löning,35095340.0,A. Bagnall,1742523204.0,S. Ganesh,123541741.0,V. Kazakov,33321734.0,Jason Lines,2724295.0,F. Király,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
82364428995c29b3dcb60c1835548eeff4adcd20,https://www.semanticscholar.org/paper/82364428995c29b3dcb60c1835548eeff4adcd20,What do Neural Machine Translation Models Learn about Morphology?,"Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.",2017,46,315,30,True,Computer Science,2083259.0,Yonatan Belinkov,145938140.0,Nadir Durrani,6415321.0,Fahim Dalvi,145775792.0,Hassan Sajjad,145898106.0,James R. Glass,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
b6f1be7f52d9f3dfaf5bb7ad726958e5d0ac92e9,https://www.semanticscholar.org/paper/b6f1be7f52d9f3dfaf5bb7ad726958e5d0ac92e9,From Predictive Methods to Missing Data Imputation: An Optimization Approach,"Missing data is a common problem in real-world settings and for this reason has attracted significant attention in the statistical literature. We propose a flexible framework based on formal optimization to impute missing data with mixed continuous and categorical variables. This framework can readily incorporate various predictive models including K- nearest neighbors, support vector machines, and decision tree based methods, and can be adapted for multiple imputation. We derive fast first-order methods that obtain high quality solutions in seconds following a general imputation algorithm opt.impute presented in this paper. We demonstrate that our proposed method improves out-of-sample accuracy in large-scale computational experiments across a sample of 84 data sets taken from the UCI Machine Learning Repository. In all scenarios of missing at random mechanisms and various missing percentages, opt.impute produces the best overall imputation in most data sets benchmarked against five other methods: mean impute, K-nearest neighbors, iterative knn, Bayesian PCA, and predictive-mean matching, with an average reduction in mean absolute error of 8.3% against the best cross-validated benchmark method. Moreover, opt.impute leads to improved out-of-sample performance of learning algorithms trained using the imputed data, demonstrated by computational experiments on 10 downstream tasks. For models trained using opt.impute single imputations with 50% data missing, the average out-of-sample R2 is 0.339 in the regression tasks and the average out-of-sample accuracy is 86.1% in the classification tasks, compared to 0.315 and 84.4% for the best cross-validated benchmark method. In the multiple imputation setting, downstream models trained using opt.impute obtain a statistically significant improvement over models trained using multivariate imputation by chained equations (mice) in 8/10 missing data scenarios considered.",2017,32,157,5,False,Computer Science,1713217.0,D. Bertsimas,108112975.0,C. Pawlowski,47990026.0,Ying Daisy Zhuo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
102b968d836177f9c436141e382915a4f8549276,https://www.semanticscholar.org/paper/102b968d836177f9c436141e382915a4f8549276,Affective multimodal human-computer interaction,"Social and emotional intelligence are aspects of human intelligence that have been argued to be better predictors than IQ for measuring aspects of success in life, especially in social interactions, learning, and adapting to what is important. When it comes to machines, not all of them will need such skills. Yet to have machines like computers, broadcast systems, and cars, capable of adapting to their users and of anticipating their wishes, endowing them with the ability to recognize user's affective states is necessary. This article discusses the components of human affect, how they might be integrated into computers, and how far are we from realizing affective multimodal human-computer interaction.",2005,57,233,6,False,Computer Science,145387780.0,M. Pantic,1703601.0,N. Sebe,1737918.0,J. Cohn,153652752.0,Thomas S. Huang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9c36232db29f23f156df3a1b5db8f035c917b25c,https://www.semanticscholar.org/paper/9c36232db29f23f156df3a1b5db8f035c917b25c,Machine Learning with Applications in Breast Cancer Diagnosis and Prognosis,"Breast cancer (BC) is one of the most common cancers among women worldwide, representing the majority of new cancer cases and cancer-related deaths according to global statistics, making it a significant public health problem in today’s society. The early diagnosis of BC can improve the prognosis and chance of survival significantly, as it can promote timely clinical treatment to patients. Further accurate classification of benign tumours can prevent patients undergoing unnecessary treatments. Thus, the correct diagnosis of BC and classification of patients into malignant or benign groups is the subject of much research. Because of its unique advantages in critical features detection from complex BC datasets, machine learning (ML) is widely recognised as the methodology of choice in BC pattern classification and forecast modelling. In this paper, we aim to review ML techniques and their applications in BC diagnosis and prognosis. Firstly, we provide an overview of ML techniques including artificial neural networks (ANNs), support vector machines (SVMs), decision trees (DTs), and k-nearest neighbors (k-NNs). Then, we investigate their applications in BC. Our primary data is drawn from the Wisconsin breast cancer database (WBCD) which is the benchmark database for comparing the results through different algorithms. Finally, a healthcare system model of our recent work is also shown.",2018,112,106,3,True,Medicine,46850609.0,Wenbin Yue,2108454322.0,Zidong Wang,50829123.0,Hongwei Chen,33896169.0,A. Payne,2110997660.0,Xiaohui Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
393d8052ed57d71de2bd4a3c05bc5e42e4072b02,https://www.semanticscholar.org/paper/393d8052ed57d71de2bd4a3c05bc5e42e4072b02,SCADA System Testbed for Cybersecurity Research Using Machine Learning Approach,"This paper presents the development of a Supervisory Control and Data Acquisition (SCADA) system testbed used for cybersecurity research. The testbed consists of a water storage tank’s control system, which is a stage in the process of water treatment and distribution. Sophisticated cyber-attacks were conducted against the testbed. During the attacks, the network traffic was captured, and features were extracted from the traffic to build a dataset for training and testing different machine learning algorithms. Five traditional machine learning algorithms were trained to detect the attacks: Random Forest, Decision Tree, Logistic Regression, Naïve Bayes and KNN. Then, the trained machine learning models were built and deployed in the network, where new tests were made using online network traffic. The performance obtained during the training and testing of the machine learning models was compared to the performance obtained during the online deployment of these models in the network. The results show the efficiency of the machine learning models in detecting the attacks in real time. The testbed provides a good understanding of the effects and consequences of attacks on real SCADA environments.",2018,32,59,1,True,Computer Science,31458539.0,M. Teixeira,1935864.0,Tara Salman,23624390.0,Maede Zolanvari,145889709.0,R. Jain,1919083.0,N. Meskin,1932846.0,M. Samaka,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
c988331ed8382bdb800d6b7c5d05f467326e5a4a,https://www.semanticscholar.org/paper/c988331ed8382bdb800d6b7c5d05f467326e5a4a,"Data mining, hypergraph transversals, and machine learning (extended abstract)","Several data mining problems can be formulated as problems of nding maximally speci c sentences that are interesting in a database. We rst show that this problem has a close relationship with the hypergraph transversal problem. We then analyze two algorithms that have been previously used in data mining, proving upper bounds on their complexity. The rst algorithm is useful when the maximally speci c interesting sentences are \small"". We show that this algorithm can also be used to e ciently solve a special case of the hypergraph transversal problem, improving on previous results. The second algorithm utilizes a subroutine for hypergraph transversals, and is applicable in more general situations, with complexity close to a lower bound for the problem. We also relate these problems to the model of exact learning in computational learning theory, and use the correspondence to derive some corollaries.",1997,47,140,2,False,Computer Science,1736832.0,D. Gunopulos,1746048.0,R. Khardon,1712654.0,H. Mannila,143785973.0,Hannu (TT) Toivonen,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
b29c20d917be052c11c1269d4d170b02a2edc489,https://www.semanticscholar.org/paper/b29c20d917be052c11c1269d4d170b02a2edc489,Preventing Over-Fitting during Model Selection via Bayesian Regularisation of the Hyper-Parameters,"While the model parameters of a kernel machine are typically given by the solution of a convex optimisation problem, with a single global optimum, the selection of good values for the regularisation and kernel parameters is much less straightforward. Fortunately the leave-one-out cross-validation procedure can be performed or a least approximated very efficiently in closed form for a wide variety of kernel learning methods, providing a convenient means for model selection. Leave-one-out cross-validation based estimates of performance, however, generally exhibit a relatively high variance and are therefore prone to over-fitting. In this paper, we investigate the novel use of Bayesian regularisation at the second level of inference, adding a regularisation term to the model selection criterion corresponding to a prior over the hyper-parameter values, where the additional regularisation parameters are integrated out analytically. Results obtained on a suite of thirteen real-world and synthetic benchmark data sets clearly demonstrate the benefit of this approach.",2007,58,233,16,False,Computer Science,8974886.0,G. Cawley,28280741.0,N. Talbot,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
610c67ffebfcd256b876f0dc6fa4cb75fbf9140d,https://www.semanticscholar.org/paper/610c67ffebfcd256b876f0dc6fa4cb75fbf9140d,Low Latency Privacy Preserving Inference,"When applying machine learning to sensitive data, one has to find a balance between accuracy, information security, and computational-complexity. Recent studies combined Homomorphic Encryption with neural networks to make inferences while protecting against information leakage. However, these methods are limited by the width and depth of neural networks that can be used (and hence the accuracy) and exhibit high latency even for relatively simple networks. In this study we provide two solutions that address these limitations. In the first solution, we present more than 10× improvement in latency and enable inference on wider networks compared to prior attempts with the same level of security. The improved performance is achieved by novel methods to represent the data during the computation. In the second solution, we apply the method of transfer learning to provide private inference services using deep networks with latency of ∼0.16 seconds. We demonstrate the efficacy of our methods on several computer vision tasks.",2018,31,103,30,False,Computer Science,2470453.0,Alon Brutzkus,31834207.0,Oren Elisha,1388775848.0,Ran Gilad-Bachrach,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
882f42973556389220dc8c474af91a141f0f43c1,https://www.semanticscholar.org/paper/882f42973556389220dc8c474af91a141f0f43c1,Deep Learning for Infrared Thermal Image Based Machine Health Monitoring,"The condition of a machine can automatically be identified by creating and classifying features that summarize characteristics of measured signals. Currently, experts, in their respective fields, devise these features based on their knowledge. Hence, the performance and usefulness depends on the expert's knowledge of the underlying physics or statistics. Furthermore, if new and additional conditions should be detectable, experts have to implement new feature extraction methods. To mitigate the drawbacks of feature engineering, a method from the subfield of feature learning, i.e., deep learning (DL), more specifically convolutional neural networks (NNs), is researched in this paper. The objective of this paper is to investigate if and how DL can be applied to infrared thermal (IRT) video to automatically determine the condition of the machine. By applying this method on IRT data in two use cases, i.e., machine-fault detection and oil-level prediction, we show that the proposed system is able to detect many conditions in rotating machinery very accurately (i.e., 95 and 91.67% accuracy for the respective use cases), without requiring any detailed knowledge about the underlying physics, and thus having the potential to significantly simplify condition monitoring using complex sensor data. Furthermore, we show that by using the trained NNs, important regions in the IRT images can be identified related to specific conditions, which can potentially lead to new physical insights.",2017,24,130,4,True,Engineering,3001762.0,Olivier Janssens,115624058.0,R. Van de Walle,2755281.0,M. Loccufier,134767416.0,S. Van Hoecke,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
f062cde1a66467ad593f9b5a6b8de8e82dcab43f,https://www.semanticscholar.org/paper/f062cde1a66467ad593f9b5a6b8de8e82dcab43f,Advanced Machine Learning Approach for Lithium-Ion Battery State Estimation in Electric Vehicles,"To fulfill reliable battery management in electric vehicles (EVs), an advanced State-of-Charge (SOC) estimator is developed via machine learning methodology. A novel genetic algorithm-based fuzzy C-means (FCM) clustering technique is first used to partition the training data sampled in the driving cycle-based test of a lithium-ion battery. The clustering result is applied to learn the topology and antecedent parameters of the model. Recursive least-squares algorithm is then employed to extract its consequent parameters. To ensure good accuracy and resilience, the backpropagation learning algorithm is finally adopted to simultaneously optimize both the antecedent and consequent parts. Experimental results verify that the proposed estimator exhibits sufficient accuracy and outperforms those built by conventional fuzzy modeling methods.",2016,37,199,1,False,Engineering,145540448.0,Xiaosong Hu,2023891.0,S. Li,2108809963.0,Yalian Yang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
775156bca909f3e7b42675fecb5a6f7abb396170,https://www.semanticscholar.org/paper/775156bca909f3e7b42675fecb5a6f7abb396170,Conditional Random Fields and Support Vector Machines for Disorder Named Entity Recognition in Clinical Texts,"We present a comparative study between two machine learning methods, Conditional Random Fields and Support Vector Machines for clinical named entity recognition. We explore their applicability to clinical domain. Evaluation against a set of gold standard named entities shows that CRFs outperform SVMs. The best F-score with CRFs is 0.86 and for the SVMs is 0.64 as compared to a baseline of 0.60.",2008,5,104,6,True,Computer Science,34377382.0,Dingcheng Li,1894531.0,G. Savova,2135004.0,K. Schuler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
0735bc67a2149d5c6f38a2e97b2ef8678666d577,https://www.semanticscholar.org/paper/0735bc67a2149d5c6f38a2e97b2ef8678666d577,TensorFuzz: Debugging Neural Networks with Coverage-Guided Fuzzing,"Machine learning models are notoriously difficult to interpret and debug. This is particularly true of neural networks. In this work, we introduce automated software testing techniques for neural networks that are well-suited to discovering errors which occur only for rare inputs. Specifically, we develop coverage-guided fuzzing (CGF) methods for neural networks. In CGF, random mutations of inputs to a neural network are guided by a coverage metric toward the goal of satisfying user-specified constraints. We describe how fast approximate nearest neighbor algorithms can provide this coverage metric. We then discuss the application of CGF to the following goals: finding numerical errors in trained neural networks, generating disagreements between neural networks and quantized versions of those networks, and surfacing undesirable behavior in character level language models. Finally, we release an open source library called TensorFuzz that implements the described techniques.",2018,66,205,25,False,Computer Science,2624088.0,Augustus Odena,153440022.0,Ian J. Goodfellow,,,,,,,,,,,,,Mathematics,,,,,,,,,,,,,,,,,,,,,,,,
df473fa93c84e54e3309282fedd755aad3d17d12,https://www.semanticscholar.org/paper/df473fa93c84e54e3309282fedd755aad3d17d12,Predicting the Mechanical Properties of Zeolite Frameworks by Machine Learning,"We show here that machine learning is a powerful new tool for predicting the elastic response of zeolites. We built our machine learning approach relying on geometric features only, which are related to local geometry, structure, and porosity of a zeolite, to predict bulk and shear moduli of zeolites with an accuracy exceeding that of force field approaches. The development of this model has illustrated clear correlations between characteristic features of a zeolite and elastic moduli, providing exceptional insight into the mechanics of zeolitic frameworks. Finally, we employ this methodology to predict the elastic response of 590 448 hypothetical zeolites, and the results of this massive database provide clear evidence of stability trends in porous materials.",2017,74,97,0,False,Materials Science,10151948.0,J. Evans,144646737.0,François-Xavier Coudert,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84e95ef743988552886cc7e988815651988058d1,https://www.semanticscholar.org/paper/84e95ef743988552886cc7e988815651988058d1,Deep Convolutional Neural Networks and Learning ECG Features for Screening Paroxysmal Atrial Fibrillation Patients,"In this paper, a novel computationally intelligent-based electrocardiogram (ECG) signal classification methodology using a deep learning (DL) machine is developed. The focus is on patient screening and identifying patients with paroxysmal atrial fibrillation (PAF), which represents a life threatening cardiac arrhythmia. The proposed approach operates with a large volume of raw ECG time-series data as inputs to a deep convolutional neural networks (CNN). It autonomously learns representative and key features of the PAF to be used by a classification module. The features are therefore learned directly from the large time domain ECG signals by using a CNN with one fully connected layer. The learned features can effectively replace the traditional ad hoc and time-consuming user’s hand-crafted features. Our experimental results verify and validate the effectiveness and capabilities of the learned features for PAF patient screening. The main advantages of our proposed approach are to simplify the feature extraction process corresponding to different cardiac arrhythmias and to remove the need for using a human expert to define appropriate and critical features working with a large time-series data set. The extensive simulations and case studies conducted indicate that combining the learned features with other classifiers will significantly improve the performance of the patient screening system as compared to an end-to-end CNN classifier. The effectiveness and capabilities of our proposed ECG DL classification machine is demonstrated and quantitative comparisons with several conventional machine learning classifiers are also provided.",2018,36,235,7,False,Computer Science,2116752.0,B. Pourbabaee,1734285.0,M. J. Roshtkhari,1724952.0,K. Khorasani,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
