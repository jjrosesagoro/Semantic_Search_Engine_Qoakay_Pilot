{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJLQoimyVyQ8"
   },
   "source": [
    "### Uncomment and run the following cells if you work on Google Colab :) Don't forget to change your runtime type to GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rVV81xc3VyQ9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/kstathou/vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C0lSFLw3VyRG"
   },
   "outputs": [],
   "source": [
    "# cd vector_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5sOhWL6UVyRQ"
   },
   "outputs": [],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbnscDwgVyRW"
   },
   "source": [
    "### Let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v7ftrzzmVyRX"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fU2i4vlCVyRc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/anaconda3/envs/SemanticS/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "# Used to import data from local.\n",
    "import pandas as pd\n",
    "\n",
    "# Used to create the dense document vectors.\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Used to create and store the Faiss index.\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Used to do vector searches and display the results.\n",
    "from vector_engine.utils import vector_search, id2details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz5YBwU5VyRi"
   },
   "source": [
    "Stored and processed data in s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VEANywYAVyRi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/anaconda3/envs/SemanticS/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3186: DtypeWarning: Columns (5,9,11,13,15,17,19,21,56,81,83,85,87,89,91,95,97,99,101,103,105,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139,141,143,145,147,149,151,153,155,157,159,161,163,165,167,169,171,173,175,177,179,181,183,185,187,189,191,193,195,197,199,201,203,205,207,209,211,213,215,217,219,221,223,225,227,229,231,233,235,237,238,240,242,244,246,248,250) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read a CSV in a table\n",
    "df = pd.read_csv('/home/jj/Desktop/semantic_search_engine/data/CSV_Data/Ready_v3_FINAL/Merged_Dataset_Final.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "HJXljSbYVyRn",
    "outputId": "80dbbfa2-7a12-431d-84e8-6492cbca002c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indexId</th>\n",
       "      <th>paperId</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>referenceCount</th>\n",
       "      <th>citationCount</th>\n",
       "      <th>influentialCitationCount</th>\n",
       "      <th>isOpenAccess</th>\n",
       "      <th>...</th>\n",
       "      <th>authors/138/authorId</th>\n",
       "      <th>authors/138/name</th>\n",
       "      <th>authors/139/authorId</th>\n",
       "      <th>authors/139/name</th>\n",
       "      <th>authors/140/authorId</th>\n",
       "      <th>authors/140/name</th>\n",
       "      <th>authors/141/authorId</th>\n",
       "      <th>authors/141/name</th>\n",
       "      <th>authors/142/authorId</th>\n",
       "      <th>authors/142/name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46200b99c40e8586c8a0f588488ab6414119fb28</td>\n",
       "      <td>https://www.semanticscholar.org/paper/46200b99...</td>\n",
       "      <td>TensorFlow: A system for large-scale machine l...</td>\n",
       "      <td>TensorFlow is a machine learning system that o...</td>\n",
       "      <td>2016</td>\n",
       "      <td>94</td>\n",
       "      <td>13969</td>\n",
       "      <td>1679</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>f9c602cc436a9ea2f9e7db48c77d924e09ce3c32</td>\n",
       "      <td>https://www.semanticscholar.org/paper/f9c602cc...</td>\n",
       "      <td>Fashion-MNIST: a Novel Image Dataset for Bench...</td>\n",
       "      <td>We present Fashion-MNIST, a new dataset compri...</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>4588</td>\n",
       "      <td>1340</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d</td>\n",
       "      <td>https://www.semanticscholar.org/paper/9c9d7247...</td>\n",
       "      <td>TensorFlow: Large-Scale Machine Learning on He...</td>\n",
       "      <td>TensorFlow is an interface for expressing mach...</td>\n",
       "      <td>2016</td>\n",
       "      <td>55</td>\n",
       "      <td>9429</td>\n",
       "      <td>1008</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   indexId                                   paperId  \\\n",
       "0        1  46200b99c40e8586c8a0f588488ab6414119fb28   \n",
       "1        2  f9c602cc436a9ea2f9e7db48c77d924e09ce3c32   \n",
       "2        3  9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.semanticscholar.org/paper/46200b99...   \n",
       "1  https://www.semanticscholar.org/paper/f9c602cc...   \n",
       "2  https://www.semanticscholar.org/paper/9c9d7247...   \n",
       "\n",
       "                                               title  \\\n",
       "0  TensorFlow: A system for large-scale machine l...   \n",
       "1  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
       "2  TensorFlow: Large-Scale Machine Learning on He...   \n",
       "\n",
       "                                            abstract  year  referenceCount  \\\n",
       "0  TensorFlow is a machine learning system that o...  2016              94   \n",
       "1  We present Fashion-MNIST, a new dataset compri...  2017               6   \n",
       "2  TensorFlow is an interface for expressing mach...  2016              55   \n",
       "\n",
       "   citationCount  influentialCitationCount isOpenAccess  ...  \\\n",
       "0          13969                      1679        False  ...   \n",
       "1           4588                      1340        False  ...   \n",
       "2           9429                      1008        False  ...   \n",
       "\n",
       "  authors/138/authorId authors/138/name authors/139/authorId authors/139/name  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  authors/140/authorId authors/140/name authors/141/authorId authors/141/name  \\\n",
       "0                  NaN              NaN                  NaN              NaN   \n",
       "1                  NaN              NaN                  NaN              NaN   \n",
       "2                  NaN              NaN                  NaN              NaN   \n",
       "\n",
       "  authors/142/authorId authors/142/name  \n",
       "0                  NaN              NaN  \n",
       "1                  NaN              NaN  \n",
       "2                  NaN              NaN  \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MljadlGpVyRs",
    "outputId": "fe2aeb52-a5aa-4185-caaf-3bbd67da4b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T'ikray Prototype: 4291\n"
     ]
    }
   ],
   "source": [
    "print(f\"T'ikray Prototype: {df.indexId.unique().shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyRG1wZLVyRw"
   },
   "source": [
    "The [Sentence Transformers library](https://github.com/UKPLab/sentence-transformers) offers pretrained transformers that produce SOTA sentence embeddings. Checkout this [spreadsheet](https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/) with all the available models.\n",
    "\n",
    "In this tutorial, we will use the `distilbert-base-nli-stsb-mean-tokens` model which has the best performance on Semantic Textual Similarity tasks among the DistilBERT versions. Moreover, although it's slightly worse than BERT, it is quite faster thanks to having a smaller size.\n",
    "\n",
    "I use the same model in [Orion's semantic search engine](https://www.orion-search.org/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjF6CrwUVyRx",
    "outputId": "a49be57b-d2ad-46d3-aec9-62c01ffb55ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the sentence-level DistilBERT\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
    "# Check if GPU is available and use it\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(torch.device(\"cuda\"))\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a3207b1dba9b4a00b1ff35d9e1666b9e",
      "2695fd99278845baabae54015c34fcdc",
      "4cf7379a5fb74234863c8d6087fd874e",
      "499b0004f8b94f298fa6549f40cfdd47",
      "f747015d71364a72bfdc7fae052f1eb4",
      "9e6b8fb59cdf41e4ba2249707b534652",
      "2dd7c083419142abafa3a3ae0313b3b7",
      "c96682ee49574cf09a9484c380b88bcd"
     ]
    },
    "id": "Y_GS0_CWVyR1",
    "outputId": "08396147-4125-409f-fac6-693367366328"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:09<00:00, 14.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# Convert abstracts to vectors\n",
    "embeddings = model.encode(df.abstract.to_list(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gE7w-RJbVyR6",
    "outputId": "c5b2e094-d807-41fb-d5cb-34c5f24ebcdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the vectorised abstract: (768,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the vectorised abstract: {embeddings[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGV4Je1EVyR_"
   },
   "source": [
    "## Vector similarity search with Faiss\n",
    "[Faiss](https://github.com/facebookresearch/faiss) is a library for efficient similarity search and clustering of dense vectors. It contains algorithms that search in sets of vectors of any size, even ones that do not fit in RAM. \n",
    "    \n",
    "Faiss is built around the `Index` object which contains, and sometimes preprocesses, the searchable vectors. Faiss has a large collection of [indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes). You can even create [composite indexes](https://github.com/facebookresearch/faiss/wiki/Faiss-indexes-(composite)). Faiss handles collections of vectors of a fixed dimensionality d, typically a few 10s to 100s.\n",
    "\n",
    "**Note**: Faiss uses only 32-bit floating point matrices. This means that you will have to change the data type of the input before building the index.\n",
    "\n",
    "To learn more about Faiss, you can read their paper on [arXiv](https://arxiv.org/abs/1702.08734).\n",
    "\n",
    "Here, we will the `IndexFlatL2` index:\n",
    "- It's a simple index that performs a brute-force L2 distance search\n",
    "- It scales linearly. It will work fine with our data but you might want to try [faster indexes](https://github.com/facebookresearch/faiss/wiki/Faster-search) if you work will millions of vectors.\n",
    "\n",
    "To create an index with the `misinformation` abstract vectors, we will:\n",
    "1. Change the data type of the abstract vectors to float32.\n",
    "2. Build an index and pass it the dimension of the vectors it will operate on.\n",
    "3. Pass the index to IndexIDMap, an object that enables us to provide a custom list of IDs for the indexed vectors.\n",
    "4. Add the abstract vectors and their ID mapping to the index. In our case, we will map vectors to their paper IDs from MAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.astype({'paperId': 'int32'}).dtypes\n",
    "#df['paperId'].astype(str).astype(int)\n",
    "#df['paperId'] = df.paperId.astype(int)\n",
    "#df['paperId'] = pd.to_numeric(df['paperId'])\n",
    "#df[\"paperId\"] = pd.to_numeric(df[\"paperId\"], errors='coerce')\n",
    "\n",
    "#s = pd.Series(df['paperId'])\n",
    "#print(s)\n",
    "#pd.to_numeric(s, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          2\n",
       "2          3\n",
       "3          4\n",
       "4          5\n",
       "        ... \n",
       "4286    4287\n",
       "4287    4288\n",
       "4288    4289\n",
       "4289    4290\n",
       "4290    4291\n",
       "Name: indexId, Length: 4291, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.indexId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kkUDtwHVyR_",
    "outputId": "f0e17ffc-02d0-4948-e58b-61d48178b95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the Faiss index: 4291\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Change data type\n",
    "embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "# Step 2: Instantiate the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "\n",
    "# Step 3: Pass the index to IndexIDMap\n",
    "index = faiss.IndexIDMap(index)\n",
    "\n",
    "# Step 4: Add vectors and their IDs\n",
    "index.add_with_ids(embeddings, df.indexId.values)\n",
    "\n",
    "print(f\"Number of vectors in the Faiss index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yt1z-433VySE"
   },
   "source": [
    "### Searching the index\n",
    "The index we built will perform a k-nearest-neighbour search. We have to provide the number of neighbours to be returned. \n",
    "\n",
    "Let's query the index with an abstract from our dataset and retrieve the 10 most relevant documents. **The first one must be our query!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "eEeJt7lYVySN",
    "outputId": "a20cb305-bda6-4f83-dbd2-720ceb068f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose a novel, efficient approach for distributed sparse learning in high-dimensions, where observations are randomly partitioned across machines. Computationally, at each round our method only requires the master machine to solve a shifted ell_1 regularized M-estimation problem, and other workers to compute the gradient. In respect of communication, the proposed approach provably matches the estimation error bound of centralized methods within constant rounds of communications (ignoring logarithmic factors). We conduct extensive experiments on both simulated and real world datasets, and demonstrate encouraging performances on high-dimensional regression and classification tasks.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paper abstract\n",
    "df.iloc[2984, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSuRcH85VySQ",
    "outputId": "487a953b-dd26-43ea-a6d6-7f0890ce90c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [0.0, 52.00844955444336, 57.677120208740234, 60.324066162109375, 61.46210861206055, 63.674522399902344, 64.19221496582031, 65.92388153076172, 67.6544189453125, 67.86244201660156]\n",
      "\n",
      "Semantic Scholar paper IDs: [2985, 1845, 678, 3171, 1437, 2179, 3120, 2803, 1255, 4074]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the 10 nearest neighbours\n",
    "D, I = index.search(np.array([embeddings[2984]]), k=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nIndex IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SiO1pa4oVySU",
    "outputId": "0cacc20e-93b7-46d2-d81f-43d717b08eff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Efficient Distributed Learning with Sparsity'],\n",
       " ['SparCML: high-performance sparse communication for machine learning'],\n",
       " ['Online learning with kernels'],\n",
       " ['Random Rotation Ensembles'],\n",
       " ['ARTMAP: supervised real-time learning and classification of nonstationary data by a self-organizing neural network'],\n",
       " ['Local-Learning-Based Feature Selection for High-Dimensional Data Analysis'],\n",
       " ['Machine learning vortices at the Kosterlitz-Thouless transition'],\n",
       " ['Overfitting or perfect fitting? Risk bounds for classification and regression rules that interpolate'],\n",
       " ['Learning with Marginalized Corrupted Features'],\n",
       " ['Study and Observation of the Variation of Accuracies of KNN, SVM, LMNN, ENN Algorithms on Eleven Different Datasets from UCI Machine Learning Repository']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the paper titles based on their index\n",
    "id2details(df, I, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p29pEtGrWUMV",
    "outputId": "0393bb3d-d20a-456f-c5a5-ef9c08f14dd6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['We propose a novel, efficient approach for distributed sparse learning in high-dimensions, where observations are randomly partitioned across machines. Computationally, at each round our method only requires the master machine to solve a shifted ell_1 regularized M-estimation problem, and other workers to compute the gradient. In respect of communication, the proposed approach provably matches the estimation error bound of centralized methods within constant rounds of communications (ignoring logarithmic factors). We conduct extensive experiments on both simulated and real world datasets, and demonstrate encouraging performances on high-dimensional regression and classification tasks.'],\n",
       " ['Applying machine learning techniques to the quickly growing data in science and industry requires highly-scalable algorithms. Large datasets are most commonly processed \"data parallel\" distributed across many nodes. Each node\\'s contribution to the overall gradient is summed using a global allreduce. This allreduce is the single communication and thus scalability bottleneck for most machine learning workloads. We observe that frequently, many gradient values are (close to) zero, leading to sparse of sparsifyable communications. To exploit this insight, we analyze, design, and implement a set of communication-efficient protocols for sparse input data, in conjunction with efficient machine learning algorithms which can leverage these primitives. Our communication protocols generalize standard collective operations, by allowing processes to contribute arbitrary sparse input data vectors. Our generic communication library, SparCML1, extends MPI to support additional features, such as non-blocking (asynchronous) operations and low-precision data representations. As such, SparCML and its techniques will form the basis of future highly-scalable machine learning frameworks.'],\n",
       " ['Kernel-based algorithms such as support vector machines have achieved considerable success in various problems in batch setting, where all of the training data is available in advance. Support vector machines combine the so-called kernel trick with the large margin idea. There has been little use of these methods in an online setting suitable for real-time applications. In this paper, we consider online learning in a reproducing kernel Hilbert space. By considering classical stochastic gradient descent within a feature space and the use of some straightforward tricks, we develop simple and computationally efficient algorithms for a wide range of problems such as classification, regression, and novelty detection. In addition to allowing the exploitation of the kernel trick in an online setting, we examine the value of large margins for classification in the online setting with a drifting target. We derive worst-case loss bounds, and moreover, we show the convergence of the hypothesis to the minimizer of the regularized risk functional. We present some experimental results that support the theory as well as illustrating the power of the new algorithms for online novelty detection.'],\n",
       " ['In machine learning, ensemble methods combine the predictions of multiple base learners to construct more accurate aggregate predictions. Established supervised learning algorithms inject randomness into the construction of the individual base learners in an effort to promote diversity within the resulting ensembles. An undesirable side effect of this approach is that it generally also reduces the accuracy of the base learners. In this paper, we introduce a method that is simple to implement yet general and effective in improving ensemble diversity with only modest impact on the accuracy of the individual base learners. By randomly rotating the feature space prior to inducing the base learners, we achieve favorable aggregate predictions on standard data sets compared to state of the art ensemble methods, most notably for tree-based ensembles, which are particularly sensitive to rotation.'],\n",
       " ['Summary form only given. The authors introduced a neural network architecture, called ARTMAP, that autonomously learns to classify arbitrarily many, arbitrarily ordered vectors into recognition categories based on predictive success. This supervised learning system is built up from a pair of adaptive resonance theory modules (ART/sub a/ and ART/sub b/) that are capable of self-organizing stable recognition categories in response to arbitrary sequences of input patterns. Tested on a benchmark machine learning database in both online and offline simulations, the ARTMAP system learns orders of magnitude more quickly, efficiently, and accurately than alternative algorithms, and achieves 100% accuracy after training on less than half of the input patterns in the database.<<ETX>>'],\n",
       " [\"This paper considers feature selection for data classification in the presence of a huge number of irrelevant features. We propose a new feature-selection algorithm that addresses several major issues with prior work, including problems with algorithm implementation, computational complexity, and solution accuracy. The key idea is to decompose an arbitrarily complex nonlinear problem into a set of locally linear ones through local learning, and then learn feature relevance globally within the large margin framework. The proposed algorithm is based on well-established machine learning and numerical analysis techniques, without making any assumptions about the underlying data distribution. It is capable of processing many thousands of features within minutes on a personal computer while maintaining a very high accuracy that is nearly insensitive to a growing number of irrelevant features. Theoretical analyses of the algorithm's sample complexity suggest that the algorithm has a logarithmical sample complexity with respect to the number of features. Experiments on 11 synthetic and real-world data sets demonstrate the viability of our formulation of the feature-selection problem for supervised learning and the effectiveness of our algorithm.\"],\n",
       " ['Efficient and automated classification of phases from minimally processed data is one goal of machine learning in condensed matter and statistical physics. Supervised algorithms trained on raw samples of microstates can successfully detect conventional phase transitions via learning a bulk feature such as an order parameter. In this paper, we investigate whether neural networks can learn to classify phases based on topological defects. We address this question on the two-dimensional classical XY model which exhibits a Kosterlitz-Thouless transition. We find significant feature engineering of the raw spin states is required to convincingly claim that features of the vortex configurations are responsible for learning the transition temperature. We further show a single-layer network does not correctly classify the phases of the XY model, while a convolutional network easily performs classification by learning the global magnetization. Finally, we design a deep network capable of learning vortices without feature engineering. We demonstrate the detection of vortices does not necessarily result in the best classification accuracy, especially for lattices of less than approximately 1000 spins. For larger systems, it remains a difficult task to learn vortices.'],\n",
       " ['Many modern machine learning models are trained to achieve zero or near-zero training error in order to obtain near-optimal (but non-zero) test error. This phenomenon of strong generalization performance for \"overfitted\" / interpolated classifiers appears to be ubiquitous in high-dimensional data, having been observed in deep networks, kernel machines, boosting and random forests. Their performance is consistently robust even when the data contain large amounts of label noise. Very little theory is available to explain these observations. The vast majority of theoretical analyses of generalization allows for interpolation only when there is little or no label noise. This paper takes a step toward a theoretical foundation for interpolated classifiers by analyzing local interpolating schemes, including geometric simplicial interpolation algorithm and singularly weighted $k$-nearest neighbor schemes. Consistency or near-consistency is proved for these schemes in classification and regression problems. Moreover, the nearest neighbor schemes exhibit optimal rates under some standard statistical assumptions. Finally, this paper suggests a way to explain the phenomenon of adversarial examples, which are seemingly ubiquitous in modern machine learning, and also discusses some connections to kernel machines and random forests in the interpolated regime.'],\n",
       " ['The goal of machine learning is to develop predictors that generalize well to test data. Ideally, this is achieved by training on very large (infinite) training data sets that capture all variations in the data distribution. In the case of finite training data, an effective solution is to extend the training set with artificially created examples--which, however, is also computationally costly. We propose to corrupt training examples with noise from known distributions within the exponential family and present a novel learning algorithm, called marginalized corrupted features (MCF), that trains robust predictors by minimizing the expected value of the loss function under the corrupting distribution-- essentially learning with infinitely many (corrupted) training examples. We show empirically on a variety of data sets that MCF classifiers can be trained efficiently, may generalize substantially better to test data, and are more robust to feature deletion at test time.'],\n",
       " ['Machine learning qualifies computers to assimilate with data, without being solely programmed [1, 2]. Machine learning can be classified as supervised and unsupervised learning. In supervised learning, computers learn an objective that portrays an input to an output hinged on training input-output pairs [3]. Most efficient and widely used supervised learning algorithms are K-Nearest Neighbors (KNN), Support Vector Machine (SVM), Large Margin Nearest Neighbor (LMNN), and Extended Nearest Neighbor (ENN). The main contribution of this paper is to implement these elegant learning algorithms on eleven different datasets from the UCI machine learning repository to observe the variation of accuracies for each of the algorithms on all datasets. Analyzing the accuracy of the algorithms will give us a brief idea about the relationship of the machine learning algorithms and the data dimensionality. All the algorithms are developed in Matlab. Upon such accuracy observation, the comparison can be built among KNN, SVM, LMNN, and ENN regarding their performances on each dataset.']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the paper abstracts based on their index\n",
    "id2details(df, I, 'abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFKvRb4QY-DL"
   },
   "source": [
    "\n",
    "## Putting all together\n",
    "\n",
    "So far, we've built a Faiss index using the misinformation abstract vectors we encoded with a sentence-DistilBERT model. That's helpful but in a real case scenario, we would have to work with unseen data. To query the index with an unseen query and retrieve its most relevant documents, we would have to do the following:\n",
    "\n",
    "1. Encode the query with the same sentence-DistilBERT model we used for the rest of the abstract vectors.\n",
    "2. Change its data type to float32.\n",
    "3. Search the index with the encoded query.\n",
    "\n",
    "Here, we will use the introduction of an article published on [HKS Misinformation Review](https://misinforeview.hks.harvard.edu/article/can-whatsapp-benefit-from-debunked-fact-checked-stories-to-reduce-misinformation/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iDhftkrhX99T"
   },
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "There have been tremendous advances in artificial intelligence (AI) and machine learning (ML) within the past decade, \n",
    "especially in the application of deep learning to various challenges. These include advanced competitive games (such as Chess and Go), \n",
    "self-driving cars, speech recognition, and intelligent personal assistants. Rapid advances in computer vision for recognition of \n",
    "objects in pictures have led some individuals, including computer science experts and health care system experts in machine learning, \n",
    "to make predictions that ML algorithms will soon lead to the replacement of the radiologist. However, there are complex technological, \n",
    "regulatory, and medicolegal obstacles facing the implementation of machine learning in radiology that will definitely preclude replacement \n",
    "of the radiologist by these algorithms within the next two decades and beyond. While not a comprehensive review of machine learning, \n",
    "this article is intended to highlight specific features of machine learning which face significant technological and health care systems challenges. \n",
    "Rather than replacing radiologists, machine learning will provide quantitative tools that will increase the value of diagnostic imaging as a biomarker, \n",
    "increase image quality with decreased acquisition times, and improve workflow, communication, and patient safety.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AFhbGnWZpWN",
    "outputId": "ad8c5d82-11cf-48d8-f298-2581da808a6a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 distance: [7.857951095369131e-11, 7.857951095369131e-11, 64.52151489257812, 67.89201354980469, 72.01084899902344, 72.01084899902344, 73.52568817138672, 74.28388977050781, 74.80601501464844, 75.0186538696289]\n",
      "\n",
      "Index IDs: [3163, 3069, 388, 150, 1781, 1743, 245, 140, 1745, 2501]\n"
     ]
    }
   ],
   "source": [
    "# For convenience, I've wrapped all steps in the vector_search function.\n",
    "# It takes four arguments: \n",
    "# A query, the sentence-level transformer, the Faiss index and the number of requested results\n",
    "D, I = vector_search([user_query], model, index, num_results=10)\n",
    "print(f'L2 distance: {D.flatten().tolist()}\\n\\nIndex IDs: {I.flatten().tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tbanjBhBZtWZ",
    "outputId": "855cc8c3-96db-4bfc-bbde-433d5f6b73e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Will machine learning end the viability of radiology as a thriving medical specialty?'],\n",
       " ['Will machine learning end the viability of radiology as a thriving medical specialty?'],\n",
       " ['Applications of Deep Learning and Reinforcement Learning to Biological Data'],\n",
       " ['Unintended Consequences of Machine Learning in Medicine'],\n",
       " ['Deep Learning: The Good, the Bad, and the Ugly.'],\n",
       " ['Deep Learning: The Good, the Bad, and the Ugly.'],\n",
       " ['Entanglement-based machine learning on a quantum computer.'],\n",
       " ['Machine Learning in Medicine.'],\n",
       " ['Machine Learning: A Historical and Methodological Analysis'],\n",
       " ['A Review of Deep Machine Learning']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching the paper titles based on their index\n",
    "id2details(df, I, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbxFKF-DZxg0",
    "outputId": "d78cdc03-41f6-469d-bf67-8f32001a7415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jj/Desktop\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jj/Desktop/home/jj/Desktop/semantic_search_engine/models/faiss_index.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53266/218530328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Serialise index and store it as a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{project_dir}/home/jj/Desktop/semantic_search_engine/models/faiss_index.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jj/Desktop/home/jj/Desktop/semantic_search_engine/models/faiss_index.pickle'"
     ]
    }
   ],
   "source": [
    "# Define project base directory\n",
    "# Change the index from 1 to 0 if you run this on Google Colab\n",
    "project_dir = Path('notebooks').resolve().parents[1]\n",
    "print(project_dir)\n",
    "\n",
    "# Serialise index and store it as a pickle\n",
    "with open(f\"{project_dir}/home/jj/Desktop/semantic_search_engine/models/faiss_index.pickle\", \"wb\") as h:\n",
    "    pickle.dump(faiss.serialize_index(index), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2695fd99278845baabae54015c34fcdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dd7c083419142abafa3a3ae0313b3b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "499b0004f8b94f298fa6549f40cfdd47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c96682ee49574cf09a9484c380b88bcd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2dd7c083419142abafa3a3ae0313b3b7",
      "value": " 264/264 [02:12&lt;00:00,  1.99it/s]"
     }
    },
    "4cf7379a5fb74234863c8d6087fd874e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Batches: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e6b8fb59cdf41e4ba2249707b534652",
      "max": 264,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f747015d71364a72bfdc7fae052f1eb4",
      "value": 264
     }
    },
    "9e6b8fb59cdf41e4ba2249707b534652": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3207b1dba9b4a00b1ff35d9e1666b9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4cf7379a5fb74234863c8d6087fd874e",
       "IPY_MODEL_499b0004f8b94f298fa6549f40cfdd47"
      ],
      "layout": "IPY_MODEL_2695fd99278845baabae54015c34fcdc"
     }
    },
    "c96682ee49574cf09a9484c380b88bcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f747015d71364a72bfdc7fae052f1eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
